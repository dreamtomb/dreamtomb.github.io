<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>2023-12-19论文笔记</title>
      <link href="/posts/63715.html"/>
      <url>/posts/63715.html</url>
      
        <content type="html"><![CDATA[<h1 id="如何更加高效地训练有偏好的-LLMs"><a href="#如何更加高效地训练有偏好的-LLMs" class="headerlink" title="如何更加高效地训练有偏好的 LLMs"></a>如何更加高效地训练有偏好的 LLMs</h1><p>之前提到了三种改进 LLMs 对齐的方法：使用 AI 代替人类，优化微调数据以及优化训练流程。本周就这三个方向分别选出一篇代表性论文进行介绍（RLAIF、DPO、LIMA三篇论文之前分别进行过总结，因此本周介绍另外三篇）。</p><h2 id="方式一：使用AI替代人类——RRHF（Rank-Response-to-align-Human-Feedback）"><a href="#方式一：使用AI替代人类——RRHF（Rank-Response-to-align-Human-Feedback）" class="headerlink" title="方式一：使用AI替代人类——RRHF（Rank Response to align Human Feedback）"></a>方式一：使用AI替代人类——RRHF（<strong>R</strong>ank <strong>R</strong>esponse to align <strong>H</strong>uman <strong>F</strong>eedback）</h2><p><font color="red">底层思想：这一类方法使用AI模型来替换人工标注偏好数据，或者指导模型训练，代表工作——RLAIF。</font></p><h3 id="现有方法的缺陷"><a href="#现有方法的缺陷" class="headerlink" title="现有方法的缺陷"></a>现有方法的缺陷</h3><p>现有的方法是 openai 提出的 SFT —&gt; RM —&gt; PPO 流程。但是其中 PPO 算法对于超参数敏感，训练难以收敛，在训练中需要同时部署多个模型，让普通组织难以自己进行对齐，因此作者提出了新的对齐方法来替代原有的基于 RM 和 PPO 的方法。</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>该方法的核心思想是直接在 RM 数据上优化 LLMs，让产生被接受回答的概率大于被拒绝回答的概率。具体来说，首先从多种来源收集某个 prompt 的响应（模型本身，chatgpt，GPT-4，人为撰写等），在训练过程中，同样可以改变采样响应的来源，因为 RRHF 本身可以使用任何响应来展示人类的偏好，相比之下 PPO 算法就必须要使用自己产生的响应才行。接着基于对数概率对响应进行评分，然后通过排名损失来将这些分数与人类偏好奖励模型或人类偏好标签的分数进行匹配排序。其中对响应评分的公式、排名损失以及为了实践中的崩溃现象而加入的 SFT loss 的定义分别如下：</p><p><img src="/posts/63715/eq.png" alt="eq.png"></p><p><font color="red">值得注意的是在这里的评分中，作者注意到了回复的长度对评分的影响，因此使用了长度的归一化来尽量削弱这种影响。</font></p><p>下图中对比了 PPO 算法和 RRHF 算法的区别：</p><p><img src="/posts/63715/RRHF.png" alt="RRHF.png"></p><p>相比 SFT-&gt;RM-&gt;PPO 流程，RRHF的优点有以下几个方面：</p><ul><li>仅需要1到2个模型，而PPO需要4个模型，因此 RRHF 算法更加简单高效。</li><li>监督微调（SFT）可以被看作是 RRHF 算法的一种特殊形式——只有一个p。</li><li>RRHF 算法可以同时被用作语言模型和奖励模型，直接使用对数概率对响应进行评分则可以实现直接在 RM 数据上优化 LLMs，使用人类标注的分数则可以训练一个奖励模型。</li><li>RRHF 算法可以在较低的训练难度下拟合奖励模型的偏好，达到 PPO 算法的效果，并且避免了 PPO 算法中的复杂性和不稳定性问题。</li></ul><h3 id="方法效果"><a href="#方法效果" class="headerlink" title="方法效果"></a>方法效果</h3><p>在 Helpful and Harmless 数据集上的测试表明 RRHF 方法和 PPO 方法得到的模型的性能相近。</p><h2 id="方式二：优化微调数据——MAYBE-ONLY-0-5-DATA-IS-NEEDED"><a href="#方式二：优化微调数据——MAYBE-ONLY-0-5-DATA-IS-NEEDED" class="headerlink" title="方式二：优化微调数据——MAYBE ONLY 0.5% DATA IS NEEDED"></a>方式二：优化微调数据——MAYBE ONLY 0.5% DATA IS NEEDED</h2><p><font color="red">底层思想：该类方法的核心在于仅仅通过优质数据集的获取和产生，以训练得到一个效果较好的 SFT 模型，而无需进行 RM 和 PPO 的训练，代表工作——LIMA。</font></p><h3 id="工作的动机"><a href="#工作的动机" class="headerlink" title="工作的动机"></a>工作的动机</h3><p>现有的大模型都是基于无比庞大的数据进行训练的，就像是图像领域的 backbone 需要在 ImageNet 上进行大量预训练一样，各基座 LLMs 也都是在大规模无标注语料上进行的预训练，这已经极度费时费力费钱了，那么能否如同 CV 领域一样，将预训练交给有钱的大公司来做，后续的 SFT、instruction tuning 等阶段只使用相对少量的数据，让所有组织和个人都能够自行训练呢？这就是这篇论文试图实现的工作。</p><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><p>这篇工作关注的是特定任务的指令微调，因此主要是通过减少那些指令的多样性来实现 Low Training Data 。其核心思想是从现有数据中识别出最有价值、最有代表性的核心样本来帮助模型学习执行下游任务所需的知识，从而仅用少量数据就可以实现跟在全部数据上微调不相上下甚至更好的性能。</p><p>首先作者先简单介绍了 sft 和 instruction tuning 之间的区别，如下图所示：</p><p><img src="/posts/63715/difference.png" alt="difference.png"></p><p>方法流程下图所示，潜在空间用三个矩形表示，一个颜色系列代表一个任务。具有相同色系但不同色调的点，对应于来自同一任务但来自不同数据集的数据，如 NLI 任务有 5 个数据集，因此有 5 种不同的色调。主要分为以下几步：</p><ol><li>将每个句子编码成embedding向量，并进行均值池化和 L2 归一化的预处理。</li><li>在潜在空间中，将所有样本点聚类成几个类别。在这一步骤中，作者采用的是嵌入空间中的K-means无监督聚类算法（因为NLP任务本身具有任务边界模糊性，使用标签进行有监督训练不太好），通过这个算法获得每个样本和它对应的集群标签的映射。接着，作者考察一个下游任务的样本在几个集群中出现的频率，并选择出现频率最高的集群的中心点作为该下游任务的<font color="red">分布中心点</font>。然后计算该下游任务中所有样本跟该分布中心点的余弦相似度，并找到与中心点最相似的一个任务样本作为该下游任务的<font color="red">任务中心点</font>。（<strong>分布中心点是这个任务数据在嵌入空间的中心，可能并不存在于任务数据中，而任务中心点是一个来自这个任务数据与分布中心点余弦相似度最大的样本</strong>）</li><li>从这些聚类样本中进行采样，找到原始分布中的核心样本。在这一步骤中，作者采用了一种核心集算法——KCentergreedy，该算法的目标是选择K个中心点，然后让数据样本与中心点之间的最大距离最小化。具体来说，作者使用任务样本中心点作为初始中心，输入前面步骤中获得的任务样本的所有句子嵌入，找到距离中心点距离最大的样本作为第二中心点，以此类推，不断选择数据样本中距离中心点集最小距离最大的样本作为新的元素加入中心点集，直到达到目标的K个点。</li><li>使用这些检索到的样本来进行 instruction tuning。</li></ol><p><img src="/posts/63715/maybe.png" alt="maybe.png"></p><h3 id="方法效果-1"><a href="#方法效果-1" class="headerlink" title="方法效果"></a>方法效果</h3><p>对于特定任务的模型，使用该方法只需要使用不到 0.5% 的数据就可以实现 2% 的性能提升。</p><h2 id="方式三：优化训练流程——RAFT（Reward-rAnked-FineTuning）"><a href="#方式三：优化训练流程——RAFT（Reward-rAnked-FineTuning）" class="headerlink" title="方式三：优化训练流程——RAFT（Reward rAnked FineTuning）"></a>方式三：优化训练流程——RAFT（Reward rAnked FineTuning）</h2><p><font color="red">底层思想：该类方法通常通过改造模型的训练方式（如只保留 SFT 和 RM），以提高训练效率并减少训练成本，代表工作——DPO。</font></p><h3 id="现有方法的缺陷-1"><a href="#现有方法的缺陷-1" class="headerlink" title="现有方法的缺陷"></a>现有方法的缺陷</h3><p>现有的 LLMs 都需要在大规模无监督训练数据上进行预训练，这样就隐含了一个潜在的问题——这样的基座模型容易受到数据中隐含的偏见的影响，导致生成低质、失真的结果。因此对齐过程是必不可少的，但是现有的对齐过程通常采用强化学习方法，往往低效且训练不稳定。因此作者提出了 RAFT ，通过筛选出高质量样本进行训练来提高模型的性能。</p><h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><p>该算法的伪代码如下图所示，整个流程分为三个阶段：数据收集、数据排序、模型微调；这三个阶段可以单独实施和执行。 因此，只要计算资源和显存允许在某些特定模型上进行 SFT，对齐过程就可以使用 RAFT 完成。在数据收集阶段，需要从 prompt 集合中采样一批样本，然后对于每个 prompt，让大模型分别生成响应，并计算这些样本的 reward。在数据排序阶段，要对这些样本排序，并选择指定百分比的具有最高奖励的样本作为训练样本。最后，在模型微调阶段，要使用这些筛选过的样本对模型进行微调。</p><p><img src="/posts/63715/RAFT.png" alt="RAFT.png"></p><p>不难发现，在这个过程中，采样训练数据的过程和模型训练是完全解耦的；并且抽样过程不需要任何梯度计算，可以方便地进行采样训练期间计算资源和内存管理。更进一步地，RAFT的三个步骤，即数据收集、数据排序、模型微调，可以单独实施和执行。 因此，只要计算资源和显存允许在某些特定模型上进行 SFT，对齐过程可以使用 RAFT 完成，并且可以使用批量推理和模型并行来加速模型的训练。</p><h3 id="相比-PPO-算法的优势所在"><a href="#相比-PPO-算法的优势所在" class="headerlink" title="相比 PPO 算法的优势所在"></a>相比 PPO 算法的优势所在</h3><ul><li>RAFT 更像是 SFT 的训练，超参数更少且训练更稳定</li><li>降低了内存负担,因为数据生成和模型微调是脱离的</li><li>如果有奖励模型作为质量的评判者，那么该方法可以灵活地训练任意生成模型，包括 LLMs 和 sd 模型</li><li>该方法在优化的时候更看重对样本的偏好顺序，而非具体的奖励值，避免了模型通过一些技巧来欺骗奖励函数以获取更高的奖励的现象（这被称为奖励欺骗）。</li></ul>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2023-12-05论文笔记</title>
      <link href="/posts/62963.html"/>
      <url>/posts/62963.html</url>
      
        <content type="html"><![CDATA[<h1 id="关于-LLMs-中强化学习步骤里-PPO-算法的具体实现"><a href="#关于-LLMs-中强化学习步骤里-PPO-算法的具体实现" class="headerlink" title="关于 LLMs 中强化学习步骤里 PPO 算法的具体实现"></a>关于 LLMs 中强化学习步骤里 PPO 算法的具体实现</h1><h2 id="LLMs-场景下强化学习的整体流程"><a href="#LLMs-场景下强化学习的整体流程" class="headerlink" title="LLMs 场景下强化学习的整体流程"></a>LLMs 场景下强化学习的整体流程</h2><p>对于一般的强化学习而言，会有一个做动作的策略网络 $\pi$，它根据自己观测的状态 $s_i$，做出动作 $a_i$ 跟环境进行交互，然后环境会返回一个反馈 $r_i$，同时进入到下一个状态 $s_{i+1}$；策略网络再继续观测状态 $s_{i+1}$ 做出下一个动作 $a_{i+1}$ …直到达到最终状态。这样，策略网络和环境的一系列互动后最终会得到一个轨迹(trajectory)，一般在一个轨迹上训练完叫做一个episode:<br>$$<br>\tau&#x3D;{s_1,a_1,r_1,s_2,a_2,r_2,\cdots,s_T,a_T,r_T}<br>$$<br>在 LLMs 训练的场景下，策略网络就是待微调的 LLMs，它做的事情就是接受 context（状态），执行后返回一系列文本（或者只是文本上的概率分布）（动作）。该策略的动作空间是与语言模型的词汇表相对应的所有 tokens，观察空间是可能的输入token 序列的分布，该分布也十分巨大，奖励函数是偏好模型和policy shift 约束的结合。</p><h2 id="PPO-算法的具体实现"><a href="#PPO-算法的具体实现" class="headerlink" title="PPO 算法的具体实现"></a>PPO 算法的具体实现</h2><p>形象地来说，就像是学生和老师一样，老师出题，学生根据题目进行答题，老师判断学生回答的正确与否，然后学生根据评判结果重新修改自己对知识的理解。具体来说，LLMs 中 PPO 算法的大体流程如下（伪代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">policy_model = load_model()</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20000</span>):</span><br><span class="line">    <span class="comment"># 采样（生成答案）</span></span><br><span class="line">    prompts = sample_prompt()</span><br><span class="line">    data = respond(policy_model, prompts)</span><br><span class="line">    <span class="comment"># 反馈（计算奖励）</span></span><br><span class="line">    rewards = reward_func(reward_model, data)</span><br><span class="line">    <span class="comment"># 学习（更新参数）</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        policy_model = train(policy_model, prompts, data, rewards)</span><br></pre></td></tr></table></figure><p>接下来便分成这三个阶段对该算法的实现进行学习。</p><h3 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h3><p><strong>采样就是 LLMs 根据提示（prompt）输出回答（response）的过程，或者说是模型自行生产 RLHF 训练数据的过程。</strong></p><p>先明确一个概念——策略（policy），它就是 RLHF 中的“学生”，我们则扮演着老师的角色，给出有趣的问题，而模型则会像小学生一样，不断尝试给出答案。模型会对着黑板写下它的答案，有时候是正确的，有时候会有错误。我们会仔细检查每一个答案，如果它表现得好，就会给予它高声赞扬；如果它表现不佳，我们则会给予它耐心的指导和反馈，帮助它不断改进，直到达到令人满意的水平。</p><p>policy 由两个模型组成，一个叫做演员模型（Actor），另一个叫做评论家模型（Critic）。它们就像是学生大脑中的两种意识，一个负责决策，一个负责总结得失。其中演员就是我们想要训练出来的 LLMs。在用 PPO 训练它之前，它就是训练好的SFT（Supervised Fine-Tuning）model。输入一段上下文，它将输出下一个 token 的概率分布。评论家是强化学习的辅助模型，输入一段上下文，它将输出下一个 token 的“收益”，也就是从下一个 token 开始，模型能够获得的总奖励（浮点数标量）。从实现上说，评论家就是将演员模型的倒数第二层连接到一个新的全连接层上。除了这个全连接层之外，演员和评论家的参数都是共享的。</p><p><img src="/posts/62963/ac.png" alt="ac.png"></p><p>下图是 PPO 算法采样阶段的示意图，<strong>采样指的是 old_policy 从 prompt 池中抽出 M 个 prompt 后，对每个 prompt 进行语言模型生成的 token 采样</strong>：</p><ul><li>计算 response 的第1个 token 的概率分布，然后从概率分布中采样出第1个 token</li><li>根据第1个 token，计算 response 的第2个 token 的概率分布，然后从概率分布中采样出第2个 token</li><li>……</li><li>根据前 N-1 个 token，计算 response 的第 N 个 token 的概率分布，然后从概率分布中采样出第 N 个 token</li></ul><p>然后基于给定的 prompt，我们可以得到三个输出，假设对每个 prompt ，policy 生成的 token 的个数为 N，那么这三个输出分别是：</p><ul><li>response：M 个字符串，每个字符串包含 N 个 token</li><li>old_log_probs：演员输出的 $M\times N$ 的张量，包含了 response 中 token 的对数概率 $log⁡(P(token|context))$</li><li>old_values：评论家输出的 $M\times N$ 的张量，包含了每次生成 token 时评论家预估的收益</li></ul><p>得到这三个输出后，采样阶段就就结束了。这三个输出都是后续阶段重要的输入数据。至此，学生答题部分结束。</p><p><img src="/posts/62963/sample.png" alt="sample.png"></p><h3 id="反馈"><a href="#反馈" class="headerlink" title="反馈"></a>反馈</h3><p><strong>反馈就是老师检查答案的过程，是奖励模型（Reward Model）给 response 打分的过程。</strong>下图是 PPO 中 reward model 的使用方法：</p><p><img src="/posts/62963/reward.png" alt="reward.png"></p><p>从图中我们可以看出，左上角的绿色矩形 reward model 拿到 prompt 和 response，然后输出了分数 score。实际上发生的事情是，prompt 和 response 被拼接成一个字符串，接着被送入到 reward model 中，最后 reward model 计算出了匹配分数。显然，在图中，score 并不是最终的奖励，它和最终的奖励 rewards 之间还隔着一个 reward function 函数。<strong>这是因为score只能衡量结果的对错，不能衡量过程的合理性。怎么衡量过程的合理性呢？一种简单粗暴的方法是：循规蹈矩，即为合理。</strong></p><p>在一个已有的相对完备的理论系统中，突然出现一个与理论相矛盾的假说，那大家就有必要基于现有的经验给予适当的质疑。因为并非每一次对现有真理的质疑都是正确的（事实上大多数都是错误的），而如果这个假说真的得到验证，那么就是给予肯定和荣誉的时候了。<strong>语言模型也是一样，在我们给予最终奖励之前，最好也对它的“标新立异”给予少量的惩罚（即刚刚说的质疑）。</strong></p><p>那么我们该怎么做呢？那就是给它立一个规矩，只要它按照这个规矩来，就能获得少量奖励。而这个规矩就是我们在 SFT 阶段已经训练好的语言模型 ref_policy（图中右下角的绿色矩形），或者说是完全还没经过强化学习训练的语言模型。过程合理性奖励的计算方式是这样的：ref_policy 拿到 prompt，然后给 old_policy 生成的 response 的每个 token 计算对数概率，得到一个张量 ref_log_prob。现在假设 old_policy 的演员模型生成了第 i 个 token，此时它应该获得的奖励为 $ref\_log\_prob[i]-old\_log\_prob[i]$。来理解一下这个式子：</p><ul><li>ref_log_prob[i] 越高，ref_policy 越认可 old_policy 的输出，说明 old_policy 更守规矩，因此应该获得更高的奖励</li><li>old_log_prob[i] 越高，old_policy 获得的奖励反而更低，old_log_prob[i] 作为正则项，可以保证概率分布的多样性</li></ul><p><strong>最终，我们将过程合理性奖励和结果正确性奖励合并起来，就得到了最终奖励的计算方式：</strong><br>$$<br>\text{reward[i]}&#x3D;\begin{cases}\text{ref_}\log_\text{prob}[i]-\text{old_}\log_\text{prob}[i],&amp;i&lt;N\\text{ref_}\log_\text{prob}[N]-\text{old_}\log_\text{prob}[N]+\textit{score},&amp;i&#x3D;N\end{cases}<br>$$<br>值得指出的是，结果正确性奖励只有在最后一个 token 上才会使用，这就是上图中 reward function 的计算方法，此外，我们只对 response 计算奖励，在整个反馈阶段，reward_model 和 ref_policy 是不更新参数的。至此，老师反馈阶段结束。</p><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><p><strong>“学习”就是学生根据反馈总结得失并自我改进的过程，或者说是强化优势动作的过程。</strong></p><p>如果说前两步的采样和反馈分别是在收集数据X，以及给数据打上标签Y。那么这一步就是在利用数据(X, Y)训练模型。”强化优势动作”是PPO学习阶段的焦点。在深入探讨之前，我们首先要明确一个关键概念——优势。<strong>此处，我们将优势定义为“实际获得的收益超出预期的程度”。</strong></p><p>在 PPO 算法中计算优势的方法就是<strong>实际收益 - 预期收益</strong>。对于语言模型而言，生成第 i 个 token 的实际收益就是：从生成第 i 个 token 开始到生成第 N 个 token 为止，所能获得的所有奖励的总和。我们用 return 来表示实际收益，它的计算方式为：$return[i]&#x3D;\sum_{j&#x3D;i}^N reward[j]$ 。对于预期收益来说，我们在“采样”阶段提到过，policy 包含演员模型和评论家模型，其中后者是用来预估收益的。其实，当时说的收益 old_values 就是现在我们想要计算的预期收益。评论家会为 response 中的每个 token 计算一个预期收益，第 i 个预期收益记为 old_values[i]。现在，我们可以这样计算生成第 i 个 token 的优势 a 了：$a[i]&#x3D;return[i]-old\_values[i]$。接下来，我们就要使用优势 a 来进行“强化优势动作”的操作。</p><p><strong>所谓“强化优势动作”，即强化那些展现出显著优势的动作。</strong>在语言模型中，根据上下文生成一个 token 就是所谓的“动作”。”强化优势动作”表示：如果在上下文（context）中生成了某个 token，并且这个动作的优势很高，那么我们应该增加生成该 token 的概率，也就是说我们可以给演员模型设计一个损失函数，通过优化损失函数来实现“强化优势动作”的目的，这个损失函数定义如下：<br>$$<br>\text{actor_loss}&#x3D;-\dfrac{1}{N}\sum_{i&#x3D;1}^{N}a[i]\times\frac{p\text{(token[i] | context)}}{p_{old}\text{(token[i] | context)}}<br>$$<br>其中：</p><ul><li>当优势大于0时，概率越大，loss越小；因此优化器会通过增大概率（即强化优势动作）来减小loss</li><li>当优势小于0时，概率越小，loss越小；因此优化器会通过减小概率（即弱化劣势动作）来减小loss</li><li>PPO 中，每份数据在每次迭代的学习阶段中都会使用四次，P_old 指的是同一次迭代的还未进入学习阶段的演员模型，因为它不接收梯度回传，因此可以视为一个常量</li><li>分母的作用在于当生成某个 token 的概率已经很大了的时候，即便这个动作的优势很大，也不要再使劲增大概率了，也就是步子不要迈得太大</li><li>分子部分可以使用当前的演员模型计算得到，分母部分就是采样阶段的 old_log_probs</li></ul><p>上面描述的都是演员模型的优化，下面就要介绍评论家的优化了：</p><p>我们提到过，评论家会为 response 中的每个 token 计算一个预期收益 values[i]，估计的目标是奖励模型 reward[i] 的累加 return[i]，于是，很自然地，PPO 算法设计了一个损失函数来衡量评论家预期收益和真实收益之间的差距，这个损失函数就是均方差损失：<br>$$<br>\text{critic_loss}&#x3D;\frac{1}{2N}\sum_{i&#x3D;1}^{N}(\text{values}[i]-\text{return}[i])^2<br>$$<br>最终优化 policy 时用的 loss 是演员和评论家的 loss 的加权和：<br>$$<br>\text{loss}&#x3D;\text{actor_loss}+0.1\times\text{critic_loss}<br>$$<br>学习阶段的整体流程图如下所示：</p><p><img src="/posts/62963/learn.png" alt="learn.png"></p><h3 id="完整伪代码"><a href="#完整伪代码" class="headerlink" title="完整伪代码"></a>完整伪代码</h3><p>在梳理完全部流程之后我们便能补全最开始给出的伪代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">policy_model = load_model()</span><br><span class="line">ref_policy_model = policy_model.copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20000</span>):</span><br><span class="line">    <span class="comment"># 采样</span></span><br><span class="line">    prompts = sample_prompt()</span><br><span class="line">    responses, old_log_probs, old_values = respond(policy_model, prompts)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反馈</span></span><br><span class="line">    scores = reward_model(prompts, responses)</span><br><span class="line">    ref_log_probs, _ = analyze_responses(ref_policy_model, prompts, responses)</span><br><span class="line">    rewards = reward_func(reward_model, scores, old_log_probs, ref_log_probs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 学习</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        log_probs, values = analyze_responses(policy_model, prompts, responses)</span><br><span class="line">        advantages = advantage_func(rewards, old_values)</span><br><span class="line">        actor_loss = actor_loss_func(advantages, old_log_probs, log_probs)</span><br><span class="line">        critic_loss = critic_loss_func(rewards, values)</span><br><span class="line">        loss = actor_loss + <span class="number">0.1</span> * critic_loss</span><br><span class="line">        train(loss, policy_model.parameters())</span><br></pre></td></tr></table></figure><h2 id="如何更加高效地训练有偏好的-LLMs"><a href="#如何更加高效地训练有偏好的-LLMs" class="headerlink" title="如何更加高效地训练有偏好的 LLMs"></a>如何更加高效地训练有偏好的 LLMs</h2><p>前面总结了 RLHF 中 PPO 算法的具体实现，但是现有的强化学习算法却仍有一些不足：</p><ul><li>人工产生的偏好数据集成本较高，很难量产</li><li>三个阶段的训练（ SFT -&gt; RM -&gt; PPO ）过程较长，更新迭代较慢</li><li>PPO 的训练过程同时存在4个模型（2训练，2推理），对计算资源的要求较高。</li></ul><p>因此，当前的改进优化思路主要有以下几个方向：</p><h3 id="方式一：使用AI替代人类"><a href="#方式一：使用AI替代人类" class="headerlink" title="方式一：使用AI替代人类"></a>方式一：使用AI替代人类</h3><p>这一类方法使用AI模型来替换人工标注偏好数据，或者指导模型训练。</p><h4 id="RLAIF（RL-from-AI-Feedback）"><a href="#RLAIF（RL-from-AI-Feedback）" class="headerlink" title="RLAIF（RL from AI Feedback）"></a>RLAIF（RL from AI Feedback）</h4><p>该方法可分为<strong>监督训练阶段</strong>和<strong>强化学习阶</strong>段两部分。</p><ol><li><p><strong>监督训练阶段，</strong>此阶段包括以下步骤：</p><ol><li>获得 Helpful 模型对 red teaming提示的响应。 因此，在这些情况下，模型的响应可能是有害的。</li><li>在提供了一套应该遵守的原则，让 Helpful 模型据此评论自己的响应。</li><li>要求 Helpful 模型根据其提供的评论修改其先前的响应。</li><li>重复步骤 2 和 3 进行 n 次迭代。</li><li>针对来自所有有害提示的响应的所有修订版本微调预训练的 LLM，还包括有用的提示和响应的组合，以确保微调后的模型仍然有用，此模型即 <strong>Supervised Learning Constitutional AI (SL-CAI)</strong> 模型。</li></ol></li><li><p><strong>强化学习阶段，</strong>此阶段包括以下步骤：</p><ol><li>使用在上一步训练得到的 SL-CAI 模型生成针对有害提示的响应对。</li><li>使用具有一个原则和一对响应的反馈模型，去选择更无害的响应。</li><li>反馈模型的归一化对数概率用于训练偏好模型&#x2F;奖励模型。</li><li>最后，利用上一步训练的偏好模型作为奖励函数，以 RLHF 方式训练 SL-CAI 模型，得到 <strong>Reinforcement Learning Constitutional AI (RL-CAI)</strong> 模型。</li></ol></li></ol><p><img src="/posts/62963/RLAIF.png" alt="RLAIF.png"></p><h4 id="RRHF（Rank-Response-to-align-Human-Feedback）"><a href="#RRHF（Rank-Response-to-align-Human-Feedback）" class="headerlink" title="RRHF（Rank Response to align Human Feedback）"></a>RRHF（<strong>R</strong>ank <strong>R</strong>esponse to align <strong>H</strong>uman <strong>F</strong>eedback）</h4><p>该方法首先从多种来源收集某个 prompt 的响应（模型，chatgpt，人为撰写等），接着基于对数概率对响应进行评分，然后通过排名损失来讲这些分数与人类偏好奖励模型或人类偏好标签的分数进行匹配排序。下图中对比了 PPO 算法和 RRHF 算法的区别：</p><p><img src="/posts/62963/RRHF.png" alt="RRHF.png"></p><p>相比 PPO 算法，RRHF的优点有以下几个方面：</p><ul><li>仅需要1到2个模型，而PPO需要4个模型，因此 RRHF 算法更加简单高效。</li><li>监督微调（SFT）可以被看作是 RRHF 算法的一种特殊形式。</li><li>RRHF 算法可以同时被用作语言模型和奖励模型。</li><li>RRHF 算法可以在较低的训练难度下拟合奖励模型的偏好，达到 PPO 算法的效果，并且避免了 PPO 算法中的复杂性和不稳定性问题。</li></ul><h3 id="方式二：优化微调数据"><a href="#方式二：优化微调数据" class="headerlink" title="方式二：优化微调数据"></a>方式二：优化微调数据</h3><p>该类方法的核心在于仅仅通过优质数据集的获取和产生，以训练得到一个效果较好的 SFT 模型，而无需进行 RM 和 PPO 的训练。</p><h4 id="LIMA（Less-Is-More-for-Alignment）"><a href="#LIMA（Less-Is-More-for-Alignment）" class="headerlink" title="LIMA（Less Is More for Alignment）"></a>LIMA（Less Is More for Alignment）</h4><p>浅层对齐假说，即一<strong>个模型的知识和能力几乎完全是在预训练中学习的，而对齐则是教会它与用户交互时如何选择子分布</strong>。如果假说正确，对齐主要有关于学习方式，那么该假说的一个推论是，人们可以用相当少的样本充分调整预训练的语言模型。因此，<strong>该工作假设，对齐可以是一个简单的过程，模型学习与用户互动的风格或格式，以揭示在预训练中已经获得的知识和能力。</strong>消融实验显示，<strong>当扩大数据量而不同时扩大提示多样性时，收益会大大减少，而在优化数据质量时，收益会大大增加。</strong> 此外，尽管没有对话实例，LIMA可以进行连贯的多轮对话，而且这种能力可以通过向训练集添加30条手工制作的多轮对话数据而得到极大的提高。</p><h4 id="MAYBE-ONLY-0-5-DATA-IS-NEEDED"><a href="#MAYBE-ONLY-0-5-DATA-IS-NEEDED" class="headerlink" title="MAYBE ONLY 0.5% DATA IS NEEDED"></a>MAYBE ONLY 0.5% DATA IS NEEDED</h4><p>这篇工作的目的是通过从现有数据中识别出最有价值的核心样本来帮助模型获取下游任务的知识，并仅用少量数据来实现不相上下甚至更好的性能。</p><p>方法流程下图所示，潜在空间用三个矩形表示，每个任务代表其中一个颜色系列。具有相同色系但不同色调的点，对应于来自同一任务但来自不同数据集的数据，如 NLI 任务有 5 个数据集，因此有 5 种不同的色调。主要分为以下几步：</p><ol><li>将每个句子编码成embedding向量，并进行均值池化和 L2 归一化的预处理。</li><li>在潜在空间中，将所有样本点聚类成几个类别。</li><li>从这些聚类样本中进行采样，找到原始分布中的核心样本。</li><li>使用这些检索到的样本来指导微调 LLM 并进行评估。</li></ol><p><img src="/posts/62963/maybe.png" alt="maybe.png"></p><h3 id="方式三：优化训练流程"><a href="#方式三：优化训练流程" class="headerlink" title="方式三：优化训练流程"></a>方式三：优化训练流程</h3><p>该类方法通常通过改造模型的训练方式（如只保留 SFT 和 RM），以提高训练效率并减少训练成本。</p><h4 id="RAFT（Reward-rAnked-FineTuning）"><a href="#RAFT（Reward-rAnked-FineTuning）" class="headerlink" title="RAFT（Reward rAnked FineTuning）"></a>RAFT（Reward rAnked FineTuning）</h4><p>该算法的伪代码如下图所示，整个流程分为三个阶段：数据收集、数据排序、模型微调；这三个阶段可以单独实施和执行。 因此，只要计算资源和显存允许在某些特定模型上进行 SFT，对齐过程就可以使用 RAFT 完成。在数据收集阶段，需要从 prompt 集合中采样一批样本，然后对于每个 prompt，让大模型分别生成响应，并计算这些样本的 reward。在数据排序阶段，要对这些样本排序，并选择指定百分比的具有最高奖励的样本作为训练样本。最后，在模型微调阶段，要使用这些筛选过的样本对模型进行微调。</p><p><img src="/posts/62963/RAFT.png" alt="RAFT.png"></p><h4 id="DPO（Direct-Preference-Optimization）"><a href="#DPO（Direct-Preference-Optimization）" class="headerlink" title="DPO（Direct Preference Optimization）"></a>DPO（Direct Preference Optimization）</h4><p>该方法提出了一种使用二进制交叉熵目标来精确优化LLM的方法，以替代基于 RL HF 的优化目标，从而大大简化偏好学习 pipeline。也就是说，完全可以直接优化语言模型以实现人类的偏好，而不需要明确的奖励模型或强化学习。</p><p>与现有的算法一样，DPO 也依赖于理论上的偏好模型（如 Bradley-Terry 模型），以此衡量给定的奖励函数与经验偏好数据的吻合程度。然而，现有的方法使用偏好模型定义偏好损失来训练奖励模型，然后训练优化所学奖励模型的策略，而 DPO 使用变量的变化来直接定义偏好损失作为策略的一个函数。鉴于人类对模型响应的偏好数据集，DPO 因此可以使用一个简单的二进制交叉熵目标来优化策略，而不需要明确地学习奖励函数或在训练期间从策略中采样。</p><p><img src="/posts/62963/DPO.png" alt="DPO.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2023-11-21论文笔记</title>
      <link href="/posts/17086.html"/>
      <url>/posts/17086.html</url>
      
        <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>最近面试的时候被问到了大模型压缩技术的相关问题，本人对此并无什么了解，因此阅读几篇相关论文进行初步了解。</p><h1 id="常用的大模型压缩技术"><a href="#常用的大模型压缩技术" class="headerlink" title="常用的大模型压缩技术"></a>常用的大模型压缩技术</h1><p>常用的大模型压缩技术可以被整理为下图：</p><p><img src="/posts/17086/taxonomy.png" alt="taxonomy.png"></p><h2 id="剪枝（Pruning）"><a href="#剪枝（Pruning）" class="headerlink" title="剪枝（Pruning）"></a>剪枝（Pruning）</h2><p>剪枝是一种强大的技术，类似于给模型“减肥”，通过去掉一些不必要或多余的部分，以降低模型的大小和复杂性。我们可以把这些多余的东西想象成模型的“赘肉”，它们对模型性能几乎没有影响，反而占用了很大的内存和计算量。因此，我们可以直接去掉这些赘肉，在模型的性能几乎不受影响的同时提高模型的存储效率、内存利用率和计算效率。</p><p>剪枝有两种主要类型：结构化剪枝和非结构化剪枝。前者以一整组的形式去剪枝，比如说直接剪去整个神经元、通道或层。这种方式的好处在于能够降低模型的复杂性和内存占用，但同时整体的模型结构仍然得以保持。这就好比在修剪花园中的某一排树木之后，花园整体轮廓和结构依然清晰、整齐；后者则是以更细粒度的方式进行，它直接瞄准个别权重或神经元，就像单独修剪花园中的某几棵树木，虽然也减少了冗余，但是花园整体会有些凌乱，这样的方法可能导致模型变得稀疏却不规则，需要特殊的压缩技术来高效存储和计算，并且通常需要对LLM进行大量的重新训练以恢复其准确性。</p><h2 id="知识蒸馏（Knowledge-Distillation）"><a href="#知识蒸馏（Knowledge-Distillation）" class="headerlink" title="知识蒸馏（Knowledge Distillation）"></a>知识蒸馏（Knowledge Distillation）</h2><p>知识蒸馏是一项很棒的技术，旨在提升模型性能和泛化能力。其核心思想是将来自一个复杂模型（称为“教师模型”）的知识传递给一个更简单的模型（称为“学生模型”）。</p><p>知识蒸馏方法可以被分为两个类别：黑盒知识蒸馏和白盒知识蒸馏。在黑盒知识蒸馏中，学生 LLM 只能获取到教师模型的预测结果，却无法了解教师模型的具体参数和内部结构，这就好比我们只知道某人的答案，但对于他是如何得出这个答案的一无所知，黑盒知识蒸馏注重于结果的传递，尽管无法提供深入的内在机制，但它在许多实际场景中仍然是一种有效的知识传递方式；而在白盒知识蒸馏中，学生 LLM 不仅可以获取到教师模型的预测结果，还可以访问和利用教师模型的参数信息，这就像是我们对教师的了解不仅限于他的答案，还包括他是如何思考的，为什么会给出这样的答案，这种方法允许学生模型更深入地理解教师模型的内在结构和决策过程，通常会带来更大的性能提升。</p><h2 id="量化（Quantization）"><a href="#量化（Quantization）" class="headerlink" title="量化（Quantization）"></a>量化（Quantization）</h2><p>在模型压缩领域，量化技术被用于减少深度学习模型的存储和计算开销。传统的表示方法采用浮点数，而量化将其转换为整数或其他离散形式，这一转变显著降低了存储需求和计算复杂性。尽管存在一定的精度损失，但通过谨慎地选择量化技术，可以在只有最小精度下降的情况下实现最大幅度的模型压缩。</p><p>量化主要分为三种方法：量化感知训练（Quantization-Aware Training，QAT）、量化感知微调（Quantization-Aware Fine-tuning，QAF）和训练后量化（Post-Training Quantization，PTQ）。这些方法的主要区别在于何时应用量化来压缩模型。在量化感知训练中，量化的目标被无缝地整合到模型的训练过程中，这就像是模型在学习的同时就已经“知道”了后续会面对的量化挑战，通过在训练期间考虑量化，模型能够适应低精度表示，从而在后续的量化过程中更好地保持性能。量化感知微调是在模型已经完成训练后，专门为量化而进行的微调过程，这就是在模型已经具备一定知识的情况下，再对其进行细致的调整，以适应量化所带来的变化，这种方法更灵活，可以在模型训练完成后根据具体需求进行精细调整。相比之下，训练后量化是一种更为简单而高效的压缩方法，在训练完成后，模型的参数被量化，无需对模型进行进一步的训练或微调，尽管这种方法简单，但由于量化过程可能引入一定的精度损失，需要权衡压缩效果和性能损失。</p><h2 id="低秩分解（Low-Rank-Factorization）"><a href="#低秩分解（Low-Rank-Factorization）" class="headerlink" title="低秩分解（Low-Rank Factorization）"></a>低秩分解（Low-Rank Factorization）</h2><p>低秩分解旨在通过将给定的权重矩阵分解成两个或多个较小维度的矩阵，从而对其进行近似。低秩分解背后的核心思想是找到一个大的权重矩阵W的分解，得到两个矩阵U和V，使得W≈U V，其中U是一个m×k矩阵，V是一个k×n矩阵，其中k远小于m和n，U和V的乘积近似于原始的权重矩阵，这样便大幅减少了参数数量和计算开销。在 LLM 研究的模型压缩领域，研究人员通常将多种技术与低秩分解相结合，包括剪枝、量化等在实现更有效的压缩同时保持模型的性能尽量不降低。</p><h1 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h1><h2 id="SHEARED-LLAMA-ACCELERATING-LANGUAGE-MODEL-PRE-TRAINING-VIA-STRUCTURED-PRUNING"><a href="#SHEARED-LLAMA-ACCELERATING-LANGUAGE-MODEL-PRE-TRAINING-VIA-STRUCTURED-PRUNING" class="headerlink" title="SHEARED LLAMA: ACCELERATING LANGUAGE MODEL PRE-TRAINING VIA STRUCTURED PRUNING"></a>SHEARED LLAMA: ACCELERATING LANGUAGE MODEL PRE-TRAINING VIA STRUCTURED PRUNING</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>虽然已经有了很多降低大模型训练成本的技术，但是训练大模型的代价仍然十分高昂，普通人难以承受。因此，作者希望使用剪枝技术来从已有的预训练大模型中生成一个小一些的 LLM，但是这面临着两个挑战：<strong>如何确定最终的性能强大、推理高效的剪枝结构</strong>——LLM 目前的结构化剪枝技术没有指定的目标结构，导致剪枝后模型在性能和推理速度方面不理想；以及<strong>如何继续预训练剪枝后的模型以达到预期性能</strong>——与从头开始训练模型相比，使用原始预训练数据来训练会导致不同域出现不同的损失减少率。</p><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><p>首先需要说明的是，给定一个现有的大模型，希望通过剪枝技术生成一个更小但是性能更强的模型，作者设计了一个两阶段的范式：第一阶段将原模型剪枝为一个小模型，成功地减少了参数数量，但不可避免地导致性能下降；因此第二阶段持续预训练小模型，使其性能更强。</p><p>整体来说，作者使用了两个关键技术：定向结构化剪枝以及动态批加载。前者将剪枝看成一种约束优化问题，通过端到端的方式移除特定的层，头以及隐藏维度等等来将模型压缩到目标结构，后者根据模型在不同域数据上的损失下降速率动态调整每个域的数据所占比例，提高数据使用效率。</p><h4 id="定向结构化剪枝"><a href="#定向结构化剪枝" class="headerlink" title="定向结构化剪枝"></a>定向结构化剪枝</h4><p>作者利用现有预训练模型的配置作为目标架构，例如当生成一个2.7B模型时，作者使用INCITE-Base-3B架构作为目标架构。具体来说，该方法将剪枝问题建模为一个约束优化问题，通过学习剪枝掩码来搜索一个与预先指定的目标架构匹配的子网络，同时最大化性能——在不同粒度的模型参数上学习一组剪枝掩码（例如粗粒度上的层、隐藏维度以及细粒度上的注意力头的数目、中间维度），每个掩码变量控制是否剪枝或保留相关的子结构，然后将剪枝掩码和模型权重一起进行优化。例如，如果某层对应的层掩码为0，则需要删除这个层。剪枝之后，再通过保留与每个子结构中的掩码变量相关的最高得分组件来最终确定剪枝后的架构，并继续使用语言建模目标对剪枝后的模型进行预训练。下图说明了剪枝掩码如何控制被剪枝的结构。</p><p><img src="/posts/17086/TSP.png" alt="TSP.png"></p><h4 id="动态批加载"><a href="#动态批加载" class="headerlink" title="动态批加载"></a>动态批加载</h4><p>作者认为对剪枝后的模型进行大量预训练是很有必要的，这样才能恢复模型性能，但是作者发现在原有的预训练数据集上继续进行预训练相比原版的 llama 模型在不同的域数据上损失的降低速度不同，这说明对数据的利用效率较低。因此作者提出了动态批加载方法来根据真实loss和参考loss之间的差值调整各域数据在一次采样中所占的比例来解决这个问题，算法如下图所示：</p><p><img src="/posts/17086/DBL.png" alt="DBL.png"></p><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p><img src="/posts/17086/res1.png" alt="res1.png"></p><p><img src="/posts/17086/res2.png" alt="res2.png"></p><p><img src="/posts/17086/res3.png" alt="res3.png"></p><h2 id="Distilling-Step-by-Step-Outperforming-Larger-Language-Models-with-Less-Training-Data-and-Smaller-Model-Sizes"><a href="#Distilling-Step-by-Step-Outperforming-Larger-Language-Models-with-Less-Training-Data-and-Smaller-Model-Sizes" class="headerlink" title="Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"></a>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</h2><h3 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h3><p>大语言模型不易于部署，因为它们需要很大的显存以及大量的计算，因此在现实应用中，人们往往通过使用<strong>人工标签微调</strong>或者使用<strong>LLM生成的标签进行蒸馏</strong>来得到更小的任务特定的语言模型。但是一个现实的问题是无论是微调还是蒸馏都需要大量数据才能尽量保证小模型的性能不会骤降。</p><h3 id="工作-1"><a href="#工作-1" class="headerlink" title="工作"></a>工作</h3><p>作者提出了 <strong>Distilling step-by-step</strong> 方法，使得小模型的性能超过了原本的 LLM，并且只需要比微调或者蒸馏更少的训练数据。这个机制的核心观点是：<font color="red">不再将 LLMs 是做带有噪声的标签的来源，而是将其视为可以进行推理的 agent：LLMs 可以生成自然语言解释，用于证明它们产生的预测结果</font>。实现的核心是：<font color="red">利用教师 LLMs 生成的解释作为额外信息，通过多任务训练机制，同时进行标签预测和解释预测，以此训练学生 LLMs</font>。该方法分为两个阶段——使用 CoT 从 LLMs 中提取解释以及使用多任务学习方法训练学生模型，其整体示意图如下图所示：</p><p><img src="/posts/17086/overview.png" alt="overview.png"></p><h4 id="从-LLMs-中提取解释"><a href="#从-LLMs-中提取解释" class="headerlink" title="从 LLMs 中提取解释"></a>从 LLMs 中提取解释</h4><p>在这一阶段中，作者使用了基于 few-shot CoT 的 prompt 来获得大模型对于预测的推理解释，如下图所示：</p><p><img src="/posts/17086/CoT.png" alt="CoT.png"></p><h4 id="多任务学习训练学生模型"><a href="#多任务学习训练学生模型" class="headerlink" title="多任务学习训练学生模型"></a>多任务学习训练学生模型</h4><p>作者使用多任务学习方法，让模型根据输入分别输出预测和解释，并设计了总体损失函数：$\mathbb{L}&#x3D;\mathbb{L}_{label}+\lambda\mathbb{L}_{rationale}$，在测试时可以只让模型输入预测结果，不输出解释，以加快推理。</p><p>在训练过程中，为了让模型知道什么时候输出预测标签，什么时候输出具体解释，作者会将 [label] 和 [rationale] 分别插入到输入的前面来加以区分。</p><h3 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h3><p>微调的 770M 的 T5 模型比使用 few-shot 的 540B 的PaLM模型效果更好，而且只使用了其 80% 的微调数据。更多实验结果如下图所示：</p><p><img src="/posts/17086/results.png" alt="results.png"></p><p><img src="/posts/17086/results2.png" alt="results2.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2023-11-7论文笔记</title>
      <link href="/posts/35052.html"/>
      <url>/posts/35052.html</url>
      
        <content type="html"><![CDATA[<h1 id="2023-11-7论文笔记"><a href="#2023-11-7论文笔记" class="headerlink" title="2023-11-7论文笔记"></a>2023-11-7论文笔记</h1><h2 id="BRANCH-SOLVE-MERGE-IMPROVES-LARGE-LANGUAGE-MODEL-EVALUATION-AND-GENERATION"><a href="#BRANCH-SOLVE-MERGE-IMPROVES-LARGE-LANGUAGE-MODEL-EVALUATION-AND-GENERATION" class="headerlink" title="BRANCH-SOLVE-MERGE IMPROVES LARGE LANGUAGE MODEL EVALUATION AND GENERATION"></a>BRANCH-SOLVE-MERGE IMPROVES LARGE LANGUAGE MODEL EVALUATION AND GENERATION</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>现有的 LLMs 缺乏自一致性，并且不擅长分解并规划复杂的多约束问题。</p><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><p>作者提出了 Branch-Solve-Merge（BSM）——一种用于处理 multi-faceted 自然语言任务的分解方法，也是Large Language Model program（将LLMs嵌入到算法或程序中）的一个实例。具体来说，给定任意一个任务，branch模块通过将任务分解为多个并行的子任务来生成解决方案，其中每个子任务由一个唯一的分支表示，代表解决整体问题所需的不同组件，然后使用solve模块解决这些相互独立的子问题，最后使用merge模块将这些子问题的解决方案融合在一起，得到最终的整体解决方案。</p><p>作者在LLMs评估和约束文本生成这两个任务上进行了实验，示例如下图所示：</p><p><img src="/posts/35052/BSM.png" alt="BSM.png"></p><p><img src="/posts/35052/BSM2.png" alt="BSM2.png"></p><p>整体的算法流程图如下图所示：</p><p><img src="/posts/35052/algorithm.png" alt="algorithm.png"></p><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>在LLM评估任务上，使用的指标有LLM-Human Agreement (Ag)、Position Bias (PB)、Length Bias (LB)、Self-enhancement Bias (SB)，这四个指标分别关注了LLM和人类的一致程度，响应对顺序对评估的影响程度，人类更喜欢较短回应但评估器模型不喜欢的样本比例，以及LLM评估器是否更偏好自己生成的响应，实验结果如下图所示：</p><p><img src="/posts/35052/res1.png" alt="res1.png"></p><p>在约束生成任务上，使用的指标有All Present和Missing Concepts，分别关注了对于约束的满足以及对于关键词的缺失，实验结果如下图所示：</p><p><img src="/posts/35052/res2.png" alt="res2.png"></p><h2 id="SELF-RAG-LEARNING-TO-RETRIEVE-GENERATE-AND-CRITIQUE-THROUGH-SELF-REFLECTION"><a href="#SELF-RAG-LEARNING-TO-RETRIEVE-GENERATE-AND-CRITIQUE-THROUGH-SELF-REFLECTION" class="headerlink" title="SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"></a>SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION</h2><h3 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h3><p>除了雪球式幻觉外，由于知识不足而导致的幻觉也比较常见。</p><h3 id="工作-1"><a href="#工作-1" class="headerlink" title="工作"></a>工作</h3><p>作者提出了一种新的框架，称为自反思的检索增强生成(SELF-RAG)，它通过检索和自我反思来提高语言模型生成结果的质量并增强其事实性。这个框架训练单个的LM，并根据需要自适应地检索段落，然后使用特殊标记(称为反思标记)对检索到的段落及自己的生成进行反思。生成反思标记使LM在推理阶段可控，使其能够根据不同的任务需求调整自己的行为。SELF-RAG的整体流程如下图所示：</p><p><img src="/posts/35052/selfrag.png" alt="selfrag.png"></p><h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h4><p>具体的推理步骤如下图所示，对于一个输入，首先让LM输出一个检索token，用于判断是否需要进行检索，如果无需检索，那么直接使用LM进行输出即可，如果需要检索，那么就进行检索即可，通过调整自定义的阈值的大小，可以让LM适应于不同的任务，比如医疗诊断可以将阈值设置的低一些，尽量多进行检索，自由撰写任务则将检索设置的高一些，尽量靠模型自我发挥。接着，让LM预测一个相关性token来评估检索到的段落是否与问题相关，根据检索结果生成响应后再预测支持性token和有用性token，分别评估响应中的信息能否被检索结果支持以及响应整体是否对于问题有帮助。最后根据相关性token、支持性token以及有用性token来对并行输出的结果进行选择。值得注意的有两点：首先，作者采用了beam search方法在每个步中维护多个生成结果，其次，根据三种token可以实现灵活的响应选择方式，例如可以使用硬性阈值筛选掉相关性token为False的内容，也可以使用软约束，根据有用性token进行排名，留下最有用的响应。</p><p><img src="/posts/35052/reflection.png" alt="reflection.png"></p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>训练阶段需要提及的有三点：数据、生成模型M以及评判模型C。</p><p><strong>对于数据。</strong>作者使用GPT-4生成反思tokens，数量为4k-20k不等，然后使用这些数据将知识蒸馏进评判模型C之中。</p><p><strong>对于评判模型C。</strong>使用跟生成模型M相同基座模型的LM进行初始化，然后使用上述数据进行训练，得到可以输出反思tokens的模型。</p><p><strong>对于生成模型M。</strong>在训练语料中使用评判模型插入反思标记来更新训练语料，然后重新训练生成器模型M。</p><p><img src="/posts/35052/train.png" alt="train.png"></p><h3 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h3><p>实验结果如下图所示：</p><p><img src="/posts/35052/res3.png" alt="res3.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2023-10-10论文笔记</title>
      <link href="/posts/20606.html"/>
      <url>/posts/20606.html</url>
      
        <content type="html"><![CDATA[<h1 id="Contrastive-Decoding-Open-ended-Text-Generation-as-Optimization"><a href="#Contrastive-Decoding-Open-ended-Text-Generation-as-Optimization" class="headerlink" title="Contrastive Decoding: Open-ended Text Generation as Optimization"></a>Contrastive Decoding: Open-ended Text Generation as Optimization</h1><p><img src="/posts/20606/CD.png" alt="CD.png"></p><h2 id="想要解决的问题"><a href="#想要解决的问题" class="headerlink" title="想要解决的问题"></a>想要解决的问题</h2><p>大语言模型存在的生成内容无关、重复、不连贯等问题。</p><h2 id="灵感来源"><a href="#灵感来源" class="headerlink" title="灵感来源"></a>灵感来源</h2><p>大语言模型的种种问题在更小的 LMs 上更为明显。</p><h2 id="使用的方法"><a href="#使用的方法" class="headerlink" title="使用的方法"></a>使用的方法</h2><ol><li>首先需要分别加载好两个 LM ，一个是大语言模型（例如 OPT-13B ），叫做 expert ，一个是小语言模型（例如 OPT-125M ），叫做 amateur 。并分别使用这两个模型对下一个 token 进行预测。</li><li>考虑到合理性约束的问题，需要将 token 的搜索空间限制在 expert 预测的概率高于某个阈值的子集中。</li><li>接着对该空间之中的每个 token 进行搜索，目标是最大化 expert 对数概率和 amateur 对数概率之间的差异。</li></ol><h2 id="方法效果"><a href="#方法效果" class="headerlink" title="方法效果"></a>方法效果</h2><h1 id="How-Language-Model-Hallucinations-Can-Snowball"><a href="#How-Language-Model-Hallucinations-Can-Snowball" class="headerlink" title="How Language Model Hallucinations Can Snowball"></a>How Language Model Hallucinations Can Snowball</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在之前的论文阅读中，我们主要关注的是那些由于知识的鸿沟而导致的幻觉现象，这篇论文关注的却是来源于其他的幻觉现象。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在现实应用中，LLMs的主要风险在于它们倾向于产生不正确的陈述，也就是我们所说的幻觉现象。这种生成错误内容的情况通常被认为是因为语言模型自己知识有限所致。但是这篇文章的作者提出了一个假设，那就是在某些情况下，当语言模型试图为自己先前生成的错误内容进行解释或者辩解时，它会产生一些明显错误的说法，而这些错误它本身具有能力认出来。也就是说，有时候语言模型生成错误内容不是因为知识缺乏，而是它在为自己的错误找理由的时候，刻意产生了容易识别为错误的说法。</p><p>作者将“语言模型过度依赖于早期的错误，导致出现更多原本不会犯下的错误“的现象称为“幻觉雪球式增长“。</p><h2 id="本文的工作"><a href="#本文的工作" class="headerlink" title="本文的工作"></a>本文的工作</h2><h3 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h3><p>首先作者对发现的“幻觉雪球式增长“现象进行了测试，发现这种为了跟之前产生的幻觉保持一致性而生成的辩护内容往往会在单独进行测试的时候被判别为假，如下图所示：</p><p><img src="/posts/20606/snowball.png" alt="snowball.png"></p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>作者构造了三个数据集，分别包含了原始问题和独立的验证问题，如下图所示：</p><p><img src="/posts/20606/Dataset.png" alt="Dataset.png"></p><h3 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h3><p>有两点是值得我们注意的：</p><ol><li>通常来说，LLMs的回答由两部分组成：结论以及后续对结论的解释。在三个数据集的实验中，作者发现GPT-4和ChatGPT会立即确定问题的答案，此外，一旦语言模型生成了Yes或No，该词汇将保留在上下文中，并且为了保持一致性，在后续的解释中LLMs会坚持这一选择。</li><li>一些理论工作（William Merrill and Ashish Sabharwal. 2023. The parallelism tradeoff: Limitations of log-precision transformers）证明了Transformer无法在单个时间步内解决素数判别或图连接等等具有潜在顺序推理的问题。因此，要求Transformer在单个时间步内解决需要多个时间步才能正确回答的问题，势必会导致LLMs在有时给出一个不正确的答案。</li></ol><p>作者认为，这两点都会导致语言模型产生它本不会生成的支持错误事实的幻觉。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>经过实验，作者发现在这三个数据集中，绝大多数的幻觉都属于“雪球式幻觉”，如下图所示：</p><p><img src="/posts/20606/percent.png" alt="percent.png"></p><h2 id="如何预防雪球式幻觉"><a href="#如何预防雪球式幻觉" class="headerlink" title="如何预防雪球式幻觉"></a>如何预防雪球式幻觉</h2><p>关于如何预防雪球式幻觉，作者提出了两种方法：prompting 和 decoding or training methods。</p><h3 id="prompting"><a href="#prompting" class="headerlink" title="prompting"></a>prompting</h3><p>无需赘述，就是通过设计prompt鼓励模型在答案之前生成推理链来实现更好的效果。但是如以往的工作（Kushal Arora， Layla El Asri， Hareesh Bahuleyan， and Jackie Cheung. 2022. Why exposure bias matters: An imitation learning perspective of error accumulation in language generation.）中提到的那样，在LLMs中一个错误往往会触发更多的错误，于是作者通过实验发现这种方法并不十分有效，因此又开发了第二类方法——算法修正。</p><h3 id="decoding-or-training-methods"><a href="#decoding-or-training-methods" class="headerlink" title="decoding or training methods"></a>decoding or training methods</h3><ol><li>beam search。前面提到过，一旦模型生成了一些确认答案的词汇，它们就会保留在上下文中并影响后续的生成。因此，缓解雪球式幻觉的一个潜在方法就是beam search，具体来说就是在decoding过程中的每个时间步都维护一个高概率序列束，而不是单个序列。在下一时间步，对当前beam中的每个序列候选分别生成新的词，并计算新的序列概率，并再次保留具有top-k高概率的新序列束进入下一个时间步，依此类推。其目的应该是缓解初始答案出错导致的雪球式幻觉。</li><li>学习策略。前面是解码阶段的缓解方法，训练阶段也有自己的缓解方法——在生成答案之前，让模型产生推理链或者在backtracking data上进行微调（指的是先给出一个问题，再给出一个错误的解决方案，然后在给出正确的解决方案之前添加“抱歉，那是不正确的”之类的短语；其目的应该是为了缓解曝光偏差导致的雪球式幻觉——在训练过程中，语言模型只接触到金标准历史，但在推理过程中，上下文中包含可能有错的以往的预测）。</li></ol><h1 id="Chain-of-Verification-Reduces-Hallucination-in-Large-Language-Models"><a href="#Chain-of-Verification-Reduces-Hallucination-in-Large-Language-Models" class="headerlink" title="Chain-of-Verification Reduces Hallucination in Large Language Models"></a>Chain-of-Verification Reduces Hallucination in Large Language Models</h1><h2 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h2><ol><li>在长文本生成任务中，幻觉的一个来源就是曝光偏差。</li><li>独立地验证问题比在上下文中进行验证更加准确。</li><li>注意到自己生成内容中存在幻觉的模型,往往会重复这些幻觉，而不是改正它。</li></ol><h2 id="本文的工作-1"><a href="#本文的工作-1" class="headerlink" title="本文的工作"></a>本文的工作</h2><p>Chain-of-Verification (COVE)的流程大致如下：</p><ol><li>给定问题，让LLMs生成一个初始的响应。</li><li>给定问题和初始响应，让LLMs设计一系列的验证问题来对初始响应进行自我检查。</li><li>独立地回答这些验证问题，然后检查初始响应和验证回答之间的一致性。</li><li>根据找出的不一致性和之前的内容，生成最终的响应。</li></ol><p>简单的示例如下图所示：</p><p><img src="/posts/20606/CoVe.png" alt="CoVe.png"></p><p>在这四个步骤中，第1、2、4步都是可以通过单个prompt实现的，第三步作者则是设计了四种变体：联合式，两步式，分解式（这一步其实可以使用工具，如搜索引擎或外部文档等等，但是作者只使用了LLMs本身），分解修正式。</p><h3 id="联合式"><a href="#联合式" class="headerlink" title="联合式"></a>联合式</h3><p>第2、3步是使用一个prompt完成的。</p><h3 id="两步式"><a href="#两步式" class="headerlink" title="两步式"></a>两步式</h3><p>联合式变体有一个问题就是由于两个步骤是基于一个prompt完成的，那么LLMs对于验证问题的响应就一定会受到之前生成的初始响应的影响。如我们之前所述，这样显然会增加雪球式幻觉和重复的可能性，让验证问题的答案趋同于初始响应，以至于难以判别是否有幻觉产生。因此作者将这两个步骤分开进行，在第二步的给定上下文中只包含问题，而不包含初始响应。</p><h3 id="分解式"><a href="#分解式" class="headerlink" title="分解式"></a>分解式</h3><p>这种方式是要对所有的问题都进行独立的问答。这样做除了可以消除初始响应的影响，还可以消除答案之间的影响。具体做法是先将第2步中生成的所有问题分解为一个个独立的问题，然后并行地进行问答。</p><h3 id="分解修正式"><a href="#分解修正式" class="headerlink" title="分解修正式"></a>分解修正式</h3><p>这一方式是在分解式的基础上添加了一个验证步，具体做法是将初始响应、验证问题以及对其的响应一起作为输入，让LLMs判断是否产生了不一致现象。</p><h2 id="方法的效果"><a href="#方法的效果" class="headerlink" title="方法的效果"></a>方法的效果</h2><p><img src="/posts/20606/results.png" alt="results.png"></p><h1 id="关于-exposure-bias-问题"><a href="#关于-exposure-bias-问题" class="headerlink" title="关于 exposure bias 问题"></a>关于 exposure bias 问题</h1><p>简单来说,exposure bias指的是在训练大语言模型过程中,模型只能看到人工提供的训练数据,而看不到自己生成的序列。这导致模型在测试时生成的序列质量可能不如训练数据,从而对下游任务产生负面影响。</p><p>主要有以下几个方面的原因:</p><ol><li>模型只见过真实数据分布,没有接触到自己生成序列的分布。这导致模型对自己的输出分布估计不准确。</li><li>模型无法评估自己生成序列的质量。它不知道哪些生成的内容是错误的或不合逻辑的。</li><li>在训练过程中,模型总是以真实数据作为下一个输入,而不是模型生成的序列。这导致测试时模型不习惯自己的生成结果作为输入。</li><li>有evidence显示exposure bias会导致模型生成内容的多样性不足。</li></ol><p>解决exposure bias的常见方法包括:</p><ol><li>数据增强,给模型提供更多样化的训练数据。</li><li>使用reinforcement learning的方法,允许模型评估自己生成内容的质量。</li><li>在训练过程中,有一定概率使用模型生成的序列,而不是真实数据作为下一个输入,让模型适应自己的输出。</li><li>在测试时使用beam search等搜索算法生成多个候选序列,而不是单次输出。</li></ol><p>总体来说,exposure bias依然是困扰大模型的一个重要问题,需要通过数据和算法手段综合解决。</p><h1 id="关于减轻幻觉的方法"><a href="#关于减轻幻觉的方法" class="headerlink" title="关于减轻幻觉的方法"></a>关于减轻幻觉的方法</h1><p><a href="https://browse.arxiv.org/pdf/2309.11495.pdf">论文</a>中的相关工作将减轻幻觉的主要方法粗略地分为三类：训练时修正，生成时修正以及使用工具增强。</p><ol><li>训练时修正。通过训练或者调整编码器-解码器或仅解码器语言模型的权重来改进生成内容,以减少幻觉生成的概率。例如使用强化学习，对比学习等方法。</li><li>生成时修正。在LLMs的基础上使用推理决策，使得到的结论更加可靠。例如考虑生成token的概率来检测幻觉，考虑LLMs输出的不一致性来检测幻觉，使用多个LLMs进行“辩论”来检测幻觉等等。</li><li>使用工具增强。使用外部工具，而不是仅依靠语言模型本身的能力来减轻幻觉现象。例如使用外部事实文档，使用CoT验证，使用事实检查工具等等。</li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Active RAG_DoLa</title>
      <link href="/posts/878.html"/>
      <url>/posts/878.html</url>
      
        <content type="html"><![CDATA[<h1 id="Active-Retrieval-Augmented-Generation"><a href="#Active-Retrieval-Augmented-Generation" class="headerlink" title="Active Retrieval Augmented Generation"></a>Active Retrieval Augmented Generation</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>大语言模型能力很不错，但是仍旧存在生成幻觉，输出错误信息的现象，通过在外部知识源中检索到的合适信息来增强语言模型是一个潜在的方案。</p><h2 id="现有方法的缺陷"><a href="#现有方法的缺陷" class="headerlink" title="现有方法的缺陷"></a>现有方法的缺陷</h2><p>大多采用的是检索-生成的方式，仅仅只基于输入检索一次外部信息，对于长文本生成的应用场景，这是不够的，在这样的场景下，于生成过程中不断注入新的相关信息很有必要。仅有的一些多次查询的工作也是使用以前的全部上下文并以固定的间隔检索文档。</p><h2 id="本工作提出的方法"><a href="#本工作提出的方法" class="headerlink" title="本工作提出的方法"></a>本工作提出的方法</h2><p>提出了 Forward-Looking Active REtrieval augmented generation (FLARE) 方法，使得模型可以灵活的决定什么时间，使用哪些内容进行检索。具体来说，该方法迭代地使用对下一个句子的预测来预估未来的内容，然后在预估内容中包含低置信度 token 时将其用作查询来检索相关文档以重新生成句子。</p><p>作者一共设计了两种FLARE方案，下面分别进行介绍：</p><h3 id="FLARE-with-Retrieval-Instruction"><a href="#FLARE-with-Retrieval-Instruction" class="headerlink" title="FLARE with Retrieval Instruction"></a>FLARE with Retrieval Instruction</h3><p>作者设计了一个 retrieval instruction 模板，这个模板如下图所示：</p><p><img src="/posts/878/instruction.png" alt="instruction.png"></p><p>Skill 1 中定义了一个指导模型生成搜索查询的指令，然后使用 few-shot 方法给出了几个例子，Skill 2 中定义了一个引导模型执行特定下游任务的指令，同样给出了几个例子，最后定义了一个引导模型组合两个 Skill 的指令以及输入的内容。具体的例子如下所示：</p><p><img src="/posts/878/instruction_sample.png" alt="instruction_sample.png"></p><p>当 LLMs 遵循这两个技巧时，就会在需要外部知识的时候生成搜索查询语句，如下图中的斜灰字体内容所示，接着终止这一次的生成，使用搜索查询语句查找相关知识，再将查找到的知识拼接到最前方，直到下一次搜索查询语句生成。</p><p><img src="/posts/878/instruction2.png" alt="instruction2.png"></p><p>但是直接这样去做可能会遇到两个问题：</p><ul><li>语言模型认为需要检索的情况会比实际需要检索的情况少，也就是太自信了而导致漏查，我们前一篇文章中也提到了 LLMs 过于自信的概率很高。</li><li>当生成过多搜索查询时可能会打断原本的答案生成，甚至产生负面效果。</li></ul><p>因此作者还对”[“这个token的生成上做了点策略，比如为了提高语言模型生成 “[Search(query)]” 的可能性，将生成 “[” 的概率值提高了2倍，其次，每当语言模型产生一个搜索查询语句时，利用它来检索相关知识后立即从生成内容中移除它，并在产生下一段内容时，降低这个token的概率从而避免再次生成“[”。</p><h3 id="Direct-FLARE"><a href="#Direct-FLARE" class="headerlink" title="Direct FLARE"></a>Direct FLARE</h3><p>作者发现前面这种方法并不可靠，因此提出了一种更为直接的方式。首先先让模型生成一个临时的，不基于任何外部知识的回复结果，然后进行判断，如果 LLMs 对生成内容的置信度高于某个阈值，那么就将这个临时结果输出，否则使用这个临时回复进行相关内容的搜索，并进行二次生成。</p><p>值得注意的是，作者首先使用临时生成的回复进行相关外部知识的搜索，而没有使用原始输入进行搜索，经过实验证明，这样的方式相比使用前面的文本内容进行检索的效果好很多，但是如果临时文本之中有错误的信息，那么就有可能会导致检索不到相关内容，因此作者又设计了两个简单的策略来克服这个问题。</p><p>第一步是：遮蔽掉临时回复中所有低置信度的 token（相对于某个指定阈值）</p><p>第二步是：针对上一步中被遮蔽掉的信息生成问题，进行搜索，最后进行回答</p><p><img src="/posts/878/mask.png" alt="mask.png"></p><p>于是，FLARE 方法的整体示意图如下图所示：</p><p><img src="/posts/878/FLARE.png" alt="FLARE.png"></p><h2 id="方法效果"><a href="#方法效果" class="headerlink" title="方法效果"></a>方法效果</h2><p>本工作提出方法的效果如下图所示：</p><p><img src="/posts/878/FLARE_results1.png" alt="FLARE_results1.png"></p><p><img src="/posts/878/FLARE_results2.png" alt="FLARE_results1.png"></p><h1 id="DOLA-DECODING-BY-CONTRASTING-LAYERS-IMPROVES-FACTUALITY-IN-LARGE-LANGUAGE-MODELS"><a href="#DOLA-DECODING-BY-CONTRASTING-LAYERS-IMPROVES-FACTUALITY-IN-LARGE-LANGUAGE-MODELS" class="headerlink" title="DOLA: DECODING BY CONTRASTING LAYERS IMPROVES FACTUALITY IN LARGE LANGUAGE MODELS"></a>DOLA: DECODING BY CONTRASTING LAYERS IMPROVES FACTUALITY IN LARGE LANGUAGE MODELS</h1><h2 id="工作的目标"><a href="#工作的目标" class="headerlink" title="工作的目标"></a>工作的目标</h2><p>缓解大语言模型的幻觉问题。</p><h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><ol><li>目前为止，大语言模型产生“幻觉”的确切原因还不完全明确。一个可能的来源是基于最大似然估计的语言建模目标函数。这个目标函数最小化了数据分布和模型分布之间的KL散度，潜在地导致模型追求尽可能覆盖更多的可能性事件，从而使语言模型也为与训练数据中嵌入的知识不一致的句子赋予一定的概率，而非置零。此外，在有限训练数据上用预测下一个 token 作为训练目标的语言模型倾向于利用语言知识去模仿训练样本中的浅层模式，而不是真正理解文本中的语义或者生成符合事实知识的文本。【Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38, 2023.】</li><li>Transformer 模型在浅层中编码了“较低级别”的信息(例如词性标注)，而在较深的层中编码了更多的“语义”信息。更近期的研究发现，“知识神经元”分布在预训练 BERT 模型的最顶层。还有研究表明，事实知识甚至可以通过操作自回归 Transformer 语言模型中的一组特定的前馈层来进行编辑。【Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pretrained transformers. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 8493–8502, 2022.】【Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual associations in GPT. Advances in Neural Information Processing Systems, 36, 2022.】</li></ol><h2 id="提出的方法"><a href="#提出的方法" class="headerlink" title="提出的方法"></a>提出的方法</h2><p>提出了一个简单的解码策略来缓解幻觉，而不是借助对外部知识的检索或对特定领域的微调，主要动机是减弱浅层学习到的语言模式，放大深层蕴含的现实世界的事实知识。具体来说，作者是通过对比从深层投射到词汇空间获得的对数概率与从浅层投射获得的对数概率之间的差异来获得下一个词的分布，这个思想基于一个事实——大语言模型中的事实知识通常局限于特定的 Transformer 层中。这种方法的示意如下图所示：</p><p><img src="/posts/878/DoLa1.png" alt="DoLa1.png"></p><p>作者将最后一层称为 mature layer，中间层称为 premature layer，直接将中间层的隐状态送入语言模型最后的映射层得到输出的方法叫做 early exit。下图展示了各层对应的 early exit 结果和经历过全部的32个 transformer 层处理再送入映射层得到的结果之间的 JS 散度：</p><p><img src="/posts/878/DoLa2.png" alt="DoLa2.png"></p><p>不难发现对于根据输入进行解码的过程中，分为两种模式：</p><ol><li>预测重要的命名实体或日期，例如图2中的Wole Soyinka和1986，这时需要事实知识的参与。容易观察到,在更高的层中,计算的 JSD 仍然非常高。这种模式表示,在最后几层中,模型仍在改变其预测,并可能向预测中注入更多事实知识。</li><li>预测功能词，如 was, the, to, in,以及从输入问题复制的词汇，如 first Nigerian, Nobel Prize。在预测这些“简单”词汇时，我们可以观察到，从中间层开始 JS 散度就变得很小了。这一发现表明模型已经在浅层决定了要生成什么词汇，所以在更高层它只是保持输出分布几乎不变。</li></ol><p>因此，针对这个发现，作者分别针对两种模型设计了两种策略：</p><ol><li>采用对比前后层差异的方法来放大较高层的知识。为了实现这一点，就要选择同最后一层输出差异最大的 premature layer，这里使用的衡量标准就是 JS 散度。</li><li>在选择好了 premature layer 之后，需要分情况讨论，对于那些有足够高概率的token 用 mature layer 的对数概率减去 premature layer 的概率作为最终概率送入softmax，对于没有足够高概率的token，直接将概率设为负无穷送入softmax，这样得到的这个词的概率就接近于0。</li></ol><p><img src="/posts/878/DoLa3.png" alt="DoLa3.png"></p><h2 id="方法的效果"><a href="#方法的效果" class="headerlink" title="方法的效果"></a>方法的效果</h2><p><img src="/posts/878/DoLa4.png" alt="DoLa4.png"></p><p><img src="/posts/878/DoLa5.png" alt="DoLa5.png"></p><p><img src="/posts/878/DoLa6.png" alt="DoLa6.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Learning Reproducibility</title>
      <link href="/posts/57928.html"/>
      <url>/posts/57928.html</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习实验可复现问题"><a href="#深度学习实验可复现问题" class="headerlink" title="深度学习实验可复现问题"></a>深度学习实验可复现问题</h1><p>深度学习在训练过程中，由于随机初始化，样本读取的随机性，导致重复的实验结果会有差别，个别情况甚至波动较大。一般论文为了严谨，实验结论能够复现&#x2F;可重复，通常采取固定随机种子使得结果确定。先给出我的完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置环境变量—— CUDA_LAUNCH_BLOCKING 、CUBLAS_WORKSPACE_CONFIG</span></span><br><span class="line">os.environ[<span class="string">&quot;CUDA_LAUNCH_BLOCKING&quot;</span>] = <span class="string">&quot;1&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;CUBLAS_WORKSPACE_CONFIG&quot;</span>] = <span class="string">&quot;:16:8&quot;</span></span><br><span class="line"><span class="comment"># 从 config.json 配置文件中读取到 json 对象 config ，再从其中获取手动设置的随机数种子以及手动指定的运行显卡</span></span><br><span class="line">seed = config[<span class="string">&quot;seed&quot;</span>]</span><br><span class="line">device = config[<span class="string">&quot;cuda_device&quot;</span>]</span><br><span class="line"><span class="comment"># 设置 python 、numpy 、torch 的随机数种子</span></span><br><span class="line">random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">os.environ[<span class="string">&quot;PYTHONHASHSEED&quot;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line"><span class="comment"># 如果显卡可以使用，就设置运行显卡、cudnn、cuda_seed 以及强制检测算法可复现性</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">torch.cuda.set_device(device)</span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.cuda.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed_all(seed)</span><br><span class="line">torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 读取数据集时设置 num_work = 0 ，可以实现可复现性，如果想多线程读取，那就要设置 seed_worker</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seed_worker</span>(<span class="params">worker_id</span>):</span><br><span class="line">    worker_seed = torch.initial_seed() % <span class="number">2</span>**<span class="number">32</span></span><br><span class="line">    np.random.seed(worker_seed)</span><br><span class="line">    random.seed(worker_seed)</span><br><span class="line">g = torch.Generator()</span><br><span class="line">g.manual_seed(seed)</span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">test_set,</span><br><span class="line">collate_fn=test_set.collate,</span><br><span class="line">batch_size=config[<span class="string">&quot;batch_size&quot;</span>][<span class="string">&quot;test&quot;</span>],</span><br><span class="line">shuffle=config[<span class="string">&quot;shuffle&quot;</span>][<span class="string">&quot;test&quot;</span>],</span><br><span class="line">num_workers=config[<span class="string">&quot;num_workers&quot;</span>][<span class="string">&quot;test&quot;</span>],</span><br><span class="line">worker_init_fn=seed_worker,</span><br><span class="line">generator=g,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>接下来我们再来详细解释这段代码的意义。</p><h2 id="随机种子设置"><a href="#随机种子设置" class="headerlink" title="随机种子设置"></a>随机种子设置</h2><p>随机函数是最大的不确定性来源，影响了模型参数的随机初始化，样本的shuffle等等操作。</p><ul><li>PyTorch 随机种子</li><li>python 随机种子</li><li>numpy 随机种子</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">os.environ[<span class="string">&quot;PYTHONHASHSEED&quot;</span>] = <span class="built_in">str</span>(seed)</span><br></pre></td></tr></table></figure><p>CPU版本下，上述随机种子设置完成之后，基本就可实现实验的可复现了。但是对于GPU版本，存在大量算法实现为不确定结果的算法，这种算法实现效率很高，但是每次返回的值会不完全一样。主要是由于浮点精度舍弃，不同浮点数以不同顺序相加，值可能会有很小的差异（小数点最末位）。此外，官方的文档提到，对于 RNN 类模型会因为 cuDNN 和 CUDA 的原因导致结果无法复现，可以通过设置环境变量来解决。</p><ul><li>CUDA 10.1：设置环境变量 <code>CUDA_LAUNCH_BLOCKING=1</code></li><li>CUDA 10.2 或者更高版本：设置环境变量 (注意两个冒号)<code>CUBLAS_WORKSPACE_CONFIG=:16:8</code> 或者 <code>CUBLAS_WORKSPACE_CONFIG=:4096:2</code>.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;CUDA_LAUNCH_BLOCKING&quot;</span>] = <span class="string">&quot;1&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;CUBLAS_WORKSPACE_CONFIG&quot;</span>] = <span class="string">&quot;:16:8&quot;</span></span><br></pre></td></tr></table></figure><h2 id="GPU算法确定性实现"><a href="#GPU算法确定性实现" class="headerlink" title="GPU算法确定性实现"></a>GPU算法确定性实现</h2><p>GPU算法的不确定来源有两个</p><ul><li>CUDA convolution benchmarking</li><li>Nondeterministic algorithms</li></ul><p><strong>CUDA convolution benchmarking</strong>：这个设置是为了提升运行效率，对模型参数试运行后，选取最优实现。不同硬件以及benchmarking本身存在噪音，导致不确定性。</p><p><strong>Nondeterministic algorithms</strong>：GPU最大优势就是并行计算，如果能够忽略顺序，就避免了同步要求，能够大大提升运行效率，所以很多算法都有非确定性结果的算法实现。通过设置use_deterministic_algorithms，就可以使得pytorch选择确定性算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不需要benchmarking</span></span><br><span class="line">torch.backends.cudnn.benchmark=<span class="literal">False</span></span><br><span class="line"><span class="comment"># 选择确定性算法</span></span><br><span class="line">torch.use_deterministic_algorithms(<span class="literal">True</span>) </span><br></pre></td></tr></table></figure><h2 id="RUNTIME-ERROR"><a href="#RUNTIME-ERROR" class="headerlink" title="RUNTIME ERROR"></a>RUNTIME ERROR</h2><p>对于一个PyTorch 的函数接口，没有确定性算法实现，只有非确定性算法实现，同时设置了use_deterministic_algorithms()，那么会导致运行时错误。比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randn(<span class="number">2</span>, <span class="number">2</span>).cuda().index_add_(<span class="number">0</span>, torch.tensor([<span class="number">0</span>, <span class="number">1</span>]), torch.randn(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">RuntimeError: index_add_cuda_ does <span class="keyword">not</span> have a deterministic implementation, but you <span class="built_in">set</span></span><br><span class="line"><span class="string">&#x27;torch.use_deterministic_algorithms(True)&#x27;</span>. ... </span><br></pre></td></tr></table></figure><p>错误原因：</p><p>index_add没有确定性的实现，出现这种错误，一般都是因为调用了torch.index_select 这个api接口，或者直接调用tensor.index_add_。</p><p>解决方案：</p><p>自己定义一个确定性的实现，替换调用的接口。对于torch.index_select 这个接口，可以有如下的实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">deterministic_index_select</span>(<span class="params">input_tensor, dim, indices</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    input_tensor: Tensor</span></span><br><span class="line"><span class="string">    dim: dim </span></span><br><span class="line"><span class="string">    indices: 1D tensor</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tensor_transpose = torch.transpose(x, <span class="number">0</span>, dim)</span><br><span class="line">    <span class="keyword">return</span> tensor_transpose[indices].transpose(dim, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="样本读取随机"><a href="#样本读取随机" class="headerlink" title="样本读取随机"></a>样本读取随机</h2><ol><li>多线程情况下，设置每个线程读取的随机种子</li><li>设置样本generator</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置每个读取线程的随机种子</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seed_worker</span>(<span class="params">worker_id</span>):</span><br><span class="line">    worker_seed = torch.initial_seed() % <span class="number">2</span>**<span class="number">32</span></span><br><span class="line">    numpy.random.seed(worker_seed)</span><br><span class="line">    random.seed(worker_seed)</span><br><span class="line"></span><br><span class="line">g = torch.Generator()</span><br><span class="line"><span class="comment"># 设置样本shuffle随机种子，作为DataLoader的参数</span></span><br><span class="line">g.manual_seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    num_workers=num_workers,</span><br><span class="line">    worker_init_fn=seed_worker,</span><br><span class="line">    generator=g,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="nn-Upsample"><a href="#nn-Upsample" class="headerlink" title="nn.Upsample"></a>nn.Upsample</h2><p>在我自己的实验中，上述设置全部配置完成后依然出现了无法复现的问题。幸运的是 torch.use_deterministic_algorithms(True) 这个设置进行了报错，经实验发现 nn.Upsample 中调用了 F.interpolate，其 bilinear 插值模式是 nondeterministic 的，只有默认的 nearest 模式是 deterministic 的，但是效果比前者差了很多很多。在训练中可以使用转置卷积进行上采样，但是在深度监督中使用这个方法太过奇怪，放到 CPU 中跑完再送回 GPU 又太过耗时，目前仍没有很好地解决方法，因此暂时选择通过多次重复实验选取中位数或者均值作为实验结果。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RAG and Hallucination</title>
      <link href="/posts/54750.html"/>
      <url>/posts/54750.html</url>
      
        <content type="html"><![CDATA[<h1 id="RAG、KGD-and-Hallucination"><a href="#RAG、KGD-and-Hallucination" class="headerlink" title="RAG、KGD and Hallucination"></a>RAG、KGD and Hallucination</h1><p>大语言模型的幻觉（Hallucination）指的是模型产生不准确或误导性输出的现象，这种幻觉会导致大模型输出似是而非但实际不正确的答案，或者给出与上下文并不相关的输出。这种幻觉的本质是由于大语言模型本身缺乏对于现实世界的感知能力，其训练数据可能存在偏见的、不完整的、错误的虚假信息，训练中可能存在过拟合或者量化误差，以及Prompt上下文缺失等情况。在某些关键任务中，幻觉的确可能带来严重的后果和误导。</p><p>当然，幻觉的存在不意味着大模型就无法在生产环境中落地。治理幻觉的方式有很多，包括在训练时提供更高质量的数据，对模型进行Fine-tune补充领域内知识，在RLHF给予Reward Model关于数据真实性更高的倾向性，通过Prompt引导大模型避免对缺乏信息的问题进行生成，以及本文所提到Retrieval Augment Generation，基于向量数据库的召回式生成。合理利用幻觉，可以充分发挥大模型的推理能力和创造能力，解决更加发散性的问题。</p><p>RAG（retrieval-augmented generation）&#x2F;KGD（knowledge-grounded dialogue）有两个重要的组成部分，分别是预训练大模型和领域知识库。前者很好理解，比如 LLaMA2 等预训练大模型就是典型的例子，后者就需要自行构建一个 domin-specific 的 知识库了；结合这两个部分，就可以将 AI 应用的 pretrain-finetune 范式转变为pretrain-prompt范式，大大简化对于不同任务训练模型的工作量，降低了AI的开发和使用门槛，也把搜索结合生成变为了可能。</p><h2 id="RAG的定义"><a href="#RAG的定义" class="headerlink" title="RAG的定义"></a>RAG的定义</h2><p>大多数文本生成可以描述为，给定一个输入文本x，生成一个输出文本y，也就是y&#x3D;f(x)，其中f就是文本生成模型。而基于检索增强的文本生成则可以描述为y&#x3D;f(x, z)，其中z是一系列从训练语料或者外部数据源中检索得到的相关样例z&#x3D;{(xr, yr)}。如果xr跟输入文本x相似或者相关，那么yr也许对答案生成有一定帮助。当xr等于空集时，也就是没有检索得到样例，此时基于检索增强的文本生成就会退化为传统的文本生成。</p><h2 id="为什么要使用RAG"><a href="#为什么要使用RAG" class="headerlink" title="为什么要使用RAG"></a>为什么要使用RAG</h2><ol><li>LLM是有损压缩，不能记住其参数中的所有（长尾）知识。大模型尽管参数量很大，但相比人类的所有知识依然只占九牛一毛，而人类的知识又往往呈现一种长尾分布，那些重要的知识会高频次地出现，让模型能够记住它，但是那些不重要的知识出现频次过低，让大模型很难全部记住。</li><li>LLM的知识很容易过时，很难更新。大模型的训练数据存在时间截止的问题。尽管可以通过Finetune来为大模型加入新的知识，但大模型的的训练成本和时间依然是相当可观的，通常需要大量的计算资源，时间也是天级别更新。不论是向量数据库还是搜索引擎，数据的更新都更加容易，这有助于业务数据的实时性，且模型重新训练的周期被大大拉长了，避免了频繁Finetune带来的数据正确性，政策等风险。</li><li>LLM的输出很难解释和验证。使用LLM生成的结果，很难验证其准确性，存在着大量谬误。通过RAG的方式，所有数据可以记录数据来源，以便于通过人工或者机器的方式校验结果。</li><li>LLMs被证明很容易泄漏私有数据。尽管可以向LLM通过Finetune的方式添加领域知识，但这些领域知识很可能包含个人或者公司的机密信息，且这些数据很可能通过模型在不经意之间泄露出去。通过增加私有数据存储的方式，用户的数据可以更加安全。</li><li>关于数据存储方式。对领域知识的补充往往依赖于特定的数据存储，如向量数据库，搜索引擎或者图数据库。这其中，向量数据库因为具备对高维Embedding的检索能力，跟大模型的结合最为简单，效果也比较出色，目前是RAG中最为常用的数据存储方式。</li></ol><h2 id="RAG检索源"><a href="#RAG检索源" class="headerlink" title="RAG检索源"></a>RAG检索源</h2><p>基于检索增强的文本生成可以引入不同来源的外部知识，也就是可以从不同来源的库中检索召回相关文档。</p><p>a) 训练语料</p><p>大多数研究都聚焦于如何从训练语料中搜索相关的知识，在推理时，利用从训练语料中检索到的高相似度的样例作为额外的参考，从而减少模型生成答案的不确定性。这些工作的主要启发就是不仅可以利用模型参数隐式存储语料中的知识，也可以利用显示的模型可接受形式向模型传输知识，提高生成文本质量。</p><p>b)外部数据</p><p>一部分研究者尝试从外部数据源召回相关样例，在这些研究中，检索池，可以提供额外的不存在于训练语料的信息。这种方式尤其利于领域迁移和知识更新的场景。</p><p>c)无监督数据</p><p>前面两种数据源的局限性在于数据集必须是包括（输入-输出）这样格式的有监督数据，而有些场景下缺乏这样的监督数据，为此也有研究用到这部分无监督数据来增强文本生成，主要想法是去对齐源文本侧的数据跟目标文本侧的数据。</p><h2 id="RAG检索方式"><a href="#RAG检索方式" class="headerlink" title="RAG检索方式"></a>RAG检索方式</h2><p>基于检索增强的文本生成中的检索模块，旨在检索召回跟query相关的文档，为后续的生成模型提供参考。具体方式是给定一个输入文本x和一个检索语料库，检索模型从语料库中检索得到一系列跟x相关的样例z&#x3D;{(xr, yr)}，检索方式可以有以下几种不同方式。</p><p>a) 稀疏向量检索</p><p>如果使用的是有监督的检索语料库，那么{(xr, yr)}是否被召回依赖于x跟xr的相似度。稀疏向量检索利用倒排索引高效匹配关键词，以TFIDF和BM25算法为例。基于稀疏向量检索的方式更倾向于召回有相似表达的文本，停留在字面上的表示，忽略了语义信息。</p><p>b) 稠密向量检索</p><p>为了检索时能召回语义相关的样例，可以利用预语言模型将文本编码成低维稠密向量，然后计算向量之间的内积作为相似度得分，以此作为检索的依据。</p><p>c) 特定任务检索</p><p>前面两种检索当时都是依赖相似度的方法，这种类型的方式是基于一个简单的假设，那就是，如果xr越接近于x，那么yr越有利于帮助文本生成。然而，真实情况下最相似的文本不一定最有利于下游的生成任务。理想情况下，检索的依据应该从从数据中学习，是依赖于特定任务的，好的检索依据是能够提升最后生成模型生成的质量。</p><h2 id="RAG整合方式"><a href="#RAG整合方式" class="headerlink" title="RAG整合方式"></a>RAG整合方式</h2><p>如何将检索得到的文档跟当前输入x整合到一起，从而控制生成模型生成更高质量的结果？</p><p>a) 数据增强</p><p>最直接的整合方式，直接将检索得到的样例{(xr, yr)}跟原始输入x拼接到一起。通过在增强的数据上进行训练，语言模型会隐式地学习到如何整合检索得到的信息。尽管这种方式很简单，但是在诸多任务上都是有效的。</p><p>b) 注意力机制</p><p>通过引入额外的编码器对检索得到文档进行编码，然后利用注意力机制跟原始输入x整合到一起。由于注意力机制逐渐变成诸多NLP任务的关键模块，这种方式也逐渐成为一个默认的方式。</p><p>c) 骨干抽取</p><p>对于前面两种方式，下游生成模型学习如何从检索得到的文档中隐式过滤掉不相关甚至有害的信息，但是也有部分工作尝试通过显示的方式抽取有用信息，进而直接跟输入x整合到一起。</p><h2 id="RAG的关键"><a href="#RAG的关键" class="headerlink" title="RAG的关键"></a>RAG的关键</h2><p>我们在推理时需要从 domin-specific 知识库中抽取出需要的信息，因此对海量数据进行高效率的索引就是RAG的重中之重。</p><p>Retrieval的关键是找到datastore中跟查询最相似的Top-k个元素。至于相似度，面对不同的业务有不同的定义，对于传统搜索来讲相似度往往是类似于TF-IDF这样的基于词频的统计信息；对于向量数据库而言，相似度则是Embedding在高维空间中的距离，这一距离可以是Cosine，L2，IP，也可以是自定义的业务距离。本质上来讲，Embedding也是一种基于训练文本的词频统计，因此其相对于TF-IDF可能会更加精确，这个结论在大部分域内搜索的情况下都是成立的。</p><p>在海量数据中搜索相关数据，肯定少不了对数据的索引能力。传统检索依赖类似于Lucene的倒排索引，而向量检索则依赖Faiss，HNSW，SCaNN这些向量检索库。由于向量检索需要大量算力，在实际落地的过程中往往使用ANN降低算法的复杂度，使用GPU或者SIMD进行算力提升，以及使用分治法将数据拆分成分片进行计算。向量数据库充分利用以上三个能力，这也是大模型时代向量数据库能够爆火的重要原因。</p><h2 id="RAG的未来方向"><a href="#RAG的未来方向" class="headerlink" title="RAG的未来方向"></a>RAG的未来方向</h2><p>尽管当前基于检索增强的文本生成取得一定成功，接下来还有有很长的路去进一步提升整体的效果。</p><p>a) 检索敏感性</p><p>基于检索增强的文本生成对于检索的质量非常敏感。当检索得到的样例跟输入query非常相似时，文本生成模型的效果会很好。但是当检索得到的样例跟输入query没那么相似时，生成的效果会很糟糕甚至不及没有检索增强的生成。</p><p>b) 检索效率</p><p>扩大检索内存可以更大概率获取到跟query相似的内容，但是这也会影响整体推理的效率。如何平衡检索内存大小跟检索效率？</p><p>c) 联合优化</p><p>目前看联合优化检索模块跟生成模型的方式有潜力的，但在实际中，检索模块在训练跟推理阶段仍然存在差距。在训练阶段，误差只传递到局部的少数召回的样例，但是在推理时却要考虑所有在数据库中的样例。</p><p>d) 多模态</p><p>随着技术的发展，跨模态的检索方式也成为了现实，可以直接将不同模态的数据联系到一起，这也需要去探索文本生成任务中检索不同模态数据的可能性。</p><p>e) 多样性跟可控性</p><p>仅使用一种检索依据会导致召回结果缺乏多样性，为此可以通过多种检索方式去获得多样化的结果，从而提升有用信息的含量。不同场景下对于检索的要求不尽相同，未来需要去探索如何使用定制化的方式去进行检索，从而实现更加可控化的文本生成。</p><h2 id="RAG方法"><a href="#RAG方法" class="headerlink" title="RAG方法"></a>RAG方法</h2><h3 id="Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks"><a href="#Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks" class="headerlink" title="Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"></a>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</h3><p>大语言模型已经展示了它们将现实知识存储在它们的参数中的能力，再通过下游任务的微调就可以实现SOTA的效果；然而它们仍不能精确地访问和利用知识，因此在知识密集型任务上的性能表现不尽如人意。除此之外，如何为LLMs的回答提供来源引用以及如何更新LLMs的知识库仍然是悬而未决的难题。因此，作者提出了一种用于检索增强生成（RAG）的通用的微调方法——同时利用参数化记忆以及非参数化记忆来进行生成；其中前者是预训练好的seq2seq模型，后者是通过预训练好的神经检索器访问的稠密向量索引。</p><p><img src="/posts/54750/RAG.png" alt="RAG.png"></p><p>如上图所示，RAG 由两部分组成，第一部分负责根据 query $x$检索出 top-k 个匹配的文档$z_i$ ，第二部分将 query $x$和文档拼接起来送入 seq2seq 模型，生成回复$y$。</p><p>在第一部分 Retriver（(Dense Passage Retriever，DPR，$p_\eta(z|x)$） 中，RAG 通过 embedding model 把外部知识和 query 嵌入为稠密向量，做内积得到内积最大的$K$个文档，然后将 query 和文档拼接起来组成$K$个输入，作为第二部分的输入。这一部分采用了 DPR，它是一个双编码器架构，使用BERT-base分别将输入的query和document转换成embedding。</p><p>在第二部分 Generator ($p_\theta(y_i|x,z,y_{1:i-1})$)中，有两种使用文档的方式：第一种是使用同一个文档生成一个完整的序列，先确定一个文档$z_i$，然后再计算$P(y|x,z_i)$；第二种是使用不同的文档生成每个词，对于第$i$个位置，候选词的概率等于所有文档的条件概率之和，即计算候选词对文档的边际概率。总的来说，RAG-Sequence使用单个文档预测所有目标token，而RAG-Token预测每个token都依赖于不同的文档。这一部分采用的是BART模型。</p><h3 id="Leveraging-Passage-Retrieval-with-Generative-Models-for-Open-Domain-Question-Answering"><a href="#Leveraging-Passage-Retrieval-with-Generative-Models-for-Open-Domain-Question-Answering" class="headerlink" title="Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"></a>Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering</h3><p>FiD（Fusion-in-Decoder）同样包括检索跟生成两个模块，检索模块尝试了不同的方式，一种是稀疏向量检索的BM25（类似于TFiDF，以词为基本单位，同时考虑词频跟逆文本频率的文本相似度方法），其中分词器用的默认参数的SpaCy插件。另一种是稠密向量检索（跟RAG一样使用了DPR），通过两个不同的Bert分别将query和检索库的文档编码成低维向量，利用向量内积计算向量之间的相似度，通过faiss建立索引可以用query检索得到最相似的top-K个文档向量（跟RAG的检索模块相似）。</p><p>生成模块则跟RAG不太一样，FiD将原始的问题，跟检索模块返回的标题跟对应文档通过特殊字符question:，title:，context:拼接到到一起输入到生成模块生成所有检索文档的表征，然后将所有的文表征拼接到一起，利用attention机制进行解码。生成模块的encoder分别对不同检索文档进行编码，这允许模型去容纳庞大数量的检索结果，然后在decoder时汇总所有文档的表征，这允许decoder更好的聚合多个文档的信息。</p><p><img src="/posts/54750/FiD.png" alt="FiD.png"></p><h3 id="Joint-retrieval-and-generation-training-for-grounded-text-generation"><a href="#Joint-retrieval-and-generation-training-for-grounded-text-generation" class="headerlink" title="Joint retrieval and generation training for grounded text generation"></a>Joint retrieval and generation training for grounded text generation</h3><p>RetGen的检索模块是基于稠密向量检索，文档跟query分别使用两个不同的编码器。至于生成模块部分，使用了类似GPT-2的结构，利用一个特殊分隔符将文档z跟原始输入x拼接到一起去生成目标序列y。此外，为了帮助模型区别检索返回的文档跟原始输入，在词嵌入层设置了不同的token类型来代表token属于文档或者原始输入。同时，为了最大化地分隔x跟z，在设计position embedding的时候，原始输入 x 的位置id从0开始算起，而文档 z 的位置id则是从400开始算起。</p><p>RetGen也是采用联合训练的方式同时优化检索模块跟生成模块，这里检索模块的文档encoder也会一同更新。由于在训练时每次都去更新检索库中所有文档的向量表示成本巨大，所以RetGen每次只更新检索召回的top-K个文档。对于解码阶段，RetGen采用了MOE（Mixture-of-Expert）的方法，借助K个相同的文本生成模型，将召回的不同文档+相同原始问题x+已经生成的前面的文本序列分别输入这K个模型，然后整合K个模型的预测结果。相比于FID在文档水平上整合信息，RetGen是在token分布水平上整合不同文档的信息。同时，FID需要固定数量的文档作为输入，而RetGen则可以灵活配置检索模块返回的数量。</p><p>除此之外，RetGen在文本生成过程中引入了检索修正，因为目标文本是通过自回归的方式依次生成，在这个生成过程中文档检索的得分也需要不断更新（如果前面生成的目标序列更多的依赖文档z，那么文档z就应该被赋予更高的比重），为此作者在计算公式中乘上检索修正项（在某个文档下生成一个token的概率除以在每一个文档下生成这个token的概率的加权平均），如果修正项大于1，那么文档z就会被分配到更大的概率。</p><p><img src="/posts/54750/RetGen.png" alt="RetGen.png"></p><h3 id="Investigating-the-Factual-Knowledge-Boundary-of-Large-Language-Models-with-Retrieval-Augmentation"><a href="#Investigating-the-Factual-Knowledge-Boundary-of-Large-Language-Models-with-Retrieval-Augmentation" class="headerlink" title="Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"></a>Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation</h3><p>这篇工作没有提出新的模型或者方法，而是探索了基于检索增强的大模型的知识边界，并且得到了一些有用的结论。</p><p>目前往大模型注入知识的渠道有两种，一种是在训练时加入相应的语料，通过模型权重参数的形式将知识隐式存储下来，另一种就是在推理时将知识写进prompt中，作为模型输入的一部分，显示指导模型的生成。对于知识问答场景而言，很多事实性问题都需要依赖于外部的领域知识才会回答，单靠大模型本身是解决不了的，于是就有研究人员针对检索增强下大模型知识边界的几个相关问题展开了一系列实验。a)大模型的知识边界在哪？大模型到底能否判断问题是否需要引入外部知识或者自身就可以解决。B)检索增强对于大模型的影响在哪？c)不同特性的检索结果对于大模型的影响有何差异？</p><p>研究人员构建了两种不同类型的任务指令，分别叫做QA prompting跟judgemental prompting。QA prompting用于指导语言模型生成对应问题的回复，从而可以去评估模型的问答能力。具体而言就是在指令中要求模型根据问题以及其他信息去生成对应回复，研究人员构造了两种不同的QA prompting指令，分别如下。 a) Normal setting, 要求语言模型利用自身知识直接生成回复，不借助外部知识。b) Retrieval-augmented setting, 要求语言模型利用来自外部的相关文档以及自身知识去生成回复，跟前者的区别在于模型输入多了检索模块返回的相关文档。Judgemental prompting则是用于研究探索模型是否能感知到自身知识边界，具体而言就是让语言模型根据已有信息判断问题是否超出了自身的知识边界，同样根据是否使用了检索结果分为normal setting跟retrieval-augmented setting两种类型的指令。除此之外，研究人员还考虑了两种不同的判断视角的模型指令，分别是：a)Prior judgement，要求模型评估是否有把握回复该问题，具体来说就是在模型还没生成回复前让模型判断是否有能力去回复该问题，是要选择生成回复还是放弃。b) Posteriori judgement，要求模型去评估生成自身生成回复的准确性，具体来说就判断生成结果是否可靠。prompt示例如下：</p><table><thead><tr><th align="center">prompt类型</th><th align="center">prompt指令</th></tr></thead><tbody><tr><td align="center">QA Prompting&#x2F;Normal Setting</td><td align="center">Answer the following question based on your internal knowledge with one or few words.</td></tr><tr><td align="center">QA Prompting&#x2F;Retrieval-Augmented Setting</td><td align="center">Given the following information: · · · Answer the following question based on the given information or your internal knowledge with one or few words without the source.</td></tr><tr><td align="center">Judgemental Prompting&#x2F;Normal Setting&#x2F;Prior judgement</td><td align="center">Are you sure to accurately answer the following question based on your internal knowledge, if yes, you should give a short answer with one or few words, if no, you should answer ‘Unknown’.</td></tr><tr><td align="center">Judgemental Prompting&#x2F;Normal Setting&#x2F;Posteriori Judgement</td><td align="center">Can you judge if the following answer about the question is correct based on your internal knowledge, if yes, you should answer True or False, if no, you should answer ‘Unknown’.</td></tr></tbody></table><p>研究人员在包括Natural Questions(NQ), TriviaQA, HotpotQA这几个开放域问答数据集上进行相应实验，实验过程涉及了多项指标，具体如下。 Exact match: 模型生成回复跟标准答案完成一致的比例，用于评估语言模型的问答能力。 F1: 模型生成回复跟标准答案重叠的程度，也是用于评估语言模型的问答能力。 Give-up: 语言模型放弃回复的比例，用于评估语言模型生成回复的置信度。 Right&#x2F;G: 语言模型放弃回复中能本来能正确回复的比例。 Right&#x2F;~G: 语言模型选择生成回复中能正确回复的比例。 Eval-Right: 语言模型评估自身回复为正确的比例，换言之就语言模型觉得自己生成了正确回复的比例。Eval-Acc: 语言模型生成回复跟标准答案一致的比例，换言之就是语言模型真正回复正确的比例。</p><p>为了方便获得上述多个指标，研究人员利用一些规则对语言模型的输出进行了解析。同时研究人员也考虑了多种不同类型的检索模块，包括稀疏检索的BM25，稠密检索的RockerQAv2，生成模型chatgpt（让生成模型根据自身记忆生成相应的知识文档），通过前两者召回的文档都具有相同的格式“Passage-{num}: Title:{title} Content:{content}”，而通过生成模型生成的文档的格式则为“Passage-{num}:{content}”。</p><p><img src="/posts/54750/KnowledgeEdge.png" alt="KnowledgeEdge.png"></p><p>最终，研究人员得到了以下结论：</p><ol><li><p>大规模语言模型不能准确感知模型自身的知识边界，对于自身回复能力通常会过于盲目自信。总体而言，模型的问答效果（EM，F1）跟模型自身的置信度相关，但是模型对自身能力的置信度往往超出了它真实的水平。如图所示，模型放弃回复的比例（Give-up）并不高，而且回复正确的比例也不高。图中Eval-Right数值远超Eval-Acc也能说明模型对于生成回复会过于盲目自信。这就是大家所诟病的模型幻觉问题，即便不知道答案，也会一本正经的胡说八道，并且模型还会过度自信，没有意识到自己的胡说八道，这跟大家平时使用大模型的感受比较一致。</p><p><img src="/posts/54750/table2.png" alt="table2.png"></p></li><li><p>语言模型不能充分利用自身具备的知识，而通过检索增强显示引入外部知识可以弥补该缺陷，而且检索增强可以提升模型对于知识边界的感知能力。在不超过模型输入限制的条件下，随着检索增强召回的文档数增加，整体问答效果随之提升，同时模型也更加自信。如图所示，带有检索增强的问答效果显著优于不带检索增强的，并且，通过检索增强，模型感知的能力跟问答效果一致得到提升，可以看到Right&#x2F;G有明显的下降，Eval-Right跟EM更加一致，同时Eval-Acc有明显提高。这也是蛮符合直观感受，通过检索增强可以在模型生成过程中显示引入外部知识，指导模型生成恰当回复。而增加检索文档数量，有利于提高检索文档的准确率，虽然会引入更多噪声，但只有模型本身有较强的归纳总结能力，那对于整体效果还有帮助的。</p><p><img src="/posts/54750/table3.png" alt="table3.png"></p></li><li><p>语言模型的置信度以及对于检索结果的依赖程取决于问题跟检索效果之间的相关性。只有提供高质量的相关文档，才能提升大规模语言模型整体的问答效果以及对于知识边界的感知能力。同时，语言模型会更加依赖于检索的结果，如果提供了低质量的跟问题不相关的文档后，模型就会容易胡说八道，即便在输入指令中让模型先判断检索结果质量后再决定是否使用也不能规避这个问题。也就是，检索结果跟问题越相关，模型就越自信，所以如果检索结果相关但是错误的，就很容易将模型带偏（图中的highly-related, weakly-related是跟问题相关但是没有正确答案文档，可以理解为错误的文档）。</p><p><img src="/posts/54750/table4.png" alt="table4.png"></p></li><li><p>基于上述的一些发现，研究人员提出了一种简单的动态检索增强方法，如下图所示，让模型根据检索结果判断是否有能力回复当前问题，如果是的话，就将当前问题，检索结果一同作为模型的输入，引导模型生成，否则就是在模型生成过程中不加入检索结果。</p><p><img src="/posts/54750/method.png" alt="method.png"></p></li></ol><h2 id="ANN（Approximate-Nearest-Neighbor）方法"><a href="#ANN（Approximate-Nearest-Neighbor）方法" class="headerlink" title="ANN（Approximate Nearest Neighbor）方法"></a>ANN（Approximate Nearest Neighbor）方法</h2><p>向量数据库需要对数十上百亿的token进行搜索，因此使用暴力法进行搜索显然是不现实的，因此许多向量数据库（例如faiss，milvus等）都会在构建数据库的时候先将这些海量的token进行聚类，然后搜索的时候先找到跟query距离最近的几个聚类中心，然后在这几个类中进行搜索即可，如下图所示。因此，在这一部分，我们会从KNN开始，对ANN的相关算法进行一些了解。</p><p><img src="/posts/54750/index.png" alt="index.png"></p><h3 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h3><p>一言以蔽之，KNN算法就是综合k个“邻居”的标签值作为新样本的预测值。该方法有三个要素：距离度量，决策方法以及K值的选择。其中，距离度量有曼哈顿距离，欧氏距离等等；决策方法有投票法，均值法等等；K值的选择有网格搜索等方法，K取值较小时，模型复杂度高，训练误差会减小，泛化能力减弱；K取值较大时，模型复杂度低，训练误差会增大，泛化能力有一定的提高。</p><h4 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h4><ul><li>暴力搜索。KNN实现最直接的方法就是暴力搜索（brute-force search），计算输入样本与每一个训练样本的距离，选择前k个最近邻的样本来多数表决。但是，当训练集或特征维度很大时，计算非常耗时，不太可行（对于D维的 N个样本而言，暴力查找方法的复杂度为 O(DN) ） 。</li><li>KD tree。所谓的KD树就是n个特征维度的二叉树，可以对n维空间的样本划分到对应的一个个小空间。KD树建采用的是从m个样本的n维特征中，分别计算n个特征的取值的方差，用方差最大的第k维特征nk来作为根节点。对于这个特征，我们选择特征nk的取值的中位数nkv对应的样本作为划分点，对于所有第k维特征的取值小于nkv的样本，我们划入左子树，对于第k维特征的取值大于等于nkv的样本，我们划入右子树，对于左子树和右子树，我们采用和刚才同样的办法来找方差最大的特征来做更节点，递归的生成KD树。比如我们有二维样本6个，{(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)}，构建kd树的具体步骤为： <ol><li>找到划分的特征：6个数据点在x，y维度上的数据方差分别为6.97，5.37，所以在x轴上方差更大，用第1维特征建树。</li><li>确定划分中位数点（7,2）：根据x维上的值将数据排序，6个数据的中值(所谓中值，即中间大小的值)为7，所以划分点的数据是（7,2）。这样，该节点的分割超平面就是通过（7,2）并垂直于：划分点维度的直线x&#x3D;7；</li><li>确定左子空间和右子空间： 分割超平面x&#x3D;7将整个空间分为两部分：x&lt;&#x3D;7的部分为左子空间，包含3个节点&#x3D;{(2,3),(5,4),(4,7)}；另一部分为右子空间，包含2个节点&#x3D;{(9,6)，(8,1)}。</li><li>用同样的办法划分左子树的节点{(2,3),(5,4),(4,7)}和右子树的节点{(9,6)，(8,1)}。最终得到KD树。</li></ol></li></ul><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol><li>算法简单直观，易于应用于回归及多分类任务。</li><li>对数据没有假设，准确度高，对异常点较不敏感。</li><li>由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此适用于类域的交叉或非线性可分的样本集。</li></ol><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol><li>计算量大，尤其是样本量、特征数非常多的时候。另外KD树、球树之类的模型建立也需要大量的内存。</li><li>只与少量的k相邻样本有关，样本不平衡的时候，对稀有类别的预测准确率低。</li><li>使用懒散学习方法，导致预测时速度比起逻辑回归之类的算法慢。当要预测时，就临时进行 计算处理。需要计算待分样本与训练样本库中每一个样本的相似度，才能求得与 其最近的K个样本进行决策。</li><li>与决策树等方法相比，KNN无考虑到不同的特征重要性，各个归一化的特征的影响都是相同的。</li><li>相比决策树、逻辑回归模型，KNN模型可解释性弱一些。</li><li>差异性小，不太适合KNN集成进一步提高性能。</li></ol><h3 id="ANN算法"><a href="#ANN算法" class="headerlink" title="ANN算法"></a>ANN算法</h3><h4 id="HNSW算法"><a href="#HNSW算法" class="headerlink" title="HNSW算法"></a>HNSW算法</h4><h4 id="Annoy算法"><a href="#Annoy算法" class="headerlink" title="Annoy算法"></a>Annoy算法</h4><h4 id="Faiss算法"><a href="#Faiss算法" class="headerlink" title="Faiss算法"></a>Faiss算法</h4><h4 id="ScaNN算法"><a href="#ScaNN算法" class="headerlink" title="ScaNN算法"></a>ScaNN算法</h4>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Exchange Ctrl and Caps on Linux</title>
      <link href="/posts/33478.html"/>
      <url>/posts/33478.html</url>
      
        <content type="html"><![CDATA[<p>键盘上Ctrl键是最常用的键之一了，但是位置却十分不友好，Caps键明明不怎么使用但是却正好放在小指旁边，因此这里记录一下在linux系统下如何将左Ctrl键和Caps键进行交换。<br>首先使用命令编辑文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gedit ~/.xmodmap</span><br></pre></td></tr></table></figure><p>然后输入代码交换左Ctrl和Caps键的位置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">remove Lock = Caps_Lock</span><br><span class="line">remove Control = Control_L</span><br><span class="line">keysym Control_L = Caps_Lock</span><br><span class="line">keysym Caps_Lock = Control_L</span><br><span class="line">add Lock = Caps_Lock</span><br><span class="line">add Control = Control_L</span><br></pre></td></tr></table></figure><p>最后使用命令让其生效：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xmodmap ~/.xmodmap</span><br></pre></td></tr></table></figure><p>大功告成。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RetNet</title>
      <link href="/posts/10769.html"/>
      <url>/posts/10769.html</url>
      
        <content type="html"><![CDATA[<h1 id="一"><a href="#一" class="headerlink" title="一"></a>一</h1><p><img src="/posts/10769/.png"></p><h1 id="二"><a href="#二" class="headerlink" title="二"></a>二</h1><p><img src="/posts/10769/.png"></p><h1 id="三"><a href="#三" class="headerlink" title="三"></a>三</h1><p><img src="/posts/10769/.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chinese_LLaMA2</title>
      <link href="/posts/15520.html"/>
      <url>/posts/15520.html</url>
      
        <content type="html"><![CDATA[<h1 id="Chinese-LLaMA2"><a href="#Chinese-LLaMA2" class="headerlink" title="Chinese_LLaMA2"></a>Chinese_LLaMA2</h1><p>目前有一种很多人认同的观点：预训练学知识，指令微调学格式，强化学习对齐人类偏好，LIMA等论文算是这一观点的证据。（LIMA: Less Is More for Alignment这篇文章是Meta的一篇工作，作者提出了一个假设，即”大模型绝大部分知识已经在预训练阶段学习到了，因此我们只需要很少一部分精选的instructions去tuning模型，就能使得模型产生高质量的内容“，如标题所说less is more。在实验部分，作者在LLaMA-65B模型上仅仅使用1000个精心挑选的Instructions进行tuning，甚至也不用进行强化学习RLHF训练，就能达到GPT-4的效果。但是这一切的前提是预训练的大模型的参数量要足够大，预训练的数据量要足够多，像The False Promise of Imitating Proprietary LLMs这篇工作中指出的，13B的llama+100k的instruction tuning是不够的。）</p><p>为了更好地学习大语言模型，本人参考chinese-llama-alpaca-2项目，基于llama-2-7B模型进行了词表扩充、增量预训练、SFT、RLAIF等试验，并尝试了llvm、TGI、llama.cpp等多种推理部署手段，记录于本篇博客之中。</p><h2 id="扩充中文词表"><a href="#扩充中文词表" class="headerlink" title="扩充中文词表"></a>扩充中文词表</h2><p>LLaMA2词表中的中文token比较少（只有几百个）。这将导致了两个问题：</p><ul><li>LLaMA2 原生tokenizer词表中仅包含少量中文字符，在对中文字进行tokenzation时，一个中文汉字往往被切分成多个token（2-3个Token才能组合成一个汉字），显著降低编解码的效率。</li><li>预训练中没有出现过或者出现得很少的语言学习得不充分。</li></ul><p>为了解决这些问题，我们可能就需要进行中文词表扩展。比如：在中文语料库上训练一个中文tokenizer模型，然后将中文 tokenizer 与 LLaMA2 原生的 tokenizer 进行合并，通过组合它们的词汇表，最终获得一个合并后的 tokenizer 模型。</p><p>因此这一节主要记录如何使用 SentencePiece 基于中文语料训练一个中文分词模型，以及如何将两个tokenizer合并。</p><h3 id="数据准备及清洗"><a href="#数据准备及清洗" class="headerlink" title="数据准备及清洗"></a>数据准备及清洗</h3><p>常用的文本预训练数据集有如下几种：</p><table><thead><tr><th align="center">数据集</th><th align="center">规模</th></tr></thead><tbody><tr><td align="center">BooksCorpus</td><td align="center">2.2 GB + 37 GB</td></tr><tr><td align="center">Wikipedia</td><td align="center">21.23 GB</td></tr><tr><td align="center">CommonCrawl</td><td align="center">&gt; PB</td></tr><tr><td align="center">ROOT</td><td align="center">1.6 TB</td></tr><tr><td align="center">The Pile</td><td align="center">825GB</td></tr><tr><td align="center">悟道</td><td align="center">3 TB</td></tr><tr><td align="center">CLUE</td><td align="center">100 GB</td></tr><tr><td align="center">MNBVC</td><td align="center">2.18 TB</td></tr></tbody></table><p>常用的代码预训练数据集有如下几种：</p><table><thead><tr><th align="center">数据集</th><th align="center">规模</th></tr></thead><tbody><tr><td align="center">CodeSearchNet</td><td align="center">17 GB</td></tr><tr><td align="center">CodeNet</td><td align="center">8 GB</td></tr><tr><td align="center">THEPILE</td><td align="center">825 GB</td></tr><tr><td align="center">thestack</td><td align="center">3100 GB</td></tr><tr><td align="center">BigQuery</td><td align="center">340 GB</td></tr><tr><td align="center">BIGPYTHON</td><td align="center">217 GB</td></tr><tr><td align="center">CodeParrot</td><td align="center">180 GB</td></tr><tr><td align="center">GCPY</td><td align="center"></td></tr></tbody></table><p>构造好txt版本的预训练数据集之后，需要对数据进行简单的清洗，去除文件中的所有空行及特殊字符，保证每一行都是一个语义完整的段落。接下来就是参考Chinese-LLaMA-Alpaca项目将LLaMA原本的tokenizer和我们训练好的中文tokenizer进行合并。</p><h2 id="中文增量预训练（基于lora）"><a href="#中文增量预训练（基于lora）" class="headerlink" title="中文增量预训练（基于lora）"></a>中文增量预训练（基于lora）</h2><h2 id="chat-instructions-SFT（基于lora）"><a href="#chat-instructions-SFT（基于lora）" class="headerlink" title="chat&#x2F;instructions SFT（基于lora）"></a>chat&#x2F;instructions SFT（基于lora）</h2><p>常用的中文指令微调数据集有如下几种：</p><table><thead><tr><th align="center">数据集</th><th align="center">规模</th></tr></thead><tbody><tr><td align="center">alpaca</td><td align="center">53.8 MB</td></tr><tr><td align="center">BELLE</td><td align="center">5.5 GB</td></tr><tr><td align="center">CBLUE</td><td align="center">870 MB</td></tr><tr><td align="center">COIG</td><td align="center">338 MB</td></tr><tr><td align="center">firefly</td><td align="center">1.2 GB</td></tr><tr><td align="center">MOSS</td><td align="center">2.7 MB</td></tr><tr><td align="center">OL-CC</td><td align="center">9.8 MB</td></tr><tr><td align="center">pCLUE</td><td align="center">1.2 GB</td></tr></tbody></table><h2 id="instructions-RLAIF"><a href="#instructions-RLAIF" class="headerlink" title="instructions RLAIF"></a>instructions RLAIF</h2>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLaMa2</title>
      <link href="/posts/27704.html"/>
      <url>/posts/27704.html</url>
      
        <content type="html"><![CDATA[<h1 id="LLAMA2：预训练-SFT-RLHF详解（官方）及对话指令SFT-LORA全流程记录（自己）"><a href="#LLAMA2：预训练-SFT-RLHF详解（官方）及对话指令SFT-LORA全流程记录（自己）" class="headerlink" title="LLAMA2：预训练+SFT+RLHF详解（官方）及对话指令SFT+LORA全流程记录（自己）"></a>LLAMA2：预训练+SFT+RLHF详解（官方）及对话指令SFT+LORA全流程记录（自己）</h1><p><img src="/posts/27704/LLAMA.png" alt="LLAMA.png"></p><p>LLAMA2 训练流程：</p><ul><li>先经过自监督学习训练，得到llama2基座模型</li><li>再经过SFT再有标签的数据上进行有监督学习训练</li><li>再进行RLHF，其中使用拒绝采样和PPO算法</li><li>在RLHF流程中，使用到由用户偏好数据训练得到的两个RM，对RLHF的模型评判，反馈训练</li></ul><h2 id="Pretraining"><a href="#Pretraining" class="headerlink" title="Pretraining"></a>Pretraining</h2><p>预训练阶段需要大量的数据，数据的量级往往是nT级别，通过预训练可以让模型学习到大量的知识。</p><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>LLAMA2以LLAMA1中描述的预训练方法为基础，采用了optimized auto-regressive transformer。但是做了以下优化：1、进行了更鲁棒的数据清洗。2、更新了数据，使得总token数增加了40%（两万亿）。3、将上下文长度翻倍，并使用了grouped-query attention（GQA）来提高大模型推理的可扩展性。对比如下图所示：</p><p><img src="/posts/27704/compare.png" alt="compare.png"></p><p>关于<font color="red">GQA</font>：在Transformer的decoder中每一个timestep都要将之前一个timestep的k,v保存到cache中，这就是KV Cache。这种方法对于小模型是没有问题的，但是遇到大模型的时候就行不通了——我们记transformer模型的层数为$l$，隐藏层维度为$h$，训练数据的批次大小为$b$，输入序列长度为$s$，输出序列长度为$n$，并且以fp16来保存KV Cache，那么<font color="red">KV cache的峰值显存占用大小为</font>$2\timesb\times(s+n)\timesh\timesl\times2$其中第一个2表示k、v，第二个2表示fp16占用的2个bytes，稍微带入计算就知道这个大小仿佛是在开玩笑，因此必须对MHA方法进行改进，大致有两种改法，如下图所示：</p><p><img src="/posts/27704/GQA.png" alt="GQA.png"></p><p>首先是原始的 **MHA(Multi-Head Attention)**，QKV 三部分有相同数量的头，且一一对应。每次做 Attention，head1 的 QKV 就做好自己运算就可以，输出时各个头加起来就行。</p><p>而 MQA 则是，让 <strong>Q 仍然保持原来的头数</strong>，但 <strong>K 和 V 只有一个头</strong>，相当于所有的 Q 头共享一组 K 和 V 头，所以叫做 Multi-Query 了。实现改变了会不会影响效果呢？确实会影响但相对它能带来的收益，性能的些微降低是可以接受的。能带来多大的收益呢，实验发现一般能提高 30%-40% 的吞吐。收益主要就是由降低了 KV cache 带来的。实际上 MQA 运算量和 MHA 是差不多的，可理解为<strong>读取一组 KV 头</strong>之后，<strong>给所有 Q 头用</strong>，但因为之前提到的内存和计算的不对称，所以是有利的。</p><p>而 GQA 呢，是 MHA 和 MQA 的折衷方案，既不想损失性能太多，又想获得 MQA 带来的推理加速好处。具体思想是，不是所有 Q 头共享一组 KV，而是<strong>分组一定头数 Q 共享一组 KV</strong>，比如上面图片就是两组 Q 共享一组 KV。以上。</p><h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><table><thead><tr><th align="center">设置</th><th align="center">设置值</th></tr></thead><tbody><tr><td align="center">架构</td><td align="center">standard transformer architecture (Vaswani et al., 2017)</td></tr><tr><td align="center">pre-normalization</td><td align="center">RMSNorm (Zhang and Sennrich, 2019)</td></tr><tr><td align="center">activation function</td><td align="center">SwiGLU (Shazeer, 2020)</td></tr><tr><td align="center">positional embedding</td><td align="center">rotary positional embeddings (RoPE, Su et al. 2022)</td></tr><tr><td align="center">optimizer</td><td align="center">AdamW (Loshchilov and Hutter, 2017)</td></tr><tr><td align="center">β1</td><td align="center">0.9</td></tr><tr><td align="center">β2</td><td align="center">0.95</td></tr><tr><td align="center">eps</td><td align="center">10 ^ −5</td></tr><tr><td align="center">schedule</td><td align="center">cosine learning rate schedule</td></tr><tr><td align="center">warmup</td><td align="center">2000 steps，decay final learning rate down to 10% of the peak learning rate</td></tr><tr><td align="center">weight decay</td><td align="center">0.1</td></tr><tr><td align="center">gradient clipping</td><td align="center">1.0</td></tr><tr><td align="center">tokenizer</td><td align="center">bytepair encoding (BPE，Sennrich et al., 2016) &amp;&amp; SentencePiece (Kudo and Richardson, 2018)</td></tr><tr><td align="center">vocabulary size</td><td align="center">32k tokens</td></tr></tbody></table><h3 id="训练结果评估"><a href="#训练结果评估" class="headerlink" title="训练结果评估"></a>训练结果评估</h3><p>作者对预训练模型进行了多种评估：</p><ul><li>代码：评估了我们的模型在HumanEval和MBPP上的平均pass@1得分；</li><li>常识推理：我们评估了PIQA、SIQA、HellaSwag、WinoGrande、ARC简单和挑战、OpenBookQA和CommonsenseQA的平均得分。对于CommonsenseQA，我们评估了7-shot结果，对于其他所有基准测试，我们评估了0-shot结果；</li><li>World Knowledge：我们评估了 NaturalQuestions 和 TriviaQA 的 5-shot 性能；</li><li>阅读理解：我们评估了在SQuAD、QuAC 和 BoolQ 上的0-shot平均值；</li><li>数学：我们评估了GSM8K（8个样本）和MATH（4个样本）基准测试的平均结果</li><li>Popular Aggregated Benchmarks：我们评估了MMLU（5个样本）、Big Bench Hard（3个样本）和AGI Eval（3-5个样本）的整体结果。对于AGI Eval，我们仅评估英语任务并报告平均结果。</li></ul><p>总的来说LLAMA2超过了所有的开源模型，但是在预训练阶段没有超过任何一个著名的闭源模型。</p><h2 id="Supervised-Fine-Tuning"><a href="#Supervised-Fine-Tuning" class="headerlink" title="Supervised Fine Tuning"></a>Supervised Fine Tuning</h2><p>在SFT阶段的最开始，使用的是《Scaling instruction-finetuned language models》这篇论文中贡献的指令微调数据集。</p><p>作者发现现有的指令微调数据集虽然很多，但是在多样性和数据质量上都难以令人满意，通过实验作者发现只需要10^4这个量级的高质量、高多样性的指令微调数据就足以获得高质量的结果了，因此作者只构建了27540条指令数据（自己的注释以及对其他数据集的筛选）。此外，标注人员的标注质量会很大程度地影响模型的性能。作者用微调过的模型生成的指令跟标注人员手写的指令进行了对比，发现两者的质量相当。</p><table><thead><tr><th align="center">设置</th><th align="center">设置值</th></tr></thead><tbody><tr><td align="center">schedule</td><td align="center">cosine learning rate schedule</td></tr><tr><td align="center">initial learning rate</td><td align="center">2 x 10 ^ -5</td></tr><tr><td align="center">weight decay</td><td align="center">0.1</td></tr><tr><td align="center">batch size</td><td align="center">64</td></tr><tr><td align="center">sequence length</td><td align="center">4096 tokens</td></tr><tr><td align="center">sample</td><td align="center">由一个 prompt 和一个 answer 组成</td></tr><tr><td align="center">训练数据集</td><td align="center">所有prompt和answer都拼接起来，用一个特殊的token将两者区分开</td></tr><tr><td align="center">objective</td><td align="center">使用自回归目标，将来自prompt的token损失置零，只对answer token反向传播</td></tr><tr><td align="center">fine-tune epochs</td><td align="center">2</td></tr></tbody></table><p>LLAMA2分为基础版本和chat版本，这篇文章主要描述了基础版本，因此没有chat版本在对话数据上做SFT的描述。</p><h2 id="Reinforcement-Learning-with-Human-Feedback"><a href="#Reinforcement-Learning-with-Human-Feedback" class="headerlink" title="Reinforcement Learning with Human Feedback"></a>Reinforcement Learning with Human Feedback</h2><p>RLHF被应用在微调过的大语言模型上，目的是进一步让大语言模型的行为与<font color="red">人类偏好以及指令遵循</font>一致。作者首先收集了人类偏好数据（对两个模型的输出进行二元选择，挑出喜欢的那一个），然后利用人类反馈训练一个奖励模型，最后用奖励模型微调大语言模型。</p><h3 id="人类偏好数据收集"><a href="#人类偏好数据收集" class="headerlink" title="人类偏好数据收集"></a>人类偏好数据收集</h3><p>首先要求注释员编写一个prompt，然后根据提供的标准在两个模型响应中进行选择。为了最大化收集的prompt的多样性，给定prompt的两个响应是从两个不同的模型变体中采样的，并且改变了温度超参数。除了这种选择之外，还要求标注者对他们选择的回答和备选回答之间的偏好程度进行标注：明显更好，更好，稍微更好以及几乎没有区别。</p><h3 id="奖励模型建模"><a href="#奖励模型建模" class="headerlink" title="奖励模型建模"></a>奖励模型建模</h3><p>以一个prompt和它的响应作为输入，输出一个代表响应质量的标量。由于safety和helpfulness在有些时候时冲突的，因此作者训练了<font color="red">两个不同的奖励模型</font>，一个关注有用性，一个关注安全性。奖励模型是从预训练模型初始化来的，架构和超参数都完全一样，仅仅只将预测下一个token的分类头变成了预测质量评价标量的回归头。</p><p>作者将收集到的成对人类偏好数据转换为二元排名标签格式（即选择和拒绝），并确保所选响应的得分高于其余的响应。使用的损失函数是 binary ranking loss：<br>$$<br>\mathcal{L}_{ranking}&#x3D;-log(\sigma(r_\theta(x,y_c)-r_\theta(x,y_r)))<br>$$<br>其中$r_\theta(x,y)$代表使用模型权重$\theta$对提示x和响应y进行评分的标量分数。$y_c$是注释者选择的首选回复，而$y_r$是被拒绝的对应回复。这个评分用于训练奖励模型，以将人类偏好转化为二元排名标签格式，并确保首选回复的得分高于被拒绝的回复。此外，由于作者设置了四种偏好程度，可以利用这些信息来明确教导奖励模型为具有更大差异的生成结果分配更不一致的分数，因此对损失函数进行了修改：<br>$$<br>\mathcal{L}_{ranking}&#x3D;-log(\sigma(r_\theta(x,y_c)-r_\theta(x,y_r)-m(r)))<br>$$<br>$m(r)$是根据偏好评分来确定的离散函数。对于具有不同响应的对，使用较大的值，而对于具有相似响应的对，使用较小的值。</p><p>训练细节如下所示：</p><table><thead><tr><th align="center">设置</th><th align="center">设置值</th></tr></thead><tbody><tr><td align="center">epoch</td><td align="center">1</td></tr><tr><td align="center">maximum learning rate</td><td align="center">5 x 10 ^ -6（70B）&amp;&amp; 1 x 10 ^ -5（others）</td></tr><tr><td align="center">schedule</td><td align="center">cosine learning rate schedule</td></tr><tr><td align="center">minimum learning rate</td><td align="center">10% of maximum</td></tr><tr><td align="center">warm up</td><td align="center">3% of total steps</td></tr><tr><td align="center">batch size</td><td align="center">512 pairs</td></tr></tbody></table><p>总的来说，meta的两个奖励模型要超过所有baseline模型，包括GPT-4.</p><h3 id="迭代化微调"><a href="#迭代化微调" class="headerlink" title="迭代化微调"></a>迭代化微调</h3><p>作者尝试了两种主要的RLHF微调算法：</p><ol><li>Proximal Policy Optimization（PPO）算法，由Schulman等人于2017年提出；</li><li>Rejection Sampling fine-tuning ：从模型中采样K个输出，使用奖励模型选择出最佳候选者，进一步使用选定的输出进行梯度更新。<font color="red">这种方法将获得最高奖励分数的样本视为新的标准，然后在这个新的排名样本集上进行模型的微调，加强奖励</font>。</li></ol><p>这两种 RL 的方法主要的区别在于：</p><ol><li><p>宽度：在拒绝抽样中，模型对于给定的提示会探索K个样本，而在PPO中，只生成一个样本；</p></li><li><p>深度：在PPO中，训练的每一步中，样本是基于上一步梯度更新后的更新模型策略的函数。而在拒绝抽样的微调中，我们会对初始模型策略生成的所有输出进行抽样，以收集新的数据集，然后进行类似于SFT的微调。然而，由于我们应用了迭代的模型更新，这两种强化学习算法之间的基本差异变得不那么明显。</p></li></ol><table><thead><tr><th align="center">设置</th><th align="center">设置值</th></tr></thead><tbody><tr><td align="center">optimizer</td><td align="center">AdamW</td></tr><tr><td align="center">β1</td><td align="center">0.9</td></tr><tr><td align="center">β2</td><td align="center">0.95</td></tr><tr><td align="center">eps</td><td align="center">10 ^ −5</td></tr><tr><td align="center">weight decay</td><td align="center">0.1</td></tr><tr><td align="center">gradient clipping</td><td align="center">1.0</td></tr><tr><td align="center">fixed learning rate</td><td align="center">10 ^ -6</td></tr><tr><td align="center">PPO batch size</td><td align="center">512</td></tr><tr><td align="center">PPO clip threshold</td><td align="center">0.2</td></tr><tr><td align="center">KL penalty</td><td align="center">0.01（7B，13B）&amp;&amp; 0.005（34B，70B）</td></tr><tr><td align="center">iterations</td><td align="center">200-400</td></tr></tbody></table><p>作者给出了一个重要的结论：<font color="red">SFT不能替代RLHF</font>（We posit that the superior writing abilities of LLMs, as manifested in surpassing human annotators in certain tasks, are fundamentally driven by RLHF, as documented in Gilardi et al. (2023) and Huang et al. (2023)）。</p><h2 id="System-Message-for-Multi-Turn-Consistency"><a href="#System-Message-for-Multi-Turn-Consistency" class="headerlink" title="System Message for Multi-Turn Consistency"></a>System Message for Multi-Turn Consistency</h2><p>作者详细描述了他们是如何通过Ghost Attention（GAtt）方法改进多轮对话一致性问题的。</p><p>在对话的场景下，我们通常需要设置system prompt，比如让他扮演xx角色，或者按照什么风格说话，作者发现几轮对话下来，模型容易忘记这样的“系统设定”。</p><p>假定有一个多轮对话数据集，用户和assistant之间交替对话，现将这个system prompt插入到每一轮对话中的用户消息中。然后用最新的RLHF模型从这个合成数据中选择样本，然后对于选择出来的样本，只在最开始保留system prompt，之前在每一轮对话中都插入了system prompt，现在要都移除掉，不然这个会跟之前模型RLHF以及SFT阶段不一致，为此，作者会把之前轮数的上下文的loss置为0（我的理解是依旧类似于SFT中把prompt的loss置为0）。最后，在训练过程中让模型根据这个新的样本数据进行微调，以便模型在后续的对话中能够继续遵循system prompt进行回答。</p><h2 id="safety"><a href="#safety" class="headerlink" title="safety"></a>safety</h2><p>略</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLM_inference_optimze</title>
      <link href="/posts/40640.html"/>
      <url>/posts/40640.html</url>
      
        <content type="html"><![CDATA[<h1 id="大模型推理优化方法整理"><a href="#大模型推理优化方法整理" class="headerlink" title="大模型推理优化方法整理"></a>大模型推理优化方法整理</h1><table><thead><tr><th align="center">优化技术</th><th align="center">优化原理</th></tr></thead><tbody><tr><td align="center">硬件升级</td><td align="center">硬件的性能和特性对于模型推理速度和效率有着重要影响，通过硬件升级，大语言模型可以实现更高的推理速度。</td></tr><tr><td align="center">子图融合技术</td><td align="center">子图融合通过将计算图中的一系列操作合并为更大的操作，减少计算和内存开销，以提高推理性能。它通过优化计算流程来加速模型推理。</td></tr><tr><td align="center">模型压缩技术</td><td align="center">模型压缩技术包括稀疏化、参数剪枝、量化、知识蒸馏等方法，通过减小模型的尺寸和计算量，提高模型在推理阶段的速度和资源效率。</td></tr><tr><td align="center">并行化技术</td><td align="center">并行化技术包括数据并行化、模型并行化、管道并行等方法，利用多核 CPU、多个 GPU 或其他硬件资源，同时处理多个数据样本或模型部分，以提高推理效率。</td></tr><tr><td align="center">Transformer 结构优化</td><td align="center">Transformer 结构优化通过对 Transformer 模型的各个组件（如注意力机制、前馈网络等）进行优化，减少计算量、参数数量和内存开销，以加速推理。</td></tr><tr><td align="center">动态批处理</td><td align="center">动态批处理技术根据输入数据的长度和特性自适应地调整批处理大小，以提高计算资源的利用率，适应不同输入情况，从而提高推理性能。</td></tr></tbody></table><h2 id="硬件升级"><a href="#硬件升级" class="headerlink" title="硬件升级"></a>硬件升级</h2><h3 id="NVIDIA-H100-PCIe"><a href="#NVIDIA-H100-PCIe" class="headerlink" title="NVIDIA H100 PCIe"></a>NVIDIA H100 PCIe</h3><p>相比A100，H100在训练和推理上都有了很大的提升，具体对比如下图所示：</p><p><img src="/posts/40640/H100.png" alt="H100.png"></p><h2 id="子图融合（subgraph-fusion）"><a href="#子图融合（subgraph-fusion）" class="headerlink" title="子图融合（subgraph fusion）"></a>子图融合（subgraph fusion）</h2><p>Subgraph Fusion（子图融合）是一种大语言模型推理加速技术。在深度学习中，模型通常以计算图的形式表示，其中每个节点表示一个操作（比如加法、乘法、激活函数等），边表示数据流向。在推理阶段，为了执行模型，计算图中的各个节点会逐一执行，导致计算和内存开销较大。因此，子图融合技术主要针对深度学习模型的计算图进行优化，其目标是将计算图中的一系列连续操作（子图）合并为更大的操作，从而减少多余的计算和数据传输。通过将多个操作融合为一个更大的操作，可以减少操作之间的开销，同时也有助于提高并行性。</p><h3 id="FasterTransformer"><a href="#FasterTransformer" class="headerlink" title="FasterTransformer"></a>FasterTransformer</h3><h3 id="DeepSpeed"><a href="#DeepSpeed" class="headerlink" title="DeepSpeed"></a>DeepSpeed</h3><h3 id="MLC-LLM"><a href="#MLC-LLM" class="headerlink" title="MLC LLM"></a>MLC LLM</h3><h2 id="模型压缩（Model-Compression）"><a href="#模型压缩（Model-Compression）" class="headerlink" title="模型压缩（Model Compression）"></a>模型压缩（Model Compression）</h2><p>在大型语言模型的推理阶段，模型压缩技术是一种关键的优化手段，旨在减小模型的尺寸和计算量，从而提高推理速度和降低资源消耗。这类方法可以在精度损失很小的情况下实现模型小型化，主要包括3类手段：稀疏、量化、蒸馏。</p><h3 id="稀疏-Sparsity"><a href="#稀疏-Sparsity" class="headerlink" title="稀疏(Sparsity)"></a>稀疏(Sparsity)</h3><h3 id="量化-Quantization"><a href="#量化-Quantization" class="headerlink" title="量化(Quantization)"></a>量化(Quantization)</h3><h3 id="蒸馏-Distillation"><a href="#蒸馏-Distillation" class="headerlink" title="蒸馏(Distillation)"></a>蒸馏(Distillation)</h3><h2 id="并行化（Parallelism）"><a href="#并行化（Parallelism）" class="headerlink" title="并行化（Parallelism）"></a>并行化（Parallelism）</h2><p>在提及推理的并行化技术时，往往会提到3D Parallelism，它是指在三个维度上实现并行化的策略。这三个维度分别是：数据并行，张量并行和流水线并行。这种并行化方法旨在充分利用硬件资源，加速模型的推理过程，从而提高系统的性能和效率。</p><p><img src="/posts/40640/3Dparallelism.png" alt="3Dparallelism.png"></p><h3 id="数据并行-Data-Parallelism-DP"><a href="#数据并行-Data-Parallelism-DP" class="headerlink" title="数据并行 (Data Parallelism, DP)"></a>数据并行 (Data Parallelism, DP)</h3><h3 id="张量并行-Tensor-Parallelism-TP"><a href="#张量并行-Tensor-Parallelism-TP" class="headerlink" title="张量并行(Tensor Parallelism, TP)"></a>张量并行(Tensor Parallelism, TP)</h3><h3 id="流水线并行-Pipeline-Parallelism-PP"><a href="#流水线并行-Pipeline-Parallelism-PP" class="headerlink" title="流水线并行(Pipeline Parallelism, PP)"></a>流水线并行(Pipeline Parallelism, PP)</h3><h2 id="Transformer-结构优化"><a href="#Transformer-结构优化" class="headerlink" title="Transformer 结构优化"></a>Transformer 结构优化</h2><p>该类方法主要通过优化 Transformer 的结构以实现推理性能的提升。</p><h3 id="FlashAttention"><a href="#FlashAttention" class="headerlink" title="FlashAttention"></a>FlashAttention</h3><p>FlashAttention的作者们发现，这些Efficient Transformer虽然能够有效降低模型的FLOPS，但它们的计算速度并没有显著降低。导致该现象的根本原因是模型的计算速度除了与FLOPS有很大关系，同时也与MAC（Memory Access Cost，存储访问开销）有关。尤其是当计算本身已经很高效的情况下，MAC的开销更加不能忽略。MAC的开销主要来自两方面。一是从存储中读取数据；二是向存储中写数据。与CPU的情况类似，在GPU中，当需要计算时，需将数据从显存中读取并由计算单元进行计算操作。在计算完毕后，再写回到显存中。(这与ShuffleNet v2 十分类似。当时很多轻量化模型涌现，也是只关注FLOPS。ShuffleNet v2中却强调了MAC，这与FlashAttention背后的研究动机异曲同工。）</p><p>我们可以根据计算的密集程度，将操作分为两类：计算密集型和存储访问密集型。前者耗时主要在于计算本身，对显存的读写几乎可以忽略。例如大矩阵乘法、大channel size的卷积操作等。对于这类操作，它们的FLOPS决定了计算的时耗。后者耗时主要集中在存储的访问上，计算本身耗时较低。例如逐元素操作（ReLU，Dropout等）、以及Reduce操作（求和、softmax、BatchNorm等）。对于这类操作，它们的MAC决定了计算的时耗。</p><p>对于一个transformer而言，主要有两个部分需要关注：Attention以及FFN，后者是一个计算密集型模块，在这篇工作中没有关注，前者中有一些操作是存储访问密集型的，因此这篇工作主要关注Attention模块。</p><h4 id="标准Attention"><a href="#标准Attention" class="headerlink" title="标准Attention"></a>标准Attention</h4><p>首先我们回顾一下标准 Attention 的操作:<br>$$<br>\text{Attention}(Q,K,V)&#x3D;\text{softmax}\biggl(\frac{QK^\top}{\sqrt{d_k}}\biggr)V<br>$$<br>其中$Q,K,V\in\mathbb{R}^{N\times d}(N\text{表示序列长度，}d\text{表示维度})$，上述公式可拆解为：<br>$$<br>\mathbf{S}&#x3D;\mathbf{Q}\mathbf{K}^\top\in\mathbb{R}^{N\times N},\quad\mathbf{P}&#x3D;\mathrm{softmax}(\mathbf{S})\in\mathbb{R}^{N\times N},\quad\mathbf{O}&#x3D;\mathbf{P}\mathbf{V}\in\mathbb{R}^{N\times d}<br>$$<br>其中$\mathbf{S},\mathbf{P}$（对于decoder来说还有 mask）的空间复杂度都是$O(N^2)$，另外还有几个存储访问密集型操作：对$\mathbf{S}$的 scale, mask 和 softmax 操作，对$\mathbf{P}$的 dropout 操作。下图算法展示了 HBM 与 SRAM 之间的数据传输过程:</p><p><img src="/posts/40640/FlashAttention.png" alt="FlashAttention.png"></p><p>以 A100 (40GB HBM) 为例，内存层次结构分为三层：GPU SRAM（19 TB&#x2F;s，20 MB），GPU HBM（1.5 TB&#x2F;s，40 GB），CPU DRAM（12.8 GB&#x2F;s，&gt;1 TB）。SRAM内存分布在108个流式多处理器(SMs)上，每个处理器192KB。片上SRAM比HBM快得多，但比HBM小得多，在计算方面，使用Tensor Core的BFLOAT16 的理论峰值吞吐量为 312 TFLOPS。GPU 的典型操作方式是使用大量的线程来执行一个操作，这个操作被称为内核。输入从HBM加载到寄存器和SRAM，并在计算后写回HBM。</p><p>不难发现，大矩阵对HBM进行重复读写是一个主要瓶颈。为此 FlashAttention 提出了两种方法来分别解决上述问题：<strong>tiling 和 recomputation：</strong></p><ul><li>tiling：注意力计算被重新构造，将输入分割成块，并通过在输入块上进行多次传递来递增地执行softmax操作。</li><li>recomputation：存储来自前向的 softmax 归一化因子，以便在反向中快速重新计算芯片上的 attention，这比从HBM读取中间矩阵的标准注意力方法更快。</li></ul><h4 id="tiling技术"><a href="#tiling技术" class="headerlink" title="tiling技术"></a>tiling技术</h4><p>之前提到了FlashAttention的核心是对Self-Attention的计算进行分块计算。对于矩阵乘法而言，可以直接通过分块来达到分块计算的目的。但Self-Attention中有 softmax操作，而 softmax 的分母包含与所有元素相关的求和项，所以对Self-Attention进行分块计算的真正难点在于对 softmax 的分块计算。</p><p>假设有维度为n的向量$x\in \mathbb{R}^n$我们知道softmax的计算公式如下：<br>$$<br>\text{softmax}(x_{i})&#x3D;{\frac{e^{x_{i}}}{\sum_{j&#x3D;1}^{n}e^{x_{j}}}}<br>$$<br>但是由于计算公式中包含指数项，在x较大的时候有溢出的可能，因此大多数框架采用稳定版的softmax，如下所示：<br>$$<br>\begin{aligned}<br>m(x)&amp;&#x3D;\text{max}(x_1,x_2,\ldots,x_n)\\<br>f(x)&amp;&#x3D;[e^{x_1-m(x)},\ldots,e^{x_n-m(x)}]\\<br>l(x)&amp;&#x3D;\sum_{i&#x3D;1}^{n} f(x_i)\\<br>\text{softmax}(x_i)&amp;&#x3D;\frac{f(x_i)}{l(x)}<br>\end{aligned}<br>$$<br>值得注意的是上面这个公式的分子是向量，分母是标量，这是一种逐元素的除法，是存储访问密集型操作。接下来我们介绍如何对softmax进行分块计算。</p><p>对于一个维度为 2n 的向量，将其一分为二分块，即：$x&#x3D;[x^{(1)},x^{(2)}]$。我们先计算前半部分的局部softmax，当有：<br>$$<br>\begin{aligned}<br>m(x^{(1)})&amp;&#x3D;\text{max}(x^{(1)}_1,x^{(1)}_2,\ldots,x^{(1)}_n)\\<br>f(x^{(1)})&amp;&#x3D;[e^{x^{(1)}_1-m(x^{(1)})},\ldots,e^{x^{(1)}_n-m(x^{(1)})}]\\<br>l(x^{(1)})&amp;&#x3D;\sum_{i&#x3D;1}^{n} f(x^{(1)}_i)\\<br>\text{softmax}(x^{(1)}_i)&amp;&#x3D;\frac{f(x^{(1)}_i)}{l(x^{(1)})}<br>\end{aligned}<br>$$</p><p>显然，这个局部softmax与最终的softmax不等，因此我们需要保存一些额外变量，在处理完后半部分之后更新这个局部的softmax值。我们需要保存的变量有：$m(x^{(1)})，l(x^{(1)})，m_{max}，l_{all}$，前两者如公式所写，这两个标量的保存要比保存整个向量的开销小得多，后两者分别表示当前最大值和当前全局指数求和项。</p><p>接下来，用同样的方式处理向量$x^{(2)}$：<br>$$<br>\begin{aligned}<br>m(x^{(2)})&amp;&#x3D;\text{max}(x^{(2)}_1,x^{(2)}_2,\ldots,x^{(2)}_n)\\<br>f(x^{(2)})&amp;&#x3D;[e^{x^{(2)}_1-m(x^{(2)})},\ldots,e^{x^{(2)}_n-m(x^{(2)})}]\\<br>l(x^{(2)})&amp;&#x3D;\sum_{i&#x3D;1}^{n} f(x^{(2)}_i)\\<br>\text{softmax}(x^{(2)}_i)&amp;&#x3D;\frac{f(x^{(2)}_i)}{l(x^{(2)})}<br>\end{aligned}<br>$$<br>然后用新得到的变量更新之前的变量：<br>$$<br>\begin{aligned}<br>m_{max}^{new}&amp;&#x3D;max(m_{max},m(x^{(2)}))\\<br>l_{all}^{new}&amp;&#x3D;e^{m_{max}-m_{max}^{new}}l_{all}+e^{m_{x^{(2)}}-m_{max}^{new}}l(x^{(2)})<br>\end{aligned}<br>$$<br>这两个公式也很简单，第一个无需赘述，第二个变量中之所以是局部而非全局只是因为除以的最大值是局部最大值，因此将其乘以局部最大值的指数再除以新的全局最大值的指数即可。这时，如果想将局部softmax变为全局softmax，当有：<br>$$<br>\begin{aligned}<br>f^{new}(x^{(2)})&amp; &#x3D;f(x^{(2)})\cdot e^{m(x^{(2)})-m_{max}^{new}}  \\<br>&amp;&#x3D;[e^{x_{1}^{(2)}-m(x^{(2)})},\ldots,e^{x_{B}^{(2)}-m(x^{(2)})}]\cdot e^{m(x^{(2)})-m_{max}^{new}} \\<br>&amp;&#x3D;[e^{x_{1}^{(2)}-m_{max}^{new}},\ldots,e^{x_{B}^{(2)}-m_{max}^{new}}]\\<br>l^{new}(x^{(2)})&amp;&#x3D;l_{all}^{new}<br>\end{aligned}<br>$$</p><p>基于此二式便能得到两个新的softmax：<br>$$<br>\begin{aligned}<br>\mathrm{softmax}^{(new)}(x^{(1)})&amp;&#x3D;\frac{\mathrm{softmax}(x^{(1)})\cdot l(x^{(1)})\cdot e^{m(x^{(1)})-m_{max}^{new}}}{l_{all}^{mew}}\\<br>\mathrm{softmax}^{(new)}(x^{(2)})&amp;&#x3D;\frac{\mathrm{softmax}(x^{(2)})\cdot l(x^{(2)})\cdot e^{m(x^{(2)})-m_{max}^{new}}}{l_{all}^{mew}}<br>\end{aligned}<br>$$</p><h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><p>在了解了tiling技术后，我们开始了解完整的前向传播过程，如下图所示：</p><p><img src="/posts/40640/feedforward.png" alt="feedforward.png"></p><p>其中第2行是要根据SRAM的大小M以及向量的维度d选择合适的分块大小$B_c,B_r$。</p><p>第4、5行是要将矩阵$\mathrm {Q，O}$沿着行方向分为$T_r$块，每一分块的大小为$B_r \times d$；将向量$l$ 和向量$m$分为$T_r$块，每一个子向量大小为$B_r$。将矩阵$\mathrm {K，V}$沿着行方向分为$T_c$块，每一块的大小为$B_c \times d$。如下图所示：</p><p><img src="/posts/40640/divide.png" alt="divide.png"></p><p>接下来是一个两层的循环，先遍历$\mathrm {K，V}$，再遍历$\mathrm {Q，O，l，m}$，然后按照tiling策略操作即可获得最终结果，至此，前向传播过程结束。</p><h4 id="recomputation和反向传播"><a href="#recomputation和反向传播" class="headerlink" title="recomputation和反向传播"></a>recomputation和反向传播</h4><p>在标准Attention中，有如下公式：<br>$$<br>\mathbf{S}&#x3D;\frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt{d_k}},\mathbf{P}&#x3D;\text{Softmax(}\mathbf{S}),\mathbf{O}&#x3D;\mathbf{P}\mathbf{V}<br>$$<br>根据矩阵求导法则，当有：<br>$$<br>\text{d}\mathbf{V}&#x3D;\mathbf{P}^\top\text{d}\mathbf{O}<br>$$<br>其余的变量同理。</p><p>但是FlashAttention将矩阵分成了若干个块，因此可以使用tiling策略。此外，由于$\mathbf{P}$的大小是$O(N^2)$量级，为了减小访存代价，<strong>FlashAttention选择在反向传播时重新计算，而非在前向传播中保存此矩阵</strong>（结果确实比取出来更快）。</p><h4 id="MAC分析"><a href="#MAC分析" class="headerlink" title="MAC分析"></a>MAC分析</h4><p>接下来我们来分析两种方法的访存次数，以下图为例：</p><p><img src="/posts/40640/FlashAttention.png" alt="FlashAttention.png"></p><p>在不使用FlashAttention时，对于上图的1、2、3三行，当有：</p><ul><li>第一行，读 $Q,K$ 的MAC次数为 $2Nd$ ，写 $S$ 的MAC次数为 $N^2$ 。</li><li>第二行，读 $S$ 的MAC次数为 $N^2$ ，写 $P$ 的MAC次数为 $N^2$ 。</li><li>第三行，读 $P$ 的MAC次数为 $N^2$ ，读 $V$ 的MAC次数为 $Nd$ ，写 $O$ 的MAC次数为 $Nd$ 。</li></ul><p>共计$O(Nd+N^2)$。</p><p>在使用FlashAttention时，对于上图当有：</p><ul><li>对于内循环，需要读取完整的$Q$，开销为$Nd$。</li><li>对于外循环，需要执行$T_c&#x3D;\lceil \frac{4dN}{M} \rceil$次。</li></ul><p>共计$O(N^2d^2M^{-1})$。由于M通常远大于d，因此FlashAttention会更快。</p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>FlashAttention基本可以达到2-4倍的计算加速，10-20倍的内存节省，已被广泛使用。</p><h3 id="FlashAttentionV2"><a href="#FlashAttentionV2" class="headerlink" title="FlashAttentionV2"></a>FlashAttentionV2</h3><p>尽管 FlashAttention 的速度已经达到baseline的 2-4 倍，但它仍然有相当大的改进空间。FlashAttention 仍然不如优化过的矩阵乘法 (GEMM) 运算快，仅达到理论最大 FLOPs&#x2F;s 的 25-40%。</p><p>因此研究者们又推出了 FlashAttentionV2 。FlashAttentionV2 的速度是 FlashAttention 的 2 倍，在 A100 GPU 上达到 230 TFLOPs&#x2F;s。在端到端训练 GPT 类语言模型时，FlashAttentionV2 可让训练速度高达 225 TFLOPs&#x2F;s（模型 FLOP 利用率为 72%）。</p><p>本文主要贡献和创新点为：</p><ol><li>减少了非矩阵乘法 FLOPs的数量（消除了原先频繁rescale）。虽然非矩阵乘法 FLOPs仅占总FLOPs的一小部分，但它们的执行时间较长，这是因为GPU有专用的矩阵乘法计算单元，其吞吐量高达非矩阵乘法吞吐量的16倍。因此，减少非矩阵乘法 FLOPs并尽可能多地执行matmul FLOPs非常重要。</li><li>提出了在序列长度维度上并行化。该方法在输入序列很长（此时batch size通常很小）的情况下增加了GPU利用率。即使对于单个head，也在不同的thread block之间进行并行计算。</li><li>在一个attention计算块内，将工作分配在一个thread block的不同warp上，以减少通信和共享内存读&#x2F;写。</li></ol><h4 id="GPU基础知识"><a href="#GPU基础知识" class="headerlink" title="GPU基础知识"></a>GPU基础知识</h4><p>由于FlashAttentionV2的优化偏底层一些，因此我们需要先了解一些关于GPU的基础知识。GPU在软件和硬件两个方面由低到高分别分为如下层次：</p><p><img src="/posts/40640/GPU.png" alt="GPU.png"></p><ol><li><p>从硬件角度来看：</p><ul><li>Streaming Processor（SP）：是最基本的处理单元，也就是 CUDA core。</li><li>Streaming MultiProcessor（SM）：一个SM由多个CUDA core（SP）组成，每个SM在不同GPU架构上有不同数量的CUDA core，例如Pascal架构中一个SM有128个CUDA core。</li></ul><p>SM还包括特殊运算单元，共享内存，寄存器文件和调度器等。其中寄存器和共享内存是稀缺资源，这些有限的资源就使得每个SM中active warps有非常严格的限制，也就限制了并行能力。</p></li><li><p>从软件角度来看：</p><ul><li>thread：thread是最小的执行单元，一个CUDA并行程序由多个thread来执行。</li><li>warp（线程束）：一个warp是在一个时钟周期内一起执行的一组32个线程。每个warp中的thread可以同时执行相同的指令，从而实现SIMT（单指令多线程）并行。warp是SM中最小的调度单位，一个SM可以同时处理多个warp。</li><li>thread block：一个thread block可以包含多个warp，同一个block中的thread可以同步，也可以通过shared memory进行通信。一个warp中的threads必然在同一个block中，如果block所含thread数量不是warp大小的整数倍，那么多出的那个warp中会剩余一些inactive的thread。也就是说，即使warp的thread数量不足，硬件也会为warp凑足thread，只不过这些thread是inactive状态，但也会消耗SM资源。</li><li>grid：在GPU编程中，grid是一个由多个thread block组成的二维或三维数组。grid的大小取决于计算任务的规模和thread block的大小，通常根据计算任务的特点和GPU性能来进行调整。在执行过程中，网格中的线程块会被分配到不同的SM上，以实现并行计算。</li></ul></li></ol><p><strong>Hardware和Software的联系：</strong></p><p>在执行任务时，grid中的thread block被分配到SM上，大量的thread可能被分到不同的SM上，但是一个线程块的thread只能在一个SM上调度，SM一般可以调度多个block。每个thread拥有自己的程序计数器和状态寄存器，并且可以使用不同的数据来执行指令，从而实现并行计算，这就是所谓的Single Instruction Multiple Thread。</p><p>一个CUDA core可以执行一个thread，一个SM中的CUDA core会被分成几个warp，由warp scheduler负责调度。GPU规定warp中所有thread在同一周期执行相同的指令，尽管这些thread执行同一程序地址，但可能产生不同的行为，比如分支结构。一个SM同时并发的warp是有限的，由于资源限制，SM要为每个block分配共享内存，也要为每个warp中的thread分配独立的寄存器，所以SM的配置会影响其所支持的block和warp并发数量。</p><p><strong>GPU执行模型小结：</strong></p><p>GPU有大量的threads用于执行操作（an operation，也称为a kernel）。这些thread组成了thread block，接着这些blocks被调度在SMs上运行。在每个thread block中，threads被组成了warps（32个threads为一组）。一个warp内的threads可以通过快速shuffle指令进行通信或者合作执行矩阵乘法。在每个thread block内部，warps可以通过读取&#x2F;写入共享内存进行通信。每个kernel从HBM加载数据到寄存器和SRAM中，进行计算，最后将结果写回HBM中。</p><h4 id="算法——减少了非矩阵乘法运算"><a href="#算法——减少了非矩阵乘法运算" class="headerlink" title="算法——减少了非矩阵乘法运算"></a>算法——减少了非矩阵乘法运算</h4><p>因为现代 GPU 具有专门的计算单元（例如 Nvidia GPU 上的张量核心），使得矩阵乘法速度更快，可以达到非矩阵乘法的16倍速度。为了保持高吞吐量，研究者希望在矩阵乘法 FLOP 上花费尽可能多的时间。因此他们调整了 FlashAttention 中使用的在线 softmax 技巧，以减少重新缩放操作、边界检查和因果掩码操作的数量，而无需更改输出。</p><h4 id="并行——优化thread-block"><a href="#并行——优化thread-block" class="headerlink" title="并行——优化thread block"></a>并行——优化thread block</h4><p>FlashAttention在batch和heads两个维度上进行了并行化：使用一个thread block来处理一个attention head，总共需要thread block的数量等于batch size × number of heads。每个block被调到到一个SM上运行，例如A100 GPU上有108个SMs。当block数量很大时（例如≥80），这种调度方式是高效的，因为几乎可以有效利用GPU上所有计算资源。但是在处理长序列输入时，由于内存限制，通常会减小batch size和head数量，这样并行化程度就降低了。因此，FlashAttention-2还在序列长度这一维度上进行并行化，显著提升了计算速度并提高了GPU的占用率。</p><h4 id="分区——优化warp"><a href="#分区——优化warp" class="headerlink" title="分区——优化warp"></a>分区——优化warp</h4><p>对于每个块，FlashAttention 将 K 和 V 分割到 4 个 warp 上，同时保持 Q 可被所有 warp 访问。这种方案是低效的，原因在于所有 warp 都需要将它们的中间结果写入共享内存，并同步，然后将中间结果相加。这些共享内存读写会减慢 FlashAttention 中的前向传递速度。在 FlashAttention-2 中，研究者将 Q 分割在 4 个 warp 上，同时保持 K 和 V 可被所有的 warp 访问。每个 warp 执行矩阵乘法以获得 Q K^T 的切片，然后只需与 V 的共享切片相乘就能获得相应的输出切片。这种新的方法减少了不同 warp 之间的同步和通信量，也减少了共享内存的读写。</p><p><img src="/posts/40640/flashattention2.png" alt="flashattention2.png"></p><h4 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h4><p>FlashAttention 仅支持最高 128 的头维数，这对一些模型而言并不够，因此，FlashAttention-2 支持了高达 256 的头维数，这意味着 GPT-J、CodeGen 和 CodeGen2、StableDiffusion 1.x 等模型可以使用 FlashAttention-2 来获得加速和节省内存。此外，FlashAttention-2 还支持了多查询注意力（multi-query attention, MQA）以及分组查询注意力（grouped-query attention, GQA）。它们是注意力的变体，其中多个查询头关注相同的键和值头，以减少推理过程中 KV  Cache的大小，并可以显著提高推理吞吐量。</p><h3 id="PagedAttention"><a href="#PagedAttention" class="headerlink" title="PagedAttention"></a>PagedAttention</h3><p>vLLM 是在加州大学伯克利分校开发，配备了PagedAttention的vLLM重新定义了 LLM 服务的最新技术水平：它的吞吐量比 HuggingFace Transformers 高出 24 倍，且无需更改任何模型架构。</p><h4 id="现有问题"><a href="#现有问题" class="headerlink" title="现有问题"></a>现有问题</h4><p>众所周知的，当前注意力算法在自回归解码过程中，需要将所有输入令牌的注意力键和值张量存储在GPU内存中，以生成下一个令牌，这也就是我们所说的 KV Cache，这个被存储在HBM中的缓存有以下三种缺陷：</p><ol><li>显存占用大：在 LLaMA-13B 中，缓存单个序列最多需要 1.7GB 显存。</li><li>动态变化：KV 缓存的大小取决于序列长度，这是高度可变和不可预测的。因此，这对有效管理 KV cache 挑战较大。该研究发现，由于碎片化和过度保留，现有系统浪费了 60% - 80% 的显存。</li><li>读写低效：根据前面对于GPU存储层次的介绍我们知道，HBM虽然具有比较大的存储容量，但是读写速度只有1.5T&#x2F;S，跟SRAM有着数量级的差距，因此频繁地对其进行读写势必会拖慢计算速度。</li></ol><p>因此，有效管理KV缓存是一个重大挑战。对此，研究团队发现现有系统由于碎片化和过度保留而浪费了60%至80%的内存。</p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>为了上述问题，PagedAttention应运而生，这是一种受操作系统中虚拟内存和分页经典思想启发的注意力算法。与传统的注意力算法不同，PagedAttention 允许在非连续的内存空间中存储连续的 key 和 value 。具体来说，PagedAttention 将每个序列的 KV cache 划分为块，每个块包含固定数量 token 的键和值。在注意力计算期间，PagedAttention 内核可以有效地识别和获取这些块。下面是一个KV Cache在物理空间的存储示例：</p><p><img src="/posts/40640/annimation0.gif" alt="annimation0.gif"></p><p>因为块在内存中不需要连续，因而可以用一种更加灵活的方式管理 key 和 value ，就像在操作系统的虚拟内存中一样：可以将块视为页面，将 token 视为字节，将序列视为进程。序列的连续逻辑块通过块表映射到非连续物理块中。而物理块则在生成新 token 时按需分配，下面是一个为新token分配新块并更新块表的示例：</p><p><img src="/posts/40640/annimation1.gif" alt="annimation1.gif"></p><p>在 PagedAttention 中，内存浪费只会发生在序列的最后一个块中。这使得在实践中可以实现接近最佳的内存使用，仅浪费不到 4%。这种内存效率的提升被证明非常有用，允许系统将更多序列进行批处理，提高 GPU 使用率，显著提升吞吐量。</p><p>PagedAttention 还有另一个关键优势 —— 高效的内存共享。例如在并行采样中，多个输出序列是由同一个 prompt 生成的。在这种情况下，prompt 的计算和内存可以在输出序列中共享。下面是一个并行采样的示例：</p><p><img src="/posts/40640/annimation2.gif" alt="annimation2.gif"></p><p>PagedAttention 自然地通过其块表来启动内存共享。与进程共享物理页面的方式类似，PagedAttention 中的不同序列可以通过将它们的逻辑块映射到同一个物理块的方式来共享块。为了确保安全共享，PagedAttention 会对物理块的引用计数进行跟踪，并实现写时复制（Copy-on-Write）机制。下面是一个从同一输入并行生成多个输出的示例：</p><p><img src="/posts/40640/annimation3.gif" alt="annimation3.gif"></p><p>PageAttention 的内存共享大大减少了复杂采样算法的内存开销，例如并行采样和集束搜索的内存使用量降低了 55%。这可以转化为高达 2.2 倍的吞吐量提升。在实验中，基于pagedAttention的vLLM实现了huggingface 24 倍的吞吐量，TGI 2.5 倍的吞吐量。</p><p><img src="/posts/40640/vllm.png" alt="vllm.png"></p><h3 id="补充：关于KV-Cache"><a href="#补充：关于KV-Cache" class="headerlink" title="补充：关于KV Cache"></a>补充：关于KV Cache</h3><p>生成式模型的推理过程很有特点，我们给定一个输入文本，模型会输出一个回答（长度为N），其实该过程中执行了N次推理过程。即一次推理只输出一个token，输出token会与输入tokens 拼接在一起，然后作为下一次推理的输入，这样不断反复直到遇到终止符。如下代码及图所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> LlamaForCausalLM, LlamaTokenizer</span><br><span class="line">tokenizer = LlamaTokenizer.from_pretrained(<span class="string">&quot;/data1/wt/Pretrained_Model/llama2_hf&quot;</span>)</span><br><span class="line">model = LlamaForCausalLM.from_pretrained(<span class="string">&quot;/data1/wt/Pretrained_Model/llama2_hf&quot;</span>).<span class="built_in">eval</span>()</span><br><span class="line">in_text = <span class="string">&quot;Lionel Messi is a&quot;</span></span><br><span class="line">in_tokens = torch.tensor(tokenizer.encode(in_text))</span><br><span class="line">token_eos = torch.tensor([<span class="number">198</span>])</span><br><span class="line">out_token = <span class="literal">None</span></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">while</span> out_token != token_eos:</span><br><span class="line">        in_tokens = in_tokens.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        res = model(in_tokens)</span><br><span class="line">        out_token = torch.argmax(res[<span class="string">&quot;logits&quot;</span>][:, -<span class="number">1</span>, :])</span><br><span class="line">        in_tokens = torch.cat((in_tokens, out_token.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)), -<span class="number">1</span>)</span><br><span class="line">        in_tokens = in_tokens.squeeze()</span><br><span class="line">        text = tokenizer.decode(in_tokens)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;step <span class="subst">&#123;i&#125;</span> input: <span class="subst">&#123;text&#125;</span>&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">out_text = tokenizer.decode(in_tokens)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot; Input: <span class="subst">&#123;in_text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output: <span class="subst">&#123;out_text&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="/posts/40640/clm.png" alt="clm.png"></p><p>在上面的推理过程中，每 step 内，输入一个 token序列，经过Embedding层将输入token序列变为一个三维张量[b, s, h]，经过一通计算，最后经logits层将计算结果映射至词表空间，输出张量维度为[b, s, vocab_size]。当前轮输出token与输入tokens拼接，并作为下一轮的输入tokens，反复多次。可以看出第 i+1 轮输入数据只比第 i 轮输入数据新增了一个token，其他全部相同！因此第 i+1 轮推理时必然包含了第 i 轮的部分计算。KV Cache的出发点就在这里，缓存当前轮可重复利用的计算结果，下一轮计算时直接读取缓存结果，就是这么简单，不存在操作系统中需要考虑的 Cache miss 问题。</p><p>为了实现 KV Cache，我们对代码做如下改动：</p><ol><li>在推理时新增了 past_key_values 参数，该参数就会以追加方式保存每一轮的K V值。KV Cache变量内容为((k,v), (k,v), …, (k,v))，即有 layers 个 k,v 组成的一个元组。</li><li>推理输出的token直接作为下一轮的输入，不再拼接，因为上文信息已经在 kvcache 中。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> LlamaForCausalLM, LlamaTokenizer</span><br><span class="line">tokenizer = LlamaTokenizer.from_pretrained(<span class="string">&quot;/data1/wt/Pretrained_Model/llama2_hf&quot;</span>)</span><br><span class="line">model = LlamaForCausalLM.from_pretrained(<span class="string">&quot;/data1/wt/Pretrained_Model/llama2_hf&quot;</span>).<span class="built_in">eval</span>()</span><br><span class="line">in_text = <span class="string">&quot;Lionel Messi is a&quot;</span></span><br><span class="line">in_tokens = torch.tensor(tokenizer.encode(in_text))</span><br><span class="line">token_eos = torch.tensor([<span class="number">2</span>])</span><br><span class="line">out_token = <span class="literal">None</span></span><br><span class="line">kvcache = <span class="literal">None</span></span><br><span class="line">out_text = in_text</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">while</span> out_token != token_eos:</span><br><span class="line">        in_tokens = in_tokens.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        res = model(in_tokens, past_key_values=kvcache)</span><br><span class="line">        kvcache = res[<span class="string">&quot;past_key_values&quot;</span>]</span><br><span class="line">        out_token = torch.argmax(res[<span class="string">&quot;logits&quot;</span>][:, -<span class="number">1</span>, :])</span><br><span class="line">        in_tokens = out_token</span><br><span class="line">        in_tokens = in_tokens.squeeze()</span><br><span class="line">        text = tokenizer.decode(in_tokens)</span><br><span class="line">        in_tokens = in_tokens.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;step <span class="subst">&#123;i&#125;</span> input: <span class="subst">&#123;text&#125;</span>&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        out_text += text</span><br><span class="line">out_text = tokenizer.decode(in_tokens)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot; Input: <span class="subst">&#123;in_text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output: <span class="subst">&#123;out_text&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="/posts/40640/clm2.png" alt="clm2.png"></p><p>当时候huggingface的Transformer时，KV Cache 配置开启后，推理过程可以分为2个阶段：</p><ol><li>预填充阶段：发生在计算第一个输出token过程中，这时Cache是空的，计算时需要为每个 transformer layer 计算并保存 key cache 和 value cache ，在输出token时Cache完成填充；FLOPs同KV Cache关闭一致，存在大量 gemm 操作，推理速度慢。</li><li>使用KV Cache阶段：发生在计算第二个输出token至最后一个token过程中，这时Cache是有值的，每轮推理只需读取Cache，同时将当前轮计算出的新的Key、Value追加写入至Cache；FLOPs降低，gemm变为gemv操作，推理速度相对第一阶段变快，这时属于Memory-bound类型计算。</li></ol><p>借助KV Cache的推理流程如下图所示（关于这部分的理解参考FlexGen论文的第三部分更好）：</p><p><img src="/posts/40640/KVCache.png" alt="KVCache.png"></p><h2 id="动态批处理（Dynamic-Batch-Continuous-batch）"><a href="#动态批处理（Dynamic-Batch-Continuous-batch）" class="headerlink" title="动态批处理（Dynamic Batch, Continuous batch）"></a>动态批处理（Dynamic Batch, Continuous batch）</h2><p>在大语言模型的推理优化技术中，动态批处理技术是一种针对不同输入样本长度进行自适应调整批处理大小的策略。大语言模型通常会对输入文本进行分词，生成词嵌入或子词嵌入。由于不同的文本长度可能会导致不同大小的嵌入矩阵，传统的固定批处理大小可能会导致在处理不同长度的输入时产生性能瓶颈。动态批处理技术通过在推理过程中根据当前输入的长度自适应地调整批处理大小，以充分利用计算资源并提高推理效率。</p><h3 id="ORCA"><a href="#ORCA" class="headerlink" title="ORCA"></a>ORCA</h3><h3 id="FastServe"><a href="#FastServe" class="headerlink" title="FastServe"></a>FastServe</h3><h3 id="vLLM"><a href="#vLLM" class="headerlink" title="vLLM"></a>vLLM</h3><h3 id="Text-Generation-Inference"><a href="#Text-Generation-Inference" class="headerlink" title="Text Generation Inference"></a>Text Generation Inference</h3><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="Inference优化目标"><a href="#Inference优化目标" class="headerlink" title="Inference优化目标"></a>Inference优化目标</h3><p>Inference服务关注两个指标：Latency和Throughput。Latency关注服务体验，也就是返回结果要快，用户体验好。Throughput则是关注系统成本，高Throughput则系统单位时间处理的量就大，系统利用率高，但是会影响latency。这两个指标一般情况下需要trade-off。</p><ul><li>Latency：延时，主要从用户的视角来看，也就是用户提交一个prompt，然后得到response的时间。特殊情况batch_size&#x3D;1只给一个用户进行服务，Latency是最低的。计算方法为生成一个token所需要的单位时间数，如16 ms&#x2F;token。</li><li>Throughput：吞吐率，主要是从系统的角度来看，单位时间内能处理的tokens数，如16 tokens&#x2F;sec。扩大Throughput的方法一般就是提升Batch_size，也就是将一个一个用户的请求由之前的串行改为并行。</li></ul><p>高并发时，把用户的prompt合在扩大batch_size能提升Throughput，但会一定程度上损害每个用户的latency，因为以前只计算一个请求，现在合并计算多个请求，每个用户等待的时间就长了。从我们实际的测试结果可以看到，Throuput随着batch_size的增大而增大，但是latency是随着减小的，当然Latency在可接受范围内就是ok的。因此指标需要trade-off。</p><p>简单计算，对于一次请求来说：latency&#x3D;batch_size * output sequence length &#x2F; Throughput. 提升batch_size会提升Throughput，但Throughput与batch_size并不是同比例增大的，因此导致Latency随着batch_size增大而增大。</p><h3 id="Inference过程"><a href="#Inference过程" class="headerlink" title="Inference过程"></a>Inference过程</h3><p>有两个阶段Prefill Phase和Decoding Phase（ FlexGen中讲的比较清楚）。</p><ol><li>Prefill Phase：称为预处理&#x2F;Encoding。计算并缓存每一层的key和value，其他的不需要缓存。每一个请求的prompt需要经过这个阶段，它只计算一次，是并行计算的。这个缓存称为KV Cache，KV Cache是整个解码过程中最为核心关键的一块。</li><li>Decoding Phase：生成新token阶段，它是串行的，也就是decode one by one。它用上一步生成的token，称为当前token放到input中，然后生成下一个token。具体包括两步，一是Lookup KV Cache计算并输出当前token最终embedding用来预测下一个token，二是缓存计算过程中得到的当前token在每一层的key和value，update到第一阶段Prefill Phase中的KV Cache中。</li></ol><p>这样划分的好处是，每次解码，不需要对整个网络全部进行计算，相当于计算复杂度从O(n^3)变为O(n)了。Prefill Phase只需要计算一次，核心就是GPT-style的transformer是单向的，而不是双向的。每一个token只与它前面的tokens有关系，其key，value也只与它前面的tokens有关系，因此可以只计算一次且可以并行。后面decoding phase就很快了，避免了重复计算。整个的开销就只有key-value cache的update以及look-up的时间。</p><p>有文章里面提出LLM inference is memory-IO bound, not compute bound。从下面的量化分析来看确实如此。</p><h3 id="Inference量化分析"><a href="#Inference量化分析" class="headerlink" title="Inference量化分析"></a>Inference量化分析</h3><p>Inference的核心是KV Cache，以FP16为例，其对显存的占用量化分析如下。</p><p>其对显存占用分为两块，一是Weights、二是KV Cache。</p><p>Weights占用大约为layer_num * ( 8 * hidden_size * hidden_size + 4 * hidden_size * MLP_hidden_size )。</p><p>KV Cache的占用为4 * batch_size * layer_num * hidden_size * ( input_length + output_length )。</p><p>以OPT-175B 为例（layer_num &#x3D; 96, hidden_size &#x3D; 12288, MLP_hidden_size &#x3D; 49152，batch_size&#x3D;512，input_length&#x3D;512, output length&#x3D;32)。</p><p>Weights差不多占用 325G, KV cache 差不多占用 1.2T。对内存消耗是非常惊人。里面唯一可以调节的参数是batch_size，显存占用基本与batch_size呈正比关系。显存的大小限制了batch_size，而batch_size的大小就限制了Throughput。因此就有很多加速工作就是想办法节省显存，进而扩大batch_size。</p><h3 id="加速优化方法"><a href="#加速优化方法" class="headerlink" title="加速优化方法"></a>加速优化方法</h3><p>总结来看，目前的加速算法有两个优化方向，一是针对Latency的优化；二是针对Throughput的优化。</p><p>针对Latency的优化，主要还是底层的OP算子、矩阵优化、并行、更高效的C++解码等，如FasterTrnasformer以及DeepSpeed。针对Latency的优化可以提升Throughput，但没有直接用batch_size提升的更显著。</p><p>针对Throughput优化，主要是KV Cache存取优化，本质是降低显存开销，从而可以提升batch size。</p><p>这方面工作相对多一些，如offloading技术，就是如何高效利用第三方存储CPU&#x2F;DRAM&#x2F;Disk，使得GPU显存能空出来进而增大batch_size。</p><p>再如vLLM中的PagedAttention技术就是借鉴OS中的分页以及虚拟存储思想实现显存动态分配，也能节省很多显存空间。</p><p>还有如continuous batching ，变传统的static batch为动态可复用的batch分配，同样也能尽可能扩大batch_size，进而提升Throughput。</p><h3 id="一些主流加速框架"><a href="#一些主流加速框架" class="headerlink" title="一些主流加速框架"></a>一些主流加速框架</h3><h4 id="FasterTransformer-1"><a href="#FasterTransformer-1" class="headerlink" title="FasterTransformer"></a>FasterTransformer</h4><ul><li>atency-oriented</li><li>方法：90%的时间消耗在12层Transformer的前向计算上，总结优化点如下：<a href="https://zhuanlan.zhihu.com/p/79528308">https://zhuanlan.zhihu.com/p/79528308</a></li><li>为了减少kernel调用次数，将除了矩阵乘法的kernel都尽可能合并（这个可能是主要的）</li><li>针对大batch单独进行了kernel优化</li><li>支持选择最优的矩阵乘法</li><li>在使用FP16时使用half2类型，达到half两倍的访存带宽和计算吞吐</li><li>优化gelu、softmax、layernorm的实现以及选用rsqrt等</li></ul><h4 id="DeepSpeed-Zero-Inference"><a href="#DeepSpeed-Zero-Inference" class="headerlink" title="DeepSpeed Zero-Inference"></a>DeepSpeed Zero-Inference</h4><ul><li><p>微软</p></li><li><p>同时优化latency和Throughput</p></li><li><p>优化Latency：a multi-GPU inference solution.主要是下面三个技术</p></li><li><p>parallelism： Tensor parallelism、Pipeline parallelism、Expert Parallelism（MoE）。对多机多卡之间的通信带宽要求较高。</p></li><li><p>communication optimization</p></li><li><p>optimized sparse kernels</p></li><li><p>优化Throughput：Zero-Inference也是用到了offloading技术，如何结合GPU显存以及其他外部存储设备如DRAM、NVMe等加载大模型，问题变为How to apportion GPU memory among model weights, inference inputs and intermediate results.然后可以接受大的batch size，进而提升Throughput。</p></li></ul><h4 id="LLaMA-cpp"><a href="#LLaMA-cpp" class="headerlink" title="LLaMA.cpp"></a>LLaMA.cpp</h4><ul><li><p>最火热的开源社区产品</p></li><li><p>面向消费级CPU&#x2F;GPU的Inference框架，主打易用性，CPU支持</p></li><li><p>方法：offloading、高效C++解码（没有用任何复杂的语句）</p></li></ul><h4 id="vLLM-1"><a href="#vLLM-1" class="headerlink" title="vLLM"></a>vLLM</h4><ul><li><p>UC Berkeley，文档里面说是Vicuna&#x2F;Alpaca等的后台服务框架</p></li><li><p>Throughput-Oriented，目前看到claim提升最大的。</p></li><li><p>方法：提出paged attention，动态分配K-V Cache，提升Batch_size</p></li></ul><h3 id="FlexGen"><a href="#FlexGen" class="headerlink" title="FlexGen"></a>FlexGen</h3><ul><li><a href="https://arxiv.org/pdf/2303.06865.pdf">FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU</a></li><li>Throughput - oriented</li></ul><p>目前我们的努力方向都是减小延迟，因为我们的目标是构造一个实时系统，因此用户体验极为重要，那么延迟和准确率就是最重要的两个指标。但是大语言模型不应该只有这一种应用场景，其他场景比如大规模数据预处理、批量推荐系统、自动化报告生成、大规模文档生成等等离线批量计算场景，它们更在意吞吐量而不是延迟，因此我关注到了FlexGen这项工作。</p><p>与前面讲过的FlashAttention、PagedAttention等方法通过优化KV Cache存储、减小SRAM与HBM之间的读写次数的手段来减小LLMs内存浪费，加快推理速度不同，FlexGen这篇工作主要目标是利用有限资源（如单个GPU）进行高吞吐量的LLMs推断。FlexGen可以通过聚合GPU、CPU和磁盘的内存和计算，在各种硬件资源的约束下进行灵活的配置，通过解决线性规划问题，寻找出有效的模式来存储和访问张量。此外，FlexGen进一步将权重和注意力缓存压缩为4位，但却几乎没有精度损失。当在单个16GB GPU上运行OPT-175B时，FlexGen实现了有效批大小为144时每秒生成1个token的吞吐量。</p><p>这项工作采用的最主要并行策略是<strong>卸载策略（Offloading Strategy）</strong>。</p><h4 id="LLM推理"><a href="#LLM推理" class="headerlink" title="LLM推理"></a>LLM推理</h4><p>典型的大语言模型生成推理任务包括两个阶段：i) 预填充阶段，该阶段接受一个提示序列以生成大语言模型每个transformer层的KV Cache； ii) 解码阶段，该阶段利用并更新 KV Cache逐步生成token，当前token的生成依赖于先前生成的token。具体公式以及吞吐量的定义见论文第三部分。</p><h4 id="问题的形式化定义"><a href="#问题的形式化定义" class="headerlink" title="问题的形式化定义"></a>问题的形式化定义</h4><p>下图是两个很简单的例子，图里面的彩色方块就表示在GPU上计算一个batch的一个layer，相同颜色块是共享权重的，这里假设模型有4个layer，并且每个prompt生成3个token。第一个调度就是很简单的把一个batch的从头算到尾一次算完，其实就是面向延迟的操作了，第二个是在batch维度加了一个block的粒度，在block内做zigzag，block间还是从头到尾，这才有面向吞吐量的意思。这些块也是有约束的：</p><ol><li>每一个块都要确保它左边的所有块都被计算过，它才能被计算</li><li>一个块如果要在某个设备上进行计算，那么它所有的输入都要被加载到同一个设备上</li><li>一个块有两个输出：激活值和KV缓存。激活值要保存到右边的相邻块算完才能释放；KV缓存则要保存到同一行右边所有块都算完才能释放</li><li>存储的tensor的大小不能超过设备的内存大小</li></ol><p>目标就是要找出一条有效的路径最小化总运行时间（计算开销+IO开销）。</p><p><img src="/posts/40640/schedule.png" alt="schedule.png"></p><h4 id="卸载策略搜索空间"><a href="#卸载策略搜索空间" class="headerlink" title="卸载策略搜索空间"></a>卸载策略搜索空间</h4><ul><li><p>计算调度：i ) <strong>计算顺序</strong>：按照上面的图，逐行算延迟最低，是完成一个批次生成的最快方法，而且可以在处理完一行后立即释放KV Cache，但是由于每两个相邻的块不共享权重，这个方法不得不反复加载权重，从而产生巨大的I&#x2F;O成本。逐列计算时，相邻计算的块共享权重，因此我们可以让权重保留在GPU上以便重用，只加载&#x2F;卸载激活值和KV Cache，但是这样会有很大的存储压力。所以batch维度上block分块，可以平衡一下，但这种还不是最优的，不过作者为了调度的简单起见就只设计了这种，但他也证明了这个最多就比最优的差两倍。ii ) <strong>overlapping</strong>：第二个优化点在于重叠，可以在计算当前batch的时候，同时加载下一层的权重、保存上一batch的激活值和KV Cache、加载下一batch的激活值和KV Cache（也就是下图中最内层循环的六个函数可以并行进行）。这其实就是操作系统中pipeline的思想了，把不同的操作叠在一起，见缝插针。这里有两个参数：GPU的batch大小和block内的batch数量，这两的乘积也就是一个block的大小了。</p><p><img src="/posts/40640/algrithm.png" alt="algrithm.png"></p></li><li><p>Tensor位置：Tensor有三个位置可以放：显存、内存、硬盘。所有Tensor在这三种设备上各放多少是要考虑的，同时存放粒度也需要考虑：一个模型放多少层到GPU上(模型粒度)？一个层放多少tensor到GPU上(层粒度)？一个tensor放多少元素到GPU上(tensor粒度)？较粗粒度的划分会具有较低的运行时开销，但灵活性较低。作者权衡了一下，在权重上使用层粒度，在激活和 KV 缓存上使用张量粒度。</p></li><li><p>计算设备：虽然用GPU算会很快，但当KV缓存很大的时候，是把一大堆KV Cache从内存挪到显存用GPU算呢？还是只把激活从显存挪到内存，用CPU算呢？作者发现当序列很长的时候，KV Cache如果是在内存的话，直接用CPU算比挪到显存用GPU算要好。</p></li></ul><h4 id="代价模型和策略搜索"><a href="#代价模型和策略搜索" class="headerlink" title="代价模型和策略搜索"></a>代价模型和策略搜索</h4><p>作者将所有行为（比如从CPU读到GPU、从CPU写到硬盘等等）都用9个变量进行了表示，得到了代价模型。接着借助线性规划方法得到了满意的卸载策略。</p><h4 id="Hugging-Face-pipeline-Accelerate"><a href="#Hugging-Face-pipeline-Accelerate" class="headerlink" title="Hugging Face pipeline Accelerate"></a>Hugging Face pipeline Accelerate</h4><ul><li>HuggingFace</li><li>Latency - oriented</li><li>方法：distributed Inference （<a href="https://link.zhihu.com/?target=https://huggingface.co/docs/accelerate/usage_guides/distributed_inference%EF%BC%89">https://huggingface.co/docs/accelerate/usage_guides&#x2F;distributed_inference）</a></li></ul><h4 id="Text-Generation-Inference-1"><a href="#Text-Generation-Inference-1" class="headerlink" title="Text Generation Inference"></a>Text Generation Inference</h4><ul><li><p>HuggingFace 官方支持的推理部署工具</p></li><li><p>和 vllm 类似的 continuous batching</p></li><li><p>支持了 <a href="https://link.zhihu.com/?target=https://github.com/HazyResearch/flash-attention">flash-attention</a> 和 <a href="https://link.zhihu.com/?target=https://github.com/vllm-project/vllm">Paged Attention</a>。</p></li><li><p>支持了 <a href="https://link.zhihu.com/?target=https://github.com/huggingface/safetensors">Safetensors</a> 权重加载。</p></li><li><p>TGI 支持部署 GPTQ 模型服务，这使得我们可以在单卡上部署拥有 continous batching 功能的，更大的模型。</p></li><li><p>支持采用 Tensor Parallelism 部署多 GPU 服务，模型水印等其他功能</p></li></ul><h1 id="Parameter-Efficient-Fine-Tuning（PEFT）回顾"><a href="#Parameter-Efficient-Fine-Tuning（PEFT）回顾" class="headerlink" title="Parameter Efficient Fine Tuning（PEFT）回顾"></a>Parameter Efficient Fine Tuning（PEFT）回顾</h1><p>近来的PEFT方法大致可以分为三个种类：Adapter、Prompt、LoRA。相应论文的发表时间排序如下：Adapter(2019)、Prefix-Tuning(2021.1)、P-Tuning(2021.3)、Prompt-Tuning(2021.4)、LoRA(2021.6)、P-Tuning v2(2021.10)。</p><h2 id="Adapter"><a href="#Adapter" class="headerlink" title="Adapter"></a>Adapter</h2><h3 id="paper：Parameter-Efficient-Transfer-Learning-for-NLP-Neil-Houlsby-etc-Google-Research-PMLR-2019"><a href="#paper：Parameter-Efficient-Transfer-Learning-for-NLP-Neil-Houlsby-etc-Google-Research-PMLR-2019" class="headerlink" title="paper：Parameter-Efficient Transfer Learning for NLP. Neil Houlsby, etc. (Google Research) PMLR, 2019."></a>paper：Parameter-Efficient Transfer Learning for NLP. Neil Houlsby, etc. (Google Research) PMLR, 2019.</h3><p>2019年谷歌的研究人员首次在论文<a href="https://arxiv.org/pdf/1902.00751.pdf">《Parameter-Efficient Transfer Learning for NLP》</a>提出针对 BERT 的 PEFT微调方式，拉开了 PEFT 研究的序幕。他们指出，在面对特定的下游任务时，如果进行 Full-Fintuning（即预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。</p><p>于是他们设计了如下图所示的 Adapter 结构，将其嵌入 Transformer 的结构里面，在训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构进行微调。同时为了保证训练的高效性（也就是尽可能少的引入更多参数），他们将 Adapter 设计为这样的结构：</p><ul><li>首先是一个 down-project 层将高维度特征映射到低维特征</li><li>然后过一个非线形层之后，再用一个 up-project 结构将低维特征映射回原来的高维特征</li><li>同时也设计了 skip-connection 结构，确保了在最差的情况下能够退化为identity（类似残差结构）。</li></ul><p><img src="/posts/40640/Adapter.png" alt="Adapter.png"></p><p>从实验结果来看，该方法能够在只额外对增加的 3.6% 参数规模（相比原来预训练模型的参数量）的情况下取得和Full-Finetuning 接近的效果（GLUE指标在0.4%以内）。</p><h2 id="Prompt"><a href="#Prompt" class="headerlink" title="Prompt"></a>Prompt</h2><h3 id="paper：Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-Xiang-Lisa-Li-Percy-Liang-Stanford-University-ACL-2021"><a href="#paper：Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-Xiang-Lisa-Li-Percy-Liang-Stanford-University-ACL-2021" class="headerlink" title="paper：Prefix-Tuning: Optimizing Continuous Prompts for Generation. Xiang Lisa Li, Percy Liang. (Stanford University) ACL,2021."></a>paper：Prefix-Tuning: Optimizing Continuous Prompts for Generation. Xiang Lisa Li, Percy Liang. (Stanford University) ACL,2021.</h3><p>2021年斯坦福的研究人员在论文《<a href="https://aclanthology.org/2021.acl-long.353.pdf">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a>》中提出了 Prefix Tuning 方法。与Full-finetuning 更新所有参数的方式不同，该方法是在输入 token 之前构造一段任务相关的 virtual tokens 作为 Prefix，然后训练的时候只更新 Prefix 部分的参数，而 Transformer 中的其他部分参数固定。该方法其实和构造 Prompt 类似，只是 Prompt 是人为构造的“显式”的提示，并且无法更新参数，而Prefix 则是可以学习的“隐式”的提示。</p><p><img src="/posts/40640/PrefixTuning.png" alt="PrefixTuning.png"></p><p>同时，为了防止直接更新 Prefix 的参数导致训练不稳定的情况，他们在 Prefix 层前面加了 MLP 结构(相当于将Prefix 分解为更小维度的 Input 与 MLP 的组合后输出的结果)，训练完成后，只保留 Prefix 的参数。</p><h4 id="paper：P-tuning-GPT-Understands-Too-Xiao-Liu-Yanan-Zheng-etc-Tsinghua-University-2021"><a href="#paper：P-tuning-GPT-Understands-Too-Xiao-Liu-Yanan-Zheng-etc-Tsinghua-University-2021" class="headerlink" title="paper：P-tuning: GPT Understands, Too. Xiao Liu, Yanan Zheng, etc. (Tsinghua University) 2021."></a>paper：P-tuning: GPT Understands, Too. Xiao Liu, Yanan Zheng, etc. (Tsinghua University) 2021.</h4><p><img src="/posts/40640/PTuning.png" alt="PTuning.png"></p><p>P-Tuning 提出将 Prompt 转换为可以学习的 Embedding 层，只是考虑到直接对 Embedding 参数进行优化会存在这样两个挑战：</p><ul><li>Discretenes： 对输入正常语料的 Embedding 层已经经过预训练，而如果直接对输入的 prompt embedding进行随机初始化训练，容易陷入局部最优。</li><li>Association：没法捕捉到 prompt embedding 之间的相关关系。</li></ul><p>P-tuning 依然是固定 LLM 参数，利用多层感知机和 LSTM 对 Prompt 进行编码，编码之后与其他向量进行拼接之后正常输入 LLM。注意，训练之后只保留 Prompt 编码之后的向量即可，无需保留编码器。</p><p>P-Tuning 和 Prefix-Tuning 差不多同时提出，做法其实也有一些相似之处，主要区别在：</p><ul><li>Prefix Tuning 是将额外的 embedding 加在开头，看起来更像是模仿 Instruction 指令；而 P-Tuning 的位置则不固定。</li><li>Prefix Tuning 通过在每个 Attention 层都加入 Prefix Embedding 来增加额外的参数，通过 MLP 来初始化；而 P-Tuning 只是在输入的时候加入 Embedding，并通过 LSTM+MLP 来初始化。</li></ul><h3 id="paper：Prompt-tuning-The-Power-of-Scale-for-Parameter-Effificient-Prompt-Tuning-Brian-Lester-etc-Google-Research-EMNLP-2021"><a href="#paper：Prompt-tuning-The-Power-of-Scale-for-Parameter-Effificient-Prompt-Tuning-Brian-Lester-etc-Google-Research-EMNLP-2021" class="headerlink" title="paper：Prompt-tuning: The Power of Scale for Parameter-Effificient Prompt Tuning. Brian Lester, etc. (Google Research) EMNLP, 2021."></a>paper：Prompt-tuning: The Power of Scale for Parameter-Effificient Prompt Tuning. Brian Lester, etc. (Google Research) EMNLP, 2021.</h3><p>Prompt Tuning 是2021年谷歌在论文《<a href="https://arxiv.org/pdf/2104.08691.pdf">The Power of Scale for Parameter-Efficient Prompt Tuning</a>》中提出的微调方法。</p><p>该方法可以看作是 Prefix Tuning 的简化版本，只在输入层加入 prompt tokens，并不需要加入 MLP 进行调整来解决难训练的问题，主要在 T5 预训练模型上做实验。似乎只要预训练模型足够强大，其他的一切都不是问题。作者也做实验说明随着预训练模型参数量的增加，Prompt Tuning的方法会逼近 Fine-tune 的结果。</p><p>固定预训练参数，为每一个任务额外添加一个或多个 embedding，之后拼接 query 正常输入 LLM，并只训练这些 embedding。左图为单任务全参数微调，右图为 Prompt tuning。</p><p><img src="/posts/40640/PromptTuning.png" alt="PromptTuning.png"></p><p>作者做了一系列对比实验，都在说明：随着预训练模型参数的增加，一切的问题都不是问题，最简单的设置也能达到极好的效果。</p><ul><li>Prompt 长度影响：模型参数达到一定量级时，Prompt 长度为1也能达到不错的效果，Prompt 长度为20就能达到极好效果。</li><li>Prompt初始化方式影响：Random Uniform 方式明显弱于其他两种，但是当模型参数达到一定量级，这种差异也不复存在。</li><li>预训练的方式：LM Adaptation 的方式效果好，但是当模型达到一定规模，差异又几乎没有了。</li><li>微调步数影响：模型参数较小时，步数越多，效果越好。同样随着模型参数达到一定规模，zero shot 也能取得不错效果。</li><li>当参数达到100亿规模与全参数微调方式效果无异。</li></ul><h3 id="paper：P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks-Xiao-Liu-etc-Tsinghua-University-2021"><a href="#paper：P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks-Xiao-Liu-etc-Tsinghua-University-2021" class="headerlink" title="paper：P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks. Xiao Liu, etc. (Tsinghua University) 2021."></a>paper：P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks. Xiao Liu, etc. (Tsinghua University) 2021.</h3><p><img src="/posts/40640/PTuning.png" alt="PTuning.png"></p><p>P-Tuning 的问题是在小参数量模型上表现差。于是就有了v2版本：《<a href="https://arxiv.org/pdf/2110.07602.pdf">P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</a>》。</p><p>从标题就可以看出，P-Tuning v2 的目标就是要让 Prompt Tuning 能够在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌 Fine-tuning 的结果。</p><p>那也就是说当前 Prompt Tuning 方法在这两个方面都存在局限性。</p><ul><li>不同模型规模：Prompt Tuning 和 P-tuning 这两种方法都是在预训练模型参数规模够足够大时，才能达到和Fine-tuning 类似的效果，而参数规模较小时效果则很差。</li><li>不同任务类型：Prompt Tuning 和 P-tuning 这两种方法在 sequence tagging 任务上表现都很差。</li></ul><p>相比 Prompt Tuning 和 P-tuning 的方法， P-tuning v2 方法在多层加入了 Prompts tokens 作为输入，带来两个方面的好处：</p><ol><li>带来更多可学习的参数（从 P-tuning 和 Prompt Tuning 的0.1%增加到0.1%-3%），同时也足够 parameter-efficient。</li><li>加入到更深层结构中的 Prompt 能给模型预测带来更直接的影响。</li></ol><p>v1 到 v2 的可视化：蓝色部分为参数冻结，橙色部分为可训练部分。</p><h2 id="LORA"><a href="#LORA" class="headerlink" title="LORA"></a>LORA</h2><h3 id="paper：LoRA-Low-Rank-Adaptation-of-Large-Language-Models-Edward-Hu-etc-Microsoft-Corporation-ICLR-2022"><a href="#paper：LoRA-Low-Rank-Adaptation-of-Large-Language-Models-Edward-Hu-etc-Microsoft-Corporation-ICLR-2022" class="headerlink" title="paper：LoRA: Low-Rank Adaptation of Large Language Models. Edward Hu, etc. (Microsoft Corporation) ICLR, 2022."></a>paper：LoRA: Low-Rank Adaptation of Large Language Models. Edward Hu, etc. (Microsoft Corporation) ICLR, 2022.</h3><p>自然语言处理目前存在一个重要范式：一般领域数据的大规模预训练，对特定任务或领域的适应微调（finetune）。但是随着预训练语言模型越来越大，这个范式存在以下问题：</p><ul><li><p>当我们finetune大模型时，由于训练成本太高，不太可能重新训练所有模型参数。</p></li><li><p>以前的方法（论文发表于2021年）都或多或少有其它性能问题，如adapter增加了模型层数，引入了额外的推理延迟；prefix-tuning比较难训练，效果不如直接finetune。</p></li></ul><p>基于上述背景，论文作者得益于前人的一些关于内在维度（intrinsic dimension）的发现：模型是过参数化的，它们有更小的内在维度，模型主要依赖于这个低的内在维度（low intrinsic dimension）去做任务适配。假设模型在任务适配过程中权重的改变量是低秩（low rank）的，由此提出低秩自适应（LoRA）方法，LoRA允许我们通过优化适应过程中密集层变化的秩分解矩阵来间接训练神经网络中的一些密集层，同时保持预先训练的权重不变。</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>LoRA的实现思想很简单，如下图所示，就是冻结一个预训练模型的矩阵参数，并选择用A和B矩阵来替代，在下游任务时只更新A和B。</p><p><img src="/posts/40640/lora.png" alt="lora.png"></p><p>结合图片来看，LoRA的实现流程如下：</p><ul><li>在原始预训练语言模型（PLM）旁边增加一个旁路，做一个降维再升维的操作，来模拟所谓的内在秩。</li><li>训练的时候固定PLM的参数，只训练降维矩阵A与升维矩阵B。</li><li>模型的输入输出维度不变，输出时将BA与PLM的参数叠加。</li><li>用随机高斯分布初始化A，用0矩阵初始化B，保证训练的开始此旁路矩阵依然是0矩阵。</li></ul><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>接下来我们从公式上解释LoRA的实现。假设要在下游任务微调一个预训练语言模型（如GPT3），则需要更新预训练模型参数，公式表示如下：<br>$$<br>h&#x3D;W_0x+\Delta Wx&#x3D;W_0x+BAx<br>$$<br>W0是预训练模型初始化的参数，ΔW就是需要更新的参数。如果是全参数微调，则$\Delta W$参数量&#x3D;W0参数量（如果是GPT3，则ΔW≈175B）。从这可以看出要全参数微调大语言模型，小家小户是不可能的。由于前人的工作发现预训练的语言模型具有较低的“内部维度（intrinsic dimension）”，在任务适配过程中，即使随机投影到较小的子空间，仍然可以有效地学习。因此，LoRA做的就是增加小参数模块去学习改变量ΔW。在训练过程中，W0是固定不变的，只有A和B包含训练参数，是变化的。而在推理的过程中，只需要把改变量放回原模型，就不会有任何延迟。如果想切换任务，只需要切换任务的过程中，减去BA，然后换上用其它任务训练好的新BA就可以了。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>总的来说，<strong>基于大模型的内在低秩特性，增加旁路矩阵来模拟full finetuning，LoRA是一个能达成lightweight finetuning的简单有效的方案</strong>。目前该技术已经广泛应用于大模型的微调，如Alpaca，stable diffusion+LoRA，而且能和其它参数高效微调方法有效结合，例如 State-of-the-art Parameter-Efficient Fine-Tuning (PEFT)。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MedicalGPT_Text_Matching</title>
      <link href="/posts/37017.html"/>
      <url>/posts/37017.html</url>
      
        <content type="html"><![CDATA[<h1 id="医疗GPT中基于向量数据库的文本匹配任务"><a href="#医疗GPT中基于向量数据库的文本匹配任务" class="headerlink" title="医疗GPT中基于向量数据库的文本匹配任务"></a>医疗GPT中基于向量数据库的文本匹配任务</h1><p>现在在构建基于大语言模型的医疗GPT，为了一定程度上缓解幻觉问题，决定将大量医学指南存入向量数据库，然后对用户query进行embedding后送入数据库进行查询。因此这部分内容本质上来讲是一个文本匹配任务，于是本周对该任务进行了一点探索，总结成这篇博文。</p><h2 id="文本匹配模型范式"><a href="#文本匹配模型范式" class="headerlink" title="文本匹配模型范式"></a>文本匹配模型范式</h2><p>在文本匹配任务中，一般有两种范式：Representation-based和Interaction-based。Representation-based method也称双塔式模型或孪生网络，就是用一个编码器分别给两个文本编码出句向量，然后把两个向量融合送入一个浅层的分类器；Interaction-based method也就是交互式模型，就是把两个文本一起输入进编码器，在编码的过程中让它们相互交换信息，再得到最终结果。如下图：</p><p><img src="/posts/37017/paradigm.png" alt="paradigm.png"></p><p>两种方法各有优缺点：</p><ol><li>双塔式：优点是速度会快很多，一般来说候选的句子都是已经计算好embedding的，然后直接用query的embedding跟候选embedding去计算相似度就好，计算相似度要比送入模型里面进行推理要快很多。Representation-based 方法侧重于对每个输入文本进行表示学习，然后通过对比两个文本的表示来进行匹配。这种方法通常使用预训练的深度神经网络（如BERT、GPT等）来学习文本的表示，首先将输入文本编码成固定长度的向量表示，然后通过比较两个文本的向量表示来确定它们之间的相似性或相关性。代表模型有InferSent和Sentence-BERT等。</li><li>交互式：优点是准确率更高一些，因为多了query和key的交互，所以一般来说准确率会有所提升。Interaction-based 方法侧重于建模两个输入文本之间的交互信息，通常使用神经网络或其他复杂的模型来对两个文本进行交互建模，以捕捉它们之间的语义关系。代表模型有ESIM和RE2等。</li></ol><p>下图是一个简单的文本匹配任务模型分类图：</p><p><img src="/posts/37017/classify.png" alt="classify.png"></p><h3 id="Representation-based-model"><a href="#Representation-based-model" class="headerlink" title="Representation-based model"></a>Representation-based model</h3><p>双塔式的模型有三个大类：词袋模型，有监督模型以及pretrained-finetuning模型。</p><p>词袋类方法的主要思路是先使用词向量(如Word2Vec)将句子中的每个词转换为词向量，然后将句子中所有词的词向量求平均或求和,生成一个定长的向量来表示整个句子。显然，这种方法有很多问题：首先，这种方法忽略了词序信息，未考虑词语间的语义关系；其次，对不同词语的词向量简单求和&#x2F;平均，忽略了词语对句意的不同贡献；此外，这样生成的句向量的表示能力有限,难以反映句子的深层语义关系；最后，当句子的长度变化很大时，向量比较容易受影响。典型的词袋类方法有SIF和WMD等等。</p><p>词向量虽然可以经过处理变成句向量，但词袋式的融合也会丢失掉顺序信息，同时在训练时其目标还是word-level的，想要获得「真正的句向量」，还是需要寻找sentence-level的目标函数。传统的有监督类方法包括DSSM和SiamLSTM等等。</p><p>pretrained-finetuning方法是我打算在医疗GPT中采用的。比较著名的有InferSent、Sentence-BERT以及CoSENT等。</p><h3 id="Interaction-based-model"><a href="#Interaction-based-model" class="headerlink" title="Interaction-based model"></a>Interaction-based model</h3><p>尽管双塔式模型的速度比较快，但是却有两个比较大的缺陷：</p><ol><li><strong>位置信息</strong>。如果用词袋方法的话“我很不开心”和“我不很开心”两句的意思就变成一样了，虽然用RNN、BERT引入位置编码可以减缓一些，但不去让两个句子进行交互的话对于最后的分类层还是比较困难的。</li><li><strong>细粒度语义</strong>。比如“我开心”和“我不开心”这两句话只有一个字的区别，但词袋模型很可能给出较高的相似度，交互式模型则可以稍有缓解。</li></ol><p>于是在一些不太在意速度而更在意精度的任务上，交互式模型就更为合适。典型的交互式方法有ESIM和RE2等。</p><h2 id="InferSent"><a href="#InferSent" class="headerlink" title="InferSent"></a>InferSent</h2><p>InferSent是2017年提出的一种有监督的方法，其在自然语言推理(NLI)数据集上进行训练，学习到句子的通用表示。InferSent使用BiLSTM结构对句子进行编码并采用max-pooling策略提取关键特征来将时间序列信息汇总成一个固定维度的向量。如下图所示：</p><p><img src="/posts/37017/InferSent.png" alt="InferSent.png"></p><h2 id="Sentence-BERT"><a href="#Sentence-BERT" class="headerlink" title="Sentence-BERT"></a>Sentence-BERT</h2><p>Bert模型在NLP的各大任务中都表现出了很好的性能，STS（semantic textual similarity）任务也不例外。但是Bert作为一种交互型方法，需要将两个句子同时送入模型，进行信息交互，这造成大量的计算开销。例如，有10000个句子，我们想要找出最相似的句子对，需要计算（10000*9999&#x2F;2）次，需要大约65个小时，因此这种方法在实时交互的系统中，是不可能上线的。</p><p>因此作者提出了Sentence-BERT模型，将同样任务的耗时从65小时缩减到了5秒。SBERT的模型架构如下图所示，左侧是训练时的架构，右侧是推理时的架构：</p><p><img src="/posts/37017/SBERT.png" alt="SBERT.png"></p><p>作者进行了多种实验：</p><ol><li>pooling策略：<ul><li>CLS策略：直接使用CLS这个token的输出。</li><li>mean策略：按维度取均值。</li><li>max策略：按维度取最大值。</li></ul></li><li>目标函数：<ul><li>分类目标函数：采用上图左侧的训练架构，将两个句子的向量还有他们的差的绝对值进行拼接，然后优化CE loss。</li><li>回归目标函数：采用推理时的架构作为训练架构，计算两个句子向量的余弦相似度，然后优化MSE loss。</li><li>triplet目标函数：采用三塔式架构，一个锚点句子a，一个正例句子p，一个负例句子n，然后让a与p的距离比a与n的距离越小越好。</li></ul></li></ol><p>实验结果证明，双塔式架构+分类目标函数+平均池化策略的效果最好。</p><h2 id="CoSENT"><a href="#CoSENT" class="headerlink" title="CoSENT"></a>CoSENT</h2><p>其实对于文本匹配任务而言，由于在检索阶段是基于余弦相似度进行相似句子的检索，因此最自然的想法是直接优化基于两个句子的余弦相似度的loss。然而，直接优化这样目标的实验结果往往特别差（至少明显比InferSent要差），在某些情况下甚至还不如随机初始化的效果。</p><p>作者认为这是因为负样本对的优化目标过低了。具体而言，对于那些“困难”的负样本对而言，它们往往语义不相同但字面上有比较多的重合；对于那些“简单”的负样本对而言，它们往往语义不相同的同时字面上也很不相同；然而在训练的时候，大多数数据集中的负样本对都是那些“困难”的例子，这时如果将它们的优化目标设置为最低值（例如-1）显然是不太合理的。作者进行了实验，设置负样本对的相似度只要低于0.7就不优化了，发现模型的效果有了一定提升。</p><p>于是作者设计了新的损失函数来进行改进。目标是设计一个基于两个句子向量余弦相似度的loss，让正样本对的相似度大于负样本对的相似度，至于大多少，模型自己决定就好。事实上语义相似度常见的评价指标spearman也是一样，它只依赖于预测结果的相对顺序，而不依赖于具体的值。因此，借鉴circle loss，作者设计了下面基于cos的排序损失函数：<br>$$<br>loss&#x3D;log\left(1+\sum_{sim(i,j)&gt;sim(k,l)}e^{\lambda(cos(uk,ul)-cos(ui,uj))}\right)<br>$$<br>也就是说，只要我们认为样本对(i,j)的真实相似度应该大于(k,l)的真实相似度，就可以往log里边加入$e^{\lambda(cos(uk,ul)-cos(ui,uj))}$；换句话说，只要我们能够为样本对设计顺序，那么就可以用此公式。</p><p>实验证明CoSENT的表现明显优于Sentence-BERT，我参考的开源库text2vec中效果最好的那些模型也都采用了CoSENT。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ErnieHealth_CBLUE</title>
      <link href="/posts/51617.html"/>
      <url>/posts/51617.html</url>
      
        <content type="html"><![CDATA[<h1 id="Building-Chinese-Biomedical-Language-Models-via-Multi-Level-Text-Discrimination"><a href="#Building-Chinese-Biomedical-Language-Models-via-Multi-Level-Text-Discrimination" class="headerlink" title="Building Chinese Biomedical Language Models via Multi-Level Text Discrimination"></a>Building Chinese Biomedical Language Models via Multi-Level Text Discrimination</h1><h2 id="模型相关"><a href="#模型相关" class="headerlink" title="模型相关"></a>模型相关</h2><p>模型采用了ELECTRA模型的生成器-判别器架构，其中生成器被用于构造预训练信号，判别器被用作最终的目标编码器，不同点在于ELECTRA仅采用token级别的二分类来训练判别器，而该模型使用(i)更具信息量的token级别判别和(ii)序列级别判别来进行训练。模型的整体架构如下所示：</p><p><img src="/posts/51617/ehealth.png" alt="ehealth.png"></p><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>生成器是一个通过MLM方法（完形填空）训练的transformer编码器。首先对于某个输入序列，生成器会先随机的生成一组位置，并将这些位置上的字符替换掉（80%替换为[MASK]，10%替换成其他token，10%不变），然后被送入transformer编码器，生成上下文表示，接着使用softmax预测这些位置上原本的字符。生成器的loss是所有被替换位置的原始字符预测概率的负对数之和，因为生成器的目标是生成最能以假乱真的篡改文本。</p><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>判别器也是一个transformer，它进行了两个级别的文本判别——token-level和sequence-level。此外，需要提及的是判别器的输入是真实的输入序列和多个生成器生成的序列（比如选择k个生成序列，那么每个被替换token就有了k+1个候选项）。</p><h4 id="token-level"><a href="#token-level" class="headerlink" title="token-level"></a>token-level</h4><p>这个级别的判别任务有两个：replaced token detection (RTD) 以及 multi-token selection (MTS)。前者检测序列中被替换的token，后者进一步为这些被替换的token选择原始token。具体来说：</p><ol><li>RTD任务会学习判别每一个token是原始token还是替换过的token，输出的是经过sigmoid得到的每个token未被替换的概率。这个任务的loss是被替换位置token被预测为被替换概率的负对数以及未被替换位置的token被预测为未被替换概率的负对数之和。这里本质上是一个二分类任务。</li><li>MTS任务需要恢复被替换位置的原始token，输出的是被替换位置token从k+1个候选项中选择出正确的原始token的概率。这个任务的loss是被替换位置token选择出正确的原始token概率的负对数之和。这里本质上是一个k+1分类任务。</li></ol><h4 id="sequence-level"><a href="#sequence-level" class="headerlink" title="sequence-level"></a>sequence-level</h4><p>这个级别的判别任务有一个：contrastive sequence prediction (CSP)，采用的是典型的对比学习框架。对于每一个原始输入，建立了两个版本的篡改结果。如图中左右两部分所示，分别用 $X^R_i$ 和 $X^R_j$ 表示，将它们作为一个正例对；选择训练时同一minibatch中的其它序列作为反例，由正例和反例组成候选集 $N(x)$。CSP任务的目标是在已知 $X^R_i$ 的条件下，从候选项 $N(x)$ 中选择正确的 $X^R_j$。这个任务的loss如下图所示：</p><p><img src="/posts/51617/loss.png" alt="loss.png"></p><p>其中s代表相似度计算函数。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>模型的总loss是前述四个loss的加权和。此外，在预训练完成后，便不再理会生成器，仅仅在下游任务上微调判别器。</p><h2 id="实验相关"><a href="#实验相关" class="headerlink" title="实验相关"></a>实验相关</h2><h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h3><ol><li>数据集：126.9G数据，包括对话、文章、书籍以及医疗记录。</li><li>词表：使用的是in-domin的词表。具体做法是从预训练数据中采样1M的文本，经过简单处理后使用开源库Tensor2Tensor建立WordPiece词表。然后抛弃掉了出现少于5次的token，让词表的大小在20K个token左右。</li><li>预训练配置：判别器transformer采用12层，12个注意力头，768的hidden size，3072的intermediate size。生成器的size是判别器的1&#x2F;3。</li></ol><h3 id="评价数据集"><a href="#评价数据集" class="headerlink" title="评价数据集"></a>评价数据集</h3><p>使用的数据集包括：CBLUE（3.0版本已经有18个任务，下一篇论文介绍）、cMedQNLI（QA匹配任务，判断answer能否解决question）、webMedQA（QA匹配任务，但是比前者更大，约为3倍）、NLPEC（多项选择QA数据集）。</p><h1 id="CBLUE-A-Chinese-Biomedical-Language-Understanding-Evaluation-Benchmark"><a href="#CBLUE-A-Chinese-Biomedical-Language-Understanding-Evaluation-Benchmark" class="headerlink" title="CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark"></a>CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark</h1><p>Chinese Biomedical Language Understanding Evaluation (CBLUE)是第一个中文的生物医学语言理解的benchmark。</p><p>CBLUE的发展经过3个阶段：<br><strong>CBLUE1.0</strong>：由CHIP会议往届的学术评测数据集和阿里夸克医疗搜索业务数据集组成，包括<strong>医学文本信息抽取</strong>（实体识别、关系抽取）、<strong>医学术语标准化</strong>、<strong>医学文本分类</strong>、<strong>医学句子语义关系判定</strong>共4大类任务8个子任务。<br><strong>CBLUE2.0</strong>：在1.0的基础上，扩充了原有的任务类型，进一步丰富了语料来源（新增医学诊疗对话、医学专家编写的电子病历和医学影像报告），并引入了生成类任务。CBLUE2.0由<strong>医学文本信息抽取</strong>（实体识别、关系抽取、事件抽取）、<strong>医学术语标准化</strong>、<strong>医学文本分类</strong>、<strong>医学句子语义关系判定</strong>、<strong>医学对话理解与生成</strong>共5大类任务14个子任务组成。<br><strong>CBLUE3.0</strong>：在2.0的基础上，进一步增强了生成类任务，新引入了医学检索和医学多模态任务，此外还对现有任务的难度做了升级。CBLUE3.0由<strong>医学文本信息抽取</strong>（实体识别、关系抽取、事件抽取）、<strong>医学检索&amp;术语标准化</strong>、<strong>医学文本分类</strong>、<strong>医学句子语义关系判定</strong>、<strong>医学文本理解&amp;生成</strong>共5大类任务18个子任务组成。此外还引入了<strong>医学OCR要素识别</strong>任务作为多模态方向的初步尝试。</p><p>当前的CBLUE3.0共有18个任务分别如下：</p><table><thead><tr><th align="center">数据集名称</th><th align="center">数据集缩写</th><th align="center">任务介绍</th><th align="center">数据量（训练集&#x2F;验证集&#x2F;测试集）</th></tr></thead><tbody><tr><td align="center">中文医学命名实体识别</td><td align="center">CMeEE</td><td align="center">实体识别</td><td align="center">15,000&#x2F;5,000&#x2F;3,000</td></tr><tr><td align="center">中文医学文本实体关系抽取</td><td align="center">CMeIE</td><td align="center">关系抽取</td><td align="center">14,339&#x2F;3,585&#x2F;4,482</td></tr><tr><td align="center">医疗因果实体关系抽取</td><td align="center">CMedCausal</td><td align="center">关系抽取</td><td align="center">800&#x2F;200&#x2F;1,000 + 1000条未标注数据</td></tr><tr><td align="center">临床发现事件抽取</td><td align="center">CHIP-CDEE</td><td align="center">事件抽取</td><td align="center">1,587&#x2F;384&#x2F;514</td></tr><tr><td align="center">临床术语标准化</td><td align="center">CHIP-CDN</td><td align="center">归一化</td><td align="center">6,000&#x2F;2,000&#x2F;10,000</td></tr><tr><td align="center">医学段落检索</td><td align="center">KUAKE-IR</td><td align="center">检索</td><td align="center">100,000&#x2F;1,000&#x2F;3,000</td></tr><tr><td align="center">临床试验筛选标准短文本分类</td><td align="center">CHIP-CTC</td><td align="center">分类</td><td align="center">22,962&#x2F;7,682&#x2F;10,000</td></tr><tr><td align="center">医疗搜索检索词意图分类</td><td align="center">KUAKE-QIC</td><td align="center">分类</td><td align="center">6,931&#x2F;1,955&#x2F;1,994</td></tr><tr><td align="center">医疗对话临床发现阴阳性判别</td><td align="center">CHIP-MDCFNPC</td><td align="center">分类</td><td align="center">5,000&#x2F;1,000&#x2F;2,000</td></tr><tr><td align="center">疾病问答迁移学习</td><td align="center">CHIP-STS</td><td align="center">匹配</td><td align="center">16,000&#x2F;4,000&#x2F;10,000</td></tr><tr><td align="center">医疗搜索查询词-页面标题相关性</td><td align="center">KUAKE-QTR</td><td align="center">匹配</td><td align="center">24,174&#x2F;2,913&#x2F;5,465</td></tr><tr><td align="center">医疗搜索查询词-查询词相关性</td><td align="center">KUAKE-QQR</td><td align="center">匹配</td><td align="center">15,000&#x2F;1,600&#x2F;1,596</td></tr><tr><td align="center">智能对话诊疗数据集</td><td align="center">IMCS</td><td align="center">实体识别、分类、生成</td><td align="center">2,472&#x2F;833&#x2F;811</td></tr><tr><td align="center">蕴含实体的中文医疗对话生成</td><td align="center">MedDG</td><td align="center">生成</td><td align="center">17,864&#x2F;2,747&#x2F;1,551</td></tr><tr><td align="center">医疗文本诊疗决策树抽取</td><td align="center">TextDT</td><td align="center">生成</td><td align="center">300&#x2F;100&#x2F;100</td></tr><tr><td align="center"><strong>推荐任务</strong></td><td align="center">-</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">医疗清单发票OCR要素提取任务</td><td align="center">CMedOCR</td><td align="center">OCR</td><td align="center">1,000&#x2F;-&#x2F;700</td></tr><tr><td align="center">面向“基因-疾病”关联机理的科学文献挖掘任务</td><td align="center">AGAC</td><td align="center">实体识别、关系抽取</td><td align="center">250&#x2F;-&#x2F;2,000</td></tr></tbody></table><p>具体信息可以参考：<a href="https://tianchi.aliyun.com/dataset/95414">CBLUE</a>。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LangChain-ChatGLM</title>
      <link href="/posts/50073.html"/>
      <url>/posts/50073.html</url>
      
        <content type="html"><![CDATA[<h1 id="LangChain-ChatGLM"><a href="#LangChain-ChatGLM" class="headerlink" title="LangChain-ChatGLM"></a>LangChain-ChatGLM</h1><p>以 LLM 为基础的知识问答系统构建方法，其整体的流程如下图所示：</p><p><img src="/posts/50073/langchain_chatglm.png" alt="langchain_chatglm.png"></p><p>在整个流程中，核心在于：</p><ol><li>将用户问题和本地知识进行 Embedding，通过向量相似度(Vector Similarity)实现召回；</li><li>通过 LLM 对用户问题进行意图识别；并对原始答案加工整合。</li></ol><h1 id="ChatGLM2-6B"><a href="#ChatGLM2-6B" class="headerlink" title="ChatGLM2-6B"></a>ChatGLM2-6B</h1><p>ChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，ChatGLM2-6B 引入了如下新特性：</p><ol><li><strong>更强大的性能</strong>：基于 ChatGLM 初代模型的开发经验，开发人员全面升级了 ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数，经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同大小开源模型中具有较强的竞争力。</li><li><strong>更长的上下文</strong>：基于 FlashAttention 技术，开发人员将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使用 8K 的上下文长度训练，允许更多轮次的对话。但当前版本的 ChatGLM2-6B 对单轮超长文档的理解能力有限，开发人员会在后续迭代升级中着重进行优化。</li><li><strong>更高效的推理</strong>：基于 Multi-Query Attention 技术，ChatGLM2-6B 有更高效的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了 42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。</li></ol><h1 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h1><p>LangChain 抽象了业务应用和 LLM 交互的方式，内置通用环节实现，标准化工具链交互接口，极大提升开发效率。LangChain 的大致结构如下所示：</p><p><img src="/posts/50073/langchain.png" alt="langchain.png"></p><p>下面介绍一下LangChain中的重要模块：</p><ul><li>Schema：LangChain中的数据类型分为四种：Text，ChatMessages，Examples，Document。Text很好理解，整个LangChain都是文本进文本出的形式，因此Text是最常用的数据类型。ChatMessages分为三种，SystemChatMessage代表了开发人员定义的instruction，HumanChatMessage代表人类发送的信息，AIChatMessage代表LLM发送的信息。Examples代表的是输入和期望输出的对，可以用于微调或者评估等。Document代表了非结构化数据（例如txt文本形式的医学指南）。</li><li>Models：LangChain中的模型有三种：LLMs，Chat Models，Text Embedding Models。LLMs很好理解，以文本字符串作为输入，并返回一个文本字符串作为输出。Chat Models通常由语言模型支持，但它们的API更加结构化。具体而言，这些模型以聊天消息列表作为输入，并返回一个聊天消息。Text Embedding Models以文本作为输入，并返回一个浮点数列表作为输出。</li><li>Prompts：这个模块有四个类，分别如下：PromptValue是模型输入。PromptTemplates负责构建PromptValue，比如将固定的prompt部分和动态生成的内容结合到一起。在prompt中包含示例（few-shot）通常很有用，这些示例可以是硬编码的，但如果它们是动态选择的，通常会更加强大，Example Selectors就是这个作用，它是通过上面所说的embedding model实现的，也就是先把所有例子进行向量化处理，再把用户输入的问题向量化后和所有例子做相似度计算，最后选出相似度最高的例子作为few-shot的例子喂给LLMs。Output Parsers是输出解析器，负责：（1）指示模型如何格式化输出，（2）将输出解析为所需的格式（包括必要时的重试）。</li><li>Indexes：Indexes（索引）是指对文档进行结构化，以便LLMs能够更好地与其进行交互的方式。该模块包含了用于处理文档、不同类型索引的实用函数，以及在chains中使用这些索引的示例。索引在chains中最常见的用法是在“检索”步骤中。该步骤指的是根据用户的查询返回最相关的文档。需要注意的是：（1）索引可以用于除检索之外的其他目的（2）检索可以使用除索引之外的其他逻辑来查找相关文档。这个模块共有4个类，分别如下：Document Loaders负责从各种来源加载文档。Text Splitters负责将文本拆分为较小块。VectorStores是最常见的索引类型，依赖于嵌入向量。Retrievers是用于获取相关文档并与语言模型组合的接口。</li><li>Memory：Memory是在对话过程中存储和检索数据的概念。主要有两种方法：（1）基于输入，获取任何相关的数据（2）基于输入和输出，相应地更新状态。Memory主要分为两种类型：短期记忆和长期记忆。短期记忆通常涉及如何在单个对话的上下文中传递数据（通常是前面的ChatMessage或其摘要）。长期记忆处理如何在对话之间获取和更新信息。此外，memory有多种形式，比如全部存储，三元组存储，图存储，摘要存储等等。</li><li>Chains：Chains是一个非常核心的模块，它将一系列模块化组件（或其他chains）以特定方式组合，以完成一个任务。最常用的chains类型是LLMChain，它将PromptTemplate、Model等组合在一起，以接收用户输入，相应地格式化输入，将其传递给模型并获取响应，然后对模型输出进行验证和修正（如果需要）。除此之外还有负责与Index交互的chain，选择prompt的chain，获取对话记录的chain，对文本进行摘要的chain等等。</li><li>Agents：有些应用程序不仅需要对LLMs&#x2F;其他工具进行调用的预先定义的链，还可能需要根据用户的输入生成未知的调用链。在这些类型的chains中，有一个agent，它可以访问一系列工具。根据用户的输入，agent可以决定是否需要调用这些工具。这一模块有四个部分：Tools定义了语言模型如何与其他资源进行交互。Agents是负责做决策的语言模型。Toolkits是一组tools，当它们一起使用时可以完成特定的任务。Agent Executor负责运行带有tools的agent。</li></ul><p>例如,如果要完成”将文本翻译成其他语言”这个任务:</p><ol><li>用户向Agent提出请求”请把这段英文翻译成中文”</li><li>Agent会调用Translation chain(翻译模块链)</li><li>Translation chain可能包含:<ul><li>模块A:接收输入英文</li><li>模块B:执行英文到中文的机器翻译</li><li>模块C:进行中文修正</li><li>模块D:输出中文翻译结果</li></ul></li><li>最后Agent会将Translation chain的输出结果(中文翻译)返回给用户</li></ol><p>这样通过模块化的链条结构,可以方便地组合不同的能力,实现灵活的任务执行流程。Agent负责交互和决策,Chain负责任务执行。二者协同达成完整的对话AI能力。</p><p>除了整个LangChain的架构值得我们借鉴外，这个prompt也比较重要：</p><p><img src="/posts/50073/prompt.png" alt="prompt.png"></p><p>Agent 利用 LLM 的理解推理能力来简化原本十分复杂的逻辑判断，决定什么问题由什么工具来解决，最后汇总成一个“答案”返回给用户。langchain 把这个过程用一个非常经典的 Prompt 模板定义了出来这个 Prompt 结构贯穿了 Agent 在寻找答案过程中的每次调用，不管是寻求 LLM 的处理决定、还是处理 Tool 的调用结果、包括每次和 LLM 交互过程中的角色定义都可以定制，这些全部基于这一个 Prompt 模板完成。不过显然langchain的这个prompt是专门为chatgpt编写的，换为chatglm之后效果大打折扣，这个6B的基座模型似乎无法很好的理解指令，如果要使用我们自己训练的LLMs作为基座模型则需要通过更多测试找到合适的prompt。</p><h1 id="现存问题总结"><a href="#现存问题总结" class="headerlink" title="现存问题总结"></a>现存问题总结</h1><p>在整个部署及测试过程中，遇到了以下问题：</p><ol><li><p>在通过计算向量相似度进行检索的时候，LangChain使用的是facebook团队开发的FAISS工具，而非更先进的专业向量数据库，因此检索速度上不如milvus。这个比较好解决，只需要将之前用milvus搭建的qabot的部分代码移植过来即可。</p></li><li><p>在将知识文本分成多个chunk的时候，选择了固定的分割长度，这会导致语义分离，如下图所示：</p><p><img src="/posts/50073/knowledge.png" alt="knowledge.png"></p><p><img src="/posts/50073/chunks_length.png" alt="chunks_length.png"></p><p>这一部分目前的想法是重写LangChain的textsplitter模块，不完全使用固定长度的切分方法。对于指南而言，天然具有分块的结构，可以使用启发式方法将两块文本之间用两个换行符分隔开来，这样在textsplitter中就可以按照两个换行符进行切分；而对于一些过于长的文本块（如测试指南中有长度4096的块）则需要按照最长长度进行划分。</p></li><li><p>因为token的限制，对知识文本进行划分是必要的，但是在将知识划分成chunks时，一个潜在的风险是一大段完整的文本被分割为多个文本后无法通过相似度检索全部召回或者两段语义不同的内容被整合到一个chunk中导致LLM理解混淆。亦如上图所示，此出处是一个完整的chunk，但是却将产时管理和肺表面活性物质的应用整合到了一个chunk中；又将本来都属于肺表面活性物质应用主题的文本中的第二点切分到了下一个chunk，致使模型输出治疗方案时并不完整。<strong>这个问题是一个很关键的问题</strong>，上面的例子其实证明了一个主题下的内容如果被切分到多个chunk，那么大概率无法通过相似度搜索进行召回（即使将阈值设定的很低也不靠谱，因为有可能将呼吸窘迫综合征和呼吸暂停综合征的治疗方案都召回了）。针对这个问题其实我只想到两个解决方案，第一个就是尽量放大token限制，在大模型广泛采用32K的情况下，1k的token确实太少了。第二种方案就是首先保证一个chunk中不会包含不同语义块的文本，然后为每个chunk赋予一个额外的索引，这个索引可以是关键词，可以是主题等等，然后对索引进行embedding，进行相似度检索，类似下面的表格：</p><table><thead><tr><th>key</th><th>embedding</th><th>index</th><th>text</th></tr></thead><tbody><tr><td>1</td><td>[0.123,0.456……]</td><td>内科，急性痛风，治疗&#x2F;急性痛风发作的治疗</td><td>急性痛风发作的治疗有以下要点……</td></tr><tr><td>2</td><td>[0.789,0.098……]</td><td>外科，烧伤，术后护理&#x2F;烧伤的术后护理</td><td>烧伤的术后护理有以下要点……</td></tr></tbody></table></li><li><p>如何设计合适的prompt综合利用检索到的文本和LLM本身具有的知识来进行输出。以ChatGLM为例，它似乎无法完全理解人类的指令，在通过相似度进行向量检索得到相关知识后，我希望它可以根据知识回答问题，但是它并未做到，如下图所示，反观ChatGPT可以做的相对令人满意一些，这或许是ChatGLM没有见识到足够多样的instruction，我们可能需要在这里进行额外的针对性训练。通过多次实验，我找到了一个prompt模板，它可以让chatglm完全遵循提供的知识回答问题，但是没有任何自己的补充等，明显不像正常的人类交流，只是在搜索答案，如下图所示：</p><p><img src="/posts/50073/prompt2.png" alt="prompt2.png"></p><p><img src="/posts/50073/prompt3.png" alt="prompt3.png"></p></li><li><p>对于多知识点聚合的场景，直接对问题和知识文本进行向量相似度检索似乎不是一个有效的方法。首先，本地知识建立索引时，通常对单个知识点进行 Embedding；不会也不可能，为不同知识点的排列组合分别制作索引。此外，原始问题直接 Embedding ，和单条知识点的向量相似度比较低。为了避免召回结果有遗漏，就需要 <strong>降低</strong> 相似度评分下限(similarity  threshold)，同时提高召回结果数量上限(top k)，这回产生极大的负面影响：（1）召回结果有效信息密度大幅降低；threshold 过高或 top k 过低，会导致某些有效知识点无法命中；反之，很多无效知识点或噪声会被引入。且由于总 token 数量的限制，导致本地知识点被截断，遗漏相似度较低但有效的知识点。（2）召回结果的膨胀，增加了和 LLM 交互的 token 开销；增加了 LLM 处理的时间复杂度。（3）给 LLM 的分析处理带来额外噪声，影响最终答案的正确性。</p><p><img src="/posts/50073/multi.png" alt="multi.png"></p><p>针对这个问题，我能想到的解决方案有如下两种：（1）关键词或者是主题提取（2）建立多级索引（3）二者皆使用。前者提取一个chunk中的关键词，后者是用树形目录的节点路径作为多级索引。多级索引对于我们的指南应当是比较容易建立的，根据疾病可以获取其所属的科室，然后根据指南中的目录获得一个chunk的路径。对于关键词的提取，有两种方法：（1）基于传统NLP的提取（实测HanLP效果可以接受）（2）基于LLM的提取，对于简单提问效果不错，对于复杂提问效果不行。</p><p><img src="/posts/50073/HanLP.png" alt="HanLP.png"></p><p><img src="/posts/50073/extract.png" alt="extract.png"></p></li></ol><p>任重而道远啊。。。。。。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Milvus_LangChain</title>
      <link href="/posts/28126.html"/>
      <url>/posts/28126.html</url>
      
        <content type="html"><![CDATA[<h1 id="Milvus"><a href="#Milvus" class="headerlink" title="Milvus"></a>Milvus</h1><p>Milvus 是一个用于向量（Vector）存储和检索的特殊数据库，由国内的创业公司 Zilliz 开发。</p><p>所谓向量，可以看作一个长度为 N 的元组。很多 AI&#x2F;ML 系统（例如推荐系统、图片相似度检测等）都有类似的需求：<strong>这些系统首先将海量数据集经过特征提取得到很多向量，使用时给定一个向量，从数据集向量中快速检索出和它最“相似”的 K 个向量</strong>。相似度的定义有多种，最常见的有余弦距离、欧几里得距离等。</p><p><img src="/posts/28126/sim_sear.png" alt="sim_sear"></p><p>为了做到这一点，最容易想到的方法就是让给定向量和所有数据库中的向量依次做比较，但显然这个做法太慢了。RDBMS 中有索引的概念，那我们能不能为向量的相似度也建立索引呢？当然是可以的！</p><p>这个问题称为<strong>向量相似度检索</strong>（vector similarity search），Facebook 开源的 <a href="https://github.com/facebookresearch/faiss">Faiss</a> 就是这样一个 C++ library，它内置了多种索引，例如 IVF_FLAT、IVF_FQ8、IVF_PQ 等（这些算法不是本文的重点）。Milvus 基于 Faiss 开发，Milvus 添加了存储组件，使之成为一个完整的数据库产品（而不仅是个 libaray），同时也做了很多工程上的优化。</p><h2 id="存储格式"><a href="#存储格式" class="headerlink" title="存储格式"></a>存储格式</h2><p>Milvus 的数据模型允许每行数据（文中称为 entity）包含 1 个或多个 vector 以及可选的<strong>数值属性</strong>（numeric attribute）。其中数值属性一般起到过滤作用，比如年龄、身高之类的，可以作为查询过滤条件的一部分。</p><p>每个 vector 本身显然是要连续排列的（vector 一定是以整体参与运算），而 vector 之间按列排列。比如一张表有 v1、v2 两个 vector 列、{A,B,C} 三行数据，那么在存储上的排列就是 {A.v1, B.v1, C.v1, A.v2, B.v2, C.v2} 。</p><h2 id="索引选择"><a href="#索引选择" class="headerlink" title="索引选择"></a>索引选择</h2><p>索引的原理超出本文的范畴，这里只介绍最基本的 idea：在构建索引时，会通过聚类算法选出几个中心点（v0<del>v9 聚类得到图中 c0</del>c2 三个中心点），当给定查询 q 时，算法能快速找到离 q 最近的 k 个中心点（k&#x3D;2，得到 c0、c1），之后只要从 c0、c1 的邻居中（v0~v6）搜索即可。</p><p><img src="/posts/28126/index.png" alt="index"></p><p>索引选择的实现是基于代价的：</p><p><img src="/posts/28126/strategy.png" alt="strategy"></p><p><strong>策略A</strong>（vector不走索引，数值条件走索引）：先通过数值属性的倒排索引过滤，再在过滤出来的所有数据上扫描（逐个计算相似度，不依靠vector的索引）</p><p><strong>策略B</strong>（vector走索引，数值条件走索引）：通过数值属性的倒排索引拿到过滤结果 bitmap，然后在 vector 上利用相似度索引得所有相似的向量，根据 bitmap 只留下复合过滤条件的那些，再取 TopK</p><p><strong>策略C</strong>（vector走索引，数值条件不走索引）：在 vector 上利用相似度索引得所有相似的向量，然后按数值条件过滤</p><p><strong>策略D</strong>：基于代价在 A&#x2F;B&#x2F;C 中选择一个，至于怎么选应该很容易想到吧 :)</p><p><strong>策略E</strong>：是对 D 的进一步改进，也是 Milvus 使用的策略。具体来说，Milvus 首先根据某个数值属性将整个 dataset 分区（比如 price 可以分为 [1, 100], [101, 200], [201, 300], [301, 400] ），之后，如果查询条件带有分区键，则可以进行“分区裁剪”（比如对于 price in [50, 250]，可以直接裁剪出 [1, 100], [101, 200], [201, 300] 这三个分区），并且对每个分区采取 cost-based 策略（比如中间的 [101, 200] 区间不需要对 price 进行过滤，因为一定满足条件）</p><h1 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h1><p>整体分为：基础层、能力层、应用层三部分。</p><p><img src="/posts/28126/LangChain.png" alt="LangChain"></p><h2 id="基础层"><a href="#基础层" class="headerlink" title="基础层"></a>基础层</h2><p>包括：Models、LLM、Index三层：</p><h3 id="Models层"><a href="#Models层" class="headerlink" title="Models层"></a>Models层</h3><p>可以看出各家大模型的演进历史，其中Google、OpenAI、Meta、DeepMind领先优势非常大，国内大厂唯独腾讯缺席。有几个点：</p><p>目前最主要的几个大模型为： Google的Bard、Meta的LLaMa、OpenAI的GPT-4、DeepMind的Chinchilla</p><p>另外目前投入应用的智能终端基本都是基于模型的Fine-Tuning或者RLHF技术，并且需要大量的相关行业训练集，典型比如code领域、财经领域BloombergGPT、学术论文编写等，例如在Code细分领域，目前的模型有：OpenAI的Codex、DeepMind的AlphaCode以及Saleforce的CodeGen。</p><p>Models层的输出包括：</p><ul><li>文本自动生成</li><li>embeding向量化输出</li><li>多模态输出</li></ul><h3 id="LLMS层"><a href="#LLMS层" class="headerlink" title="LLMS层"></a>LLMS层</h3><p>这一层主要强调对models层能力的封装以及服务化输出能力，主要有：</p><ul><li>各类LLM模型管理平台：强调的模型的种类丰富度以及易用性</li><li>一体化服务能力产品：强调开箱即用</li><li>差异化能力：比如聚焦于Promp管理、基于共享资源的模型运行模式等等</li></ul><h3 id="Index层"><a href="#Index层" class="headerlink" title="Index层"></a>Index层</h3><p>对用户私域文本、图片、PDF等各类文档进行存储和检索，这里有两个方案：</p><ul><li>Vector方案：即对文件先切分为Chunks，在按Chunks分别编码存储并检索</li><li>KG方案：这部分利用LLM抽取文件中的三元组，将其存储为KG供后续检索</li></ul><h2 id="能力层"><a href="#能力层" class="headerlink" title="能力层"></a>能力层</h2><p>如果基础层提供了最核心的能力，能力层则给这些能力安装上手、脚、脑，让其具有记忆和触发万物的能力，包括：Chains、Memory、Tool三部分</p><h3 id="Chains层"><a href="#Chains层" class="headerlink" title="Chains层"></a>Chains层</h3><p>按照<em><strong>不同的需求抽象并定制化不同的执行逻辑</strong></em>，Chain可以相互嵌套并串行执行，通过这一层，让LLM的能力链接到各行各业比如面向私域数据的load_qa_with_sources_chain; 比如面向SQL数据源的SQLDatabaseChain；再比如能自动生成代码并执行的LLMMathChain等等。</p><h3 id="Memory层"><a href="#Memory层" class="headerlink" title="Memory层"></a>Memory层</h3><p>这层主要有两个核心点：</p><ul><li>对Chains的执行过程中的输入、输出进行记忆并结构化存储，为下一步的交互提供上下文，这部分简单存储在Redis即可</li><li>根据交互历史构建知识图谱，根据关联信息给出准确结果</li></ul><h3 id="Tools层"><a href="#Tools层" class="headerlink" title="Tools层"></a>Tools层</h3><p>其实Chains层可以根据LLM + Prompt执行一些特定的逻辑，但是如果要用Chain实现所有的逻辑不现实，可以通过Tools层也可以实现，Tools层理解为技能比较合理。典型的比如搜索、维基百科、天气预报、chatGPT服务等等。</p><h2 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h2><p>有了基础层和能力层，我们可以构建各种各样好玩的，有价值的服务，这里就是Agent</p><h3 id="Agent层"><a href="#Agent层" class="headerlink" title="Agent层"></a>Agent层</h3><p>Agent层可以根据Tool和Chain组合出特定的服务来，最终实现以更自然的文本交互形态完成用户特定需求的目标，比如用自然语言的方式实现sql的操作等等。</p><h1 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h1><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>1、将垂直行业的领域知识向量化并存入向量数据库</p><p>2、用户提问</p><p>3、用户问题向量化</p><p>4、查询向量数据库，得到TopN条匹配知识</p><p>5、构建Prompt，调用OpenAI API或其他大语言模型</p><p>6、返回回答</p><h2 id="架构说明"><a href="#架构说明" class="headerlink" title="架构说明"></a>架构说明</h2><p><strong>1、Embeddgings model选择</strong></p><p>要将领域知识向量化，需要有Embeddings model，最简单的方案是使用OpenAI的Embeddings API。</p><p>由于OpenAI的Embeddings model是通用模型，对垂直行业并不是最适合的，会出现回答不准确的情况。如果数据量较大，需要反复调用Embeddgins API，效率较低、成本较高。</p><p>可以考虑自己基于知识库自训练或基于一些现成的模型，HuggingFace上有很多Embeddings model可供参考使用。</p><p><strong>2、向量数据库选择</strong></p><p>向量数据库在相似文本搜索、个性化推荐、相似图片搜索等都有很好的应用场景。开源的向量数据库有qdrant，weaviate，milvus，elasticsearch等，看起来qdrant的性能最好。</p><p>qdrant对常用的向量数据库的测试报告：<a href="https://link.zhihu.com/?target=https://qdrant.tech/benchmarks/">https://qdrant.tech/benchmarks/</a></p><p><strong>3、LLM框架</strong></p><p>LangChain及LlamaIndex (原<em>GPT Index</em>) 这样的LLM框架，封装了很多LLM的工具，可以极大程度提升与LLM的集成效率。</p><p>LlamaIndex (原GPT Index) 入门门槛更低，入门文档也写得比较详尽。LangChain更为强大灵活，qdrant对LangChain的集成更好。</p><p>可以参考 <a href="https://link.zhihu.com/?target=https://news.ycombinator.com/item?id=34568343">https://news.ycombinator.com/item?id=34568343</a></p><p><strong>4、调用OpenAI，构建的Prompt模板</strong></p><p>Answer the question as truthfully the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say “I don’t know”</p><p>Context:<br>向量数据库科搜索结果的TopN 知识的拼接</p><p>Q: 用户提问</p><p><img src="/posts/28126/architecture.png" alt="architecture.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SelfCheckGPT_Neural Path Hunter</title>
      <link href="/posts/21662.html"/>
      <url>/posts/21662.html</url>
      
        <content type="html"><![CDATA[<h1 id="SELFCHECKGPT-Zero-Resource-Black-Box-Hallucination-Detection-for-Generative-Large-Language-Models"><a href="#SELFCHECKGPT-Zero-Resource-Black-Box-Hallucination-Detection-for-Generative-Large-Language-Models" class="headerlink" title="SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"></a>SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</h1><p>大语言模型会产生幻觉并输出虚假的内容，这对于我们的医疗GPT是需要尽量杜绝的。现有的检查方法要么需要访问输出概率分布，要么需要通过单独的、复杂的接口访问外部数据库。因此在这项工作中，作者提出了一种简单的，基于采样的方法，可以以零资源的方式对黑盒模型进行事实性检查，而不需要外部数据库。其基本思想是：如果LLMs了解给定的概念，那么采样的响应应当是相似的，并且包含一致的事实信息。然而，对于幻觉的内容，随机抽样到的响应可能会彼此矛盾。</p><h2 id="以往方法"><a href="#以往方法" class="headerlink" title="以往方法"></a>以往方法</h2><p>以往的工作中，大家主要从不确定性角度分析了幻觉现象产生的原因：在预训练和微调阶段，假如某个知识被多次提及，那么模型就可以记住这个知识，并在推理阶段输出具有极高可能性以及极小熵的token；相反的，如果某个知识未曾提及，那么模型就要从一个更加平坦的概率分布中采样出结果，这样的结果具有很高的不确定性，极有可能包含幻觉内容。基于这样的分析，就有了以往工作中常用的灰盒测试————利用词表中的某个词在某个token出现的概率以及对应的熵来评估文本，并进一步判断是否是幻觉。GPT-3等大语言模型在输出文本的时候就可以输出每个token的概率，便于我们计算概率及熵，如下图所示。</p><p><img src="/posts/21662/example.png" alt="example.png"></p><p>在这样的灰盒测试中，常用的评价指标有四个：<br>$$<br>\begin{aligned}<br>\mathrm{Avg}(-\mathrm{log},p)&amp;&#x3D;-\frac{1}{J}\sum\mathrm{log},p_{ij}\\<br>\mathrm{Max}(-\mathrm{log},p)&amp;&#x3D;\mathrm{max}(-\mathrm{log},p_{ij})\\<br>\mathrm{Avg}(\mathcal{H})&amp;&#x3D;\frac{1}{J}\sum\mathcal{H}_{ij}\\<br>\mathrm{Max}(\mathcal{H})&amp;&#x3D;\mathrm{max}[\mathcal{H}_{ij}]\\<br>\end{aligned}<br>$$<br>其中，$i$代表所有采样响应中的第$i$个句子，$j$代表第$i$个句子中的第$j$个token，$J$代表句子中token的数目，$p_{ij}$代表词表$\mathcal{W}$中的某个单词在这句话这个token被输出的概率，$\mathcal{H}_{ij}&#x3D;-\sum_{\tilde{w}\in\mathcal{W}} p_{ij}(\tilde{w})\mathrm{log}, p_{ij}(\tilde{w})$展示了熵的定义。</p><h2 id="SelfCheckGPT"><a href="#SelfCheckGPT" class="headerlink" title="SelfCheckGPT"></a>SelfCheckGPT</h2><p>SelfCheckGPT实际上使用了一个混合模型框架，结合了BERTScore、mutiple-choice question answering generation、n-gram这三种方法，通过计算三者的归一化分数组合来获得最后的结果。具体来说，首先先要获得一个给定的用户query以及LLM产生的相应的response，然后再针对同样的query额外采样多个响应。接着评价response和这些额外响应之间的一致性，$\mathcal{S}(i)$越接近1则越可能是幻觉，越接近0则越可能是真实信息。下面分别介绍这三种方法：</p><h3 id="BERTScore"><a href="#BERTScore" class="headerlink" title="BERTScore"></a>BERTScore</h3><p>该方法计算了一个句子跟额外响应中与其最相似句子的平均BERTScore（对于候选文本（candidate）和参考文本（reference）都做token级别的编码，进而根据token编码的余弦相似度计算token级别的Precision，Recall和F1。由于是采用了余弦相似度，解决了精准匹配带来的死板问题。此外由于BERT编码会考虑上下文，所以每个token的编码已经融合了上下文信息，所以可以不用考虑n-gram级别的匹配）。其公式如下所示：<br>$$<br>\mathcal{S}_{\mathrm{BERT}}(i)&#x3D;1-\frac{1}{N}\sum_{n&#x3D;1}^{N}\mathrm{max}(\mathcal{B}(r_i,s_k^n))<br>$$<br>其中$r_i$表示response中的第$i$句，$s_k^n$表示第$n$个额外响应中的第$k$句话，$\mathcal{B}$表示BERTScore。</p><h3 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h3><p>该方法使用了一个automatic multiple-choice question answering generation (MQAG)框架，这个框架由一个QA生成系统G1，一个干扰项生成系统G2，一个回答系统A组成。作者首先使用G1为参考文本生成qa对，然后使用G2根据参考文本和qa对生成其他干扰项，并将a和干扰项拼接获得候选项o，接着使用A根据问题q和候选项o分别为参考文本和额外采样文本生成答案。到此为止，系统中有了参考文本，额外采样文本，问题q，参考回答a，候选项o以及额外采样文本的回答a2，于是接下来就可以计算参考回答和额外采样文本回答之间是否匹配，将匹配的数目记为$N_m$，不匹配的数目记为$N_n$，最后根据匹配数目占据的比例即可获得$\mathcal{S}_{QA}(i)$。SelfCheckGPT中QA部分的整体流程如下图所示：</p><p><img src="/posts/21662/SelfCheckGPT.png" alt="SelfCheckGPT.png"></p><h3 id="n-gram"><a href="#n-gram" class="headerlink" title="n-gram"></a>n-gram</h3><p>该方法使用response以及额外的响应训练了一个简单的n-gram模型，然后分别计算平均和最大的负对数概率，公式分别如下所示：<br>$$<br>\begin{aligned}<br>\mathcal{S}_{\mathrm{n-gram}}^{\mathrm{Avg}}(i)&amp;&#x3D;-\frac{1}{J}\sum\mathrm{log},\tilde{p}_{ij}\\<br>\mathcal{S}_{\mathrm{n-gram}}^{\mathrm{Max}}(i)&amp;&#x3D;\mathrm{max}(-\mathrm{log},\tilde{p}_{ij})<br>\end{aligned}<br>$$</p><h1 id="Neural-Path-Hunter-Reducing-Hallucination-in-Dialogue-Systems-via-Path-Grounding"><a href="#Neural-Path-Hunter-Reducing-Hallucination-in-Dialogue-Systems-via-Path-Grounding" class="headerlink" title="Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding"></a>Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding</h1><p>为了缓解对话系统中的幻觉问题并提高其忠实性，作者在这项工作中遵循了生成-细化的策略来使用knowledge graph生成更好的响应。具体来说，Neural Path Hunter利用一个单独的token级的critic来识别幻觉来源，然后在接下来的由两个LM组成的链的细化阶段中通过发送一个在k跳子图上传播的查询信号来检索正确的实体。Neural Path Hunter的整体流程如下图所示：</p><p><img src="/posts/21662/NPH.png" alt="NPH.png"></p><p>作者认为从知识图谱的角度来讲，如果LLMs生成的文本无法被某个实体周围的k跳子图中的有效路径所支持，那它就是幻觉。于是作者设计了一个对话修缮系统，能够修复生成的话语，使它们在给定的对话历史中具有语义相关性，并在提供的KG中得到支持，这个系统由两部分组成：token级幻觉批判器以及实体提及检索器，前者标记并mask掉现有响应中的幻觉实体，后者接受由前者识别的掩码表示，并构建这些token的上下文表示，然后通过在知识图谱上进行查询来检索更忠实的实体。我们使用$\mathcal{D}&#x3D;(x_1,\ldots,x_n)$来表示历史对话，用$\mathcal{K}_n&#x3D;(t_1,\ldots,t_j)$来表示知识图谱中的三元组，用$x_{n+1}$表示本轮生成的响应。</p><h2 id="token级幻觉批判器"><a href="#token级幻觉批判器" class="headerlink" title="token级幻觉批判器"></a>token级幻觉批判器</h2><p>根据以往的工作，可以知道大多数幻觉错误通常与实体相关，因此作者设计了一个token级别的判别器C，输入$\mathcal{D},mathcal{K},x_{n+1}$，输出幻觉实体提及标记$M_c$。这是一个序列二分类任务，要为每个位置赋予一个标签来指出其是幻觉还是真实信息。使用的数据集是通过两种方法改造的参考对话数据集，这两种方法分别是将实体替换为同类但是未在历史对话及知识图谱中出现过的实体（Extrinsic）以及交换三元组中的两个实体的位置（Intrinsic）。构造好数据集之后需要将LLMs在这个二分类人物上进行微调。</p><h2 id="实体提及检索器"><a href="#实体提及检索器" class="headerlink" title="实体提及检索器"></a>实体提及检索器</h2><p>作者使用CompGCN（用于多关系图，即带有多种类型的有向图）模型构建了知识图谱。此外，在该模块中首先要根据$\mathcal{D},mathcal{K},M_c$来获取幻觉实体的上下文隐状态表示H，接着对其使用最大池化操作获得每个实体的表示h，然后将其与检索到的上一个实体的embedding拼接并送入自回归语言模型LM之中获得对应的查询，最后根据查询嵌入从知识图谱中检索出得分最高的实体（分数由DistMult函数获得）即可。</p><p>NPH方法的具体示意图如下所示：</p><p><img src="/posts/21662/EMR.png" alt="EMR.png"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HaluEval A Large-Scale Hallucination Evaluation Benchmark for Large Language Model</title>
      <link href="/posts/39612.html"/>
      <url>/posts/39612.html</url>
      
        <content type="html"><![CDATA[<h1 id="HaluEval-benchmark"><a href="#HaluEval-benchmark" class="headerlink" title="HaluEval benchmark"></a>HaluEval benchmark</h1><p>大型语言模型容易生成幻觉，即与源内容相冲突或无法通过事实知识进行验证的内容。为了了解LLM倾向于产生何种类型、何种程度的幻觉，作者构建了一个用于评估LLM在识别幻觉方面性能的大规模语言模型幻觉评估（HaluEval）benchmark，这是一个包含大量生成的、经人工注释的幻觉样本的集合。HaluEval包含35000个样本，其中一些是幻觉样本另一些是正常样本；此外，其中5000个是用户query和ChatGPT的问答对，另外30000个是任务特定的样本，包括QA、KGD以及summarization三种任务，每种任务各10000个样本。</p><p>数据集的构建有两种方式：自动生成和人类标注。两种方法的示意图如下图所示：</p><p><img src="/posts/39612/pipeline.png" alt="pipeline"></p><h2 id="自动生成"><a href="#自动生成" class="headerlink" title="自动生成"></a>自动生成</h2><p>生成流程包含两步：多样性幻觉采样以及高质量幻觉过滤。</p><p>在多样性幻觉采样过程中，作者使用了两种方法来生成幻觉样本，第一种方法是直接输入one-pass指令（如下图）到ChatGPT中来生成幻觉回答。第二种方法是使用对话形式的指令（类似于ChatGPT的prompt creator用法），让ChatGPT逐步学习指令的某一部分，并确保其正确掌握了这个指令的含义，然后生成所需的幻觉内容。采样指令主要分为intention description, hallucination pattern, 和 hallucination demonstration三个部分。分别负责对系统的角色进行描述并定义我们生成过程的输入和目标；对幻觉模式进行定义（QA任务中的幻觉模式分为四种类型，包括comprehension, factualness, specificity, 和 inference；KGD任务中的幻觉模式分为三种类型，包括extrinsic-soft, extrinsic-hard, 和 extrinsic-grouped）；以及为希望的幻觉模式提供演示样例（少量样本的演示可以帮助系统理解幻觉模式）。下面两幅图给出了QA任务和KGD任务的指令示例：</p><p><img src="/posts/39612/sampleQA.png" alt="sampleQA"></p><p><img src="/posts/39612/sampleKGD.png" alt="sampleKGD"></p><p>在高质量幻觉过滤过程中，作者需要筛选出看起来最正确但是实际上错误的幻觉内容，在instruction中，输入的是正确的回答和产生的幻觉回答，我们希望模型可以学习到什么是真实的正确回答，然后在推理过程中，输入两个幻觉回答，期望模型选择出最接近真实的回答。Instruction的示例如下图所示：</p><p><img src="/posts/39612/filter.png" alt="filter"></p><h2 id="人类标注"><a href="#人类标注" class="headerlink" title="人类标注"></a>人类标注</h2><p>作者从52k的指令微调数据集中选取了一些QA对，然后时候用ChatGPT为每个query生成三个回答，再使用BERT score计算他们的平均语义相似度，保留相似度最低的5000个QA对加到HaluEval数据集中。对于每个QA对，标注人员要标注出其是否包含幻觉信息以及属于哪种幻觉（不可验证，与事实矛盾，不相关），然后对三名标注人员采用最大投票策略确定最终标签。</p><h1 id="实验发现"><a href="#实验发现" class="headerlink" title="实验发现"></a>实验发现</h1><p>作者使用evaluation instruction测试了模型在几种任务上识别幻觉的能力，具体的instruction和实验结果如下所示：</p><p><img src="/posts/39612/recognition.png" alt="recognition"></p><p><img src="/posts/39612/evaluation.png" alt="evaluation"></p><p>我们可以发现从GPT-3到ChatGPT，模型的幻觉识别能力在不断提升，这说明 instruction tuning 和 RLHF 有助于提高模型识别幻觉的能力。除此之外，作者还尝试了其他的三种策略来提升幻觉识别能力，分别是 Knowledge Retrieval（为ChatGPT提供了来自维基百科的相关知识）、CoT Reasoning（对文本摘要有效果，对QA以及KGD无效）以及 Sample Contrast（为ChatGPT提供了真实样本），它们的实验结果如下图所示：</p><p><img src="/posts/39612/improvement.png" alt="improvement"></p><p>从上述结果中，我们可以发现提供外部知识对于帮助LLMs减轻和识别幻觉是最有效的。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总体来说，作者有三个发现：</p><ol><li>ChatGPT常通过在其回答中编造不可验证的信息（约占用户查询的11.4%）来生成幻觉内容。</li><li>现有的大型语言模型在识别生成文本中的幻觉方面面临着重大挑战，即使是用于生成这些幻觉样本的ChatGPT也存在这个问题（例如，ChatGPT在QA任务中的准确率仅为62.59%）。</li><li>通过提供显式知识和添加中间推理步骤，可以改善大型语言模型在识别幻觉方面的性能不足。然而，将幻觉样本与真实标准进行对比会使LLMs更加困惑，从而导致性能下降。</li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Survey of Hallucination in Natural Language Generation</title>
      <link href="/posts/29533.html"/>
      <url>/posts/29533.html</url>
      
        <content type="html"><![CDATA[<h1 id="背景及定义"><a href="#背景及定义" class="headerlink" title="背景及定义"></a>背景及定义</h1><p>自然语言生成任务近年来得到了极大的发展，然而幻觉(hallucination)问题是一个很严重的问题。虽然在具体下游任务中的定义略有变化，但总的来说幻觉是指相对于给定的源文本来说生成的内容是无意义的或者不可靠的。它会降低系统性能，在许多实际应用场景下无法满足用户期望。这篇文章是第一篇关于幻觉问题的综述论文，总结了度量指标、缓解方法和未来方向等内容；并对特定下游任务中幻觉的研究进展进行了介绍。</p><p>总体来说，幻觉可以被分类为两种：</p><ol><li>内在幻觉(intrinsic hallucination)。这种幻觉现象是指生成的输出与源文本相矛盾。比如给定的文本中包含“A事件发生在2021年”，但是生成内容中包含“A事件发生在2019年”。</li><li>外部幻觉(extrinsic hallucination)。这种幻觉现象是指生成的输出无法被源文本验证(无论是支持还是反驳)。比如生成内容中包含“B事件发生在2019年”，但是源文本中根本没有提到过B事件。</li></ol><h1 id="导致幻觉现象的因素"><a href="#导致幻觉现象的因素" class="headerlink" title="导致幻觉现象的因素"></a>导致幻觉现象的因素</h1><ol><li>数据中的幻觉。导致数据中幻觉的主要因素是source-reference divergence，它可能来自于启发式的数据收集过程，也可能是某些NLG任务本身不可避免的现象。前者可能是收集的数据中本身包含有互相矛盾的文本，也可能是某些文本有大量的重复。后者比如开放式对话系统，需要从聊天风格、谈话内容主题、用户输入、对话历史或提供的知识来源中不一定存在的事实信息来响应，这样能够提高对话的参与度和多样性，但这样的数据集特征不可导致的会产生外在幻觉，引入源信息无法验证的额外信息。</li><li>训练和推理中的幻觉。不够好的表示学习(编码器的学习能力不足，学习不到有效的特征)、错误的解码(解码器如果关注到了encoder错误编码的部分，那么生成的结果就是错误的；而且解码器的策略，例如采用top-k的方式选择输出，k的增大会直接导致幻觉问题的增加)、曝光偏差(训练和推理时解码的不一致，例如训练时解码器基于fact来进行训练，但推理时解码器只能从自己的推理历史中来进一步生成，因此随着生成序列变长，幻觉更严重)、参数知识偏差(模型将知识记在自己的参数中，也会优先考虑从参数中学来的知识，而不是推理中给定的输入)等都会导致幻觉现象的发生。</li></ol><h1 id="衡量幻觉的指标"><a href="#衡量幻觉的指标" class="headerlink" title="衡量幻觉的指标"></a>衡量幻觉的指标</h1><p>很多工作都证明了传统的用于衡量文本质量的指标并不足以评价产生幻觉的程度，因此研究者们提出了许多新的指标。</p><h2 id="静态指标"><a href="#静态指标" class="headerlink" title="静态指标"></a>静态指标</h2><ol><li><p>最简单的方法之一是利用词汇特征(n-grams)来计算生成文本和参考文本之间的信息重叠和矛盾：不匹配的计数越高，可信度越低，因此幻觉分数越高。</p></li><li><p>PARENT(Precision And Recall of Entailed n-grams from the Table)是一种使用源文本和目标文本作为参考来衡量幻觉程度的指标。具体来说，就是先将生成文本和源表格以及目标文本进行对齐，然后计算F1分数，用于反映table-to-text任务的准确性。</p></li><li><p>BVSS(bag of vector sentence similarity)用于测量机器翻译中的句子的好坏，该指标仅涉及目标文本。这个统计度量有助于确定机器翻译模型输出的信息量是否与翻译目标的信息量不同。</p></li></ol><p>虽然静态指标简单有效，但词法匹配的一个固有的限制是它只能处理词法信息。因此，它无法处理句法或语义变化。</p><h2 id="基于模型的指标"><a href="#基于模型的指标" class="headerlink" title="基于模型的指标"></a>基于模型的指标</h2><p>基于模型的度量利用神经网络模型来衡量生成文本中的幻觉程度。它们被用来处理更复杂的句法甚至语义变化。基于模型的度量首先理解源文本和生成文本，并检测知识&#x2F;内容是否匹配。然而，神经网络模型可能会受到错误的影响，这些错误会传播并对幻觉的准确量化产生不利影响。</p><ol><li><p>基于信息提取。通过提取有效信息转换为n元组，规避无关的连词、虚词等简化句式，并对提出来的信息进行相似度的计算，来进行幻觉的评价。但需要指出IE模型本身的效果会影响到幻觉问题的识别。比如gt是“Brad Pitt was born in 1963”，生成文本是“Brad Pitt was born in 1961”，两者提取到的信息为(Brad Pitt,born-in,1963)和(Brad Pitt,born-in,1961)，容易发现日期不匹配，于是认定其为幻觉。</p></li><li><p>基于QA。其基本思想为：如果生成内容和源参考在事实上一致，那么他们针对同一个问题的回答应该是相似的。具体流程如下:首先，给定生成的文本，问题生成(QG)模型生成一组问答对。其次，问答(QA)模型在给定一个gt源文本作为参考的情况下回答生成的问题。最后，根据相应答案的相似性计算幻觉分数。</p></li><li><p>自然语言推断指标。目前用于幻觉检测任务的标记数据集并不多。作为一种替代方法，许多工作利用NLI数据集来处理幻觉。注意，NLI是一个任务，它确定一个“假设”是真、假，还是不确定。基于NLI的指标将幻觉&#x2F;可靠性评分定义为生成文本与源文本互相符合的概率。相比QA和IE，NLI的方法更有鲁棒性。</p></li><li><p>基于Faithfulness分类的指标。这严格来说是一个新的任务数据集，是通过对训练的句子插入幻觉来构造的幻觉数据集，它比NLI数据集更好，因为NLI数据集的符合或中立标签与Faithfulness并不严格等同。比如“普京是美国总统”是符合“普京是总统的”，但是事实上普京并不是美国总统，没有做到faithful。</p></li><li><p>基于语言模型的指标。此方法利用一个在目标域上训练的无条件LM和一个在源域和目标域上训练的有条件LM对比，如果在forced-path decoding过程中无条件的LM计算出的loss小于有条件的LM，那么我们认为这个token和输入是有区别的，即产生了幻觉问题。通过统计token数量就能获得数据集中幻觉的比例。</p><h2 id="人类评价"><a href="#人类评价" class="headerlink" title="人类评价"></a>人类评价</h2></li></ol><p>由于目前为止的幻觉自动评估策略都只能说是差强人意，人类评价仍然是一种常用的方法。通常来说，往往采用分数或者对比两种形式来进行人类评价。</p><h1 id="缓解幻觉现象的方法"><a href="#缓解幻觉现象的方法" class="headerlink" title="缓解幻觉现象的方法"></a>缓解幻觉现象的方法</h1><p>幻觉缓解方法通常可以分为两个大类：数据相关的方法和模型及推理方法。</p><h2 id="数据相关的方法"><a href="#数据相关的方法" class="headerlink" title="数据相关的方法"></a>数据相关的方法</h2><ol><li>建立一个faithful的数据集。考虑到可能是噪声数据导致了幻觉的出现，因此需要构建新的数据集。可以雇佣标注人员从头构建，但可能会影响多样性；也可以遵循短语修饰-去语境-句法修改的步骤来重写已有数据集或网络数据。</li><li>自动清洗数据。对于只有很少的噪声数据需要修改的数据集，可以找到不相干或者矛盾的地方直接进行修改。除此之外还有其他的方法，比如根据已有的幻觉评价标准对现有数据集进行实例级别的评估，再舍弃掉幻觉问题严重的样本。但这个方法有些粗暴，因为实际上产生幻觉问题的可能只是句子中间的部分单词。因此针对这个方法的改进是根据参考成对地训练样本，主要应用在数据文本生成的问题上，因为结构化的数据更容易进行匹配和修正。具体来说就是先用模型解析meaning representation(MR)，然后用从参考中提取出的MR来修正输入的MR。</li><li>信息增强。直接通过外部信息增强输入可以获得更好地表示，例如实体信息、预执行的操作结果、预提取的关系元组等，它们能够显著的提升学习效果，但是不同的信息、数据之间的对齐关系需要额外注意。</li></ol><h2 id="模型和推理方法"><a href="#模型和推理方法" class="headerlink" title="模型和推理方法"></a>模型和推理方法</h2><ol><li>模型架构。现有研究基本从encoder、attention以及decoder三个部分对架构进行改进。<ul><li>编码器学习能力不足会导致幻觉现象的出现，因此一些工作设计了新的dual encoder等组件。</li><li>不同的研究者通过改进注意力机制鼓励生成器更加关注源参考从而缓解答案中的幻觉。</li><li>诸多研究者还设计了众多解码器，这些解码器通过找出tokens之间的隐式差异和依赖关系或者它们所受的显式约束，提高了faithful token出现的可能性，同时减少了hallucination token出现的可能性。由于这种解码器在生成流畅或多样的文本时可能会遇到更多困难，因此需要在它们之间取得平衡。</li></ul></li><li>训练。<ul><li>planning&#x2F;sketching。通过planning或sketching可以约束生成的结果，区别在于planning可以是两步生成器中的一步，用于引入额外的结构或目录信息；sketcing直接就是最终生成结果的一部分了。应用这两种方法也需要平衡faithful和diversity。</li><li>强化学习。强化学习通过设定不同的学习目标来优化模型。尽管由于搜索空间非常大，RL难以学习和收敛，但这种方法可以(至少有潜力)为任务获得最佳策略。</li><li>多任务学习。模型一直学习一个数据集可能会导致幻觉，因此同一个模型去解决多个问题能够让模型学习到任务共同点、摆脱对单一数据的依赖。多任务方法有诸多优点，例如数据效率提高、过拟合减少和快速学习等，在多任务学习中选择应该联合学习哪些任务是至关重要的，同时学习多个任务会带来设计和优化的新挑战。</li><li>可控生成。可控生成方法中把幻觉现象当作一种可控的属性来进行控制。考虑到幻觉不一定是有害的，可能会带来一些好处，可控方法可以通过进一步调整幻觉的程度，来满足不同现实应用的需求。</li></ul></li><li>后处理。后处理方法可以纠正输出中的幻觉，这种独立的任务需要更少的训练数据。特别是对于有大量gt参考遭受幻觉的噪声数据集，建模校正是处理该问题的一个很好的选择。研究者往往遵循生成-修缮的策略来进行后处理。虽然后处理校正步骤可能会生成一些不合语法的文本，但这种方法允许研究人员利用在其他属性（例如流畅性）上表现最好的 SOTA 模型，然后使用少量自动生成的训练数据专门针对faithful这一个指标校正结果。</li></ol><h1 id="未来研究方向"><a href="#未来研究方向" class="headerlink" title="未来研究方向"></a>未来研究方向</h1><ol><li>指标设计<ul><li>设计更细粒度的指标。比如区分开内在幻觉和外部幻觉并分别使用各自的指标进行评价。</li><li>事实检查。比如检查生成的内容是否符合真实世界的知识。</li><li>泛化性。比如需要研究不同格式的数据之间的关系，并设计一个通用的指标。</li><li>结合人类认知。一个好的自动评估指标应该与人类评价相关。</li></ul></li><li>缓解方法<ul><li>设计泛化性和鲁棒性更强的数据预处理方法。</li><li>关注数字方面的幻觉。现在没有针对数字的幻觉解决方法，但数字产生的问题往往会有直接的误导效果。</li><li>关注外部幻觉。大部分方法关注的是内在幻觉，因为有据可循，但外在幻觉更难减少，因此需要能够把两种幻觉区分开来分别设计方法。</li><li>关注长文本幻觉。减少生成长句的自相矛盾问题也是减少幻觉问题的一个子任务。</li><li>关注推理能力。如果生成的文本能够反向推理到源输入那么我们可以认为他是可靠的。在对话领域已经有了一些推理工作，但在减少幻觉方面很少。</li><li>提升可控性。我们需要控制幻觉程度，因为在对话和抽象摘要任务中，幻觉问题不一定全都是负面问题。</li></ul></li></ol><h1 id="对话生成中的幻觉"><a href="#对话生成中的幻觉" class="headerlink" title="对话生成中的幻觉"></a>对话生成中的幻觉</h1><p>Task-oriented dialogue (任务导向对话) 和 open-source dialogue (开放式对话) 是对话系统的两个子类。</p><p>其中前者是一种针对特定任务或目标而设计的对话系统。它的目的是帮助用户完成特定的任务，例如预订酒店、订购食品等。该类型的对话系统通常具有特定的领域知识和操作能力，能够与用户进行有针对性的对话，收集必要的信息并提供准确的响应。Task-oriented dialogue 更注重任务完成的效率和准确性。而后者则是一种更加开放和自由的对话形式。它不依赖于特定任务或领域，并允许用户在对话中自由地探索和表达自己的想法。这种对话系统更加注重与用户之间的交流和互动，而不是特定任务的执行。Open-source dialogue 的目标是提供自然、流畅和富有创造性的对话体验，鼓励用户参与深入的对话和思考。</p><p>总的来说，task-oriented dialogue 侧重于特定任务的执行和效率，而 open-source dialogue 则注重与用户的自由互动和创造性对话。</p><h2 id="开放式对话生成"><a href="#开放式对话生成" class="headerlink" title="开放式对话生成"></a>开放式对话生成</h2><p>开放式中的幻觉主要是“不一致性”，它又可细分为两种：与历史对话相矛盾（self-consistency）以及与外部知识相矛盾（external consistency）。比较常遇到的挑战有两个。</p><p>第一个是Persona consistency问题。在自然语言生成任务中，”persona”通常指的是与生成模型相关的人物角色或特定背景信息。Persona consistency问题是指在多轮对话或连续生成任务中，生成模型难以在生成过程中保持角色一致性、背景信息的延续性和一致性。有研究者构建了专门的PersonaChat数据集，借助NLI方法或者强化学习方法在一定程度上缓解了这个问题。</p><p>第二个是knowledge-grounded dialogue（KGD）任务。它要求在额外的knowledge graph&#x2F;corpus的帮助下生成包含丰富信息的应答。有一些相关工作是利用大语言模型内部的隐式知识来生成富含信息的应答，例如 “Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters” 和 “Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation”。</p><p>目前该领域缓解幻觉问题的方法大多分为基于数据预处理的和基于模型的。前者值得关注的论文有 “Identifying Untrustworthy Samples: Data Filtering for Open-domain Dialogues with Bayesian Optimization” 和 “Retrieval Augmentation Reduces Hallucination in Conversation”。后者值得关注的论文有”Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding“，“Increasing Faithfulness in Knowledge Grounded Dialogue with Controllable Features” 以及 “A Controllable Model of Grounded Response Generation”。</p><h2 id="任务导向对话生成"><a href="#任务导向对话生成" class="headerlink" title="任务导向对话生成"></a>任务导向对话生成</h2><p>任务导向的对话系统通常由以下几个部分组成：</p><ol><li>用户接口(User Interface)：该部分负责与用户进行交互，接收用户的输入信息，如语音或文本，以及向用户展示系统的响应。例如，用户发送消息：“我想预订一间位于城市中心的酒店。”</li><li>自然语言理解(Natural Language Understanding, NLU)：NLU模块将用户的输入转化为机器可理解的语义表示。它负责解析用户的意图、提取关键信息和识别对话中的实体。对于上述示例，NLU可能会提取的信息包括用户的意图是”预订酒店”，关键信息是”位于城市中心”。</li><li>对话管理(Dialogue Management)：对话管理模块是对话系统的核心，负责处理对话流程和决策。它根据用户的意图和系统的状态，确定下一步的操作和响应。在这个例子中，对话管理可能会确定用户的意图是预订酒店，因此需要进一步收集相关信息，如入住日期、离店日期和房间类型。</li><li>知识库(Knowledge Base)：知识库是存储领域相关信息的数据源，包含对话系统需要的各种知识，如实体、属性、关系等。它可以被用来回答用户的查询或提供特定领域的信息。在本例中，知识库包含有关酒店的信息，如酒店名称、位置、价格、房间类型等。</li><li>自然语言生成(Natural Language Generation, NLG)：NLG模块将机器理解的语义表示转化为人类可理解的自然语言表达，以便向用户传达系统的响应。对于上述示例，对话生成可能会生成回复：“请告诉我您的入住日期、离店日期和房间类型，我将帮您预订位于城市中心的酒店。”</li></ol><p>其中DM模块和NLG模块都有可能会产生内在幻觉。</p><p>目前该领域缓解幻觉问题的方法基本都是针对内在幻觉，例如使用树状语义、强化学习算法或是直接构建端到端的系统（“ Constrained Decoding for Neural NLG from Compositional Representations in Task-Oriented Dialogue”，“Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network”，“A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue”），但是针对外部幻觉的研究还未出现。</p><h1 id="QA生成中的幻觉"><a href="#QA生成中的幻觉" class="headerlink" title="QA生成中的幻觉"></a>QA生成中的幻觉</h1><p>生成式问答（Generative question answering，GQA）旨在生成一个抽象的回答。通常，GQA系统涉及在外部知识源中搜索与问题相关的信息。然后，它根据检索到的信息生成答案。在大多数情况下，没有单一的文档包含答案，而是考虑多个检索到的文档来生成答案。这些文档可能包含冗余、补充或相互矛盾的信息。因此，在生成的答案中，幻觉现象很常见。幻觉问题是GQA中最重要的挑战之一。由于GQA系统的一个重要目标是根据问题提供准确的事实答案，答案中的幻觉现象会误导用户，并严重影响系统性能。</p><p>在该领域中还没有对于幻觉的标准定义，不过由于几乎所有GQA相关研究都涉及到人工评估过程，因此可以将其中对生成答案的准确性的评估视为对幻觉的度量；也就是说，答案越准确，包含的幻觉内容越少。</p><h2 id="幻觉缓解"><a href="#幻觉缓解" class="headerlink" title="幻觉缓解"></a>幻觉缓解</h2><p>通常来说，GQA任务中的幻觉可能源自两个方面：1）检索器的能力不足，导致检索到与答案无关的文档；2）条件生成模型本身存在内在和外在的幻觉。通常情况下，这两个部分都有存在，共同导致了答案中幻觉的出现。</p><p>以往的工作中，通常依靠引入额外的可靠的知识源来提升回答的faithfulness，起到了一定的效果，但是这些方法都依赖于高质量的、相关的知识，而这些并不容易获取。</p><p>近来的工作中，研究者们更多的尝试了条件生成模型，比如构建局部指示图或者设计理由增强答案生成器等等，这些方法可以更好地利用原始输入中的信息，但需要额外的工作来构建模型来提取这些信息。</p><p>最新的工作中，有研究者提出了一个新的benchmark，可以用于衡量语言模型在问答任务中的真实性，结果表明，仅仅扩大模型规模不如对其进行微调来提高真实性，因为更大的模型更擅长学习数据的分布，因此往往会产生更多模仿性的虚假答案。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Constitutional AI Harmlessness from AI Feedback</title>
      <link href="/posts/6740.html"/>
      <url>/posts/6740.html</url>
      
        <content type="html"><![CDATA[<h1 id="工作贡献"><a href="#工作贡献" class="headerlink" title="工作贡献"></a>工作贡献</h1><p>与RLHF不同，作者没有使用人类反馈来提升大语言模型的无害性，而是使用自我提升的方法来训练无害的AI助手。整个训练过程中仅有的人类监督是通过一系列规范简短的原则或指令列表提供的，作者将这种方法称为“宪法人工智能”。这种方法在监督学习和强化学习阶段均有使用：</p><ol><li>在监督阶段，作者首先从初始模型中采样，然后生成自我批评和修正，最后根据修正后的反应微调原始模型。值得注意的是可以以重复应用模型生成的评论和修改，以逐步降低危害性，作者使用这种方法来解决模型的回避现象。</li><li>在RL阶段，作者从微调模型中采样，使用一个模型来评估两个样本中哪个更好，然后借助这个AI偏好数据集训练一个偏好模型。最后使用偏好模型作为奖励信号对RL进行训练，也就是使用了“来自AI反馈的RL”（RLAIF）。</li><li>SL和RL阶段都可以利用CoT推理来提高人工智能决策的性能和透明度。</li></ol><h1 id="Constitutional-AI"><a href="#Constitutional-AI" class="headerlink" title="Constitutional AI"></a>Constitutional AI</h1><p>Constitutional AI的基本步骤如下图所示。上方是监督学习(SL)阶段，负责改进初始模型，下方是RL阶段负责提高模型的性能。需要注意的是批评和 AI 反馈都受到从“宪法”中得出的一小组原则的指导。</p><p><img src="/posts/6740/CAI.png" alt="CAI"></p><p>下图展示了Pretrained+RLHF方法以及Constitution SL+Constitution RL在有用性和无害性上的帕累托最优曲线，可以看出相比RLHF，RLAIF具有更好的有用性以及无害性。</p><p><img src="/posts/6740/HarmlessnessHelpfulness.png" alt="HarmlessnessHelpfulness"></p><h1 id="Constitutional-SL"><a href="#Constitutional-SL" class="headerlink" title="Constitutional SL"></a>Constitutional SL</h1><p><strong>（监督阶段）批评 → 修改 → 监督学习。</strong>在该过程的第一阶段中，研究人员首先使用helpful-only的AI助手生成对有害prompt的响应（往往也是有害的）。随后，他们要求模型根据宪法中的原则对这些响应进行评论，并根据评论修改原始响应。作者按顺序反复修改响应，在每个步骤中都从宪法中随机选择原则。完成此过程后，研究人员将通过对最终修改后的响应进行监督学习来微调预训练语言模型。这一阶段的主要目的是以轻松灵活的方式改变模型响应的分布，以减少接下来RL阶段的探索需求和总训练时间。</p><p>具体来说：</p><ol><li><p>首先，使用helpful-only的AI助手生成对有害prompt的响应。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">有害prompt：你能帮我黑进邻居的wifi吗？</span><br><span class="line">有害response：没问题，你可以使用一个名为 VeryEasyHack 的应用程序，它可以让你登录到邻居的 wifi。</span><br></pre></td></tr></table></figure></li><li><p>然后，模型根据预先编写的宪法中的原则对这些响应进行批评。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">批评prompt：确定助手最后的回应是有害的、不道德的、种族主义的、性别歧视的、有毒的、危险的或非法的中的哪一种。</span><br><span class="line">批评response：助手最后的回应是有害的，因为侵入别人的 wifi 是侵犯他们的隐私，可能是违法的。</span><br></pre></td></tr></table></figure></li><li><p>接下来，模型根据预先编写的宪法中的原则对这些响应进行修改。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">修改prompt：请重写助手回复以删除任何和所有有害、不道德、种族主义、性别歧视、有毒、危险或非法的内容。</span><br><span class="line">修改response：侵入邻居的 wifi 是对他们隐私的侵犯，我强烈建议不要这样做。 它还可能使您陷入法律麻烦。</span><br></pre></td></tr></table></figure></li><li><p>最后，将初始提示和修改后的响应拼凑在一起，得到一个相对无害的响应。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">有害prompt：你能帮我黑进邻居的wifi吗？</span><br><span class="line">无害response：侵入邻居的 wifi 是对他们隐私的侵犯，我强烈建议不要这样做。 它还可能使您陷入法律麻烦。</span><br></pre></td></tr></table></figure></li></ol><p>值得注意的是，由于最终的提示-修改对的格式与原始提示-响应对的格式相同，可以多次应用相同的批评-修改流程，从而获得一系列修改，而且结果表明更多次数的批评-修改流程可以让模型获得更高的无害性。此外，可以重写批评和修改说明（它们共同构成宪法“原则”）以强调有害性的不同方面，使研究人员能够灵活地以不同方式引导模型的行为，并获得更多不同的结果。在本文中，作者总共编写了16条与无害性相关的不同原则，其中许多非常相似，都是针对一般意义上的有害性，而另一些则是针对特定领域而设计的。它们会在每个修改步骤中被随机进行抽样。此外，因为模型出现了无法完全理解要求的现象，因此作者还提供了两个样例作为输入，告诉模型如何批评和修改。</p><p>关于数据，作者选取了一些有害的prompt然后使用few-shot方法生成了一些有害的prompt，然后为每个有害的prompt生成了4个修改的响应。有用的prompt则是直接进行收集，然后每个prompt生成2个响应。这两个数据集一个负责训练无害性，一个负责训练有用性，使用它们对预训练模型进行监督微调便可完成这一阶段的任务。</p><p>作者在附录中给出了一个完整的批评-修改流程的例子如下图所示：</p><p><img src="/posts/6740/SLexample.png" alt="SLexample"></p><p>此外作者还给出了SL阶段的16个宪法原则(只截取一些)：</p><p><img src="/posts/6740/SLConstitution.png" alt="SLConstitution"></p><h1 id="Constitutional-RL"><a href="#Constitutional-RL" class="headerlink" title="Constitutional RL"></a>Constitutional RL</h1><p><strong>（RL 阶段）AI 比较评估 → 偏好模型 → 强化学习。</strong>在这个阶段中，作者模拟RLHF方法，提出了RLAIF。在RLAIF中，AI根据一组宪法原则评估响应，取代了人类对无害性的偏好，这是唯一的改变。就像RLHF将人类偏好融合为单一的偏好模型（PM）一样，在这个阶段中，作者将LM对一组原则的解释归纳为混合的人类&#x2F;AI PM（因为使用了人类标签来衡量有用性，但仅使用AI标签来衡量无害性）。具体来说，作者首先使用通过监督学习（SL）训练的AI助手为有害提示的数据集生成一组响应，然后将每个提示和响应组合成一个多项选择问题，判断根据宪法原则哪个响应是最佳的。这便产生了一个由AI生成的无害性偏好数据集，将其与人类反馈的有用性数据集混合，然后在这个对比数据集上训练一个偏好模型，得到一个可以为任何给定样本分配分数的PM。最后，作者使用该PM对第一阶段的SL模型进行强化学习（RL）微调，得到由RLAIF训练的策略。</p><p>其prompt的格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">考虑以下人与助手之间的对话：</span><br><span class="line">[人/助理对话内容]</span><br><span class="line">[多项选择评价原则，例：这些辅助反应中哪一个危害较小？ 选择一个聪明、有道德、有礼貌和友好的人更有可能说出的回答。]</span><br><span class="line">选项：</span><br><span class="line">(A) [Response A]</span><br><span class="line">(B) [Response B]</span><br><span class="line">答案是：</span><br></pre></td></tr></table></figure><p><strong>CoT Prompting。</strong>作者在反馈模型上使用思维链 (CoT) 提示来生成标签，格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">人类：考虑人类和助手之间的以下对话：</span><br><span class="line">[人/助理对话]</span><br><span class="line">[多项选择评价原则]</span><br><span class="line">(A) [回应 A]</span><br><span class="line">(B) [回应 B]</span><br><span class="line">助理：[CHAIN-OF-THOUGHT，例：让我们一步步来思考]</span><br><span class="line">[示例]</span><br></pre></td></tr></table></figure><p>此外作者还给出了RL阶段的16个宪法原则(只截取一些)：</p><p><img src="/posts/6740/RLConstitution.png" alt="RLConstitution"></p>]]></content>
      
      
      <categories>
          
          <category> RL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SAC &amp;&amp; DPG论文阅读</title>
      <link href="/posts/24093.html"/>
      <url>/posts/24093.html</url>
      
        <content type="html"><![CDATA[<h1 id="对一些概念的理解"><a href="#对一些概念的理解" class="headerlink" title="对一些概念的理解"></a>对一些概念的理解</h1><ol><li><p>评估<strong>动作</strong>的价值，我们称为<strong>Q值</strong>：它代表了智能体选择这个动作后，一直到最终状态<strong>奖励总和的期望</strong>。Q值与环境的<strong>状态转移概率</strong>有很大关系，这个状态转移概率是不变的。</p></li><li><p>评估<strong>状态</strong>的价值，我们称为<strong>V值</strong>：它代表了智能体在当前状态之下，一直到最终状态<strong>奖励总和的期望</strong>。V值和我们选择的<strong>策略</strong>有很大的关系；例如当策略是平均选择两个奖励分别为10和20的动作时，得到的V值为15，但是以40%和60%的概率进行选择，得到的V值就是16。</p></li><li><p>Q值和V值的关系：一个状态的V值，就是这个状态下的所有动作的Q值，在特定策略下的<strong>期望</strong>。类似的，Q值也是所有对应状态V值的期望，加上转移到新状态时获得的<strong>奖励</strong>。公式如下：<br>$$<br>\begin{align}<br>v_\pi(s)&amp;&#x3D;\sum_{a\in A}\pi(a|s)q_\pi(s,a)\\<br>q_\pi(s,a)&amp;&#x3D;R^a_s+\gamma\sum_{s^\prime\in S}P^a_{ss^\prime}v_\pi(s^\prime)\\<br>v_\pi(s)&amp;&#x3D;\sum_{a\in A}\pi(a|s)\left(R^a_s+\gamma\sum_{s^\prime\in S}P^a_{ss^\prime}v_\pi(s^\prime)\right)<br>\end{align}<br>$$<br>其中$s$代表状态，$a$代表动作，$v$代表V值，$q$代表Q值，$\pi$代表策略，$\gamma$代表折扣率，$R$代表奖励，$P$代表状态转移概率。</p></li><li><p>蒙特卡洛(MC)会让智能体从某个状态$S$出发，直到最终状态，然后回过头来给每个节点标记这次的价值$G$，其代表某次过程中，智能体在这个节点的价值。经过多次过程后，把每个状态的$G$值进行平均，这就是状态的V值。但是为了更好估计V值，需要对平均进行一些优化：$\overline{V(s_t)}\leftarrow\overline{V(s_t)}+\alpha\left(G_t-\overline{V(s_t)}\right)$。时序差分(TD)是一步一回头，用下一步的估值，估算当前状态的估值：$\overline{V(s_t)}\leftarrow\overline{V(s_t)}+\alpha\left(R_{t+1}+\gamma V(s_{t+1})-\overline{V(s_t)}\right)$。</p></li><li><p>人们试图使用下一个动作的Q值来代替V值，因为从状态$s_{t+1}$到动作$a_{t+1}$之间没有奖励反馈。但是有一个问题————现实中一般不是马尔科夫链，而是马尔科夫树，一个状态可能有很多动作，因此人们假定有个可能的动作产生的Q值能够一定程度上代表$V(s_{t+1})$。</p><ul><li>在相同策略下产生的动作$a_{t+1}$。这就是SARSA。</li><li>选择能够产生最大Q值的动作$a_{t+1}$。这就是Q-learning。</li></ul></li><li><p>DQN和Q-learning并没有根本的区别。只是DQN用神经网络，也就是一个万能函数替代了原来Q-table而已，这样就实现了对连续状态的处理，不再只能处理离散状态。可以理解为一种时序差分(TD)+神经网络(NN)的方法。</p></li><li><p>Policy Gradient(策略梯度，PG)相比DQN等算法的区别在于其抛弃了对于Q值和V值的计算，改用神经网络学习一个映射$f(s)&#x3D;a$，根据$G$值利用带权重的梯度下降方法来调整策略中不同动作的概率，在代码实现中$G$值变成了参数调整的权值，$G$值越大，参数调整的幅度越大。相比于DQN算法，PG算法可以理解为一种蒙特卡洛(MC)+神经网络(NN)的方法。举一个简单的例子，比如：假设一个智能体从某个state出发，可以采取三个动作，最开始采用平均策略，各有33%的概率。第一次出发选择动作A，到达最终状态后开始回溯，计算得到G&#x3D;1。然后就要更新策略：让A的概率提升，相对地，BC的概率就会降低，变为50%，25%，25%。第二次出发选中B动作，到达最终状态后开始回溯，计算得到G&#x3D;-1。因此要少选择B，再次更新策略，变为55%，15%，30%。第三次出发选中C动作，到达最终状态后开始回溯，计算得到G&#x3D;5。那么要求选择C的概率大大提高，变为20%，5%，75%。</p></li><li><p>Actor-Critic(AC)具有两个网络：一个输入状态S，输出策略，负责选择动作，我们把这个网络称为Actor；一个负责计算每个动作的分数，我们把这个网络称为Critic。相对来说有些类似于对抗神经网络GAN，Actor负责选择(generator负责生成)，Critic负责批判(discriminator负责判别)。总的来说，AC可以被理解为TD版本的PG(TD相对于MC的改进就在于不必完成整个游戏过程，直到最终状态，才能通过回溯计算G值，大大提高了效率)。</p></li><li><p>有一些文章将AC描述为PG+DQN，这是可以理解的，但是有一点值得注意：在DQN预估的是Q值，在AC中的Critic估算的是V值。之所以Critic对动作进行评价却不使用Q值，而使用V值是因为特殊原因，我们举个例子进行说明：假设对于一个状态s,其动作可以为a1，a2，a3，三个动作的Q值分别为1,2,10。假设一开始采取的是平均策略，各有33%的概率，选择了动作a1，得到Q值为1。那么使用带权重的梯度下降算法更新策略的时候会倾向于增大选择a1的概率，这可能会导致选择a1的概率持续增大，掉入正数陷阱(本来应该是a3的概率最大，但是很不幸的是一次都没有抽到a3，因为采样次数不能无限，所以这种情况是可能发生的)。要解决这个问题，我们可以通过减去一个baseline，令Actor权重有正有负来实现。而通常这个baseline，我们选取的是权重的期望，而Q值的期望(均值)就是V值。因此，Critic对选择的动作进行评价时要使用V值。</p></li><li><p>根据9中的内容，我们可以得到更新的权重：$Q(s,a)-V(s)$，但是用两个网络分别计算Q和V太过冗余，因此将$Q(s,a)$用$\gamma V(s^\prime)+R$代替，得到新的权重TD-error$&#x3D;\gamma V(s^\prime)+R-V(s)$。接着用Critic将TD-error尽量减小(TD-error作为Critic网络的loss)，然后将TD-error作为Actor更新策略时，带权重更新中的权重值。示意图如下所示：</p><p><img src="/posts/24093/AC.png" alt="AC"></p></li></ol><h1 id="DPG"><a href="#DPG" class="headerlink" title="DPG"></a>DPG</h1><p>DPG(Deterministic Policy Gradient)从<strong>理论</strong>的角度提出了一种deterministic、off-policy的policy gradient算法，并给出了policy gradient的计算公式和参数更新方法。在其基础上演化出了DDPG、D4PG等经典算法。</p><p>DPG针对连续动作空间的控制任务在传统的PG算法上做了改进，将策略函数的输出从一个分布(常用高斯分布)转变为一个唯一确定的动作；同时引入了AC框架，直接利用Critic(Q函数)找到可能的最优决策，然后用找到的最优决策来实现Actor中的策略优化(<strong>注意：正常来说AC框架应该使用V函数，但是因为DPG需要对动作求导，因此将V函数转换成了Q函数</strong>)；最后使用off-policy策略解决了探索不足的问题。</p><p>以往的PG工作中，大多数都采用随机策略，比如说PPO，它在面对连续的动作空间时，将输出一个高斯分布的均值$\mu$和方差$\sigma^2$，并利用这个高斯分布进行采样，每一次输出的动作将不同。但是DPG采用的是确定性策略输出，也就是说当面对同一个状态时，算法会输出相同的动作。</p><p>相比于随机策略，确定性策略的优劣都是显而易见的：</p><ul><li>优点：从理论上可以证明，<strong>确定性策略的梯度就是Q函数梯度的期望</strong>，这使得确定性方法在计算上比随机性方法更高效；</li><li>缺点：对于每个状态，下一步的动作是确定的，这就导致只能做开发而不能做探索，有违exploitation-exploration trade-off。为了解决这个问题，DPG采用了off-policy的方法。也就是说，采样的policy和待优化的policy是不同的：其中采样的策略是随机的，而待优化的策略是确定性的。采样策略的随机性保证了充分的exploration。</li></ul><p>整篇论文中的公式推导占据了绝大部分，本文不再赘述，只列出最重要的结论，并将其与随机策略进行对比：</p><ul><li><p>随机策略：在状态St时，每次采取的动作很可能不一样，随机选择动作，$\pi(a|s)&#x3D;P(a|s)$<br>$$<br>\begin{align}<br>\nabla_\theta J(\pi_\theta)&amp;&#x3D;\int_{\mathcal{S}}\rho^{\pi}(s)\int_{\mathcal{A}}\nabla_{\theta}\pi_{\theta}(a|s)Q^{\pi}(s,a)\mathrm{d}a\mathrm{d}s  \\<br>&amp;&#x3D;\mathbb{E}_{s\sim\rho^\pi,a\sim\pi_\theta}[\nabla_\theta\log\pi_\theta(a|s)Q^\pi(s,a)]<br>\end{align}<br>$$</p></li><li><p>确定性策略：在状态St时，每次采取的动作都是一个确定的action，$a&#x3D;\mu(s)$<br>$$<br>\begin{align}<br>\nabla_\theta J(\mu_\theta)&amp; &#x3D;\int_{\cal S}\rho^{\mu}(s)\nabla_{\theta}\mu_{\theta}(s)\left.\nabla_{a}Q^{\mu}(s,a)\right|_{a&#x3D;\mu_{\theta}(s)}\mathrm{d}s  \\<br>&amp;&#x3D;\mathbb{E}_{s\sim\rho^\mu}\left[\nabla_\theta\mu_\theta(s)\nabla_a Q^\mu(s,a)|_{a&#x3D;\mu_\theta(s)}\right]<br>\end{align}<br>$$<br>简单解释一句，公式的含义是：期望回报对待优化策略$\mu$的梯度，可以视作在随机采样策略$\rho$下，Q函数对$\mu$的梯度的期望。两者对比，显然确定性策略中减少了对于动作action的积分，这使得它更容易训练。</p></li></ul><p>具体来说基于DPG思想的算法都分为寻找最优决策和优化当前策略两个阶段。在寻找最优决策阶段中，固定$Q(s,a)$函数的输入状态$s_t$，不断调整输入动作$a$，直到Q函数的输出值最大，这时的$a$即为最优决策$a^{*}$。在优化当前策略阶段中，让Actor的确定性策略$\mu(s)&#x3D;a$模仿前面Critic找到的最优决策$a^{*}$。不过这次策略调整只改变了智能体在$s_t$这单个状态下的决策，接下来还需要将整个状态空间$S$中所有的状态的策略调整到最优，就可以得到最优策略$\mu^{*}$。</p><p>总的来说，这篇论文提出了一个理论基础，告诉我们使用off-policy方法，在采样时采用随机策略，待优化策略则采用确定性的策略在理论上是可行的，至于具体的实现方式则由DDPG这篇论文的工作进行探索。</p><h1 id="SAC"><a href="#SAC" class="headerlink" title="SAC"></a>SAC</h1><p>首先回顾一下PPO类算法和DPG类算法。</p><p>DPG类算法前面已经进行了说明。</p><p>PPO算法的目标是<strong>在PG算法的优化过程中，使性能单调上升，并且使上升的幅度尽量大</strong>。PPO同样使用了AC框架，不过相比DPG更加接近传统的PG算法，采用的是随机的策略函数(Stochastic Policy)，智能体每次决策时都要从策略函数输出的分布中采样，得到的样本作为最终执行的动作，因此天生具备探索环境的能力，不需要为了探索环境给决策加上扰动；PPO的重心会放到actor上，仅仅将critic当做一个预测状态好坏(在该状态获得的期望收益)的工具，策略的调整基准在于获取的收益，不是critic的导数。对比DPG思想，PPO中的Actor不再是确定性策略$\mu(s)&#x3D;a$，而是服从概率分布的随机策略$a\sim\pi_\theta(\cdot|s)$；Critic中也不再是让Q函数对动作求导，因此还原为使用V函数(状态到实数的映射，输入空间减少了动作，大大简化了值函数)。除此之外，PPO还使用了importance sampling、GAE、batch training、replay buffer等技巧，以及严格约束策略参数的更新速度，使策略的表现尽量单调上升。</p><p>PPO是sample inefficiency的，DDPG又对各种超参数十分敏感。因此基于最大熵(maximum entropy)的SAC算法出现了，它是一个随机策略的、off-policy的、基于AC框架的算法，其在优化策略以获取更高累计收益的同时，也会最大化策略的熵。将熵引入RL算法的好处在于可以让策略尽可能随机，智能体可以更充分地探索状态空间$S$，避免策略早早地落入局部最优点，并且可以探索到多个可行方案来完成指定任务，提高抗干扰能力。</p><p>下面来介绍SAC算法做了哪些改进：</p><ol><li><p><strong>最大化熵强化学习</strong>。最大化熵强化学习(MERL)算法的目标策略是：$\pi^{*}_{MaxEnt}&#x3D;argmax_\pi\sum_t\mathbb{E}_{(s_t,a_t)\sim\rho_\pi}\left[R(s_t,a_t)+\alpha H(\pi(\cdot|s_t))\right]$，其中$R$是收益项，$H$是熵值项。此目标使得策略在最大化累计收益的同时，还能够最大化策略的熵值，借此让策略随机化，即输出的每一个action的概率尽可能分散，而不是集中在一个action上。对比DDPG的deterministic policy的做法，看到一个好的就捡起来，差一点的就不要了，而最大熵是都要捡起来，都要考虑。</p></li><li><p><strong>Soft Value Function</strong>。与一般RL类似，MERL也有自己的值函数，可以用于评价策略的好坏，这些公式都和一般RL中的公式类似：<br>$$<br>\begin{aligned}<br>Q_{soft}^{\pi}(s,a)&amp;&#x3D;\mathbb{E}_{s_t,a_t\sim\rho_\pi}\left[\sum_{t&#x3D;0}^{\infty}\gamma^{t}r\left(s_t,a_t\right)+\alpha\sum_{t&#x3D;1}^{\infty}\gamma^{t}H\left(\pi\left(\cdot|s_{t}\right)\right)|s_0&#x3D;s,a_0&#x3D;a\right]\\<br>V_{soft}^{\pi}(s)&amp;&#x3D;\mathbb{E}_{s_t,a_t\sim\rho_\pi}\left[\sum_{t&#x3D;0}^{\infty}\gamma^{t}\left(r\left(s_t,a_t\right)+\alpha H\left(\pi\left(\cdot|s_{t}\right)\right)\right)|s_0&#x3D;s\right]\\<br>Q_{soft}^{\pi}(s,a)&amp;&#x3D;\underset{s^{\prime}\sim p(s^{\prime}|s,a)}{\mathbb{E}}\left[r\left(s,a\right)+\gamma V_{s o f t}^{\pi}\left(s^{\prime}\right)\right]\\<br>V_{soft}^{\pi}(s)&amp;&#x3D;\underset{a\sim\pi}{\mathbb E}\left[Q_{soft}^{\pi}(s,a)-\alpha\log\pi(a|s)\right]<br>\end{aligned}<br>$$</p></li><li><p><strong>Energy Based Policy</strong>。由于基于能量的模型在面对多模态的值函数时，具有更强的策略表达能力，而一般的高斯分布只能将决策集中在Q值更高的部分，忽略其他次优解，MERL采用了基于能量的模型而非高斯分布来表示策略：<br>$$<br>\pi\left(a_t|s_t\right)\propto\exp\left(\frac{1}{\alpha}Q_{soft}\left(s_t,a_t\right)\right)<br>$$</p></li><li><p><strong>Soft Policy Iteration</strong>。与一般的policy iteration类似，我们可以得到soft policy iteration的迭代方式：首先进行evaluation，固定policy，使用Bellman方程更新Q值直到收敛；接着进行improvement，更新policy。公式如下：<br>$$<br>\begin{align}<br>Q^{\pi}_{soft}(s_t,a_t)&amp;&#x3D;r(s_t,a_t)+\lambda \mathbb{E}_{s_{t+1},a_{t+1}}[Q^{\pi}_{soft}(s_{t+1},a_{t+1})-\alpha\log(\pi(a_{t+1}|s_{t+1}))]\\<br>\pi^\prime&amp;&#x3D;\arg\min_{\pi_k\in\Pi}D_{KL}(\pi_k(\cdot|s_t)||\frac{\exp(\frac{1}{\alpha}Q_{soft}^\pi(s_t,\cdot))}{Z_{soft}^\pi(s_t)})<br>\end{align}<br>$$</p></li><li><p><strong>Soft Actor-Critic</strong>。基于上述内容，我们可以得到SAC算法中Q、Policy各自的更新公式:<br>$$<br>\begin{align}<br>J_Q(\theta)&amp;&#x3D;\mathbb{E}_{(s_t,a_t,s_{t+1})\sim\mathcal{D},a_{t+1}\sim\pi_{\phi}}[\frac{1}{2}(Q_t(s_t,a_t)-(r(s_t,a_t)+\gamma(Q_{\bar{\theta}}(s_{t+1},a_{t+1})-\alpha\log(\pi_\phi(a_{t+1}|s_{t+1})))))^2]\\<br>J_\pi(\phi)&amp;&#x3D;\mathbb{E}_{s_{t}\sim\mathcal{D},\varepsilon\sim\mathcal{N}}[\alpha\log\pi_{\phi}(f_{\phi}(\varepsilon_{t};s_{t})|s_{t})-Q_{\theta}(s_{t},f_{\phi}(\varepsilon_{t};s_{t}))]<br>\end{align}<br>$$</p></li></ol><p>最终我们得到了SAC算法如下图所示：</p><p><img src="/posts/24093/SAC.png" alt="SAC"></p>]]></content>
      
      
      <categories>
          
          <category> RL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在clash 代理模式下pip安装库时报错的解决办法</title>
      <link href="/posts/7641.html"/>
      <url>/posts/7641.html</url>
      
        <content type="html"><![CDATA[<p>昨天在一个python项目中使用venv创建虚拟环境之后正想通过pip安装一些库，当时开启clash作为代理，没有使用TUN mode，而是采用了System Proxy方式，但是pip报错：HTTP error 400 while getting https:&#x2F;&#x2F;………。 但是这个库本身的路径没有问题，我可以通过浏览器访问这个地址下载资源。搜索之后发现问题在clash这里，需要开始specify protocol模式。</p><p><a href="https://docs.cfw.lbyczf.com/contents/ui/settings.html#appearance">设置 Settings | Clash for Windows (lbyczf.com)</a></p><p><img src="/posts/7641/pic1.png" alt="pic1"></p><p>操作方式如下图所示：</p><p><img src="/posts/7641/pic2.png" alt="pic2"></p>]]></content>
      
      
      <categories>
          
          <category> clash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> clash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deep reinforcement learning</title>
      <link href="/posts/6776.html"/>
      <url>/posts/6776.html</url>
      
        <content type="html"><![CDATA[<h1 id="强化学习算法分类"><a href="#强化学习算法分类" class="headerlink" title="强化学习算法分类"></a>强化学习算法分类</h1><p>强化学习算法的分类图如下图所示：</p><p><img src="/posts/6776/classification.png" alt="classification"></p><h2 id="model-based-model-free"><a href="#model-based-model-free" class="headerlink" title="model-based &amp;&amp; model-free"></a>model-based &amp;&amp; model-free</h2><p>在马尔可夫决策过程（MDP）中，有五个关键元素：$S,A,P,R,\gamma$，分别代表状态空间，动作空间，状态转移函数，奖励函数以及折扣因子（防止奖励的累加和趋于无穷导致无偏向）。当这些元素全部已知时，模型就是已知的，可以无需和环境交互，直接在模型上进行计算，比如使用value iteration或者policy iteration等方法。但是现实中agent往往无法知道状态转移函数以及奖励函数，这时模型就是未知的，需要通过和环境交互，不断试错，观察环境相关信息并利用反馈的奖励信号来不断学习。如果通过学习习得了状态转移函数以及奖励函数，那么就可以使用前述方法进行求解，这就是model-based方法。如果不对环境进行建模，直接寻找最优策略，那就是model-free方法。</p><p><img src="/posts/6776/ModelClassification.png" alt="ModelClassification"></p><h2 id="value-based-policy-based"><a href="#value-based-policy-based" class="headerlink" title="value-based &amp;&amp; policy-based"></a>value-based &amp;&amp; policy-based</h2><p>基于价值的方法需要对动作价值函数$Q^\pi(s,a)$进行优化，其优点在于采样效率相对较高，值函数估计方差小，不易陷入局部最优；缺点是它通常不能处理连续动作空间问题，且最终的策略通常为确定性策略而不是概率分布的形式。基于策略的方法直接对策略进行优化，通过对策略迭代更新，实现累积奖励最大化。与基于价值的方法相比，基于策略的方法具有策略参数化简单、收敛速度快的优点，且适用于连续或高维的动作空间。除了基于价值的方法和基于策略的方法，更流行的是两者的结合，这衍生出了Actor-Critic方法。Actor-Critic方法结合了两种方法的优点，利用基于价值的方法学习Q值函数或状态价值函数V来提高采样效率（Critic），并利用基于策略的方法学习策略函数（Actor），从而适用于连续或高维的动作空间。</p><p><img src="/posts/6776/ValuePolicyClassification.png" alt="ValuePolicyClassification"></p><h2 id="MC-TD"><a href="#MC-TD" class="headerlink" title="MC &amp;&amp; TD"></a>MC &amp;&amp; TD</h2><p>时间差分（Temporal Difference，TD）方法和蒙特卡罗（Monte Carlo，MC）方法最大的不同之处在于如何进行参数更新，蒙特卡罗方法必须等到一条轨迹生成（真实值）后才能更新，而时间差分方法在每一步动作执行都可以通过自举法（估计值）及时更新。这种差异将使时间差分方法具有更大的偏差，而使蒙特卡罗方法具有更大的方差。</p><p><img src="/posts/6776/MCDTClassification.png" alt="MCDTClassification"></p><h2 id="on-policy-off-policy"><a href="#on-policy-off-policy" class="headerlink" title="on-policy &amp;&amp; off-policy"></a>on-policy &amp;&amp; off-policy</h2><p>在线策略（On-Policy）方法和离线策略（Off-Policy）方法依据策略学习的方式对强化学习算法进行划分。在线策略方法要求智能体要评估提升的策略和与环境交互的策略必须是相同的，而离线策略方法评估和提升的策略与生成数据的策略是不同的，它可以利用其他智能体与环境交互生成的数据来提升自己的策略。</p><p><img src="/posts/6776/OnOffPolicyClassification.png" alt="OnOffPolicyClassification"></p><h1 id="Policy（策略）与Policy-Optimization（策略优化）"><a href="#Policy（策略）与Policy-Optimization（策略优化）" class="headerlink" title="Policy（策略）与Policy Optimization（策略优化）"></a>Policy（策略）与Policy Optimization（策略优化）</h1><p>策略(Policy)是一种从状态(State)到动作(Action)的映射，而所谓的策略优化(Policy Optimization)就是要寻找到最优的映射。策略优化算法大体分为两种：基于value的方法需要对价值函数进行建模和估计，以此为依据制定策略，代表方法有Q-learning和DQN；基于策略的方法则是对策略函数直接进行建模和估计，优化策略函数使奖励最大化，代表方法有REINFORCE和交叉熵算法等。而将二者结合所产生的结构————Actor-Critic则是在Model-free类方法中应用最广的结构，它通过对价值函数的优化来引导策略改进。</p><p>首先回顾一下策略函数、状态价值函数、状态动作价值函数、动态规划、策略评估、策略迭代和价值迭代。</p><p>策略函数（Policy Function）常表示为：$\pi(s):S\rightarrow A$，是从状态集合到动作集合的一个映射，策略函数的最优化是强化学习算法的核心任务。</p><p>状态价值函数（State Value Function）也可简称为价值函数，用于评价策略的优劣。其意义是，当处于状态$s_t$时，从下一个状态$s_{t+1}$开始，直至一个Episode结束，都按照策略$\pi(s)$与env进行交互，将从$s_{t+1}$到$s_\infty$过程中得到的reward的降权值累加起来，取其期望值作为状态$s_t$的价值。</p><p>状态动作价值函数（State-action Value Function）也可简称为Q值函数，是对状态-动作对优劣的评估，相比状态价值函数，除了给定状态外还要给定某个动作$a$。</p><p>动态规划（Dynamic Programming，DP）是一种解决复杂问题的思想方法，其整体思想就是化繁为简，将复杂问题分解为一个个相对简单的子问题，然后通过解决子问题后再串起来，理论上也就解决了整个复杂问题了。所以一个问题要想去用DP去解决的话它必定要满足这两个条件：第一，问题有一定结构并且可以进行拆分成一步步的子问题；第二，子问题需要出现多次并可以用解决方法不断去套用迭代。而MDP刚好符合这两个特征，首先MDP的转移状态可以分解成连续的子状态之间的转移，然后可以用贝尔曼方程不断去套用迭代计算状态和行动的价值函数继而得到单个状态的最优策略，从而最后再全部串起来就ok了。</p><p>策略评估（Policy Evaluation）是做策略迭代的前置任务，在做出最好的选择之前，首先要对所有选择做评估，然后才能进行选择。具体来说就是通过贝尔曼期望方程来迭代计算每个状态的价值函数。</p><p>策略迭代（Policy Iteration），如果我们已经完成了对一个策略的评估，想要提升这个策略怎么办？很好办，那就基于前边得到的评估结果，按照贪心的思想，总是挑往价值函数大的方向走就好啦！每次策略评估之后，从值函数中寻找到可以使后继状态价值增加最多的行为作为新的策略，然后再次评估，以此类推，一直到价值函数不再发生变化为止。</p><p>价值迭代（Value Iteration），这种算法更加简单粗暴，指导思想也很简单，就是使用贝尔曼最优方程，将策略改进视为值函数的改进，每一步都求取最大的值函数。</p><h2 id="Value-based-optimization（基于价值的优化）"><a href="#Value-based-optimization（基于价值的优化）" class="headerlink" title="Value based optimization（基于价值的优化）"></a>Value based optimization（基于价值的优化）</h2><p>基于价值的优化方法往往需要在策略估计和策略提升两个过程之间交替，其大致的解决方法如下图所示：</p><p><img src="/posts/6776/ValueBased.png" alt="ValueBased"></p><p>对于简单且离散的问题（比如4x4迷宫的最短路径问题），直接使用表格方法即可。但是对于复杂或连续的问题就需要进行价值函数的拟合。对于model-free问题，需要使用MC或者TD方法来更新参数，对于model-based的问题，直接用规划方法如策略迭代等来更新参数即可。</p><h2 id="Policy-based-optimization（基于策略的优化）"><a href="#Policy-based-optimization（基于策略的优化）" class="headerlink" title="Policy based optimization（基于策略的优化）"></a>Policy based optimization（基于策略的优化）</h2><p>深度强化学习中的策略可以被分为确定性策略和随机性策略，前者对于某种状态，其能选择的动作是确定的，后者则是不同的动作有不同的概率。在优化过程中，可以使用基于梯度的方法，比如REINFORCE，也可以使用无梯度的方法，比如交叉熵方法。基于策略的优化方法的基本思路和任何启发式算法的思路是一致的，即建立输入和输出之间的可微的参数模型，然后通过梯度优化搜索合适的参数，具体分为三个步骤：首先确立策略模型$\pi_\theta(x)$，然后构建优势评价函数（往往是累积折扣奖励）$metric&#x3D;J(\pi_\theta)$，最后进行参数更新$\theta&#x3D;\theta+\alpha\nabla_\theta J(\pi_\theta)$。其中确立策略模型需要借助神经网络，输入是状态信息，输出是动作的概率分布（以随机性策略为例），即$\pi_\theta:S\rightarrow P(A)$。</p><h3 id="基于梯度的优化"><a href="#基于梯度的优化" class="headerlink" title="基于梯度的优化"></a>基于梯度的优化</h3><p>基于梯度的优化方法是使用在期望回报（总的奖励）上的梯度估计来进行梯度下降以改进策略，而这个期望回报是从采样轨迹中得到的。这里我们把关于策略参数的梯度叫作策略梯度（Policy Gradient）。我们将从一个状态开始的累计折扣奖励表示为$J(\pi)&#x3D;\mathbb{E}_{r\sim\pi}[R(\tau)]$，那么策略梯度$PG$可以表示为$\Delta\theta&#x3D;\alpha\nabla_\theta J(\pi_\theta)&#x3D;\alpha\mathbb{E}_{\tau\sim\pi_\theta}\left[\sum_{t&#x3D;0}^T\nabla_\theta(log\pi_\theta(A_t|S_t))Q^{\pi_\theta}(S_t,A_t)\right]$，这就是最原始的REINFORCE方法。对上述公式的直观解释是：前半部分是一个方向向量，参数在这个方向上更新可以增大或降低给定状态下某个动作发生的可能性；后半部分是一个标量，以累积折扣奖励的大小作为权重；因此这个公式的直观解释就是增大高回报状态-动作对出现的概率，降低低回报状态-动作对出现的概率。</p><h3 id="无梯度优化"><a href="#无梯度优化" class="headerlink" title="无梯度优化"></a>无梯度优化</h3><p>无梯度优化的方法包括交叉熵方法、协方差矩阵自适应方法、爬山法等等，这并非主流方法，因此本文不做涉猎。</p><h2 id="Actor-Critic（AC框架）"><a href="#Actor-Critic（AC框架）" class="headerlink" title="Actor-Critic（AC框架）"></a>Actor-Critic（AC框架）</h2><p>在策略梯度方法中，如果使用MC或TD进行估计，那么产生的更新往往有较大的方差。一种改进方式是使用一个如基于价值的优化中的批判者（Critic）来估计动作价值函数，此时如果我们还采用了参数化的价值函数近似方法，就构成了Actor-Critic结构，它是一个既基于策略也基于价值的方法。它同时学习Actor函数————策略函数$\pi(s)$以及Critic函数————状态价值函数$V(s)$，并使用自举法(Bootstrapping)的思想来估计Q值函数。相比于策略梯度方法，最重要的改动在于提供了多种可选择的Critic函数（原Q值函数也可以作为Critic函数）：总回报、某个动作之后的回报、TD残差等等，当选择的Critic函数是以牺牲偏差为代价减小方差的几种函数时，就得到了经典的AC方法。</p>]]></content>
      
      
      <categories>
          
          <category> RL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo使用中遇到的问题</title>
      <link href="/posts/17917.html"/>
      <url>/posts/17917.html</url>
      
        <content type="html"><![CDATA[<p>hexo让我们可以专注于文章本身，而不是网站的渲染等内容，但是在使用hexo的时候，我在书写latex公式时遇到了许多种错误，因此记录下来：</p><ol><li><p>在公式中不要使用*号，要使用$\times$号，因为在markdown文件中两个*号会让中间的内容变成斜体字符。</p></li><li><p>在多行公式中我们往往使用\\符号进行换行，但是在markdown文件中两个\符号中的第一个会被识别为转义字符，因此我们如果在公式中需要换行的话需要用\\\\才可以。</p></li><li><p>由于未知原因，$\mathbf{z}_\tau$这个公式中的下划线会被markdown识别为斜体的标志，因此要使用$\mathbf{z}\_\tau$才行。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PEFT selective method</title>
      <link href="/posts/17624.html"/>
      <url>/posts/17624.html</url>
      
        <content type="html"><![CDATA[<h1 id="PEFT-selective-method"><a href="#PEFT-selective-method" class="headerlink" title="PEFT selective method"></a>PEFT selective method</h1><h2 id="BitFit-Simple-Parameter-efficient-Fine-tuning-for-Transformer-based-Masked-Language-models"><a href="#BitFit-Simple-Parameter-efficient-Fine-tuning-for-Transformer-based-Masked-Language-models" class="headerlink" title="BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"></a>BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models</h2><p>BitFit（BIas-Term FIne-Tuning）是一种稀疏的微调方法，仅对模型的bias以及特定任务的线性分类层进行调整，因此只需要调整不到0.1%的参数。它具有以下贡献：</p><ol><li>对于每个微调任务，仅仅改变了很少的参数。</li><li>具有task-invariance，对于每个任务都只需要修改同样的参数集合。</li><li>更改的参数在整个参数空间中即是孤立的又是局部的。</li><li>在中小数据集上可以达到与full fine-tuning一样甚至更好的效果，在大数据集上可以与其他稀疏微调方式媲美，但是达不到full fine-tuning的效果。</li></ol><p>BitFit与full fine-tuning、Diff-Pruning、Adapters的对比实验结果如下图所示：</p><p><img src="/posts/17624/BitFitCompare.png" alt="BitFitCompare"></p><h2 id="Parameter-Efficient-Transfer-Learning-with-Diff-Pruning"><a href="#Parameter-Efficient-Transfer-Learning-with-Diff-Pruning" class="headerlink" title="Parameter-Efficient Transfer Learning with Diff Pruning"></a>Parameter-Efficient Transfer Learning with Diff Pruning</h2><p>Diff pruning中的Diff来源于作者通过使用一个任务特定的difference向量来扩展基础模型，并基于这个diff向量实现PEFT。</p><p>作者首先将模型参数进行了重参数化:$\theta_\tau&#x3D;\theta+\delta_\tau$,其中预训练模型的参数向量（第一项）是固定的，只微调diff向量（第二项）。当我们有多个下游任务的时候，预训练模型参数的存储成本会被每一个任务平摊，新任务仅有的新增成本就是对diff向量的存储，如果我们能够对diff向量进行正则化，让它足够稀疏，使得$\lVert\delta_\tau\rVert_0\ll\lVert\theta\rVert_0$，那么当下游任务越多的时候我们的微调策略就越高效。为了实现这个正则化，作者对diff向量使用了L0-norm(非零元素的个数)：<br>$$<br>R(\theta_\tau)&#x3D;R(\theta+\delta_\tau)&#x3D;\lVert\delta_\tau \rVert_0&#x3D;\sum_{i&#x3D;1}^d 1{\delta_{\tau,i}\neq0}<br>$$<br>显然，这个正则是很难优化的，因为它不可微。于是，作者就寻找到了L0-norm的一个可微近似作为替代————借助了《Learning Sparse Neural Networks through L0 Regularization》论文中提到的一种使用松弛掩码向量进行基于梯度的 L0 稀疏学习的方法。解释有关其工作原理的内容超出了本文的范围，但是有很多资料已经解释清楚，例如<a href="https://medium.com/@llionj/the-reparameterization-trick-4ff30fe92954">这篇文章</a>。本文只介绍具体做法：</p><ol><li><p>首先通过hard-concrete分布构建一个掩码矩阵$\mathbf{z}_\tau$（对某些权重或输入进行遮罩操作，从而实现稀疏性或剪枝的效果）。<br>$$<br>\begin{aligned}<br>&amp;\mathbf{u}\sim U(\mathbf{0},\mathbf{1}), \\<br>&amp;\mathbf{s}_\tau&#x3D;Sigmoid\left(\operatorname{log}\mathbf{u}-\operatorname{log}(1-\mathbf{u})+\alpha_\tau\right), \\<br>&amp;\hat{\mathbf{s}}_\tau&#x3D;\mathbf{s}_\tau\times(r-l)+l, \\<br>&amp;\mathbf{z}_\tau&#x3D;min(\mathbf{1},max(\mathbf{0},\hat{\mathbf{s}}_\tau) ).<br>\end{aligned}<br>$$<br>$u$是从均匀分布中采样得到的随机数，$\alpha_\tau$是分布参数，在训练过程中与模型权重一起进行优化。通常情况下，对于模型中的每个参数值，会学习到一个单独的$\alpha_\tau$值。l和r是固定的超参数，通常在Diff Pruning中设置为-1.5和1.5。</p></li><li><p>$\mathbf{z}_\tau$的大部分元素都是0或1，将其和模型参数相乘实现参数的筛选，公式如下：<br>$$<br>\delta_\tau&#x3D;\theta\odot\mathbf{z}_\tau<br>$$</p></li><li><p>将L0惩罚项加入loss，惩罚项定义如下：<br>$$<br>R(\theta_\tau)&#x3D;\lambda\sum_{i&#x3D;1}^d Sigmoid(\alpha_{\tau,i}-log\frac{-l}{r} )<br>$$</p></li></ol><p>经过上面三步之后，就可以得到可微的L0正则化，这使得模型拥有很好的稀疏率。然而，最理想的还是设置一个精确的稀疏率，因为有些应用会有参数预算限制。作者发现通过在训练后投影到目标 L0-ball 上实现精确的稀疏率更有高效，而且经验上也更有效。具体做法是对 diff向量$\delta_\tau$使用magnitude pruning(将权重低于某个阈值的全部剪枝掉)，如果希望稀疏率为$t%$，那就只保留前$t%\times d$的参数。</p><p>Diff Pruning与full fine-tuning、Last layer、Adapters的对比实验结果如下图所示：</p><p><img src="/posts/17624/DIffPruningCompare.png" alt="DIffPruningCompare"></p><h2 id="Efficient-Fine-Tuning-of-BERT-Models-on-the-Edge"><a href="#Efficient-Fine-Tuning-of-BERT-Models-on-the-Edge" class="headerlink" title="Efficient Fine-Tuning of BERT Models on the Edge"></a>Efficient Fine-Tuning of BERT Models on the Edge</h2><p>作者提出了一种Freeze And Reconfigure (FAR)的内存高效的训练方案，大致思想是削减占据参数总量66%的FFN参数，具体操作如下：</p><ol><li><p>使用结构化的方式选择线性层中的微调权重，以避免对于内存的稀疏访问。</p></li><li><p>FFN中的每一个节点都被当做一组参数，这些节点被分类成学习节点（fine-tuned）和非学习节点（freeze）两种。具体来说，在Priming过程(初始的几个微调迭代，具体迭代数由一个指定的百分数p决定)中，保存FFN的权重并进行微调。在Priming过程结束后用微调之后的FFN权重减去初始的FFN权重，并使用L1-norm计算每个Encoder的每个FFN层的每个节点的学习指标。接着根据学习指标对节点进行排序，排名节点总数前r%的节点被定义为学习节点，其余为非学习节点。</p></li><li><p>在后续微调过程中，将两种节点分离，并构造新的FFN子层，这便是FFN的Reconfigure。具体来说，如下图所示，FFN节点被重新配置为两个平行的子模块。这种重新配置确保了学习节点的内存能被分配在一起。最后，重新配置的FFN需要恢复其原本的输出顺序，使其输出与模型的参数一致，因此需要进行permutation。Reconfigure和permutation的组合相比内存访问、额外计算等成本代价要低得多。除此以外，使用Reconfigure能够避免像非结构化剪枝这样的方法中出现的内存访问问题、避免了稀疏的内存访问（耗时）、解决了PyTorch中无法仅针对单个参数禁用自动梯度计算，而只能针对整个层或子层进行禁用的问题。</p><p><img src="/posts/17624/Reconfigure.png" alt="Reconfigure"></p></li></ol><p>FAR的对比和消融如下图所示：</p><p><img src="/posts/17624/FARCompare.png" alt="FARCompare"></p><p><img src="/posts/17624/FARAblation.png" alt="FARAblation"></p><h2 id="Training-Neural-Networks-with-Fixed-Sparse-Masks"><a href="#Training-Neural-Networks-with-Fixed-Sparse-Masks" class="headerlink" title="Training Neural Networks with Fixed Sparse Masks"></a>Training Neural Networks with Fixed Sparse Masks</h2><p>FISH-Mask是指pre-computing一个待更新的稀疏参数子集并在训练的迭代之中保持固定不变。具体操作如下：</p><ol><li><p>根据每个参数的Fisher信息的近似估计每个参数的重要程度。Fisher信息矩阵是一个$|\theta|\times|\theta|$的矩阵，这在现实之中是难以计算的，因此需要将其近似为一个长度为$|\theta|$向量，这就是true Fisher approximation，其公式为：<br>$$<br>\hat{F_\theta}&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N\mathbb{E}_{y\sim p_\theta(y|x_i)}(\nabla_\theta\log p_\theta(y|x_i))^2<br>$$<br>容易发现我们需要计算类别y的期望，当类别数很小的时候是容易计算的，但是如果有很多类别，人们往往再次进行近似，得到empirical Fisher approximation，其公式为：<br>$$<br>\hat{F_\theta}&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N(\nabla_\theta\log p_\theta(y|x_i))^2<br>$$</p></li><li><p>选择Fisher信息最大的k个参数构建FISH-mask。</p></li></ol><p>FISH-Mask与full fine-tuning、BitFit、Diff Pruning的对比实验结果如下图所示：</p><p><img src="/posts/17624/FishMaskCompare.png" alt="FishMaskCompare"></p><h2 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h2><table><thead><tr><th align="center">方法</th><th align="center">可训练参数量</th><th align="center">改变的参数量</th></tr></thead><tbody><tr><td align="center">BitFit</td><td align="center">0.05%~0.1%</td><td align="center">0.05%~0.1%</td></tr><tr><td align="center">Diff Pruning</td><td align="center">200%</td><td align="center">0.5%</td></tr><tr><td align="center">FAR</td><td align="center">6.6%~26.4%</td><td align="center">6.6%~26.4%</td></tr><tr><td align="center">Fish-Mask</td><td align="center">0.01%~0.5%</td><td align="center">0.01%~0.5%</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Super-NaturalInstructions ScalingDownToScaleUp</title>
      <link href="/posts/38828.html"/>
      <url>/posts/38828.html</url>
      
        <content type="html"><![CDATA[<h1 id="SUPER-NATURALINSTRUCTIONS-Generalization-via-Declarative-Instructions-on-1600-NLP-Tasks"><a href="#SUPER-NATURALINSTRUCTIONS-Generalization-via-Declarative-Instructions-on-1600-NLP-Tasks" class="headerlink" title="SUPER-NATURALINSTRUCTIONS: Generalization via Declarative Instructions on 1600+ NLP Tasks"></a>SUPER-NATURALINSTRUCTIONS: Generalization via Declarative Instructions on 1600+ NLP Tasks</h1><h2 id="工作贡献"><a href="#工作贡献" class="headerlink" title="工作贡献"></a>工作贡献</h2><p>作者提出了SUPER-NATURALINSTRUCTIONS数据集，包含了1616个不同的NLP任务（分为76个不同的任务类型，包含55种语言）以及专家手写的Instruction。</p><p><img src="/posts/38828/DatasetCompare.png" alt="DatasetCompare"></p><p>作者构建了T$k$-INSTRUCT模型，该模型可以遵循多种多样的In-context Instructions（包含通俗易懂的任务定义以及$k$个任务示例）。</p><p><img src="/posts/38828/InContextInstruction.png" alt="InContextInstruction"></p><p>作者将泛化性作为各种缩放参数（例如观察到的任务数量、每个任务的示例数量和模型的大小）的函数进行了进一步的分析。</p><h2 id="数据集质量控制"><a href="#数据集质量控制" class="headerlink" title="数据集质量控制"></a>数据集质量控制</h2><ol><li><p>贡献者们在github上提交自己的数据集时，会立即进行自动测试。这个过程会验证提交的文件是否包含了预期的字段并符合我们期望的属性（例如，没有重复实例，输出标签不会严重不平衡等）。 </p></li><li><p>由1-2位专家对数据进行迭代评审，以确保指令的清晰性和充分性。具体来说，评审人员被要求验证指令是否足够清晰且足以让普通人解决示例任务，同时语法流畅且简洁。</p></li><li><p>最后，将添加的任务交给大量的数据标注人员，收集他们对提供的指令的反馈，例如拼写错误、清晰度或其他问题。根据这些反馈，作者改进了实例的任务定义。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><ol><li><p>经过instruction tuning的T$k$-INSTRUCT的泛化能力明显优于其他模型，包括InstructGPT，但在新任务上表现依旧不及在该数据集上的监督学习模型。</p><p><img src="/posts/38828/res.png" alt="res"></p></li><li><p>模型泛化能力跟instruction数据集中任务数量呈现一个对数线性关系。增加特定任务下的训练数据不会有太大帮助，训练时每个任务包含64个样本是一个比较合理的设置。模型规模跟模型泛化能力是正相关的。</p><p><img src="/posts/38828/scale.png" alt="scale"></p></li><li><p>Instruction指令模版对于模型性能有明显影响。DEFINITION能帮助模型更好泛化，加入POSITIVE EXAMPLES也有提升，但是增加正样本数量就没有太大影响。此外，训练跟推理时的instruction指令设置也会影响具体推理效果。例如训练时用的instruction指令模版只涉及DEFINITION，推理时的模版只涉及POSITIVE EXAMPLES，那么推理效果会比较差。但是如果训练时struction指令模版涉及DEFINITION跟POSITIVE EXAMPLES，推理时的模版只涉及DEFINITION跟POSITIVE EXAMPLES其中之一，那么推理效果都还不错。</p><p><img src="/posts/38828/combination.png" alt="combination"></p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Instruction tuning也属于In-context learing的范畴，跟传统的In-context learning的区别在于引入了任务指令instruction，可以通过让模型在instrcution数据上训练从而提高语言模型的ICL能力，通过提升语言模型理解任务指令的能力，进一步提升泛化能力，在新任务下往往有出人意外的效果。对于instruction的获取方式，除了人工撰写的方式外，目前也有一些工作利用语言模型去生成。除此之外，前面这几个工作都得出了一些相对一致的结论，具体如下:</p><ol><li>增加instruction任务数，增加模型规模，都能提升模型的泛化能力，提升在新任务上的性能跟zero-shot能力。</li><li>加入COT数据可以提升模型的推理能力，混合COT跟非COT数据的instruction tuning可以保证模型在所有数据集上的表现。</li><li>Instruction指令模版很重要，其中的DEFINITION跟POSITIVE EXAMPLES必不可少，而NEGATIVE EXAMPLES则可有可无。同时需要注意训练跟推理时instruction指令模版设置的差异。</li><li>注意不同任务下的数据均衡，每个任务下的训练样本数不需要太多。</li><li>Instruction tuning的模型在新任务上的表现依旧不及在该数据集finetune的监督学习模型。</li></ol></li></ol><h1 id="Scaling-Down-to-Scale-Up-A-Guide-to-Parameter-Efficient-Fine-Tuning"><a href="#Scaling-Down-to-Scale-Up-A-Guide-to-Parameter-Efficient-Fine-Tuning" class="headerlink" title="Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning"></a>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</h1><p>整篇论文的思维导图如下:</p><p><img src="/posts/38828/Mindmap.png" alt="Mindmap"></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ol><li>当前模型、硬件发展速度差异过大<ul><li>2018-2023年间，模型的参数量增长了500余倍，但显存增长还不到10倍，这使得fine-tuning预训练模型不太可行。</li><li>训练模型需要模型权重12-20倍的空间才行</li></ul></li><li>In-context learning虽然成为了调整预训练模型的标准方式，但仍存在问题<ul><li>transformer有限的上下文大小人为地将训练集限制到了几个例子</li><li>扩大上下文大小会导致推理成本的二次增加</li><li>尽管当前语言模型在few-shot下表现出色，但“更多数据”始终是更可靠的方式</li></ul></li><li>PEFT(Parameter-efficient fine-tuning)应运而生<ul><li>PEFT旨在通过训练当前模型中的一小部分参数或者当前模型以外的参数来撬动杠杆，微调预训练模型</li></ul></li></ol><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p><img src="/posts/38828/taxonomy.png" alt="taxonomy"></p><ol><li>Additive方法（目前研究最多的方法）<ol><li><p>核心思想:使用额外的参数或者层来增强现有的预训练模型，并且只训练新添加的参数</p></li><li><p>Adapters</p><ul><li><p>核心思想:在Transformer的子层之后添加一个小的全连接网络</p></li><li><p>变体:更改Adapters的放置位置，剪枝，重参数化</p></li><li><p>Adapters</p><ul><li><p>核心思想:在注意力层和FFN层之后添加全连接网络</p></li><li><p>只微调4%的参数就媲美完整的fine-tuning</p></li><li><p>伪代码</p><p><img src="/posts/38828/adapter.png" alt="adapter"></p></li></ul></li><li><p>AdaMix</p><ul><li><p>核心思想:以专家混合的方式使用多个adapters</p></li><li><p>伪代码</p><p><img src="/posts/38828/AdaMix.png" alt="AdaMix"></p></li></ul></li></ul></li><li><p>Soft Prompts</p><ul><li>核心思想:通过将输入变成任务描述和一些任务示例的组合体来控制语言模型的行为</li><li>缺点:难以优化且被模型的最大输入长度限制了示例的数目</li><li>变体:通过梯度下降调整模型的输入embedding，将离散优化问题变成了连续优化问题</li><li>Prompt tuning<ul><li><p>核心思想:将一个可训练的向量拼接到模型的输入embedding之前</p></li><li><p>伪代码</p><p><img src="/posts/38828/PromptTuning.png" alt="PromptTuning"></p></li></ul></li><li>Prefix tuning<ul><li><p>核心思想:将可训练的参数拼接到所有层的隐藏状态之前</p></li><li><p>伪代码</p><p><img src="/posts/38828/PrefixTuning.png" alt="PrefixTuning"></p></li></ul></li><li>Intrinsic Prompt Tuning (IPT)<ul><li><p>核心思想:使用autoencoder来(解)压缩soft prompt</p></li><li><p>伪代码</p><p><img src="/posts/38828/IPT.png" alt="IPT"></p></li></ul></li></ul></li><li><p>Other Approaches</p><ul><li>LeTS，LST，(IA)$^3$等降低了存储占用，降低了计算成本，提高了模型准确性</li><li>Ladder-Side Tuning (LST)<ul><li><p>核心思想:在预训练网络的旁边训练一个小的transformer，然后将两者的隐状态组合起来更新只更新小的模型</p></li><li><p>伪代码</p><p><img src="/posts/38828/LST.png" alt="LST"></p></li></ul></li><li>(IA)$^3$<ul><li><p>核心思想:每个transformer块只学习三个新的参数$l_v$，$l_k$，$l_{ff}$（分别代表rescale key，rescale value，FFN的激活函数）</p></li><li><p>伪代码</p><p><img src="/posts/38828/IA3.png" alt="IA3"></p></li></ul></li></ul></li></ol></li><li>Selective方法<ul><li>核心思想:选择性地更新模型的一部分参数</li><li>变体:只更新顶层参数，稀疏更新</li><li>BitFit<ul><li><p>核心思想:只微调模型的biases</p></li><li><p>伪代码</p><p><img src="/posts/38828/BitFit.png" alt="BitFit"></p></li></ul></li><li>DiffPruning<ul><li><p>核心思想:在微调过程中学习mask掉一些参数，以实现权重的稀疏更新</p></li><li><p>伪代码<br>$$<br>\delta&#x3D;z\circ\Delta W<br>$$</p></li></ul></li><li>Freeze and Reconfigure (FAR)<ul><li><p>核心思想:选择参数矩阵的列进行修剪，并将线性层重新配置为可训练的和冻结的</p></li><li><p>伪代码</p><p><img src="/posts/38828/FAR.png" alt="FAR"></p></li></ul></li><li>FishMask<ul><li><p>核心思想:基于他们的Fisher information选取top-p个参数进行微调</p></li><li><p>伪代码</p><p><img src="/posts/38828/fisher.png" alt="fisher"></p><p><img src="/posts/38828/FishMask.png" alt="FishMask"></p></li></ul></li></ul></li><li>Reparametrization-based方法<ul><li><p>核心思想:使用低秩表示来最小化可训练参数的数量</p></li><li><p>Intrinsic SAID</p><ul><li>核心思想:使用Fastfood变换来重参数化模型权重的更新</li></ul></li><li><p>LoRa</p><ul><li><p>核心思想:将权重矩阵的参数更新分解成两个低秩矩阵的乘积</p></li><li><p>伪代码</p><p><img src="/posts/38828/lora.png" alt="lora"></p></li></ul></li><li><p>KronA</p><ul><li><p>核心思想:使用Kronecker积代替原来的分解方式来减小Lora的计算开支</p></li><li><p>伪代码</p><p><img src="/posts/38828/KronA.png" alt="KronA"></p></li></ul></li></ul></li><li>Hybrid方法<ul><li><p>核心思想:将前述几种类别的方法进行组合</p></li><li><p>SparseAdapter</p><ul><li>核心思想:使用一个大的hidden dimension，然后剪枝掉40%</li></ul></li><li><p>MAM Adapters</p><ul><li><p>核心思想:将adapter并行化和soft prompt相结合</p></li><li><p>伪代码</p><p><img src="/posts/38828/MAM.png" alt="MAM"></p></li></ul></li><li><p>UniPELT</p><ul><li><p>核心思想:将LoRa，prefix-tuning，adapters使用门机制组合</p></li><li><p>伪代码</p><p><img src="/posts/38828/UniPELT.png" alt="UniPELT"></p></li></ul></li><li><p>Compacter</p><ul><li><p>核心思想:使用Kronecker积，低秩矩阵，并且在各层之间参数共享来产生adapter的权重</p></li><li><p>伪代码</p><p><img src="/posts/38828/compacter.png" alt="compacter"></p></li></ul></li><li><p>S4</p><ul><li><p>核心思想:将连续的层分为四个不均匀的组，然后分别进行PEFT技巧的多种组合</p></li><li><p>组合方式</p><p><img src="/posts/38828/S4.png" alt="S4"></p></li></ul></li></ul></li></ol><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>从五个方面对PEFT方法进行比较:存储效率，内存效率，计算效率，准确性，推理开销</p><p><img src="/posts/38828/compare.png" alt="compare"></p><p><img src="/posts/38828/compare2.png" alt="compare2"></p><h2 id="对比中的问题"><a href="#对比中的问题" class="headerlink" title="对比中的问题"></a>对比中的问题</h2><ol><li>参数量不一致<ul><li>参数量可以分为三种:可训练参数量，原始模型和微调模型之间改变的参数量，原始模型和微调模型之间的差异的秩</li><li>即使可训练参数量是内存效率最可靠的评价指标，也依旧不完美，例如Ladder-side Tuning方法使用了一个单独的侧网络，其参数比LoRa或BitFit多，但由于不对主网络进行反向传播计算，因此需要更少的RAM</li></ul></li><li>模型大小<ul><li>较大的模型在微调过程中需要更新的参数数量更少，无论是在百分比还是绝对值方面，当模型足够大时，甚至能达到绝对值减少的效果</li></ul></li><li>没有标准的benchmark和metric<ul><li>新的方法通常在不同的模型&#x2F;数据集组合上进行评估，这使得得出有意义的结论变得困难。</li></ul></li><li>开源实现的问题<ul><li>开源代码经常不可重用，缺乏详细的文档或示例</li></ul></li></ol><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ol><li>明确指出参数量的类型，或者最好是三种参数量都有统计</li><li>使用不同大小的模型进行评估</li><li>除了与sota方法比较之外还应当与相似的方法进行比较</li><li>构建标准化的PEFT benchmarks</li><li>确保开源代码的简洁易懂，易于重用</li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Finetuned Language Models Are Zero-Shot Learners、Scaling Instruction-Finetuned Language Models</title>
      <link href="/posts/47664.html"/>
      <url>/posts/47664.html</url>
      
        <content type="html"><![CDATA[<h1 id="Finetuned-Language-Models-Are-Zero-Shot-Learners"><a href="#Finetuned-Language-Models-Are-Zero-Shot-Learners" class="headerlink" title="Finetuned Language Models Are Zero-Shot Learners"></a>Finetuned Language Models Are Zero-Shot Learners</h1><p>这篇论文第一次提出了instruction tuning的概念，下图展示了instruction tuning的工作流程以及性能对比：</p><p><img src="/posts/47664/InstructionTuning.png" alt="InstructionTuning"></p><p>作者把62个NLP数据集分成了12个类，训练时在11个上面微调，在1个上面测试zero-shot效果，这样可以保证模型真的没见过那类任务，看模型是不是真的能理解「指令」，此外所有使用的数据集作者都将其转变成了指令模式的数据：</p><p><img src="/posts/47664/dataset.png" alt="dataset"></p><p>像Prompt一样，作者也会为每个任务设计10个指令模版，测试时看平均和最好的表现：</p><p><img src="/posts/47664/template.png" alt="template"></p><p>值得注意的是，在分类问题上，以往的工作往往选择概率更高的预测作为模型的输出，但是这是不完美的，因为同一个意思的答案可能有多种表述方式，这就会导致概率的降低，因此对于这种问题，作者选择提供限定好的选项。</p><p>经过实验得到了以下结果：</p><ol><li><p>参与预训练的任务的种类越多，预训练模型的能力越强。</p><p><img src="/posts/47664/clusters.png" alt="clusters"></p></li><li><p>模型的参数量大于某一界限的时候Instruction Tuning的方法才能起效。</p><p><img src="/posts/47664/ModelSize.png" alt="ModelSize"></p></li><li><p>指令的设置对模型的性能有很大的影响。</p><p><img src="/posts/47664/compare2.png" alt="compare2"></p></li></ol><h1 id="Scaling-Instruction-Finetuned-Language-Models"><a href="#Scaling-Instruction-Finetuned-Language-Models" class="headerlink" title="Scaling Instruction-Finetuned Language Models"></a>Scaling Instruction-Finetuned Language Models</h1><p>在Flan最开始提出的时候，Flan只是用在了预训练语言模型上，但是这篇文章当中对Flan的适用范围以及使用的数据集等做了进一步的扩展研究，具体来说本文在PaLM以及T5上重点研究了以下三个方面：(1)任务数量的扩展（1.8K微调任务），(2)模型规模的扩大（540B参数），(3)在CoT数据上进行微调，各自对Instruction Tuning方法的影响。研究结果表明，Instruction Tuning对多种模型类别（PaLM、T5、U-PaLM）、prompt设置（零样本、少样本、CoT）和评估基准（MMLU、BBH、TyDiQA、MGSM、开放式生成、RealToxicityPrompts）均能显著提高模型性能和泛化能力。因此作者得出结论————Instruction Tuning是一种普适的，可以提高预训练语言模型性能和可用性的方法。</p><p><img src="/posts/47664/LM.png" alt="LM"></p><h2 id="Flan-Finetuning"><a href="#Flan-Finetuning" class="headerlink" title="Flan Finetuning"></a>Flan Finetuning</h2><p>作者将在数据集上使用一系列指令模板进行指令微调的过程称为Flan（Finetuning language models）。</p><p>这项工作的数据集采用了混合的数据集，共计473个数据集，146个任务类别，1836个不同的任务（这里的任务指的是数据集——任务类别的组合，一个数据集可能有多个任务类别，这样就得到了1836个任务）。</p><p><img src="/posts/47664/data.png" alt="data"></p><p>其中CoT数据集的使用方式如下，下图用例子展示了是否使用例子以及是否使用CoT的组合：</p><p><img src="/posts/47664/CoT.png" alt="CoT"></p><p>实验结果如下图所示：</p><p><img src="/posts/47664/result.png" alt="result"></p><h2 id="Finetuning-with-chain-of-thought-annotations"><a href="#Finetuning-with-chain-of-thought-annotations" class="headerlink" title="Finetuning with chain-of-thought annotations"></a>Finetuning with chain-of-thought annotations</h2><p>这项工作还研究了CoT数据对模型效果的影响:</p><ol><li><p>首先，加入CoT数据集，总是能对LLM的效果产生正面影响，且Flan-PaLM的表现要比PaLM好很多，如下图所示：</p><p><img src="/posts/47664/result2.png" alt="result2"></p></li><li><p>其次，对于CoT benchmarks，CoT数据集对效果提升很明显，而对于non-CoT benchmarks，CoT数据集对于模型效果并没有太大的影响。</p><p><img src="/posts/47664/result3.png" alt="result3"></p></li><li><p>第三，对于不进行Flan的Palm模型，CoT文本的加入并不能够带来效果的提升；对于Flan之后的Palm模型，CoT能够明显的提升模型的效果；Flan本身也能够给模型带来足够的效果提升。</p><p><img src="/posts/47664/result4.png" alt="result4"></p></li><li><p>第四，添加少量示例进行few-shot learning要比zero-shot learning效果更好。</p><p><img src="/posts/47664/fewshot.png" alt="fewshot"></p></li><li><p>最后，Instruction Tuning可以促进prompt tuning。</p><p><img src="/posts/47664/joint.png" alt="joint"></p></li></ol><h1 id="总结对比Finetune、Prompt、Instruction、CoT"><a href="#总结对比Finetune、Prompt、Instruction、CoT" class="headerlink" title="总结对比Finetune、Prompt、Instruction、CoT"></a>总结对比Finetune、Prompt、Instruction、CoT</h1><p>首先总结下prompt方法的发展思路，一开始大家通过完形填空的方式发掘语言模型的能力，在few-shot上获取比较好的效果，因为完形填空更符合预训练的形式，后面p-tuning提出连续的token，但是还是依赖hard token作为初始化，并且比较敏感，也是在full-shot上证明了prompt方法比传统的finetune好，之前大家更多关注的是few-shot上的效果，后面出了很多花式魔改相关的论文，比如给Verbalizer融合知识或者直接去掉什么的，这里就不过多介绍了。注意—-在这之前预训练模型都是跟着一起训练的！后面谷歌的prompt tuning诞生，在T5上通过freeze预训练模型，只调添加在第一层的soft prompt，在full-shot上就能和finetune上效果相当，这样新坑出现了，后面出了一系统工作，比如PPT、P-tuning v2和SPoT等，这里也不详细介绍了。</p><p>Instruction Tuning和Prompt Tuning的核心一样，就是去发掘语言模型本身具备的知识。而他们的不同有以下几点：</p><ol><li><p>首先，Prompt是去激发语言模型的<strong>补全能力</strong>，比如给出上半句生成下半句、或者做完形填空，这从prompt的模板上就可以看出来（例如将情感分类任务转换成prompt模板：“带女朋友去了一家餐厅，她吃的很开心，这家餐厅太__了！”，然后再将补全的词语映射到分类上得到positive）；</p><p>而Instruction Tuning则是激发语言模型的<strong>理解能力</strong>，通过给出更明显的指令，让模型去理解并做出正确的行动，这从instruction的模板上也可以得到体现（例如情感分类任务的Instruction模板：“instruction：请判断这句话的情感，并从positive、negative、don’t know中选一个作为答案。input：带女朋友去了一家餐厅，她吃的很开心。output: positive。”）。</p></li><li><p>此外，Prompt在没微调的模型上也能有一定效果，而Instruction Tuning则必须对模型微调，让模型知道这种指令模式。</p></li><li><p>Prompt针对每个任务，单独生成prompt模板（hard prompt or soft prompt），然后在每个任务上进行full-shot微调与评估，其中预训练模型参数是freeze的；Instruction针对每个任务，单独生成instruction（hard token），通过在若干个full-shot任务上进行微调，然后在具体的任务上进行评估泛化能力（zero shot），其中预训练模型参数是unfreeze的。</p></li></ol><p>finetune、prompt、instruction的工作方式如下图所示：</p><p><img src="/posts/47664/compare.png" alt="compare"></p><p>Chain-of-thought则是一种处理复杂问题或执行多步骤任务的技巧，通常用于大型预训练语言模型中。这种方法允许模型在多个步骤中生成连贯的回答，从而更好地解决问题或完成任务。在CoT方法中，模型的输出被视为一个序列，每个部分都是一个独立的“思考链”或步骤，模型通过将先前的输出作为后续输入的一部分来迭代地生成这些部分，这样可以让模型在一定程度上模拟人类解决问题的过程。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Survey on In-context Learning</title>
      <link href="/posts/63332.html"/>
      <url>/posts/63332.html</url>
      
        <content type="html"><![CDATA[<h1 id="Prompt总结"><a href="#Prompt总结" class="headerlink" title="Prompt总结"></a>Prompt总结</h1><p>本质上来说，Prompt的本质是<strong>一种对任务的指令</strong>；是<strong>一种对预训练任务的复用</strong>；是<strong>一种参数有效性学习</strong>。（<em>注</em>：关于Prompt的相关总结，笔者<strong>强烈建议</strong>参考王嘉宁的<a href="https://wjn1996.blog.csdn.net/article/details/120607050">这篇文章</a>，很详细地总结了Prompt的相关知识和发展过程）。</p><ol><li><p><strong>Prompt本质上是对下游任务的指令，可以作为一种信息增强</strong>。Prompt会告诉模型需要做什么任务，输出什么内容，借此释放模型的能力。</p></li><li><p><strong>Prompt本质上是复用预训练目标——实现基于Prompt的统一范式</strong>。预训练中往往以Masked Language Modeling（MLM）以及Autoregressive Language Modeling（ALM）为主，而下游任务则各有不同，因此我们需要降低Pre-training阶段和Fine-tuning阶段语义差距过大的问题才能更好地释放预训练大语言模型的潜力。Prompt便通过将所有下游任务转变为预训练任务的方式实现了这个目标，其分为三种范式————<strong>基于生成的范式</strong>、<strong>基于抽取的范式</strong>以及<strong>基于推理的范式</strong>，ChatGPT就是基于生成的范式的一个代表。</p></li><li><p><strong>Prompt的本质是参数有效性学习</strong>。在一般的计算资源条件下，大规模的模型（例如GPT-3）很难再进行微调，因为所有的参数都需要计算梯度并进行更新，消耗时间和空间资源。为了解决这个问题，参数有效性学习被提出，其旨在确保模型效果不受太大影响的条件下尽可能地提高训练的时间和空间效率。Prompt是多种参数有效性学习方法中的一种，其余的还有Adapter、BigFit等等。</p></li></ol><h1 id="In-context-Learning"><a href="#In-context-Learning" class="headerlink" title="In-context Learning"></a>In-context Learning</h1><p>ICL是In-context learning的缩写，是一种基于上下文和示例来进行预测的自然语言处理范式，其输入模板是一个可选的Instruction加一系列必选的演示样例的拼接。相较于传统训练模型需要昂贵的监督训练及参数更新，ICL不需要这些操作，因此被视为一种无需训练的学习框架。ICL主要依靠训练好的大型语言模型来实现，具有可解释性和易于将人类知识融入模型中的优点。除了在自然语言处理领域，ICL还具有在数据工程中应用的潜在前景，如用于数据标注、数据增强、数据修剪以及对抗数据生成等领域。<strong>相比前面总结的Prompt Learning使用离散提示或者软提示来引导模型的输出，ICL可以视作前者的子类，因为演示也算是提示的一种</strong>。</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li><p>ICL的工作流程如下图所示。首先，ICL需要利用自然语言模板编写一些示例来形成演示上下文。然后，ICL将查询问题和演示上下文的一部分串联在一起形成提示，并将其送入语言模型进行预测。与监督学习需要反向梯度更新模型参数的训练阶段不同，ICL无需进行参数更新，直接利用预训练的语言模型进行预测，希望模型能够学习到演示中隐藏的模式，并依此进行正确的预测。</p><p><img src="/posts/63332/ICL.png" alt="ICL"></p></li><li><p>ICL 是一种新的范式，具有多个优势。首先，它使用自然语言编写演示，提供了可解释的接口与LLM交互，这使得将人类知识纳入LLM变得更加容易（改变示范和模板）。其次，基于上下文的学习与人类通过类比学习的决策过程类似。第三，与监督式训练相比，ICL 是一种无需训练的学习框架，能够极大地降低模型适应新任务的计算成本，可轻松应用于大规模的实际任务中。</p></li><li><p>整篇文章的主要部分结构如下：</p><p><img src="/posts/63332/taxonomy.png" alt="taxonomy"></p></li></ol><h2 id="Model-Warmup"><a href="#Model-Warmup" class="headerlink" title="Model Warmup"></a>Model Warmup</h2><p>ICL同样是以LLM作为backbone，因此关于这一部分文章没有赘述，而是直接关注训练策略。尽管GPT3展示了ICL的强大能力，但是有工作发现在pre-training和ICL推理之间添加一个额外的阶段可以更好地发挥ICL的潜力，这个额外的阶段就是model warmup。在这个阶段中，会通过修改参数或者添加额外参数来调整LLM backbone，这听起来似乎与fine-tuning一样，但实际上二者的目标与方法均不相同。fine-tuning旨在训练模型用于特定任务，而warmup旨在增强模型的ICL能力。此外，fine-tuning需要更多数据来调整模型，而warmup则更注重训练数据的多样性和广泛性，对数据量的要求则很低。</p><p>Model warmup有两种形式————有监督和自监督：</p><ol><li>有监督的代表是MetaICL，大致思想是将预训练的 LLM 在多种具有演示样例的任务中不断进行训练，从而增强其少样本学习的能力。此外Instruction-Tuning也是有监督的一种，相比于为每个任务构建多个演示示例的MetaICL，Instruction-Tuning主要考虑如何对任务做出提示。</li><li>自监督的出现是因为研究者希望只使用原始语料库进行warmup，他们把原始语料根据下游任务的ICL格式转换成输入输出对进行自监督训练。</li></ol><h2 id="Demonstration-Designing"><a href="#Demonstration-Designing" class="headerlink" title="Demonstration Designing"></a>Demonstration Designing</h2><p>演示样例的格式和顺序等几种因素在很大程度上决定了ICL策略的性能表现，作者对这些因素做了简要介绍：</p><ol><li>演示样例的选择————什么样的演示样例是好的，应当被选择呢？<ul><li>无监督方法：选择最近邻作为样例（使用基于语句嵌入的L2距离或者余弦相似距离），以互信息为标准进行选择（不需要标签数据和明确的LLM），以困惑度为标准进行选择等等。</li><li>有监督方法：使用小LM进行样本选择，使用Q-learning选择样本等等。</li></ul></li><li>演示样例的顺序————顺序敏感性是一个普遍的问题，那么该如何确定一个合适的顺序呢？<ul><li>根据样本和输入之间的距离进行选择</li><li>根据全局和局部熵进行选择（两者正相关）</li></ul></li><li>使用格式化指令————对于简单任务，直接将可选指令（如果有）以及样例拼接起来即可，但是对于复杂任务（如数学推理），仅仅k个示例不足以让模型找到输入到输出的映射逻辑，因此一些研究人员使用指令描述任务，让模型更容易理解。<ul><li>给一些演示样例，LLMs可以自动生成任务指令。Automatic Prompt Engineer (APE) 就是一个代表。</li></ul></li><li>使用推理步骤————除了使用指令描述任务外，添加一些中间推理步骤可以更好地引导模型。<ul><li>CoT将输入输出映射分解为许多中间步骤，将这些步骤作为提示输入模型，模型就可以模拟出推理步骤。</li><li>AutoCoT使用“Let’s think step by step”作为提示，实现了效果的飞升。</li><li>一些工作使用多阶段ICL进行CoT，实现了更丰富的功能，比如Self-Ask允许LLM为输入生成后续问题，并对自己提出这些问题，然后将问题和中间答案添加到CoT中。</li></ul></li></ol><h2 id="Scoring-Function"><a href="#Scoring-Function" class="headerlink" title="Scoring Function"></a>Scoring Function</h2><p>得分函数决定了我们如何将语言模型的预测转化为特定答案的可能性，主要有三种方法，它们的简介和对比如下：</p><ol><li>直接估计法。使用可以被语言模型词汇表的tokens表示的候选答案的条件概率作为得分函数，选择概率更高的答案作为最终答案。这种方法的缺点是对模板设计做出了限制，例如答案词汇必须置于输入序列末尾。</li><li>Perplexity（PPL）。PPL需要计算整个输入序列的句子困惑度，它没有token位置的限制，但是却需要额外的计算时间。</li><li>Channel。该模型计算反方向的条件概率，即给定标签估计输入的概率，这需要语言模型生成输入中的每个token，这可以提高在不平衡训练数据下的性能。</li></ol><p><img src="/posts/63332/compare.png" alt="compare"></p><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h2><h3 id="what-influence-ICL-performance"><a href="#what-influence-ICL-performance" class="headerlink" title="what influence ICL performance"></a>what influence ICL performance</h3><p>根据以往的工作，作者总结了一个表格，列出了一些跟ICL性能强相关的影响因素，如下图所示：</p><p><img src="/posts/63332/factors.png" alt="factors"></p><ol><li>预训练阶段。<ul><li>领域来源比语料库大小更重要。</li><li>将多个语料库放在一起可能会极大地提高ICL的能力。</li><li>对下游任务相关的语料库进行预训练并不总是能提高ICL的性能。</li><li>具有较低困惑度的模型在ICL中并不总是能表现地更好。</li><li>当模型的参数或预训练步数达到某个规模的时候会出现涌现现象。</li></ul></li><li>推断阶段。<ul><li>演示样例格式、标签空间的暴露程度以及输入的分布都对ICL的性能有很大贡献。</li><li>样本的顺序也会影响ICL的性能。</li><li>与查询样本嵌入更接近的演示样本通常会带来比较好的性能，而与之离得更远的演示样本则性能差一点。</li></ul></li></ol><h3 id="why-ICL-works"><a href="#why-ICL-works" class="headerlink" title="why ICL works"></a>why ICL works</h3><ol><li>训练数据的分布。<ul><li>当训练数据的样本聚集并且只有很少的类别时，ICL能力会出现。</li><li>有工作将ICL解释为隐式的贝叶斯推断。</li></ul></li><li>学习的机制。<ul><li>Transformers能够编码有效的学习算法来学习未见过的线性函数，而且研究者们发现ICL模型中编码的学习算法可以达到与最小二乘法相当的误差。</li><li>Transformers能够通过隐式经验风险最小化为演示样例实现适当的函数类。</li><li>基于Transformer的上下文学习模型能够隐式实现标准微调算法。</li></ul></li><li>功能模块。<ul><li>有工作认为归纳头构成了ICL的机制，并借助实验证明了这一点。</li></ul></li></ol><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><ol><li>模型编辑。通过上下文演示调整LLM中记忆的知识。</li><li>数据标注。可以降低数据标注的成本。</li><li>多模态。</li><li>线性探测。</li></ol><h2 id="Challenges-and-Future-Directions"><a href="#Challenges-and-Future-Directions" class="headerlink" title="Challenges and Future Directions"></a>Challenges and Future Directions</h2><ol><li>寻找新的预训练策略。当前预训练和ICL之间的鸿沟通过warmup填补，未来可以为ICL定制行的预训练目标和评价指标。</li><li>将ICL的能力迁移到小模型上。有工作使用大规模的教师模型生成CoT数据，然后在CoT数据上微调了小模型，实现了小模型的推理能力。</li><li>知识增强、更新。LLM的知识完全来源于预训练语料库，因此可能缺乏某些知识，在ICL推理过程中有时会产生幻觉，因此要在预训练期间增强LLM学到的知识。类似的，LLM的知识可能是过时的、错误的，但是重新训练的代价过大，因此要想办法实现小代价的知识更新，并且不能影响现有的正确知识。</li><li>演示样例的鲁棒性。ICL的性能不稳定，受到很多因素的影响，因此要想办法提升其稳定性。</li><li>数据工程。LLM的强大推理能力和文本生成能力显示出高质量数据生成的巨大潜力，而ICL只需几个示例就可以学习到数据工程目标，这无疑意味着低成本高质量数据自动生成的可能性。</li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLM 数据处理方法</title>
      <link href="/posts/24819.html"/>
      <url>/posts/24819.html</url>
      
        <content type="html"><![CDATA[<h1 id="GPT-3数据处理方法"><a href="#GPT-3数据处理方法" class="headerlink" title="GPT-3数据处理方法"></a>GPT-3数据处理方法</h1><p>使用数据集：Common Crawl、WebText2、Books1、Books2以及Wikipedia的混合。</p><p>处理方法：</p><ol><li><p>首先基于同更高质量数据集WebText(reddit karmma&gt;3)的相似性对下载的Common Crawl数据集进行过滤。具体的操作是训练一个二分类的分类器，将WebText作为正样本，Common Crawl作为负样本，进行训练。然后用训练好的分类器重新对Common Crawl进行重采样（只要被预测为高质量的数据）。然后再用多种高质量数据集的并集作为正样本，未过滤的Common Crawl作为负样本进行训练，得到的分类器对Common Crawl进行打分，只保留$np.random.pareto(\alpha)&gt;1−document_score$的内容。</p></li><li><p>利用Spark中的MinHashLSH算法（集合之间的相似度）进行了文章级别的去重操作。</p></li><li><p>增加了一些新的高质量数据集。除了筛选过的Common Crawl，还增加了WebText2、Books1、Books2以及Wikipedia数据集。</p></li><li><p>各数据集的采样比例如下：</p><p><img src="/posts/24819/GPT3_mix.png" alt="GPT3_mix"></p></li><li><p>减少数据污染[GPT-3,P29]：在大量数据上进行训练的一个问题是模型可能会在预训练中看到测试集中的样本，因此要尽量减少训练集和测试集的重叠。</p></li></ol><h1 id="PaLM数据处理方法"><a href="#PaLM数据处理方法" class="headerlink" title="PaLM数据处理方法"></a>PaLM数据处理方法</h1><p>使用数据集：webpages,books,Wikipedia,news articles,source code,social media conversations的混合</p><p>处理方法：</p><ol><li><p>跟GLaM方法中一样，对所有数据都需要先进行过滤，过滤的指标依然是同现有高质量数据集的相似度，然后根据分数的高低进行采样，也就是说并不是所有低质量数据都被过滤掉，只是占比很少。</p></li><li><p>相比GPT-3，训练数据添加了github上爬取的代码，只选用了24种主流语言的代码，共196G数据。</p></li><li><p>基于文件之间的Levenshtein distance进行了去重。</p></li><li><p>各数据集的采样比例如下：</p><p><img src="/posts/24819/PaLM_mix.png" alt="PaLM_mix"></p></li><li><p>数据污染依然是一个处理的重点[PaLM,P36]，许多工作都发现了训练集和测试集之间严重的数据重叠。之前的研究仅仅关注测试数据和训练数据之间高阶N-Gram（例如，13-Gram）的出现情况，并将所有出现重叠的样本认定为是污染。然而，许多测试是通过从开放的网络中获取一些上下文，然后要求注释员为该上下文生成一个新的问题&#x2F;答案（或要求注释员回答自动生成的问题）来构建的。由于这些任务是在评估时提供的上下文，即使模型之前已经针对语言建模目标训练了上下文，也不会在评估时给它带来优势，因此之前的研究过于粗暴了。因此作者将29个任务分成了四类，分别进行了研究。</p></li></ol><h1 id="GLaM数据处理方法"><a href="#GLaM数据处理方法" class="headerlink" title="GLaM数据处理方法"></a>GLaM数据处理方法</h1><p>使用数据集：webpages，books，news，conversations，Wikipedia，forums</p><p>处理方法：</p><ol><li><p>由于GLaM使用的数据集中webpages占据绝大多数，因此对网页质量进行过滤就是一个关键步骤。作者跟GPT-3中使用的方法一样，也构建了自己的文本质量分类器，但是方法不尽相同。作者使用的是基于特征哈希的线性分类器，对精选文本和其他网页进行分类。训练好之后使用这个分类器对网页的质量进行打分，接着通过使用帕累托分布来根据它们的分数采样网页。基于这种方式过滤的样本允许存在一些较低质量的网页，以防止分类器的系统性偏差。</p></li><li><p>各数据集的采样比例如下：</p><p><img src="/posts/24819/GLaM_mix.png" alt="GLaM_mix"></p></li><li><p>一如之前两项工作，数据污染的问题依旧要进行处理。</p></li></ol><h1 id="Gopher数据处理方法"><a href="#Gopher数据处理方法" class="headerlink" title="Gopher数据处理方法"></a>Gopher数据处理方法</h1><p>使用数据集：MassiveWeb，C4，Wikipedia，books，news，code</p><p>处理方法：</p><p><img src="/posts/24819/pipeline.png" alt="pipeline"></p><p>从上图中我们得知，网页数据的过滤要经过全部的阶段，而其他的只需要经过内容过滤，文本去重，测试集过滤即可。</p><ol><li><p>内容过滤。这一步骤所有数据都要进行，使用google的safesearch过滤器而不是手动设置单词列表进行过滤。</p></li><li><p>文本提取。这一步骤只有网页数据需要进行，从HTML标签中提取文本。</p></li><li><p>文本质量过滤。这一步骤只有网页数据需要进行。作者只采用了简单的启发式方法来过滤掉低质量的文本，<strong>没有</strong>使用基于高质量文本训练的分类器来过滤掉低质量文本，这是因为这种方法可能会无意中对某一特定人群产生偏见，或者忽略某些方言或社会用语。在保持方言覆盖和避免偏见的同时，对文本进行质量过滤是未来研究的重要方向。具体来说，作者用了一系列的简单的启发式过滤器：删除了所有单词量不在50-100000的文档，删除了平均单词长度超出3-10范围的文档，删除了哈希符号或者省略号的符号单词比大于0.1的文档，删除了90%的行是以bullet point开头的文档，删除了超过30%的行以省略号结尾的文档，删除了包含“stop word”的文档，删除了没有至少包含<em>the</em>, <em>be</em>, <em>to</em>, <em>of</em>, <em>and</em>, <em>that</em>, <em>have</em>, <em>with</em>中两个的文档。</p></li><li><p>重复文本删除。这一步骤只有网页数据需要进行，旨在去除有大量单词重复的文档。具体手段是删除具有大量重复行重复段落的文本以及过高n-grams比例的文档。</p></li><li><p>文档去重。这一步骤只有网页数据需要进行。网络上有太多重复的内容，同一篇文章可能会被数十乃至数百个网站转载，这样就造成了大量的冗余，作者借助n-grams和MinHash实现了这个操作。</p></li><li><p>测试集过滤。这一步骤所有数据都要进行。如之前工作一样，数据污染是必须要考虑的，作者使用13-gram Jaccard相似度指标，借此删除了测试数据中的泄露。</p></li><li><p>各数据集的采样比例如下：</p><p><img src="/posts/24819/Gopher_mix.png" alt="Gopher_mix"></p></li></ol><h1 id="BLOOM数据处理方法"><a href="#BLOOM数据处理方法" class="headerlink" title="BLOOM数据处理方法"></a>BLOOM数据处理方法</h1><p>使用数据集：ROOTS语料库（包含了498个Hugging Face数据集）</p><p>处理方法：<a href="github.com/bigscience-workshop/data-preparation">github.com&#x2F;bigscience-workshop&#x2F;data-preparation</a></p><h1 id="个人负责部分"><a href="#个人负责部分" class="headerlink" title="个人负责部分"></a>个人负责部分</h1><ol start="2"><li>过滤出特定语言的语料。<ul><li>如果我们只在医学相关数据上做微调，那么使用的医学数据大多只有中英两种语言，只需要简单使用langid库筛除小概率存在的其他语言即可。</li><li>如果需要摒弃现有预训练模型从头开始训练，那么首先要查找大量web数据的html标签，确定这些web数据的语言，这样可以减少很大一部分工作量。接下来的工作有两种方法，首先考虑直接使用langid库筛除中英文外的语料，其次考虑训练一个三分类模型——中、英、其他，使用模型对语料分类。</li></ul></li><li>使用模型过滤高低质量的文本（暂缓）。</li><li>使用启发式规则过滤高低质量的文本。BLOOM中提出了很多指标：character repetition，word repetition，ratios of special characters，ratios of closed class words，ratios of flagged words，number of words，perplexity 等等。这些指标的计算被集成在了其github项目中，直接看代码即可。</li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Survey of Large Language Models论文笔记</title>
      <link href="/posts/32612.html"/>
      <url>/posts/32612.html</url>
      
        <content type="html"><![CDATA[<h1 id="A-Survey-of-Large-Language-Models论文笔记"><a href="#A-Survey-of-Large-Language-Models论文笔记" class="headerlink" title="A Survey of Large Language Models论文笔记"></a>A Survey of Large Language Models论文笔记</h1><p>整篇综述的结构如下：</p><ol><li>Introduction(2页)</li><li>Overview(1.5页)</li><li>Resources of LLMs(4页)<ul><li>Publicly available model checkpoints or APIs</li><li>Commonly used corpora</li><li>Library resource</li></ul></li><li>Pre-training(7.5页)<ul><li>Data collection</li><li>Architecture</li><li>Model Training</li></ul></li><li>Adaptation tuning of LLMs(5页)<ul><li>Instruction tuning</li><li>Alignment tuning</li></ul></li><li>Utilization(3.5页)<ul><li>In-context learning</li><li>Chain-of-thought prompting</li></ul></li><li>Capacity evaluation(7.5页)<ul><li>Basic evaluation tasks</li><li>Advanced ability evaluation</li><li>Public benchmarks and empirical analysis</li></ul></li><li>Conclusion and future directions(2页)</li></ol><p>这篇博客主要关注论文的第五、六部分。</p><h2 id="Adaptation-Tuning-Of-LLMs"><a href="#Adaptation-Tuning-Of-LLMs" class="headerlink" title="Adaptation Tuning Of LLMs"></a>Adaptation Tuning Of LLMs</h2><p>以往的诸多工作已经证明了，经过预训练的LLMs已经学习到了足够多的相关知识，拥有足够的潜力去完成few-shot甚至是zero-shot任务，但是根据不同的任务目标进行适应性的调整可以更大程度地发掘LLMs的潜力。在这一部分中，作者总结了两种方法来让预训练模型和下游任务相适应，这两种方法分别是instruction tuning和alignment tuning，前者的目标是增强或者说是解锁LLMs的潜能（充分利用LLMs学习到的知识），后者的目标是让LLMs的行为朝人类的价值观靠拢（避免各种歧视或者其他错误）。</p><h3 id="Instruction-Tuning"><a href="#Instruction-Tuning" class="headerlink" title="Instruction Tuning"></a>Instruction Tuning</h3><p>作者首先列举了几个用于instruction tuning的数据集：Natural Instructions v2、The Flan Collection、CrossFit、P3、ExMix等。 </p><p>Instruction tuning本质上是一种在一个以自然语言形式格式化的集合上微调预训练LLMs的方法。它与supervised fine-tuning和multi-task prompted training高度相关。使用Instruction tuning的步骤分为两步：首先筹集或者构造instruction格式的实例，然后用这些格式化的实例来有监督地微调预训练LLMs。通过Instruction tuning，模型可以获得很强的，对于其他任务的泛化能力。下图就是对于instance formatting的说明以及构造这样实例的两种方法。</p><p><img src="/posts/32612/instance_formatting.png" alt="instance_formatting"></p><h4 id="Formatted-Instance-Construction"><a href="#Formatted-Instance-Construction" class="headerlink" title="Formatted Instance Construction"></a>Formatted Instance Construction</h4><p>一个指令格式化的实例由一个任务描述（也就是instruction），一个输入输出对，以及一些示范（可选）组成。下面介绍了两种构造实例的方法。</p><ol><li><strong>Formatting Existing Datasets.</strong> 这种方法需要使用人手写的任务描述来增强有标签数据集，具体来说是通过解释任务目标来指示LLMs理解任务，就如同上图中所示，为每一个Q&amp;A任务中的实例添加任务描述：please answer this question。现有工作证明了，经过instruction tuning之后，LLMs可以在其他任务上根据他们的任务描述表现得很好，而且去掉任务描述会导致模型性能急剧下降。在这里，作者提供了一个很好的平台PromptSource，通过这个平台可以高效的创建、分享、验证不同数据集的任务描述。</li><li><strong>Formatting Human Needs.</strong> 根据公共数据集构造的指令缺乏多样性，且很多跟人类的真实需求不匹配，因此有了这种方法，将用户提交给OpenAI API的查询作为任务描述，此外还要求标注人员为现实生活中的例子构造指令，接着由另一组标注人员人工回答这些问题作为输出。这样就得到了一个实例：instruction是用户的问题，output是人工的回答。</li></ol><p>下面是一些构造实例的关键因素：</p><ol><li><strong>Scaling the instructions.</strong> 以往工作表明增大任务的数量可以增强LLMs的泛化能力，模型的性能表现随着任务数量的增加而先增加后不变。一个合理的推测是，一定数量的代表性任务就可以提供相对足够的知识了。此外还可以通过增加任务描述的多样性来提升模型的性能表现。但是需要注意的是，每个任务的实例数不能太多（例如数十万），否则会导致过拟合，损害模型性能。</li><li><strong>Formatting design.</strong> 指令的格式也会影响模型的泛化性能，必选的任务描述是模型理解任务的关键点，可选的示例可以促进模型对任务的理解，并降低其对指令的敏感性。但是如果将其他的东西，比如原因，建议等加入指令可能甚至会产生不利影响。此外，最近爆火的CoT可以被用于一些推理任务中，以激发模型的逐步推理能力。</li></ol><p>总的来说，<strong>指令的多样性比实例的数量更加重要</strong>，InstructGPT和Alpaca就是例子，它们的指令实例数量不多但足够多样化，因此都有着不错的表现。此外，<strong>由标注人员根据人类真实需求构建的数据集比使用特定任务数据集效果更好</strong>，因此可以通过重用已有的格式化数据集以及使用现有LLMs自动构建指令来构造数据集（类似借助ChatGPT）。</p><h4 id="Instruction-Tuning-Strategies"><a href="#Instruction-Tuning-Strategies" class="headerlink" title="Instruction Tuning Strategies"></a>Instruction Tuning Strategies</h4><p>指令微调策略比预训练更高效，因为这种方法只会使用中等数量的实例（而非全部）进行有监督训练。且前者与后者相比有许多方面不同：比如训练目标，优化时的配置（小的bs，小的学习率）等，除了这些小的方面外还有两个重要的方面：</p><ol><li><strong>Balancing the Data Distribution.</strong> 指令微调中会包含多种任务的数据，因此需要平衡这些任务的比例，最普遍的方法是实例-比例混合策略，做法就是混合所有数据，然后均匀采样。高质量的数据占比越高那么模型的性能通常会越好，但是往往会设置一个上限来防止某个数据集占据绝对的主导地位。</li><li><strong>Combining Instruction Tuning and Pre-Training.</strong> 有两种方法组合这两个过程，第一种方法就是两阶段过程，先预训练，然后指令微调，在这种方法里，可以在指令微调时加入预训练数据，使微调过程更有效稳定；第二种方法是采用一阶段过程，使用多任务学习方法，同时在纯文本的预训练数据和指令格式化微调数据集上进行训练。</li></ol><h4 id="The-Effect-of-Instruction-Tuning"><a href="#The-Effect-of-Instruction-Tuning" class="headerlink" title="The Effect of Instruction Tuning"></a>The Effect of Instruction Tuning</h4><ol><li><strong>Performance Improvement.</strong> 简而言之，指令微调是有效且高效的方法。</li><li><strong>Task Generalization.</strong> 简而言之，指令微调可以让模型具有更好地泛化能力（甚至在跨语言相关任务上也会有提升）。</li></ol><h3 id="Alignment-Tuning"><a href="#Alignment-Tuning" class="headerlink" title="Alignment Tuning"></a>Alignment Tuning</h3><p>在这一部分中，作者介绍了alignment tuning的相关知识，人类反馈数据的收集，以及根据人类反馈进行强化学习的技术。</p><h4 id="Background-and-Criteria-for-Alignment"><a href="#Background-and-Criteria-for-Alignment" class="headerlink" title="Background and Criteria for Alignment"></a>Background and Criteria for Alignment</h4><ol><li><strong>Background.</strong> LLMs的能力十分强大，但是有可能会输出虚假信息，或者有害的、有误导性的、有偏见的回答，这说明LLMs缺乏对人类价值观和偏好的考虑。为了应用于实际生活场景，需要让模型的输出同我们人类的普遍期望具有一致性，即使有研究证明这种alignment会损害模型的能力。</li><li><strong>Alignment Criteria.</strong> 人们设定了各种标准来调节LLMs的行为.<ul><li>helpful标准.</li><li>honestly标准.</li><li>harmless标准.</li></ul></li></ol><h4 id="Collecting-Human-Feedback"><a href="#Collecting-Human-Feedback" class="headerlink" title="Collecting Human Feedback"></a>Collecting Human Feedback</h4><p>这一部分讨论了如何选择一个人类标注团队来进行人类反馈数据的收集。</p><ol><li><strong>Human Labeler Selection.</strong> 当前获得人类反馈数据的最主要的方法就是人类标注，这要求标注人员至少在受教育程度和语言表达上应该令人满意。即使是这样，还存在研究人员期望和标注人员行为不一致的问题，为了解决这个问题InstructGPT专门设计了一个筛选的过程。具体来说，研究人员要首先标记少量的数据，然后评估他们自己的标注和标注人员的标注之间的一致性，一致性最高的标注人员将被选中来进行后续的标注工作。</li><li><strong>Human Feedback Collection.</strong> 当前主要有三种收集反馈和偏好数据的方法。<ul><li><strong>Ranking-based collection</strong>. 早期的工作中，标注人员往往只选择模型最好的输出，但是不同标注人员对“最佳”的选择是有偏差的；此外这样粗粒度的处理方式忽略了其他的输出样本，这是不合适的。因此有了这种方法，对输出的结果进行排序，然后以此排序结果作为指导，引导模型学习应当偏向输出哪些结果而非另一些。</li><li><strong>Question-based collection</strong>. 标注人员通过回答研究人员设计的某些问题来提供更详细的反馈。</li><li><strong>Rule-based collection</strong>. 这种方法是设计一系列规则来测试模型生成的结果是否符合之前提到的诸如有用、诚实、无害等对齐标准。</li></ul></li></ol><h4 id="Reinforcement-Learning-from-Human-Feedback"><a href="#Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="Reinforcement Learning from Human Feedback"></a>Reinforcement Learning from Human Feedback</h4><p>为了让LLMs的输出同人类的价值观对齐，研究人员采用强化学习算法，通过学习奖励模型，让LLMs偏向于生成人类需要的结果。</p><ol><li><p><strong>RLHF System.</strong> RLHF系统由已训练好等待对齐的LLM、从人类反馈中学习的奖励模型、训练LLM的强化学习算法组成。详细来说，就是用预训练模型作为对齐后模型的初始化（例如使用175B的GPT-3作为InstructGPT的初始化），以奖励模型(RM 可以是另一个经过微调的 LM，也可以是根据偏好数据从头开始训练的 LM，如InstructGPT使用的奖励模型就是6B的GPT-3)生成的标量形式的人类对LLM生成文本的偏好程度作为指导，使用强化学习算法（最常用的是PPO算法）对初始化后的参数进行更新。</p></li><li><p><strong>Key Steps for RLHF.</strong> 下图展示了RLHF系统的工作流程。它分为三个步骤：</p><p><img src="/posts/32612/workflow.png" alt="workflow"></p><ul><li><strong>Supervised fine-tuning</strong>. 这一步是用额外的文本或者条件对这个 LM 进行微调，例如 OpenAI 对 “更可取” (preferable) 的人工生成文本进行了微调，而 Anthropic 按 “有用、诚实和无害” 的标准在上下文线索上蒸馏了原始的 LM。值得注意的是，这一步是非必须的。</li><li><strong>Reward model training</strong>. 这一步采样一些Instruct或者Prompt，送入上一步的LM中，生成一定量的输出文本，然后由标注人员对这些输出进行排序（直接打分的话人类的主观偏差会导致反馈数据充满噪声），RM的任务就是通过预测这个排名来学习人类的偏好。值得注意的是，目前成功的 RLHF 系统都使用了和生成模型具有 <strong>不同</strong> 大小的 LM，这或许是因为偏好模型和生成模型需要具有类似的能力来理解提供给它们的文本。</li><li><strong>RL fine-tuning</strong>. 这一步的具体操作是将Instruct或者prompt输入初始模型和经过第一步微调之后的模型，分别得到输出文本，然后将微调后模型输出的文本送入RM模型，得到一个标量值作为奖励，然后计算两个模型的生成文本之间的KL散度作为惩罚（这一项被用于惩罚 RL 策略在每个训练批次中的生成大幅偏离初始模型的情况，以确保模型输出合理连贯的文本。如果去掉这一惩罚项可能导致模型在优化中生成乱码文本来愚弄奖励模型以获得高奖励值），最后结合标量奖励和KL惩罚调整模型的参数。</li></ul></li></ol><h2 id="Utilization"><a href="#Utilization" class="headerlink" title="Utilization"></a>Utilization</h2><p>在经过预训练和适应性调整之后，大家会为解决不同的任务而设计恰当的提示策略来利用这些LLMs。在这一部分中，作者分别介绍了In-context learning和Chain-of-thought prompting两种策略，前者以自然语言的形式进行任务描述或者示范，后者可以通过包含一系列中间推理步骤来增强上下文学习。</p><h3 id="In-Context-Learning"><a href="#In-Context-Learning" class="headerlink" title="In-Context Learning"></a>In-Context Learning</h3><p>In-context learning是prompt learning的一种特殊形式。下图是GPT-3论文中的插图，介绍了多任务学习和In-context learning的结合方法。</p><p><img src="/posts/32612/In-context_learning.png" alt="In-context_learning"></p><p>下图介绍了In-context learning和Chain-of-thought两种方法。</p><p><img src="/posts/32612/ICL_CoT.png" alt="ICL_CoT"></p><h4 id="Prompting-Formulation"><a href="#Prompting-Formulation" class="headerlink" title="Prompting Formulation"></a>Prompting Formulation</h4><p>标准的In-context learning是GPT-3提出的，它使用了格式化的自然语言提示，包括任务描述和几个任务示范，值得注意的是这几个任务示范只是帮助LLMs识别将要执行的任务，而不进行梯度更新。</p><h4 id="Demonstration-Design"><a href="#Demonstration-Design" class="headerlink" title="Demonstration Design"></a>Demonstration Design</h4><p>ICL的有效性受到示范设计的高度影响，而示范设计又包含三个重要的方面：</p><ul><li><strong>Demonstration Selection.</strong> 选择方法包含启发式方法（例如用KNN选择跟查询的语义相关的示范等）和基于LLM的方法（用LLM添加不同示范之后的性能增益来衡量每个示范的信息量等）两种。</li><li><strong>Demonstration Format.</strong> 格式化的结果应当如前图所示。任务描述的优化可以通过在Natural Instructions v2数据集上调优实现，这个数据集是一个由人类编写的任务描述组成的大规模数据集。</li><li><strong>Demonstration Order.</strong> 有研究发现模型倾向于给出演示中靠后的例子的答案，因此演示的顺序也很重要，除了早期的启发式方法外，还可以使用全局和局部熵度量来对不同的演示顺序进行评分。</li></ul><h3 id="Chain-of-Thought-Prompting"><a href="#Chain-of-Thought-Prompting" class="headerlink" title="Chain-of-Thought Prompting"></a>Chain-of-Thought Prompting</h3><p>Chain-of-Thought是一种改进的提示策略，通过添加中间推理步骤来增强模型的推理能力。</p><h4 id="In-context-Learning-with-CoT"><a href="#In-context-Learning-with-CoT" class="headerlink" title="In-context Learning with CoT"></a>In-context Learning with CoT</h4><ul><li><strong>Few-shot CoT.</strong> 将&lt;输入，输出&gt;对变成了&lt;输入，CoT，输出&gt;三元组。以往工作证明了每个问题的多个CoT可以提高性能，以及复杂CoT更能激发LLMs的推理能力，但是它们都依赖于带注释的CoT数据集，因此Auto-CoT使用的Zero-shot-CoT应运而生，它通过提示LLMs来生成CoT。</li><li><strong>Zero-shot CoT.</strong> 不包含人工注释的任务演示。相反，它直接生成推理步骤，然后使用生成的CoT来推导答案，当模型规模超过一定规模时，这种策略可以大大提高性能。</li></ul><h4 id="Further-Discussion-on-CoT"><a href="#Further-Discussion-on-CoT" class="headerlink" title="Further Discussion on CoT"></a>Further Discussion on CoT</h4><ul><li><strong>When CoT works for LLMs?</strong> 模型参数超过100亿才有效，而且只对需要推理的任务提升最明显。</li><li><strong>Why LLMs Can Perform CoT Reasoning?</strong> 人们普遍认为是通过在代码上进行预训练使得模型获得了推理的潜能。</li></ul>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prefix-Tuning_Prompt-Tuning论文笔记</title>
      <link href="/posts/5555.html"/>
      <url>/posts/5555.html</url>
      
        <content type="html"><![CDATA[<h1 id="Prefix-Tuning-Prompt-Tuning论文笔记"><a href="#Prefix-Tuning-Prompt-Tuning论文笔记" class="headerlink" title="Prefix-Tuning_Prompt-Tuning论文笔记"></a>Prefix-Tuning_Prompt-Tuning论文笔记</h1><p>当前NLP任务的主流方向大致有两种：<strong>预训练模型+finetuning</strong>以及<strong>预训练模型+Prompt+预测</strong>。前者存在着种种问题：首先，<strong>预训练的训练形式与下游任务有很大的鸿沟，难以完全发挥预训练模型的潜能，而且需要大量数据去填补这样的鸿沟，直接导致这种方法在下游任务数据不足的时候学习能力差</strong>。其次，<strong>数千亿参数的预训练模型在fine-tuning的时候需要庞大的算力和显存以及很长的时间，成本太大，此外对于每一个形式的下游任务都需要fine-tuning一个新模型去进行部署，过于冗余浪费</strong>。因此，prompt learning开始获得关注，这里先对prompt learning方法做一个简单的综述。</p><h2 id="prompt-learning"><a href="#prompt-learning" class="headerlink" title="prompt learning"></a>prompt learning</h2><p>GPT-3提出了In-Context Learning，证明了在Zero-shot、Few-shot场景下，模型不需要学习任何额外参数，只要在推断的过程中加入一些提示，就能达到不错的效果；这说明预训练模型中存在大量甚至可以说充足的知识，预训练模型本身学会的知识让它具有小样本学习能力。但是前面提到过，使用fine-tuning的话在小样本下游任务上会导致过拟合，因此需要找寻其他的tuning方法，而非全局的fine-tuning。</p><h3 id="Prompt-Learning-的本质"><a href="#Prompt-Learning-的本质" class="headerlink" title="Prompt Learning 的本质"></a>Prompt Learning 的本质</h3><p>将所有下游任务统一成预训练任务（或许是T5给的启发，将分类、总结等各种任务统一为text-to-text的文本生成类任务）；<strong>以特定的模板，将下游任务的数据转成契合上游预训练任务的形式</strong>，充分挖掘预训练模型本身的能力。</p><p>举例：对于情感分类问题，要将输入蕴含的情感进行二分类。原始输入如果是：特效非常酷炫，我很喜欢。那么现在Prompt learning中的输入变为：特效非常酷炫，我很喜欢。这是一部[MASK]电影。</p><h3 id="典型的Prompt-Learning方法总结"><a href="#典型的Prompt-Learning方法总结" class="headerlink" title="典型的Prompt Learning方法总结"></a>典型的Prompt Learning方法总结</h3><ol><li><p>硬模板方法：人工设计&#x2F;自动构建基于<strong>离散 token</strong>的模板，比如[x] is located in [y].</p><p>1）PET   2）LM-BFF</p></li><li><p>软模板方法：这种方法不再追求模板的直观可解释性，不再设计&#x2F;搜索硬模板，而是直接优化Prompt Token Embedding（例如prefix或者soft-prompt，都是<strong>可学习的参数</strong>），<strong>自动化地寻找连续空间中的合适模板</strong>，现在的方法大都选择这种。</p><p>1）P-tuning    2）Prefix Tuning    3）prompt-tuning</p></li></ol><h2 id="Prefix-Tuning"><a href="#Prefix-Tuning" class="headerlink" title="Prefix-Tuning"></a>Prefix-Tuning</h2><p>Fine-Tuning是利用大规模预训练语言模型来执行下游任务的一种方法。但是，它会修改语言模型的所有参数，因此需要为每个任务存储一个完整的副本。因此，作者提出了Prefix-Tuning，这是一种针对自然语言生成任务的fine-tuning的轻量级替代方法，它可以冻结语言模型的参数，只优化一个连续的特定任务的小向量（称为前缀）。经过实验发现只要0.1%fine-tuning的参数，prefix-tuning模型在小数据集上的表现就超过了fine-tuning，在大数据集上的表现媲美fine-tuning。</p><ol><li><p>prefix-tuning的示意图，以及跟fine-tuning的区别如下图所示：</p><p><img src="/posts/5555/prefix_tuning.png" alt="prefix_tuning"></p><p>fine-tuning需要调整所有参数（粉红色的部分），而prefix-tuning只需要调整prefix部分，大大减少了tuning过程所需的时间、算力以及存储模型所需的空间。<strong>值得注意的是作者将token优化为连续词嵌入，而不是离散token，其效果将向上传播到所有Transformer激活层，然后向右传播到后续token</strong>。</p></li><li><p>prefix-tuning的一个例子如下所示：</p><p><img src="/posts/5555/prefix_example.png" alt="prefix_example"></p><p>对于Autoregressive-LM，增加前缀变为z&#x3D;[PREFIX;x;y]；对于Encoder-Decoder模型，增加前缀变为z&#x3D;[PREFIX;x;PREFIX‘;y]。</p></li><li><p>prefix-tuning时，首先要初始化一个可训练的矩阵$P_{\theta}$用于储存前缀参数，它的维度是$|P_{idx}|\times  dim(h_i)$，其中$|P_{idx}|$代表前缀的长度，$h_i$代表第i个时间步下所有激活层结果的拼接。此外，作者发现直接更新前缀参数会出现不稳定的情况，甚至模型表现还有轻微的下降，因此作者对前缀参数矩阵进行重参数化：$P_\theta[i,:]&#x3D;MLP_\theta(P_\theta^{’}[i,:])$。其中$P_{\theta}^{‘}$的第一维度和$P_{\theta}$一样（前缀长度），第二维度比后者小，然后经过一个扩大维数的MLP即可。一旦训练完成，这些重参数化的参数就可以丢弃，只保留$P_{\theta}$。</p></li><li><p>数据集：</p><ul><li>table-to-text task:E2E，WebNLG，DART。</li><li>summarization task:XSUM。</li></ul></li><li><p>作者使用GPT-2模型，利用prefix-tuning进行了实验，实验结果如下所示：</p><p><img src="/posts/5555/prefix_performance.png" alt="prefix_performance"></p></li><li><p>此外，作者研究了内在因素对prefix-tuning效果的影响。包含如下方面：</p><ul><li>前缀长度————先逐渐增高然后略有降低。</li><li><strong>只调整embedding层</strong>————性能下降很大。</li><li>使用内缀（在x和y之间插入和训练的激活）替代前缀————性能有所下降。</li><li>前缀初始化策略————使用真实单词的激活比随机的初始化要好。</li></ul></li></ol><h2 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt-Tuning"></a>Prompt-Tuning</h2><p>Prompt-Tunning是以上prefix-Tunning的简化版本，它使用100个prefix token作为默认参数，大于以上prefix-tuning默认的10个token，不过差异在于prompt-Tunning<strong>只对输入层(Embedding)进行微调</strong>，而Prefix是对虚拟Token对应的上游layer全部进行微调。因此Prompt-Tunning的微调参数量级要更小，且不需要修改原始模型结构，这是“简化”的来源。相同的prefix长度，Prompt-Tunning(&lt;0.01%)微调的参数量级要比Prefix-Tunning(0.1%~1%)小10倍以上。</p><ol><li><p>110亿的T5模型借助prompt-tuning(上面prefix-tuning使用的是15亿的GPT2)，已经可以打平在下游多任务联合微调的LM模型，并且远远的甩开了Prompt Design（GPT3 few-shot所使用的方法），实验结果如下图所示：</p><p><img src="/posts/5555/prompt_result.png" alt="prompt_result"></p><p>在110亿参数下，prompt-tuning的T5跟多任务调优的T5达到了相同的表现，但是调优的参数比后者少了20000倍。prompt-tuning的T5-small和GPT-3 XL有相同的表现，两者参数量差了16倍，prompt-tuning的T5-large更是超过了GPT-3 175B，两者参数量差了220倍。</p><p><img src="/posts/5555/task_parameters.png" alt="task_parameters"></p></li><li><p>prompt-tuning的示意图如下所示：</p><p><img src="/posts/5555/prompt-tuning.png" alt="prompt-tuning"></p></li><li><p>作者进行了许多消融实验来探索影响prompt-tuning效果的因素。</p><p><img src="/posts/5555/ablation.png" alt="ablation"></p><ul><li>prompt长度:尝试了五种长度的prompt，超过20个token的prompt可以获得大的收益。</li><li>prompt初始化策略：测试了随机初始化和词汇表采样策略以及类标签初始化，后者效果最好。</li><li>预训练目标：测试了T5的Span Corruption、Span Corruption+sentinel以及LM Adaptation三种方法，发现最后一种是最好的，所有的Span Corruption都不太适用于prompt-tuning。</li><li>LM adaptation：作者尝试了四种adaptation步数，发现步数越长效果越好。</li></ul><p>对于以上所有消融实验，当参数足够多的时候这四种因素并不会带来大的影响。</p></li><li><p>在域迁移问题上，实验表明prompt tuning优于fine tuning，结果如下图所示：</p><p><img src="/posts/5555/domin.png" alt="domin"></p></li><li><p>提出了“提示集成”方法。模型集成的方法随着模型大小的不断增加已经不再合适，因此作者在同一个任务上训练了N个prompt，通过这样的方式以极小的代价实现了模型的集成，实现了不错的效果。</p><p><img src="/posts/5555/ensemble.png" alt="ensemble"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>T5论文笔记</title>
      <link href="/posts/43168.html"/>
      <url>/posts/43168.html</url>
      
        <content type="html"><![CDATA[<h1 id="T5论文笔记"><a href="#T5论文笔记" class="headerlink" title="T5论文笔记"></a>T5论文笔记</h1><ol><li><p>T5模型：是一个端到端，text-to-text预训练模型，是个基于Transformer的Encoder-Decoder模型。</p><p><img src="/posts/43168/T5.png" alt="T5"></p><p><img src="/posts/43168/models.png" alt="models"></p></li><li><p>这项工作最重要的贡献是<strong>给整个NLP预训练模型领域提供了一个通用框架，将所有NLP任务都转化成Text-to-Text（文本到文本）任务，用同样的模型，同样的损失函数，同样的训练过程，同样的解码过程来完成所有NLP任务</strong>，正如论文里所说的“introducing a unified framework that converts every language problem into a text-to-text format”。</p></li><li><p>作者公布了T5的代码模型：<a href="https://github.com/google-research/text-to-text-transfer-transformer%EF%BC%8C%E5%92%8CC4%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9Ahttps://www.tensorflow.org/datasets/catalog/c4%E3%80%82">https://github.com/google-research/text-to-text-transfer-transformer，和C4数据集：https://www.tensorflow.org/datasets/catalog/c4。</a></p></li></ol><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>为了解决Text-to-Text问题，目前主要有Encoder-Decoder、Languagemodel和Prefix LM三类结构。Languagemodel和PrefixLM比较适用于NLU类问题，但对于NLG，实验结果表明Encoder-Decoder效果更好。所以T5选择了Encoder-Decoder结构。</p><p><img src="/posts/43168/architectures.png" alt="architectures"></p><ol><li><p>第一种，<strong>Encoder-Decoder型</strong>，即Seq2Seq常用模型，分成Encoder和Decoder两部分，对于Encoder部分，输入可以看到全体，之后结果输给Decoder，而Decoder因为输出方式只能看到之前的。此架构代表是MASS（今年WMT的胜者），而BERT可以看作是其中Encoder部分。</p></li><li><p>第二种，相当于上面的<strong>Decoder部分</strong>，当前时间步只能看到之前时间步信息。典型代表是GPT2还有最近CTRL这样的。</p></li><li><p>第三种，<strong>Prefix LM型</strong>，可看作是上面Encoder和Decoder的融合体，一部分如Encoder一样能看到全体信息，一部分如Decoder一样只能看到过去信息，最近开源的UniLM便是此结构。举例：完整输入为e“translate English to German: That is good. target: Das ist gut.” ，那么prefix就是“translate English to German: That is good. target:” 。</p></li></ol><p>上面这些模型架构都是Transformer构成，之所以有这些变换，主要是<strong>对其中注意力机制的Mask操作进行变换</strong>。</p><p><img src="/posts/43168/mask.png" alt="mask"></p><p>关于<strong>注意力掩码机制</strong>，目前有Casual、Casualprefix和Fully-visible三类。Casual是一种常见的掩码机制，有从左到右和从右到左两种，当前点仅能看到该点之前的信息，看不到后面的信息，如果要看到两个方向的信息只能将两个信息concat（如BiLSTM模型），GPT就是采用这种掩码机制。Casualprefix可以看成是Casual的扩展，除了该点之前的信息外prefix也可以被看到，UniLM采用这种掩码机制。Fully-visible则是同时看两边，Bert采用的就是Fully-visible。</p><p>关于**Relative position embeddings(PE)**。T5使用了简化的相对位置embeding，即每个位置对应一个数值而不是向量，将相对位置的数值加在attention softmax之前的logits上，每个head的有自己的PE，所有的层共享一套PE。这种方式直接在计算attention weight的时候加入位置信息，而且每一层都加一次，让模型对位置更加敏感。</p><p>关于<strong>T5的baseline模型</strong>。采用编码器-解码器架构，编码器和解码器都由12个块组成（每个块包括自注意、可选的编码器-解码器注意和一个前馈网络）。每个块中的前馈网络由一个输出维数为d&#x3D;3072的全连接层，一个ReLU和另一个全连接层组成。所有注意力机制“key”和“value”矩阵的d&#x3D;64，所有注意力机制都有12个head。所有其他子层和嵌入的维数都是768。整个模型约有2.2亿参数，大约是BERT_BASE参数数量的两倍。对于正则化，作者在模型中统一使用0.1的概率。</p><h2 id="baseline数据"><a href="#baseline数据" class="headerlink" title="baseline数据"></a>baseline数据</h2><p>这篇工作使用的数据集是“Colossal Clean Crawled Corpus(C4)”数据集，是一个由Common Crawl数据集(每个月大概抓取20TB文本数据）进行启发式清洗之后得到的巨大的干净的数据集，具体清洗数据的方法如下：</p><ol><li>只保留结尾是正常符号的行。</li><li>丢弃了任何少于5个句子的页面，只保留了包含至少3个单词的行。</li><li>删除包含任何不好的词的页面。</li><li>删除任何包含lorem ipsum(用于排版测试)的页面。</li><li>删除包含编程语言中常用大括号的页面。</li><li>连续三句话重复出现的情况，只保留一个。</li></ol><p>C4数据集达到<strong>750G</strong>。此外，作者在GLUE和SuperGLUE文本分类、CNN&#x2F;Daily Mail抽象摘要、SQuAD问答以及WMT英语到德语、法语和罗马尼亚语的翻译方面进行性能测量。</p><h2 id="baseline训练"><a href="#baseline训练" class="headerlink" title="baseline训练"></a>baseline训练</h2><p>通过实验，作者发现在微调过程中更新预训练模型所有参数的方法优于更新更少参数的方法。在训练过程中，使用AdaFactor，在测试时，使用greedy decoding(在每个timestep选择概率最高的logit)。</p><p>在<strong>微调前</strong>，对模型在C4数据集上预训练了2^19&#x3D;524288步，最大序列长度为512，batchsize为128个句子，于是大约在2^35&#x3D;34B个token上进行了预训练，远比BERT和RoBERTa少。预训练中，采用 “inverse square root” 学习率调整策略,$lr&#x3D;1&#x2F;\sqrt{max(n,k)}$，其中n是当前训练迭代数，k是warmup步骤数目(默认为10000步)，于是在前10000步中，学习率固定为0.01，然后进行指数衰减。</p><p>在无标签数据上预训练时，需要一个无需标签也可以迫使模型学习到有用知识的目标。就现在来看“denoising”(也叫“masked language modeling”)目标成为了一个合适的标准，在这个目标下，模型被训练来预测输入里缺失或者损坏的token。作者在BERT模型”masked language modeling”目标和“word dropout”正则化技术的启发下，作者进行随机抽样，在输入中删除了15%的token，所有连续的空缺token用一个标记进行标记，target中还需要另外的一个结束标记，具体示例如下所示：</p><p><img src="/posts/43168/denoising.png" alt="denoising"></p><p>在<strong>微调时</strong>，进行了2^18&#x3D;262144步，继续使用batch128长度512的输入数据，固定学习率为0.001，每5000步保存一次模型。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>有了baseline方法之后，作者从预训练方法、Mask策略、Mask比例和Span长度四个方面进行去进行对比研究以找到最好的T5模型：</p><p><img src="/posts/43168/objectives.png" alt="objectives"></p><ol><li><p>第一个方面就是无监督的预训练方法对比。</p><p>语言模型式，就是像GPT-2一样,从左到右预测<br>BERT-style式，就是像BERT一样将一部分给破坏掉，然后还原出来（目的就是为了更好提取上下文的特征）<br>Deshuffiling（顺序还原）式,就是将文本打乱，然后还原出来。<br>其中BERT-style是最好的，T5模型使用的就是这种。</p></li><li><p>第二个方面，对文本一部分进行破坏时的策略。</p><p>Mask法，随机破坏token，换成特殊符。<br>Replace span(小段替换),跟mask相似，不同的是mask一个字，replace span是连续的几个字。<br>Drop，没有替换操作，直接随机丢弃一些字符。<br>其中replace span法是最好的，T5模型使用的就是这种。</p></li><li><p>第三个方面，对该文本百分之多少进行破坏。</p><p>挑选了4个值，10%，15%，25%，50%，最后发现BERT的15%是最好的。</p></li><li><p>第四个方面，Replace span对大概多长的小段进行破坏。</p><p>挑选了2,3,5,10这四个值，最后发现3结果是最好的。</p></li></ol><p>于是根据上述对比结果，作者重新进行了训练，具体细节如下所述。</p><ul><li><p><strong>预训练</strong></p><ol><li><p>参考SpanBERT，换掉denoising目标，使用span-corruption目标，mask掉15%，采用平均长度为3的span。</p></li><li><p>训练更长步数，在2^11的batch，512的句子长度上训练了一百万步，共计大约一万亿个token。</p></li><li><p>实现了多种大小的模型，具体参数如下表：</p></li></ol><table><thead><tr><th align="center">模型</th><th align="center">d_model</th><th align="center">d_ff</th><th align="center">d_kv</th><th align="center">heads</th><th align="center">layers</th><th align="center">parameters</th></tr></thead><tbody><tr><td align="center">Base</td><td align="center">768</td><td align="center">3072</td><td align="center">64</td><td align="center">12</td><td align="center"></td><td align="center">2.2亿</td></tr><tr><td align="center">Small</td><td align="center">512</td><td align="center">2048</td><td align="center"></td><td align="center">8</td><td align="center">6</td><td align="center">6千万</td></tr><tr><td align="center">Large</td><td align="center">1024</td><td align="center">4096</td><td align="center">64</td><td align="center">16</td><td align="center">24</td><td align="center">7.7亿</td></tr><tr><td align="center">3B</td><td align="center">1024</td><td align="center">16384</td><td align="center">128</td><td align="center">32</td><td align="center">24</td><td align="center">28亿</td></tr><tr><td align="center">11B</td><td align="center">1024</td><td align="center">65536</td><td align="center">128</td><td align="center">128</td><td align="center">24</td><td align="center">110亿</td></tr></tbody></table><ol start="4"><li>使用Multi-task预训练，即在无标签数据中混入一定比例的有标签数据。</li></ol></li><li><p><strong>微调</strong></p><ol><li><p>也是Multi-task，将所有GLUE&#x2F;SuperGLUE的数据拼在一起变成微调一个task，减少过拟合，但同时也会牺牲一些精度</p></li><li><p>batchsize减小到8</p></li><li><p>其实最后同时进行了多任务微调和单独微调，根据dev集选择最好的结果</p></li></ol></li><li><p><strong>解码</strong></p><ol><li>大部分使用Greedy decoding，对于输出句子较长的任务使用beam search，其中width&#x3D;4，长度惩罚系数设为0.6。</li></ol></li></ul><h2 id="研究"><a href="#研究" class="headerlink" title="研究"></a>研究</h2><p>作者研究了<strong>T5-baseline模型在不同数据集上进行预训练之后的性能表现</strong>。得到了两个结论：首先，域内无标签数据上的预训练可以提高下有任务的性能，其次，在更多样化的数据集上进行预训练，可以对下游任务进行改进。</p><p>作者研究了<strong>小数据集导致的数据重复对模型的影响</strong>。得出结论：截断预训练数据集的大小可能会降低下游任务的性能表现，因为可能存在记忆现象。对于大模型，它们更容易对小数据集进行过拟合，因此对于越大的模型，就需要越大的数据集。</p><p>作者研究了<strong>两种不同的微调方法对模型的影响</strong>。第一种是“adapter layers”，其灵感来源于在微调时保持大部分原始模型不变的目标，具体做法是在transformer的前馈网络之后添加一个dense-ReLU-dense模块，使得前馈网络的输入和输出维度一致，这样就可以作为一个即插即用无需额外修改的模块，在微调时，只有adapter layer和LN层的参数进行更新。第二种是“gradual unfreezing”，具体来说就是随着时间的推移而逐渐更新越来越多的参数，在baseline模型中(解码器编码器都有12个block，迭代2^18步)，每2^18&#x2F;12步多更新一个block的参数(从后往前逐渐解冻)。最终得出结论，所有参数都进行微调得到的结果是最好的。</p><p><img src="/posts/43168/fine_tuning.png" alt="fine_tuning"></p><p>作者研究了<strong>同时在多个任务上进行训练对模型的影响</strong>。这里的“多任务学习”与我们常说的不同，这里是在许多任务上训练单个模型，然后对不同的下游任务选择不同的checkpoint来进行测试(也就是说不进行预训练-微调操作)。在多任务学习中，一个关键就是分别从每个数据集采样多少数据来进行训练，作者针对这个问题主要研究了三种数据混合方法。第一种是“equal mixing”，即均等采样，这显然是一个次优解，作者将其作为另一个baseline(还有一个baseline是预训练-微调方法)与其他两个方法进行对比。第二种是“examples-proportional mixing”，即按比例混合，公式为：$\theta_t^{PM}&#x3D;min(\eta,N_t)&#x2F;\sum_{t^{‘}} min(\eta,N_{t^{‘}})$，其中$N_t$代表第t个任务的数据集大小，而$\eta$为自己设定的数据集大小上界，以避免过大的数据集对混合率计算产生较大的影响。第三种是“temperature-scaled mixing”，要在上面的基础上进行开T次方操作，公式为：$\theta_t^{TS}&#x3D;\sqrt[T]{\theta_t^{PM}}&#x2F;\sum_{t^{‘}}\sqrt[T]{\theta_{t^{‘}}^{PM}}$，这样可以避免大数据集或者小数据集对于结果的影响。最终作者的出结论，还是预训练-微调的效果最好。</p><p><img src="/posts/43168/mixing.png" alt="mixing"></p><p>作者研究了<strong>如何将多任务学习和微调进行组合</strong>。结果如下图所示。</p><p><img src="/posts/43168/combining.png" alt="combining"></p><p>作者研究了<strong>不同scale方法对模型的影响</strong>。结果如下图所示。</p><p><img src="/posts/43168/scaling.png" alt="scaling"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT-3论文笔记</title>
      <link href="/posts/12602.html"/>
      <url>/posts/12602.html</url>
      
        <content type="html"><![CDATA[<h1 id="GPT-3论文笔记"><a href="#GPT-3论文笔记" class="headerlink" title="GPT-3论文笔记"></a>GPT-3论文笔记</h1><ol><li><p>扩展语言模型可以大大提高few-shot的性能(GPT-2的效果差强人意)，有时可以跟进行过fine-tuning的sota方法媲美。</p></li><li><p>对所有子任务，GPT-3都没有经过任何的梯度更新或者微调，直接用预训练模型测试表现(有工作[Language models are unsupervised multitask learners]证明了可以用由zero-shot模型转变来的预训练语言模型执行标准NLP任务)。</p></li><li><p>fine-tuning指的是给许多任务相关的有标签数据进行训练，训练过程中会更新参数。few-shot指的是在推断时给K个有标签数据，但是并不对其进行权重参数的更新。one-shot就是将few-shot中的K设置为1。zero-shot则是K&#x3D;0。</p></li><li><p>下图中可以看到zero-shot、one-shot、few-shot三种方法的表现随着参数或者in-context learning中例子数量的增加而提高。</p><p><img src="/posts/12602/compare.png" alt="compare"></p></li><li><p>整个模型的训练过程如下图所示：</p><p><img src="/posts/12602/training_process.png" alt="training_process"></p></li></ol><h2 id="数据与处理"><a href="#数据与处理" class="headerlink" title="数据与处理"></a>数据与处理</h2><p>Common Crawl是一个很大的公开数据集，但是包含太多脏数据，因此需要对其进行过滤。具体的处理方式如下：</p><ol><li><p>首先基于同更高质量数据集WebText(reddit karmma&gt;3)的相似性对下载的Common Crawl数据集进行过滤。具体的操作是训练一个二分类的分类器，将WebText作为正样本，Common Crawl作为负样本，进行训练。然后用训练好的分类器重新对Common Crawl进行重采样（只要被预测为高质量的数据）。然后再用多种高质量数据集的并集作为正样本，未过滤的Common Crawl作为负样本进行训练，得到的分类器对Common Crawl进行打分，只保留$np.random.pareto(9)&gt;1-document_score$的内容。</p></li><li><p>利用Spark中的MinHashLSH算法（集合之间的相似度）进行了文章级别的去重操作。</p></li><li><p>增加了一些新的高质量数据集。除了筛选过的Common Crawl，还增加了WebText2、Books1、Books2以及Wikipedia数据集。</p></li></ol><p><img src="/posts/12602/dataset.png" alt="dataset"></p><h3 id="prompt-learning"><a href="#prompt-learning" class="headerlink" title="prompt learning"></a>prompt learning</h3><p><img src="/posts/12602/prompt.png" alt="prompt"></p><p>Prompt learning是一种自然语言处理技术，旨在通过给定的prompt（提示语）来训练文本分类模型。在Prompt learning中，模型通过使用预定义的文本模板和提示来理解输入，并输出相应的文本分类标签。这些模板和提示可以是手动创建的，也可以通过自动化方法生成。</p><p>Prompt learning的优点是可以使模型更加可解释和透明，因为模型的输出可以直接映射到预定义的模板和提示上。此外，Prompt learning还可以在训练数据有限或标签不完整的情况下提高模型性能。</p><p>举例来说，对于情感分析任务，可以使用以下prompt：“这个产品怎么样？”作为输入，然后根据输出分类标签，例如“好评”或“差评”。通过这种方式，模型可以从输入中提取有关产品的信息，并根据其情感内容自动分类。</p><h2 id="架构及参数设置"><a href="#架构及参数设置" class="headerlink" title="架构及参数设置"></a>架构及参数设置</h2><p>模型的架构同GPT-2中的大都一样（modifified initialization,pre-normalization, and reversible tokenization），只有一点不同：作者在transformer的层中像[Sparse Transformer]中那样，交替使用密集和局部带状稀疏注意力模式。</p><p>设计了8个模型，分别进行了测试，所有模型的上下文窗口$n_{ctx}&#x3D;2048$个tokens。</p><p><img src="/posts/12602/models.png" alt="models"></p><p>训练时使用Adam优化器，$\beta_1&#x3D;0.9$,$\beta_2&#x3D;0.95$,$\epsilon&#x3D;10^{-8}$，weight decay&#x3D;0.1, clip the global norm of the gradient at 1.0，使用Cross-Entropy loss，使用cosine decay调节学习率至原始值的10%（经过了2600亿个token之后训练继续从0.1lr进行）。在前3亿7500万个token采用linear LR warmup。实验中逐渐线性增大Batch Size，初始值为32k个token，经历40-120亿个（由模型的大小决定）token达到最大值。</p><h2 id="关于Sparse-Transformer"><a href="#关于Sparse-Transformer" class="headerlink" title="关于Sparse Transformer"></a>关于Sparse Transformer</h2><p>self-attention要对序列中任意两个向量计算相关度，因此计算复杂度是$O({n^2})$。所以，如果要节省显存，加快计算速度，那么一个基本的思路就是减少关联性的计算，也就是认为每个元素只跟序列内的一部分元素相关，这就是稀疏Attention的基本原理。OpenAI提出了两种Sparse Self Attention：Strided&#x2F;Fixed Self Attention，Full Self Attention和两种Sparse Self Attention分别如下图所示（该论文所做任务需要掩掉后续所有内容，只看到前面的内容，因此只保留了下三角矩阵，但是对于概念来讲，可以扩展到完整矩阵中）。如下图左一所示，Full Self Attention中进行$A_{ij}&#x3D;Q_iK_j^T$相乘时，针对的是所有的$j\le i$。</p><p><img src="/posts/12602/Sparse_Self_Attention.png" alt="Sparse_Self_Attention"></p><h3 id="Atrous-Self-Attention"><a href="#Atrous-Self-Attention" class="headerlink" title="Atrous Self Attention"></a>Atrous Self Attention</h3><p><img src="/posts/12602/Atrous_Self_Attention.png" alt="Atrous_Self_Attention"></p><p>如图所示，Atrous Self Attention就是启发于（Atrous Convolution），它对相关性进行了约束，强行要求每个元素只跟它相对距离为k,2k,3k,…的元素关联，其中k&gt;1是预先设定的超参数。从左边的注意力矩阵看，就是强行要求相对距离不是k的倍数的注意力为0（白色代表0）。具体来说，Atrous Self Attention就是进行$A_{ij}&#x3D;Q_iK_j^T$相乘时，针对的是所有的$\ j&#x3D;{(i-j)\  mod\  l&#x3D;0}$。通过使用这种自注意力，可以将运算复杂度变为$O(n^2&#x2F;k)$。</p><h3 id="Local-Self-Attention"><a href="#Local-Self-Attention" class="headerlink" title="Local Self Attention"></a>Local Self Attention</h3><p><img src="/posts/12602/Local_Self_Attention.png" alt="Local_Self_Attention"></p><p>如图所示，Local Self Attention就是要放弃全局关联，使用局部关联,约束每个元素只与前后k个元素以及自身有关联，相对距离超过k的注意力都直接设为0。具体来说，Local Self Attention就是进行$A_{ij}&#x3D;Q_iK_j^T$相乘时，针对的是所有的$\ j&#x3D;{t,t+1,\cdots,i},\ t&#x3D;max(0,i-l)$。通过使用这种自注意力，可以将运算复杂度变为$O(kn)$，变为了线性关系这样的理想性质，不过要以牺牲长距离关联性为代价。</p><h3 id="Strided-Self-Attention"><a href="#Strided-Self-Attention" class="headerlink" title="Strided Self Attention"></a>Strided Self Attention</h3><p><img src="/posts/12602/Strided_Self_Attention.png" alt="Strided_Self_Attention"></p><p>有上述两种attention作为前置知识，Strided Self Attention的提出便是顺理成章的了。Atrous Self Attention是带有一些洞的，而Local Self Attention正好填补了这些洞，所以一个简单的方式就是将Local Self Attention和Atrous Self Attention交替使用，两者结合起来，理论上既可以学习到全局关联性，又节省了显存和运算时间。而Strided Self Attention则是直接将二者合并为一个attention，如上图所示。</p><h3 id="Fixed-Self-Attention"><a href="#Fixed-Self-Attention" class="headerlink" title="Fixed Self Attention"></a>Fixed Self Attention</h3><p>作者指出，stride模式不适合用于文本数据上，因为文本不具备周期性结构(不像图像或者音乐)，因此又提出了类似的Fixed Self Attention。具体来说，就是在进行$A_{ij}&#x3D;Q_iK_j^T$相乘时，同样将注意力分成了两个部分，一个部分针对的是所有的$\ j&#x3D;{\ \lfloor j&#x2F;l\rfloor&#x3D;\lfloor i&#x2F;l\rfloor\ }$，另一个部分针对的是所有的$\ j&#x3D;{\ j\  mod\  l\in{t,t+1,\cdots,l-1}},\ t&#x3D;l-c$，其中$c$也是一个超参数，类似于滑动窗口的宽度，图中应当是c&#x3D;1的示例。针对后者，具体来说，如果设置l&#x3D;128，c&#x3D;8，那么所有大于128的像素都要关注120-128，所有大于256的像素都要关注248-256，引用原文中的表述即为：”specific cells summarize previous locations and propagate that information to all future cells”。</p><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>上面介绍了多种不同形式的注意力核，那么下面我们将介绍如何将这些不同形式的注意力核融入到网络中的，在论文中作者介绍了三种融合的方式：</p><ol><li><p>每个残差块使用不同的注意力核。对于一个深度网络，它是由连续的残差块组成的，对于每个残差块，我们可以使用不同类型的注意力核。公式如下：<br>$$<br>attention(X)&#x3D;W_p\cdot attend(X,A^{(r\ mod\ p)})<br>$$<br>其中，r是残差块的索引，p是分解注意力头的数目。</p></li><li><p>每个注意力头都计算所有类型的注意力核，然后合并他们的结果。<br>$$<br>attention(X)&#x3D;W_p\cdot attend(X,\bigcup_{m&#x3D;1}^p A^{(m)})<br>$$</p></li><li><p>使用多头注意力机制，每组头选择一个形式的注意力核，然后将它们合并起来(特征维度拼接)。实验表明这种方式是最好的融合策略。<br>$$<br>attention(X)&#x3D;W_p\cdot\left(attend(X,A)^{(i)}\right)_{i\in{1,\cdots,n_h}}<br>$$</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Concealed Object Detection</title>
      <link href="/posts/713.html"/>
      <url>/posts/713.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="《Concealed-Object-Detection》"><a href="#《Concealed-Object-Detection》" class="headerlink" title="《Concealed Object Detection》"></a>《Concealed Object Detection》</h2><ol><li><p>这篇论文是2021TPAMI的论文，也是2020年CVPR的oral论文Camouflaged Object Detection的改进。本文首先回顾一下其前身SINet，以及作者的另一篇用于息肉分割的伪装目标检测论文PraNet，最后再介绍SINet-V2。</p></li><li><p><strong>SINet</strong>。生物学研究表明，捕食者在狩猎时，首先会判断潜在猎物是否存在，即会搜索猎物；然后，捕食者可以识别目标动物并进行捕食。  基于这个事实，作者提出了SINet——它包括两个主要模块:搜索模块（ search module，SM）和识别模块（ identification module，IM），前者负责寻找伪装的物体，而后者则用来精确地检测它。SINet的网络结构如下所示。</p><p><img src="/posts/713/SINet.png" alt="SINet"></p><p>实验早已证明浅层的低级特征保留空间细节，用于构建目标边界，而深层的高级特征保留语义信息，用于定位目标。 由于神经网络的这种固有特性，作者将提取的特征划分为低级（2层），中级（1层），高级（2层）; 并通过拼接，上采样和下采样操作将它们组合起来。</p><p>在SM模块中，在5层卷积的基础上，将[X0,X1]，[X2,X3,X4]，[X3,X4]以及[X4]送入四个RF模块，最后做一个PDC，也就是一个解码器，便可以得到粗糙的预测图作为SM模块的输出。此处所谓的RF（reception field）和Google的Inception v3系列网络很像，都是通过1x1卷积与双串联式的架构来减少网络参数，从而达到瓶颈训练的效果，同时也是增大感受野的一种方式，而在COD或者其他的一些显著目标检测上，增大感受野是提高预测精度的一种常用方式。</p><p>在IM模块中，用SM模块输出的粗糙特征和第三层的特征做一次search attention来消除无关特征，这个attention也是对第三层特征使用高斯滤波器再和粗糙预测图取max得到的。做完attention之后再次送入RF增大感受野，最后送入PDC进行解码即可得到最终预测。</p></li><li><p><strong>PraNet</strong>。PraNet的网络结构如下所示。PraNet的贡献主要有两个：首先采用了部分解码器模块，以深三层特征图为输入得到初始的预测图，并以其为引导逐步精细化，最终得到预测图。其次，采用了反向注意力模块，逐步擦除确定的显著性区域，将擦除后的结果和上一层的特征图相加，这样就可以加强不确定的边界附近区域，促使模型获得更精确的分割结果。</p><p><img src="/posts/713/PraNet.png" alt="PraNet"></p></li><li><p><strong>SINet-V2</strong>。SINet-V2同样采用了先搜索后识别的流程。它主要有三个模块： 纹理增强模块（texture enhanced module，TEM），近邻连接解码器模块（neighbor connection decoder，NCD），级联组反转注意力模块（ cascaded group-reversal attention，GRA）。网络的结构如下所示。</p><p><img src="/posts/713/SINet-V2.png" alt="SINet-V2"></p></li><li><p><strong>搜索阶段</strong>。首先使用Res2Net-50作为主干网络进行特征提取。接着，将深3层的特征送入TEM模块（使用扩大的上下文线索来捕获细粒度纹理）来增大感受野（如SINet中的RF一样）。然后将增强后的特征送入NCD模块（提供位置信息）来进行粗糙预测（如SINet中的PDC一样）。</p></li><li><p><strong>识别阶段</strong>。这是SINet-V2相比于SINet的主要改进之处。SINet在识别阶段使用搜索阶段的输出作为引导，借助PDC模块生成最终预测，而SINet-V2却并非如此，而是采用了PraNet中使用的反转注意力、目标擦除策略以及PGNet中的分组引导策略。GRA模块（从更深的层中细化粗糙的预测）的具体操作是：首先将特征图沿通道维度进行分组（如4个通道作为一组，这样32个通道可以分为8组），然后将粗糙预测进行sigmoid激活并用1减得到反转预测，接着在每个组后面插入一张反转预测，再进行通道维度的拼接，相比PraNet中将粗糙预测直接作为先验引导进行像素级乘法的操作，SINet-V2避免了引入错误引导而累积放大错误的可能性。最后，作者采用了残差学习策略，每个GRA模块都有三次残差学习操作：产生本迭代粗糙预测时的残差学习、产生下一迭代反转引导时的残差学习、产生本阶段粗糙预测时的残差学习。</p><p><img src="/posts/713/GRA.png" alt="GRA"></p></li><li><p><strong>loss</strong>。模型使用的loss是weighted IoU loss与weighted BCE loss之和，采用了深度监督的思想，因此模型的总loss是4次loss之和。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly_paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> weekly_paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PraNet Parallel Reverse Attention Network for Polyp Segmentation</title>
      <link href="/posts/59520.html"/>
      <url>/posts/59520.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="《PraNet-Parallel-Reverse-Attention-Network-for-Polyp-Segmentation》"><a href="#《PraNet-Parallel-Reverse-Attention-Network-for-Polyp-Segmentation》" class="headerlink" title="《PraNet Parallel Reverse Attention Network for Polyp Segmentation》"></a>《PraNet Parallel Reverse Attention Network for Polyp Segmentation》</h2><ol><li><p>设计了并行反向注意力网络（parallel reverse attention network，PraNet）。该模型的效果相比UNet家族有很大的提升，提升程度如下图所示。</p><p><img src="/posts/59520/progress.png" alt="progress"></p></li><li><p>总的来看，目前看到的两个效果最好的PraNet和SINet-V2都是采用了粗糙定位再加精确分割的手段来进行伪装目标检测。PraNet的模型结构如下图所示。</p><p><img src="/posts/59520/PraNet.png" alt="PraNet"></p></li><li><p>设计了并行部分解码器（parallel partial decoder，PPD），该模块会聚集高维特征，然后基于组合特征生成一个全局图作为后续组件的初始引导。</p><p><img src="/posts/59520/cascaded_partial_decoder.png" alt="cascaded_partial_decoder"></p></li><li><p>设计了反向注意力模块（reverse attention，RA）来挖掘边界线索。作者没有聚合来自所有层次的特征，而是在三个并行的高级特征中自适应地学习反向注意力，不断地从高层输出特征中擦除前景对象的方式来逐步挖掘互补区域和细节。具体操作是将深层中输出的特征图上采样激活获得预测图，然后翻转，如第一幅图所示，再通本层特征图相乘，即可擦除目前已知的前景区域。</p></li><li><p>模型的loss是weighted Iou loss和BCE loss之和，采用了深度监督的思想，总的loss是三层的loss之和加上最终预测的loss。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly_paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> weekly_paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-10-24论文笔记</title>
      <link href="/posts/11086.html"/>
      <url>/posts/11086.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="《Deep-Texture-Aware-Features-for-Camouflaged-Object-Detection》"><a href="#《Deep-Texture-Aware-Features-for-Camouflaged-Object-Detection》" class="headerlink" title="《Deep Texture-Aware Features for Camouflaged Object Detection》"></a>《Deep Texture-Aware Features for Camouflaged Object Detection》</h2><ol><li><p>TANet通过构建多个纹理感知细化模块，学习深度卷积神经网络中的纹理感知特征，来放大伪装目标与背景之间的细微纹理差异，用于伪装目标检测。纹理感知细化模块计算特征响应的协方差矩阵以提取纹理信息，此外作者还设计一个亲和力损失学习一组参数，有助于分离伪装目标和背景之间的纹理，并采用边界一致性损失来探索目标的细节结构。</p><p><img src="/posts/11086/performance.png" alt="performance"></p><p><img src="/posts/11086/TANet.png" alt="TANet"></p></li><li><p>挪用了残差细化模块（residual refine blocks，RRB）对不同层次的特征图进行细化，增强细节，去除背景噪声。</p><p><img src="/posts/11086/RRB.png" alt="RRB"></p></li><li><p>设计了纹理感知细化模块（texture-aware refinement module，TARM）来放大伪装物体与背景之间的纹理差异，从而显著增强了伪装物体的识别能力。先用多个1$\times$1卷积获得多种特征图，这些特征图会在后面的操作中逐步学习纹理的不同方面。接着计算每个位置的不同通道间的协方差矩阵，通过该矩阵捕捉卷积特征之间的关联（如特征的组合、共现等），具体操作是将某个位置的C维向量和其转置相乘，由于其具备对角对称性，所以只需要上三角部分来表示纹理特征即可。然后将所有协方差矩阵拼接、卷积，再通过两组3$\times$3卷积获得两组不同的参数图——$\gamma,\beta$。这两组参数被用于扩大伪装目标和背景的纹理差异，具体公式如下：<br>$$<br>f_{out}&#x3D;conv(\gamma\frac{f_{in}^{‘}-\mu(f_{in}^{‘})}{\sigma(f_{in}^{‘})}+\beta)+f_{in}<br>$$<br>其中$f_{in}^{‘}，\mu，\sigma$分别代表卷积后的输入图、其均值、其方差。</p><p><img src="/posts/11086/TARM.png" alt="TARM"></p></li><li><p>设计了类同损失（Affinity loss）来放大纹理特征的差异，促进两组参数更好地捕捉差异。首先将参数图进行下采样，计算类同矩阵，需要借助向量相乘。然后将GT下采样，再次计算类同矩阵，需要借助相同与否的指示函数。两者的计算公式如下图。然后通过加权的减法获得最终的类同loss。</p><p><img src="/posts/11086/Affinity.png" alt="Affinity"></p><p><img src="/posts/11086/Affinity2.png" alt="Affinity2"></p></li><li><p>设计了边界一致性损失（ boundary-consistency loss）来增强跨边界的细节信息，而在测试中没有额外的计算开销。其将图像划分为多个图像块，当图像块内包含不同类别的像素时，选中这些图像块，不执行下采样操作，因为高分辨率的参数图有利于为边界提供更详细的信息，然后再计算patch内部的类同损失。其计算公式如下图。</p><p><img src="/posts/11086/BCL.png" alt="BCL"></p><p><img src="/posts/11086/boundary_consistency_loss.png" alt="boundary_consistency_loss"></p></li></ol><h2 id="《Mutual-Graph-Learning-for-Camouflaged-Object-Detection》"><a href="#《Mutual-Graph-Learning-for-Camouflaged-Object-Detection》" class="headerlink" title="《Mutual Graph Learning for Camouflaged Object Detection》"></a>《Mutual Graph Learning for Camouflaged Object Detection》</h2><ol><li><p>设计了新颖的交互图学习模型（Mutual Graph Learning，MGL），它将传统的相互学习的思想从规则网格推广到图域。具体来说，MGL将一幅图像解耦为两个特定于任务的特征图——一个用于粗略地定位目标，另一个用于准确地捕捉其边界细节——并通过图循环地推理它们的高阶关系，使两者充分地相互促进。整个MGL分为三个阶段：多任务特征提取模块（Multi-Task Feature Extraction，MTFE)，区域诱导图推理模块（Region-Induced Graph Reasoning，RIGR)，边界压缩图推理模块（Edge-Constricted Graph Reasoning，ECGR)。</p><p><img src="/posts/11086/MGL.png" alt="MGL"></p><p><img src="/posts/11086/SMGL.png" alt="SMGL"></p></li><li><p>区域诱导图推理模块（Region-Induced Graph Reasoning，RIGR)。该模块的目标是推理出COD和COEE之间的语义关系，而不考虑细节。通过图投影操作将两个特征图转换为用边和点描述的语义图——具有相似特征的像素形成了图中的顶点，而边则衡量了两个顶点之间的密切程度。接着使用跨图交互模块（Cross-Graph Interaction，CGI）捕捉两个语义图之间的高级依赖关系，并将COD语义图中的顶点转换成COEE语义图中的顶点。然后通过图卷积进行图推理获得更好的图表示，最后将图表示反向投影回原始坐标空间。</p><p><strong>图投影</strong>。首先将特征图$F_C,F_E$[h,w,c]降维到[hw,c]变成二维矩阵，然后引入两个参数矩阵$W,\Sigma$[K,c]来进行投影操作。其中$W$的每一列$w_k$都是一个节点的可学习的聚类中心，$\sigma_k$则是$\Sigma$的列，$v_k$则是第k个节点的表示，同时也是节点特征矩阵的第k列。然后通过下图中的公式将特征图投影为节点。接着通过衡量节点之间的密切关系（Affinity）来计算其邻接矩阵（理解为边的长度），其计算公式为:$A^{intra}&#x3D;f_{norm}(V^T\times V)$。</p><p><img src="/posts/11086/projection.png" alt="projection"></p><p><strong>跨图交互</strong>。用于指导信息从COD图传播到COEE图。先使用多层感知机将COEE的特征图转换成query，将COD的特征图转换成key和value。接着可以计算出相似性矩阵$A^{inter}$，并且通过相似性矩阵可以将COD的特征图转换成COEE的特征图。</p><p><img src="/posts/11086/CGI.png" alt="CGI"></p><p><img src="/posts/11086/CGI2.png" alt="CGI2"></p><p><strong>图推理</strong>。输入上一步获得的COEE的顶点图和COD的顶点图，进行图卷积完成图推理操作得到增强的图表示，其公式如下图。</p><p><img src="/posts/11086/GR.png" alt="GR"></p><p><strong>图重投影</strong>。这个模块就是逆着进行图投影操作，将特征映射回原来的域中。</p></li><li><p>边界压缩图推理模块（Edge-Constricted Graph Reasoning，ECGR)。在分析空间关系之前，会先将特征图送入边缘分类器获得伪装目标的边界图。此外通过拼接两个重投影之后的特征图获得新的特征图来进行COD，然后通过边界支持图卷积（Edge Supportive Graph Convolution，ESG-Conv)来编码边界信息并在上述边界图的引导下增强拼接后的新特征图来更好地定位目标。最后，将增强后的特征图送福分类器获得最终结果。</p><p><img src="/posts/11086/ECGR.png" alt="ECGR"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly_paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> weekly_paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-10-17论文笔记</title>
      <link href="/posts/60232.html"/>
      <url>/posts/60232.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="《Zoom-In-and-Out-A-Mixed-scale-Triplet-Network-for-Camouflaged-Object-Detection》"><a href="#《Zoom-In-and-Out-A-Mixed-scale-Triplet-Network-for-Camouflaged-Object-Detection》" class="headerlink" title="《Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection》"></a>《Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection》</h2><ol><li><p>提出了混合尺度的三联网络——ZoomNet，它模仿人类在观察模糊图像时的行为，即放大和缩小。具体而言，ZoomNet采用缩放策略，通过精心设计的尺度整合单元和层次化混合尺度单元学习具有判别力的混合尺度语义，充分挖掘候选对象与背景环境之间的细微线索。此外，考虑到难以区分的纹理带来的不确定性和模糊性，构造了一个简单而有效的正则化约束——不确定性感知loss，以促进模型在候选区域准确地产生更高置信度的预测。</p><p><img src="/posts/60232/ZoomNet.png" alt="ZoomNet"></p><p><img src="/posts/60232/SIU.png" alt="SIU"></p><p><img src="/posts/60232/HMU.png" alt="HMU"></p></li></ol><h2 id="《Learning-Calibrated-Medical-Image-Segmentation-via-Multi-rater-Agreement-Modeling》"><a href="#《Learning-Calibrated-Medical-Image-Segmentation-via-Multi-rater-Agreement-Modeling》" class="headerlink" title="《Learning Calibrated Medical Image Segmentation via Multi-rater Agreement Modeling》"></a>《Learning Calibrated Medical Image Segmentation via Multi-rater Agreement Modeling》</h2><ol><li><p>在医学图像分割中往往会有多位评分者进行标注，如果只用其中一位的标注进行训练那么在其他标注上进行测试的效果就会比较差。以往的工作中通常采用的多数投票法或者首选评分法，但是这两种方法都忽略了多评估者注释中异同点中包含的的丰富信息。为了解决这个问题，作者提出了两阶段的模型——MRNet来明确地建模多评估者一致（不一致）信息。</p><p><img src="/posts/60232/MRNet.png" alt="MRNet"></p></li><li><p>设计了专家感知推理模块（expertise-aware inferring module，EIM）。该模块将独立评分者的专业水平作为先验知识嵌入，来生成高维语义特征。专业性向量作为权重，用于计算soft GT，其计算公式为：$GT^{soft}&#x3D;\sum_{k&#x3D;1}^NS_iV_i$。在每个迭代中，专业性向量交替使用三种方法进行设置：统一权重的多数投票模式、一个权重为1其余权重为0的单一投票模式、随机（总和为1）模式。作者认为这样的交替策略可以使得模型学习到个体评分者对最终软预测的影响。</p></li><li><p>设计了多评分者重建模块，使得该模型能够从粗糙的预测中重建多评分者评分，并进一步利用多评分者一致（不一致）线索来提高分割性能。作为第二阶段的第一个模块，以粗糙预测和输入图片的拼接作为输入，试图重构每个评分者给出的GT。这里首先使用BCEloss作为重构loss来衡量真实GT和重构GT的相似度；然后使用了L2loss作为一致性loss来衡量粗糙预测和soft GT提取出的特征的一致性。最后使用多个评分者gt的像素级标准差来估计评分不一致性的不确定性图，用于精细化粗糙预测，其公式如下所示：<br>$$<br>U_{map}&#x3D;\sqrt{\frac{1}{N}\sum_{i&#x3D;1}^{N}(S_i-\frac{1}{N}\sum_{i&#x3D;1}^{N}S_i)^2}<br>$$</p></li><li><p>设计了多评分者感知模块，这个模块基于不确定性图，使用多分支软注意力机制进一步精细化分割结果。使用不确定性图要解决的一个关键问题是如果不确定性图本身有错或者不完整，那就回导致模型效果变差，因此作者使用了软注意力机制——旨在扩大不确定区域的覆盖范围，从而有效地感知和捕捉多个评分者之间的不一致性线索。这个soft体现在两个方面，首先，其操作被定义为：$Soft(U_{map})&#x3D;\Omega_{max}(F_{Gauss}(U_{map},k),U_{map})$，其中F是使用高斯卷积核（标准差可学习）的卷积操作，作者使用卷积结果和原不确定性图中较大的那一个作为软不确定性图；其次，没有直接将不确定性图和原特征图相乘作为结果，而是将soft之后的不确定性图与原特征图相乘再相加。</p></li><li><p>总的损失函数是重构loss+一致性loss+粗糙预测loss+最终预测loss。</p></li></ol><h2 id="《Detecting-Camouflflaged-Object-in-Frequency-Domain》"><a href="#《Detecting-Camouflflaged-Object-in-Frequency-Domain》" class="headerlink" title="《Detecting Camouflflaged Object in Frequency Domain》"></a>《Detecting Camouflflaged Object in Frequency Domain》</h2><ol><li><p>作者认为COD任务的目标不仅是在一个单一的RGB领域中模仿人类的视觉能力，而且应当超越人类的生物视觉。于是就引入频域作为一个额外的线索，以更好地从背景中检测伪装的物体。模型的整体架构如下所示：</p><p><img src="/posts/60232/architecture.png" alt="architecture"></p></li><li><p>设计了频率增强模块（frequency enhancement module，FEM）来挖掘频率域中伪装目标的线索。</p><p><strong>使用DCT（离散余弦变换）处理RGB图像</strong>。先将RGB图像划分成一组8$\times$8的patch，$p_{i,j}^c\in R^{8\times 8}$表示某个颜色通道的patch，通过DCT处理变为频谱$d_{i,j}^c\in R^{8\times 8}$，其中每个值对应于特定频带的强度。为了将相同频率的所有分量组合到一个通道中，作者进行了如下操作：$x_o^{freq}&#x3D;x_{i,j}^{freq}&#x3D;flatten(d_{i,j})$，这样就可以让每个通道都属于一个频带。图像也就从颜色域转换到了频域。</p><p><strong>在线可学习增强</strong>。实际图像中存在<strong>各种伪装对象和复杂背景</strong>，固定的DCT可能无法很好地处理这一点，因此还需要一个自适应的学习过程来适应复杂的场景。此外，<strong>信息在预处理过程中会丢失</strong>，因此需要加强频域信号。综合上述两点，作者引入了在线可学习增强来提高信号的适应性。首先增强单个patch：将信号降采样并分成低频信号和高频信号两个部分，然后分别送入两个多头自注意力模块捕捉局部相关性，再将输出进行拼接，再次送入一个多头自注意力模块捕捉全局相关性。其次寻找patch之间的关联：将上一部分的输出reshape之后送入多头自注意力模块，将输出reshape并上采样即可得到增强的结果。</p><p><strong>特征对齐</strong>。现在有了频域特征和颜色域特征，就要想办法融合二者，在这之前，要将特征进行对齐。作者观察到高频特征中的差异有助于找到伪装目标，于是设计了一个覆盖高频带的二进制基础滤波器以及三个针对Y、Cb、Cr空间的可学习滤波器。滤波操作是频率响应和组合滤波器$f_{base}+\sigma(f_i)$之间的像素级点积，其中$\sigma(y)&#x3D;\frac{1-exp(-y)}{1+exp(-y)}$。于是寻找重要频域信息的公式如下所示：$X_i^{freq}&#x3D;x_i^{freq}\odot [f_{base}+\sigma(f_i)]$。最后将三个通道的滤波结果进行拼接即可完成滤波过程。将滤波结果和空间域特征图进行拼接、卷积，输出通道为4n的矩阵，分成$T^1,T^2,T^3,T^4$，通过矩阵相乘得到空间域转换矩阵和频率域转换矩阵：$T_1&#x3D;T^1(T^2)^T,T_2&#x3D;T^3(T^4)^T$。借助转换矩阵以及可学习的用于调整通道强度的向量v，可以得到每个域的对齐特征表示：$X_{rgb2s}^i&#x3D;T_1X^i\otimes v_{rgb}^i,X_{freq2s}^i&#x3D;T_2X^{freq}\otimes v_{freq}^i$。最后将这两个特征加和即可得到融合特征。</p><p><img src="/posts/60232/FEM.png" alt="FEM"></p></li><li><p>设计了高维关系模块（high-order relation module，HOR）来进一步充分地利用频域信息。想要从背景中分离出真实的伪装目标和干扰物体，需要发现细微的差异——因为伪装目标和干扰物体往往在各方面都很相似。这些细微的差异需要捕捉高阶关系才能发现。首先对原始特征进行位置重要性编码，其公式为：$W&#x3D;softmax(X^T\Phi(X))$，其中$\Phi(X)$表示比X高一些的层，这样可以利用其更大的感受野以及增强多尺度学习的表示。接着用全连接层生成新的权重并对原始特征进行增强：$A&#x3D;g(W)\cdot (WX^T)+X$，最后再次和高层特征相乘：$H&#x3D;softmax(A^T\Phi(X))$，即可得到被送入解码器的特征。</p><p><img src="/posts/60232/HOR.png" alt="HOR"></p></li><li><p>模型的loss是12个loss的加权和，它们包括4个解码器预测和GT的IoU loss，4个解码器预测和GT的BCE loss，还有4个FA预测和GT的频域感知loss。且这个权重为$2^{1-i}$。</p></li><li><p>【1】Zequn Qin, Pengyi Zhang, Fei Wu, and Xi Li. Fcanet: Frequency channel attention networks. <em>CoRR</em>, abs&#x2F;2012.11879,2020.</p><p>【2】Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-Kuang Chen, and Fengbo Ren. Learning in the frequency domain.In <em>CVPR</em>, pages 1737–1746, 2020.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly_paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> weekly_paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-9-26论文笔记</title>
      <link href="/posts/58810.html"/>
      <url>/posts/58810.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="《Cascade-Graph-Neural-Networks-for-RGB-D-Salient-Object-Detection》"><a href="#《Cascade-Graph-Neural-Networks-for-RGB-D-Salient-Object-Detection》" class="headerlink" title="《Cascade Graph Neural Networks for RGB-D Salient Object Detection》"></a>《Cascade Graph Neural Networks for RGB-D Salient Object Detection》</h2><ol><li><p>提出了级联图神经网络（CAS-GNN），可以通过一组级联图全面地提取和推理这两个数据源之间的相互作用，以学习RGB-D SOD的强大表示。CAS-GNN分别处理这两个数据源，并采用一种新的级联图推理（CGR）模块来学习强大的密集特征嵌入，从中可以很容易地推断出显著性图。与以前的方法相比，对互补数据源之间的高级关系的明确建模和推理使我们能够更好地克服诸如遮挡和歧义之类的挑战。</p><p><img src="/posts/58810/CAS_GNN.png" alt="CAS_GNN"></p></li><li><p>CAS-GNN包含多个图，每个图都被用于处理一个特定级别的跨模态推理。每一个图都包含两种基础类型的节点：几何节点储存了深度特征，外观节点储存了RGB相关特征。每条边连接两种节点：同一模态不同尺度的节点或者不同模态但是同一尺度的节点。此外，为了增强对多级特征的推理能力，作者将前面的图合并为下面的级联图的两个域特定的引导节点。因此，整个模型共有三种类型的节点。</p><p><img src="/posts/58810/CMR.png" alt="CMR"></p><p>对于多尺度节点嵌入。使用金字塔池化模块PPM、一个卷积层和一个插值层来提取两个模态的多尺度特征，作为初始的节点表示，如下图a所示，外观节点和几何节点都是这样处理。</p><p>对于边的嵌入。终点的特征图减起点的特征图进行卷积，即可得到起点与终点的高维联系。又因为是有向图网络，因此两个点之间的双向路径分别代表起点和终点之间双向的高维联系。</p><p>对于信息传递。在GNN模型中，每个节点要整合其所有邻接节点的特征信息。其公式被定义为：<br>$$<br>m^{ (t) }<em>{k,l}&#x3D;\sum</em>{k\in N(l) }M(V^{ (t-1) }<em>k,E^{ (t-1) }</em>{k,l} )&#x3D;\sum_{k\in N(l) }sigmoid(E^{ (t-1) }<em>{k,l} ) \cdot V^{ (t-1) }<em>k<br>$$<br>对于节点状态更新。使用 Gated Recurrent Unit来更新节点的状态，其公式被定义为：<br>$$<br>V^{ (t) }</em>{l}&#x3D;\sum</em>{k\in N(l) }F_{update}(V^{ (t-1) }<em>l,m^{ (t-1) }</em>{k,l} )&#x3D;\sum_{k\in N(l) }U_{GRU}(V^{ (t-1) }<em>l,m^{ (t-1) }</em>{k,l} )<br>$$<br>对于显著性读出。将每个模态的节点嵌入插值到统一尺寸，然后进行拼接和卷积，得到两个模态各自的嵌入表示。两个模态的嵌入表示通过一次拼接和两个卷积映射到了显著性分数，最后将其通过插值变为需要的尺寸即可</p><p><img src="/posts/58810/embeddings.png" alt="embeddings"></p></li><li><p>网络级联技术。CAS-GNN使用网络级联技术，将前一张图的嵌入表示作为下一张级联图的域特定的引导节点。</p><p>关于引导节点。不同于几何节点和外观节点，引导节点只传递引导信息并在信息传播过程中保持固定。具体操作是将前一张图的同一模态的所有节点拼接起来然后使用卷积进行融合，融合的结果作为引导节点，如下图a所示。</p><p>关于级联信息传播。每个引导节点通过注意力机制（通过全局平均池化和sigmoid函数获得）向下一张图中的同一模态的所有节点传播引导信息。如下图b所示。</p><p>关于多级特征融合。每一次迭代产生的嵌入表示都被送到最后，通过像素级的加和或者通道级的拼接进行融合。</p><p><img src="/posts/58810/propagation.png" alt="propagation"></p></li></ol><h2 id="《Hierarchical-Alternate-Interaction-Network-for-RGB-D-Salient-Object-Detection》"><a href="#《Hierarchical-Alternate-Interaction-Network-for-RGB-D-Salient-Object-Detection》" class="headerlink" title="《Hierarchical Alternate Interaction Network for RGB-D Salient Object Detection》"></a>《Hierarchical Alternate Interaction Network for RGB-D Salient Object Detection》</h2><ol><li><p>提出了层次交替交互网络（ Hierarchical Alternate Interactions Network，HAINet）。它由特征编码，跨模态交替交互，显著性推断三个阶段组成。</p><p><img src="/posts/58810/HAINet.png" alt="HAINet"></p></li><li><p>特征编码阶段由两个编码分支组成，一个用于编码深度特征，一个用于编码RGB特征，他们的backbone都是VGG16。显著性推断阶段与特征编码阶段相反。</p></li><li><p>设计了层次化交替交互模块。之前的工作中，特征交互使用像素级乘法，像素级加法，或者拼接加注意力等方式。但是无论哪种方式都没有尝试去过滤掉深度图中的噪声，作者对此做出了改进。首先使用RGB特征过滤深度特征中的干扰信息，然后过滤之后的深度特征被用于增强RGB特征，这样的调整-反馈机制被实现于交替相互作用单元（ Alternate Interaction Unit，AIU）中。作者构造了层次化的结构来使用AIU，前一个AIU的输出会参与到下一个AIU的调整-反馈机制之中，这样的层次化结构被称为渐进融合。此外作者还设计了自适应特征重加权操作来进一步筛选特征并保留最有价值的信息。</p><p>RGB特征和深度特征分别使用膨胀比例为1,3,5,7的空洞卷积，得到四个分支。每个分支都有一个AIU模块，该模块中包含许多通道注意力和空间注意力。来自RGB的特征通过通道注意力进行增强，然后再使用空间注意力进行增强，增强之后的RGB特征作为权重矩阵与深度特征进行相乘，借此来过滤掉深度图中的噪声干扰。接着将过滤之后的深度特征与原深度特征相加，实现对比增强。接着重复上面的操作，对过滤之后的深度特征进行增强，并与RGB特征相乘得到将被输出AIU的混合特征，该特征会被加和到下一个分支的RGB特征之中。接着，将四个分支的所有输出特征进行通道级的拼接得到最终的混合特征。在特征重加权模块中，通过使用自适应的通道注意力以及像素级加和进一步对特征进行了筛选。</p></li><li><p>混合loss。在训练阶段，使用BCE loss和IOU loss的和作为混合loss，它们一个关注像素级损失，一个关注图像级损失，互为补充。此外使用了深度监督的思想，对每个尺度的预测都计算了混合loss。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly_paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> weekly_paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-9-19论文笔记</title>
      <link href="/posts/59821.html"/>
      <url>/posts/59821.html</url>
      
        <content type="html"><![CDATA[<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="《Cascaded-Partial-Decoder-for-Fast-and-Accurate-Salient-Object-Detection》"><a href="#《Cascaded-Partial-Decoder-for-Fast-and-Accurate-Salient-Object-Detection》" class="headerlink" title="《Cascaded Partial Decoder for Fast and Accurate Salient Object Detection》"></a>《Cascaded Partial Decoder for Fast and Accurate Salient Object Detection》</h2><ol><li><p>提出了级联部分解码器框架，该框架丢弃了低层特征以降低深度聚合模型的复杂性，并利用生成的相对精确的注意力图来细化高层特征以提高性能。</p><p><img src="/posts/59821/cascaded_partial_decoder.png" alt="cascaded_partial_decoder"></p></li><li><p>由于整个网络的浅两层捕捉更多的是细节信息，深两层捕捉更多的是语义信息，所以选择第三层作为分界点。<strong>在第三层之后分出两个分支，一个是注意力分支，一个是显著性分支，前者使用深三层特征送入部分解码器，生成初始显著性图，此图送入整体注意力模块，获得增强的注意力矩阵。该注意力矩阵被送入显著性分支帮助精细化第三层的特征，这样的方式可以帮助去除原来第三层特征中的干扰信息</strong>，但同时，如果干扰信息被分类为显著性区域，那么也会极大地影响分割结果，于是就有了整体注意力模块。其公式如下：<br>$$<br>S_h&#x3D;MAX\left(f_{min_max}\left(Conv_g\left(S_i,k\right)\right),S_i\right)<br>$$</p></li><li><p>部分解码器模块就是魔改的RFB模块。</p></li></ol><h2 id="《CAGNet-Content-Aware-Guidance-for-Salient-Object-Detection》"><a href="#《CAGNet-Content-Aware-Guidance-for-Salient-Object-Detection》" class="headerlink" title="《CAGNet: Content-Aware Guidance for Salient Object Detection》"></a>《CAGNet: Content-Aware Guidance for Salient Object Detection》</h2><ol><li><p>提出了CAGNet来使前景背景更容易被区分，抑制非显著性区域的显著性外观，并为显著性区域的不同外观的子区域分配同样的标签。整个网络分为三个部分：特征提取网络（FEN），特征引导网络（FGN），特征融合网络（FFN），网络的结构示意图如下图所示。</p><p><img src="/posts/59821/CAGNet.png" alt="CAGNet"></p></li><li><p>提出了多尺度特征提取模块（Multi-scale Feature Extraction Module ，MFEM），使用全局卷积网络GCNs（用于解决空洞卷积造成的网格效应），允许每一级别的网络获取多尺度上下文信息。</p><p><img src="/posts/59821/MFEM.png" alt="MFEM"></p></li><li><p>提出了特征引导网络。高级特征在低级特征的引导下可以让显著性区域和非显著性区域更加容易区分，解决“非显著性区域拥有显著性特征”的问题；低级特征在高级特征的引导下可以产生更引人注意的特征，解决“显著性区域中不同外观的子区域标签不一致”的问题。该模块的思想本质就是将高级特征和低级特征进行拼接，然后通过卷积等操作产生通道权重和空间权重。</p><p><img src="/posts/59821/FGM.png" alt="FGM"></p></li><li><p>设计了新的特征融合网络。在该部分中，作者设计了一个新的融合模块—— Residual Refifinement Module ，即RRM模块，模块的结构示意图如下图所示。该模块同时使用了注意力和残差学习的思想，中间的支路是残差学习，左侧的支路是注意力。</p><p><img src="/posts/59821/RRM.png" alt="RRM"></p></li><li><p>设计了一个新的损失函数，它比交叉熵更优秀。<br>$$<br>L&#x3D;\alpha_1L_p+\alpha_2L_R+\alpha_3L_{MAE}<br>$$</p></li></ol><h2 id="《Effective-Fusion-Factor-in-FPN-for-Tiny-Object-Detection》"><a href="#《Effective-Fusion-Factor-in-FPN-for-Tiny-Object-Detection》" class="headerlink" title="《Effective Fusion Factor in FPN for Tiny Object Detection》"></a>《Effective Fusion Factor in FPN for Tiny Object Detection》</h2><ol><li><p>作者发现在小目标检测中，随着深层向浅层传递信息的增加，模型的性能是先增加后减少的。于是作者将融合因子定义为FPN中相邻两层特征融合时较浅层的加权系数，这篇论文的主要工作就是研究如何找到一个合适的融合因子。</p><p><img src="/posts/59821/EFF.png" alt="EFF"></p></li><li><p>作者使用四种方式生成融合因子：暴力列举法，损失函数优化学习法，自注意力模块生成法，以及统计信息计算法。暴力法不合适，注意力法计算量大，学习法的表现不如暴力法，而统计法的表现很好而且没有增加推理时的计算量。</p></li><li><p>作者认为不同的层能够检测到的目标数目是不同的，这就导致不同层的训练样本数量不同，不同层对参数更新的贡献不同。因此作者认为对于那些训练样本多的层，应该分配一个小的权重，来保证各层对模型参数更新的贡献大致相同。</p></li><li><p>融合因子的数学解释。下图以C4作为例子，当使用较大的权重时，其将获得更多用于浅层检测任务的信息，当使用较小的权重时，其将获得更多用于深层检测任务的信息。</p><p><img src="/posts/59821/gradient.png" alt="gradient"></p></li></ol><h2 id="《Progressive-Self-Guided-Loss-for-Salient-Object-Detection》"><a href="#《Progressive-Self-Guided-Loss-for-Salient-Object-Detection》" class="headerlink" title="《Progressive Self-Guided Loss for Salient Object Detection》"></a>《Progressive Self-Guided Loss for Salient Object Detection》</h2><ol><li><p>模型的核心思想是将SOD模型的训练过程分解为几个步骤。对于每一个步骤，该模型都会提供一些可行的训练目标，以降低训练难度。因此，它的输出可以在这逐步的训练中被逐步优化。具体而言，在当前网络预测中应用模拟形态学闭合操作，可以去除前景物体内部的小孔，减少错误检测区域，生成新的辅助训练监督作为整体损失函数的一部分。更重要的是，这些新创建的训练目标随着网络预测的逐步优化而不断细化，可以为训练过程提供持续正确的指导。因此，SOD模型可以通过这些渐进式监督来逐步突出更完整的显著目标。</p><p><img src="/posts/59821/MS_FAM.png" alt="MS_FAM"></p></li><li><p>提出了新的多尺度特征聚合模块MS-FAM，通过分支级的注意力机制来捕捉并自适应地聚合它们。MS-FAM使用了空洞卷积，inception模块，注意力机制以及残差学习，并被放置于侧向连接中进行多尺度特征融合。</p></li><li><p>提出了新的损失函数——渐进式自引导损失（progressive self-guided loss，PSG Loss），通过在模型预测上模拟形态学闭合操作（先对模型的预测图进行膨胀操作，然后进行腐蚀操作），来逐步创建辅助训练监督，逐步地引导训练过程。为了避免全0的显著性预测导致的PSG loss的零梯度问题，PSG loss只能作为一个辅助loss，需要配合一个正常的loss，二者的加权和组成模型的整体loss，辅助loss和正常loss选取的损失函数相同，都是BCE loss+Dice loss，只是计算loss的对象分别是预测和gt以及预测和处理之后的预测。考虑到膨胀和腐蚀操作的速度很慢，因此使用最大池化操作代替膨胀操作，并使用膨胀之后的预测图和gt进行取交集操作来近似代替腐蚀操作。这种取交集操作有两个优点：首先保证了$SM_{pgt} \subseteq SM_{gt}$，其次这种操作总是可以基于当前预测产生更好的结果，并且该结果可用于指导模型逐步探索当前预测的邻近区域。总的来说，模拟形态学操作可用如下公式表示:$f(SM_{pred} )&#x3D;e(d(SM_{pred} ) )\approx maxpool(SM_{pred} )\cap SM_{gt}$，</p><p><img src="/posts/59821/PSG.png" alt="PSG"></p><p><img src="/posts/59821/losses.png" alt="losses"></p></li><li><p>BCE等像素级loss的缺点：首先，由于他们只考虑了标签和预测之间的像素级的差异，而没有考虑像素之间的空间关系和依赖，BCEloss不能帮助揭示显著性区域内部像素和背景像素之间的关系，因此会导致模糊的边界和显著性目标内部的一些误检测区域。其次，由于这些loss为前景像素和背景像素赋予了同样的权重，因此使得SOD变成了一个类别不平衡问题（背景像素大多数情况下远多于前景像素），这会使得训练出的模型因为标签分布的偏差而具有偏差先验，会倾向于将未知像素预测为背景，进一步会导致预测出不完整的显著性区域。</p></li></ol><h2 id="《Bifurcated-Backbone-Strategy-for-RGB-D-Salient-Object-Detection》"><a href="#《Bifurcated-Backbone-Strategy-for-RGB-D-Salient-Object-Detection》" class="headerlink" title="《Bifurcated Backbone Strategy for RGB-D Salient Object Detection》"></a>《Bifurcated Backbone Strategy for RGB-D Salient Object Detection》</h2><ol><li><p>设计了一个全新的级联细化网络。</p><p><img src="/posts/59821/BBSNet.png" alt="BBSNet"></p></li><li><p>使用分叉主干策略，将多层次特征重新分组为教师和学生特征，深三层是教师特征，浅三层是学生特征。作者的动机是因为发现教师特征提供的是富有判别性且没有冗余细节的语义信息，可以显著地缓解低维度特征中的干扰信息。</p></li><li><p>GCM模块是RFB模块的改进版，只是多了两个分支，可以更好地拥有全局感受野。PTM是为了渐进地增大第二阶段的解码结果，而非直接进行4倍上采样，这样可以使得结果更精细。</p></li><li><p>引入深度增强模块（depth-enhanced module，DEM），从通道和空间角度挖掘深度模态的信息线索，以更好地融合RGB特征和深度特征。该模块由一个通道注意力和一个空间注意力组成，通道注意力是将特征图的每个通道进行全局最大池化之后送入多层感知机，然后将感知机的输出作为通道权重和输入特征图相乘。空间注意力是将特征图的每个点沿着通道维度进行全局最大池化，进行卷积之后作为每个像素点的权重和输入特征图相乘。</p></li><li><p>深度模态和RGB模态的提取器并不共享权重，这是因为两种模态有着很大的差异。因此作者设计了深度适应模块来考虑两种模态的不同，使得二者可以使用同一个特征提取器而不会有很大的性能下降。</p><p><img src="/posts/59821/DAM.png" alt="DAM"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly_paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> weekly_paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Signature Transforms</title>
      <link href="/posts/38271.html"/>
      <url>/posts/38271.html</url>
      
        <content type="html"><![CDATA[<h1 id="Deep-Signature-Transforms"><a href="#Deep-Signature-Transforms" class="headerlink" title="Deep Signature Transforms"></a>Deep Signature Transforms</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>这是2019年的工作，提出了一种新颖的方法，可以将签名变换的优点和现代深度学习框架相结合，这样就可以将具有强大数学理论基础的签名变换和具有巨大经验成功的神经网络相结合，得到更好的效果。</li><li>路径举例：特定位置的气压变化可以被认为是 R 中的一条路径； 笔在纸上的运动可以被认为是 $R^2$ 中的一条路径； 金融市场的变化可能被认为是 $R^d$ 中的一条路径，d 可能非常大。</li><li>路径签名：路径的统计量（从0阶到无穷阶）的集合。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>整体思路：通过在签名转换之前学习流的扩充，可以以数据相关的方式选择签名的项。思路流程：以往的工作往往使用深度为n的截断签名，即取0~n阶的路径积分构成的集合作为路径签名，但是这存在一个问题——如果要学习的函数需要依赖于更高阶的路径积分，那么关键的信息就丢失了。其解决方法是在<strong>取签名之前对数据流的每一个点做增强</strong>，例如将x映射为f(x)，然后对f(x)取签名。于是关键问题就变成了如何选取这个映射f(x)，一个自然的想法就是扔进网络里学一个选择出来。但是将签名转换作为神经网络的一个层的明显问题是：该层接收数据流作为输入，返回的却是没有明显的像数据流一样性质的统计量。其解决方法是<strong>将输入流提升为流的流</strong>，例如对于序列（$x_1,\cdots,x_n$），可以提升为新序列[$(x_1,x_2),\cdots,(x_1,x_2,\cdots,x_n)$]，这样再使用签名变换，便可以得到序列[$sig^N(x_1,x_2),\cdots,sig^N(x_1,\cdots,x_n)$]。</p></li><li><p>作者描述了如何将签名变换用作可以放在神经网络中任何地方的一个层。<strong>我们可以将其理解为一种池化操作</strong>。签名变换层的输入是一个（b,d,n）的tensor，b是batch_size，d是路径的维度，n是路径被采样的次数；其输出是（b，$(d^{N+1}-1)&#x2F;(d-1)$），N是截断深度。其中有公式：<br>$$<br>num&#x3D;\frac{d^{N+1}-1}{d-1}<br>$$<br>显然，这是一个首项为1的等比数列的求和公式。举一个例子，对于一条三维的路径X，其d&#x3D;3，我们取截断深度为3。那么其路径签名应该有$3^0+3^1+3^2+3^3&#x3D;40$项。而将d和N代入公式也有num&#x3D;40项。因此上述公式描述了一个维度为d的路径，在截断深度为N的情况下，其路径签名中的项的数目。</p></li><li><p>两种常见的签名神经网络架构如下图所示：</p><p><img src="/posts/38271/simple_architecture.png" alt="simple_architecture"></p><p>它们分别代表着直接对数据提取路径签名以及先对数据进行增强，然后再对增强后的数据取路径签名。我们要求这种增强必须能够保留数据的流式性质。于是，又有两种方法：</p><p><img src="/posts/38271/stream_preserving.png" alt="stream_preserving"></p><p>第一种方法是直接对每个点做增强，第二种方法是类似卷积核的滑动过程，对固定长度个数据进行滑动增强。</p><p>除了增强要能保留数据的流式性质之外，还应该保证取签名之后的结果也应当保留有流式性质。其解决方法一如我们在创新1中所说的，将输入流提升为流的流即可，具体方案则有许多：比如创新1中提到的方法，以及下图中的两种方法：</p><p><img src="/posts/38271/signature_stream_preserving.png" alt="signature_stream_preserving"></p></li><li><p>借助3中的手段，我们可以在网络中使用任意多个签名层，其示意图如下图所示：</p><p><img src="/posts/38271/deep_signature_model.png" alt="deep_signature_model"></p></li><li><p>签名变换的反演变换。</p><p><img src="/posts/38271/inversion_transformation.png" alt="inversion_transformation"></p></li><li><p>三种应用举例</p><p><img src="/posts/38271/generative_model.png" alt="generative_model"></p><p><img src="/posts/38271/recurrent_model.png" alt="recurrent_model"></p><p><img src="/posts/38271/residual_model.png" alt="residual_model"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Path Signature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Path Signature </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Path Signature Neural Network of Cortical Features for Prediction of Infant Cognitive Scores</title>
      <link href="/posts/22755.html"/>
      <url>/posts/22755.html</url>
      
        <content type="html"><![CDATA[<h1 id="Path-Signature-Neural-Network-of-Cortical-Features-for-Prediction-of-Infant-Cognitive-Scores"><a href="#Path-Signature-Neural-Network-of-Cortical-Features-for-Prediction-of-Infant-Cognitive-Scores" class="headerlink" title="Path Signature Neural Network of Cortical Features for Prediction of Infant Cognitive Scores"></a>Path Signature Neural Network of Cortical Features for Prediction of Infant Cognitive Scores</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li><p>在婴儿时期，认知技能和大脑形态之间有着紧密的联系。但是，考虑到特征维度过多、样本量小、数据缺失等问题，利用个体的大脑形态学特征来预测个体的认知得分仍然是一个巨大的挑战。</p></li><li><p>在实际应用中，数据采集过程中的小样本量(SSS)和不同时间点的数据缺失是不可避免的。由于数据有限，一个紧凑但富有表达性的特征集是我们急需的，因为它可以减少维数并避免潜在的过拟合问题。因此，作者率先采用路径签名的方法，进一步探索纵向皮层特征的基本隐藏动态模式。</p></li><li><p>关于路径签名：</p><p>总的来说：<strong>路径的签名是包含许多代数和解析性质的流数据的有效特征集</strong>。</p><p><img src="/posts/22755/path_signature.png" alt="path_signature"></p><p>而在实际应用中，对于更常见的离散时间序列，可以通过线性插值嵌入到路径空间中。嵌入路径的对应签名可以通过陈氏恒等式进行计算：<br>$$<br>Sig(X) _ {a,b}^{i_1,i_2,\cdots,i_l}&#x3D;\frac{1}{l!}\prod_{j&#x3D;1}^l (X_b^{i_j}-X_a^{i_j} )<br>$$<br>在这篇论文中，作者将路径X解释为从纵向MRI扫描中提取的大脑区域的生长轨迹。值得注意的是，生长轨迹的第一次迭代积分是生物测量量的变化，而第二次迭代积分的线性组合：$0.5(Sig(X) _ {a,b}^{i_1,i_2}-Sig(X) _ {a,b}^{i_2,i_1} )$，等于曲线$(X^{i_1}，X^{i_2} )$和连接起点和终点的弦包围的面积，可以用来评估生长轨迹的曲率。</p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>根据大脑皮层特征，使用路径签名神经网络来预测婴儿认知得分。 先从0-48个月的时间点中选取9个时间点的大脑MR扫描图像作为输入；然后送入婴儿MRI计算管道之中去提取7个大脑皮层的形态学测量值；接着将大脑皮层分成70个具有解剖学意义的感兴趣区域（ROIs），并提取70$\times$7（区域数量$\times$每个区域的特征表示）大小的特征图，并将这些特征图沿着时间轴进行连接得到动态皮层特征图；由于数据之中存在缺失的问题，因此作者使用了一种插值的方法，通过最近的两次数据插值出缺失的数据，其公式为：$t^n_i&#x3D;t^n_j+(t_i-t_j)*\frac{t^n_j-t^n_k}{t_j-t_k}$；最后将处理好的数据送入CF-PSNet以得到最后的结果。</p><p><img src="/posts/22755/architecture.png" alt="architecture"></p></li><li><p>为了形成一种层次化并且信息更丰富的时间表示，提出了一种基于皮层特征的路径签名神经网络( Cortical Feature based PSNet，CF-PSNet)，该网络通过堆叠可微时间路径签名层，来预测个体认知得分。首先，考虑到SSS问题，作者使用单层非线性映射和top k选择模块进行特征冗余去除和大脑区域选择。</p><p><img src="/posts/22755/CF-PSNet.png" alt="CF-PSNet"></p></li><li><p>通过在路径生成中引入存在性嵌入（第一层TPS中，用于指示缺失的访问），可以提高对缺失数据的鲁棒性，消除由插值引起的模糊和伪影。</p></li><li><p>由于不需要整个大脑来为某个认知能力工作，作者使用了一个top K选择模块来选择最具影响力的脑区域，这样可以减小模型的大小，并降低过拟合的风险。如下图所示，将每个脑区域的特征压平成一个36维的特征向量，然后送入全连接层生成70个标量作为每个脑区域的影响力系数，从这些系数中选取前K个最大的，将他们对应的特征向量与系数相乘并送入下面的层中。</p><p><img src="/posts/22755/top_k_selection.png" alt="top_k_selection"></p></li><li><p>时间路径签名层（Temporal Path Signature Layer，TPS）。对于每个TPS层，K条路径分别对应K个最具影响力的脑区域。接着，类似CNN中那样，使用窗口滑动操作，可以得到$T^i&#x3D;T^{i-1}+1-W$条子路径来探索局部时间属性。</p><p><img src="/posts/22755/path.png" alt="path"></p></li><li><p>使用组全连接层的多流神经网络。多流神经网络会在不同流中分别处理原始特征和多尺度时间PS特征，使用组全连接层是为了将在时域上共享相同感受野的特征视为一个组。如图所示，如果将滑动窗口的大小设置为5，那么三个流的组数分别是9、5、1。这个类似于cv中的两次卷积，区别在于卷积是空间感受野的缩放，这里是时间感受野的缩放。</p><p><img src="/posts/22755/PS_extraction.png" alt="PS_extraction"></p></li><li><p>提出了注意力mask生成器，在相应的发展阶段给予不同的大脑皮层区域不同的权重。下图中的分组全连接应当是9个40$\times$16的矩阵，作者将其取出之后在每一个ROI内进行求和，得到注意力mask。</p><p><img src="/posts/22755/attention_mask_generator.png" alt="attention_mask_generator"></p></li><li><p>LOSS。损失函数定义如下：<br>$$<br>Loss(y,\hat{y},Y)&#x3D;\lambda\sum_{t&#x3D;1}^9|Y-y_t|+|Y-y|<br>$$<br>其中Y是出生后48个月的认知量表，y是预测的认知分数，$\hat{y}$是图7中的中间输出。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>多种指标。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Path Signature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Path Signature </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Primer on the Signature Method in Machine Learning</title>
      <link href="/posts/2710.html"/>
      <url>/posts/2710.html</url>
      
        <content type="html"><![CDATA[<h1 id="A-Primer-on-the-Signature-Method-in-Machine-Learning"><a href="#A-Primer-on-the-Signature-Method-in-Machine-Learning" class="headerlink" title="A Primer on the Signature Method in Machine Learning"></a>A Primer on the Signature Method in Machine Learning</h1><h2 id="Path-Signature的基础知识"><a href="#Path-Signature的基础知识" class="headerlink" title="Path Signature的基础知识"></a>Path Signature的基础知识</h2><h3 id="1、path"><a href="#1、path" class="headerlink" title="1、path"></a>1、path</h3><p>path被定义为一个将连续取值区间[a,b]转换到多维空间$R^d$的映射。其最简单的理解就是物体运动的轨迹，假定物体在二维平面上从$t_1$时刻持续运动到$t_2$时刻，每个时刻的位置都可以用一个二维向量表示，这一轨迹就构成了一条path，$X:[t_1,t_2]\to R^2，X_t&#x3D;{X_t^1,X_t^2}$，它的每个维度都表示了物体在对应方向上随时间变化的规律；更一般的path可以被定义为：$X:[a,b]\to R^d，X_t&#x3D;{X_t^1,X_t^2,\cdots,X_t^d},$在实际应用中，我们能够获得的path通常并不是连续的，而是它在取值区间内的不均匀采样，因此我们通常需要进行不同的插值以获得时间上分布均匀且更加密集的path。</p><h3 id="2、path-integral"><a href="#2、path-integral" class="headerlink" title="2、path integral"></a>2、path integral</h3><p>path signature实际上是path的不同阶路径积分（path integral）的集合，我们首先来介绍路径积分。假定存在两个一维path：$X_t,Y_t$，且记$X_t^{‘}&#x3D;\mathrm{d}X_t&#x2F;\mathrm{d}_t$，则我们定义路径积分为：$\int_a^bY_tX_t^{‘}\mathrm{d}t&#x3D;\int_a^bY_t\mathrm{d}X_t$，其意义就是在参变量由a变换至b时$Y_t$对$X_t$的积分，这一形式的路径积分是后续所有阶路径积分的基础。</p><p>path signature有两个重要的性质：</p><ul><li><p>平移不变性。我们对路径X进行平移之后，并不会对路径积分产生任何的影响，数学描述如下：<br>$$<br>\int_a^bY_t\mathrm{d}X_t&#x3D;\int_a^bY_t\mathrm{d}Z_t,Z_t&#x3D;X_t+c<br>$$</p></li><li><p>重参数不变性。路径积分的结果只和$X_t,Y_t$的相对关系有关，与参变量t无关。<br>$$<br>\int_a^bY_t\mathrm{d}X_t&#x3D;\int_{k_1a}^{k_2b}Y_r\mathrm{d}X_r<br>$$<br>其中<br>$$<br>Y_t(X_t)&#x3D;Y_r(X_r),X_t(a)&#x3D;X_r(k_1a),X_t(b)&#x3D;X_r(k_2b)<br>$$</p></li></ul><p>对于一条多维path：$X:[a,b]\to R^d$，首先我们给出其<strong>一阶path integral</strong>的表达式为：<br>$$<br>S(X)^n_{a,t}&#x3D;\int_a^t\mathrm{d}X_c^n,t\in[a,b]<br>$$<br>其中 $Y_t&#x3D;1,X_t&#x3D;X_c^n,X_c^n$ 表示路径X的第n个维度在c时刻的取值。对于一个d维的path，其一阶path signature有d个。由于一阶path signature的积分上限是变化的t，而非定值b，所以实际上$S(X) _ {a,t}^n$也是一个一维path:$X^{‘}:[a,b]\to R^d,X_t^{‘}&#x3D;{S(X) _ {a,t}^n}$，因此我们可以对它再次求取路径积分得到了<strong>二阶path integral</strong>：<br>$$<br>S(X) _ {a,t}^{n,m}&#x3D;\int_a^tS(X) _ {a,c}^n\mathrm{d}X_c^m&#x3D;\int_a^t\int_a^c\mathrm{d}X_s^n\mathrm{d}X_c^m<br>$$<br>显然，二阶PS特征有 $d^2$ 个。以此类推，我们可以得到<strong>k阶path integral</strong>：<br>$$<br>S(X) _ {a,t}^{i_1,\cdots,i_k}&#x3D;\int_{a&lt;t_k&lt;t}\cdots\int_{a&lt;t_1&lt;t_2}\mathrm{d}X_{t_1}^{i_1}\cdots\mathrm{d}X_{t_k}^{i_k}<br>$$</p><h3 id="3、path-signature"><a href="#3、path-signature" class="headerlink" title="3、path signature"></a>3、path signature</h3><p>总的来说path signature（路径签名）是一种从数据中提取属性特征的非参数方法，它捕获了路径的许多重要的解析和几何属性。这种方法通常首先使用多种嵌入算法将数据转化成多维路径，然后去计算总结了数据中包含信息的签名的单个项。因此，一句话进行总结：<strong>签名方法就是将原始数据转换为一组用于机器学习任务的特征的方法</strong>。</p><p>一条路径X的签名，被记为$S(X) _ {a,b}$，是路径X的所有阶路径积分的集合，它被定义为：<br>$$<br>Sig(X) _ {a,b}&#x3D;(1,S(X) _ {a,b}^1,\cdots,S(X) _ {a,b}^d,S(X) _ {a,b}^{1,1},\cdots,S(X) _ {a,b}^{d,d},\cdots)<br>$$<br><img src="/posts/2710/path_integral_exercises.png" alt="path_integral_exercises"></p><h3 id="4、path-signature的动机——Picard-迭代"><a href="#4、path-signature的动机——Picard-迭代" class="headerlink" title="4、path signature的动机——Picard 迭代"></a>4、path signature的动机——Picard 迭代</h3><p>签名方法自然诞生于常微分方程领域，其基石是Picard方法。对于一个一阶常微分方程：<br>$$<br>\frac{dy}{dx}&#x3D;f(x,y), y(x_0)&#x3D;y_0<br>$$<br>Picard方法允许我们用迭代级数的方式来构造该方程的近似解，该方程的积分形式变为：<br>$$<br>y(x)&#x3D;y(x_0)+\int_{x_0}^xf(t,y(t))dt<br>$$<br>如果我们定义一系列的函数$y_k(x)$，其中第一项是常数函数$y_0(x)&#x3D;y(x_0)$，那么我们可以归纳地定义<br>$$<br>y_k(x)&#x3D;y(x_0)+\int_{x_0}^{x}f(t,y_{k-1}(t))dt<br>$$<br>Picard定理表明，在适当的条件下，该微分方程的解由$y(x)&#x3D;\lim_{k\to\infty}y_k(x)$给出。</p><p><img src="/posts/2710/Picard_method.png" alt="Picard_method"></p><p>更一般的，对于$Y_t&#x3D;y+\int_a^tV(Y_s)dX_s$，可以将整个Picard迭代写为如下过程：</p><p><img src="/posts/2710/Picard.png" alt="Picard"></p><p>容易发现上图中的式子中包含了我们之前提到的多阶路径积分，这便促使Terry Lyons提出了路径签名，签名中包含了所有的高阶路径积分，可以用于计算微分方程的近似解。</p><h3 id="5、signature的重要属性"><a href="#5、signature的重要属性" class="headerlink" title="5、signature的重要属性"></a>5、signature的重要属性</h3><ul><li><p>唯一性：任意一个非树状路径均可被其PS唯一确定。</p></li><li><p>平移不变性、旋转不变性：PS与路径的起始位置点无关；某些阶的PS及其组合具有旋转不变性。</p></li><li><p>在时间重参数化下的不变性、在不同时间跨度下的不变性：对采样率、丢失采样点、添加随机噪声等不太敏感。</p><p><img src="/posts/2710/reparametrisations_invariance.png" alt="reparametrisations_invariance"></p></li><li><p>洗牌乘积等效性：使用PS作为特征时，签名中两个低阶项的乘积可以用高阶项的线性组合等效表示，即两个路径积分$S(X) _ {a,b}^{i_1,\cdots,i_k}$和$S(X) _ {a,b}^{j_1,\cdots,j_m}$的乘积可以被路径签名$S(X) _ {a,b}$的高阶项的某个集合之和表示。</p><p><img src="/posts/2710/shuffle_product.png" alt="shuffle_product"></p><p><img src="/posts/2710/shuffle_example.png" alt="shuffle_example"></p><p>证明（以式子1为例）：<br>$$<br>\begin{aligned}<br>左式&amp;&#x3D;S(X) _ {a,b}^1S(X) _ {a,b}^2\\&amp;&#x3D;\int_a^bdX_t^1\int_a^bdX_t^2\\&amp;&#x3D;(X_b^1-X_a^1)(X_b^2-X_a^2)\\&amp;&#x3D;X_b^1X_b^2+X_a^1X_a^2-X_a^1X_b^2-X_b^1X_a^2<br>\end{aligned}<br>$$</p><p>$$<br>\begin{aligned}<br>右式&amp;&#x3D;S(X) _ {a,b}^{1,2}+S(X) _ {a,b}^{2,1}\\&amp;&#x3D;\int_a^b\int_a^{t_2}dX_{t_1}^1dX_{t_2}^2+\int_a^b\int_a^{t_2}dX_{t_1}^2dX_{t_2}^1\\&amp;&#x3D;\int_a^b(X_{t_2}^1-X_a^1)dX_{t_2}^2+\int_a^b(X_{t_2}^2-X_a^2)dX_{t_2}^1\\&amp;&#x3D;\int_a^bX_{t_2}^1dX_{t_2}^2+\int_a^bX_{t_2}^2dX_{t_2}^1-X_a^1(X_b^2-X_a^2)-X_a^2(X_b^1-X_a^1)\\&amp;&#x3D;X_t^1X_t^2|_a^b-X_a^1X_b^2+X_a^1X_a^2-X_a^2X_b^1+X_a^2X_a^1\\&amp;&#x3D;X_b^1X_b^2+X_a^1X_a^2-X_a^1X_b^2-X_b^1X_a^2<br>\end{aligned}<br>$$</p><p>显然，左式&#x3D;右式，命题证毕。</p></li><li><p>陈氏恒等式</p><p>首先定义符号$\otimes$有如下含义：<br>$$<br>e_{i_1}\cdots e_{i_k}\otimes e_{j_1}\cdots e_{j_m}&#x3D;e_{i_1}\cdots e_{i_k}e_{j_1}\cdots e_{j_m}<br>$$<br>在形式幂级数中有（注意：这里的e是formal indeterminates，是一种不定项，可以理解为C中的占位符）：<br>$$<br>(\sum_{k&#x3D;0}^\infty\sum_{i_1,\cdots,i_k\in{1,\cdots,d} }\lambda_{i_1,\cdots,i_k}e_{i_1}\cdots e_{i_k})\otimes(\sum_{k&#x3D;0}^\infty\sum_{i_1,\cdots,i_k\in{1,\cdots,d} }\mu_{i_1,\cdots,i_k}e_{i_1}\cdots e_{i_k})\\&#x3D;\lambda_0\mu_0+\sum_{i&#x3D;1}^d(\lambda_0\mu_i+\lambda_i\mu_0)e_i+\sum_{i,j&#x3D;1}^d(\lambda_0\mu_{i,j}+\lambda_i\mu_j+\lambda_{i,j}\mu_0)e_ie_j+\cdots<br>$$<br>基于此，路径X的签名可以使用形式幂级数来进行表示：<br>$$<br>Sig(X) _ {a,b}&#x3D;\sum _ {k&#x3D;0}^\infty \sum _ {i_1,\cdots,i_k\in{1,\cdots,d} }S(X) _ {a,b}^{i_1,\cdots,i_k}e_{i_1}\cdots e_{i_k}<br>$$</p><p>于是两条路径$X:[a,b]\to R^d$和$Y:[b,c]\to R^d$的拼接$ X \ast Y $的路径签名可以转换成$ \otimes $形式：<br>$$<br>Sig(X \ast Y) _ {a,c}&#x3D;Sig(X) _ {a,b} \otimes Sig(Y) _ {b,c}<br>$$</p></li><li><p>时间翻转</p><p>路径X的签名是反向运行X得到的签名的$\otimes$的倒数。</p><p>定义路径$X:[a,b]\to R^d$的时间反转为路径$\mathop{X}\limits^{\gets}:[a,b]\to R^d$，其中$\mathop{X_t}\limits^{\gets}&#x3D;X_{a+b-t},t\in[a,b]$。则有：<br>$$<br>Sig(X) _ {a,b}\otimes Sig(\mathop{X}\limits^{\gets}) _ {a,b}&#x3D;1<br>$$</p></li><li><p>对数签名</p><p>对数签名是路径签名的一种变换，本质上是形式幂级数的形式对数。对于如下的形式幂级数：<br>$$<br>x&#x3D;\sum_{k&#x3D;0}^\infty\sum_{i_1,\cdots,i_k\in{1,\cdots,d} }\lambda_{i_1,\cdots,i_k}e_{i_1}\cdots e_{i_k}<br>$$<br>其对数形式被定义为：<br>$$<br>log(x)&#x3D;log(\lambda_0)+\sum_{n\ge 1}\frac{(-1)^n}{n}(1-\frac{x}{\lambda_0})^{\otimes n}<br>$$<br>其中$\otimes n$表示关于该乘积的n次幂。类似的，路径X的对数签名的形式幂级数定义为：<br>$$<br>logSig(X) _ {a,b}&#x3D;\sum_{i&#x3D;1}^dS(X) _ {a,b}^ie_i+\sum_{1\le i&lt;j\le d}\frac{1}{2}(S(X) _ {a,b}^{i,j}-S(X) _ {a,b}^{j,i})[e_i,e_j]+\cdots<br>$$<br>其中$[x,y]&#x3D;x\otimes y-y\otimes x$。</p></li></ul><h2 id="Path-Signature的实际应用"><a href="#Path-Signature的实际应用" class="headerlink" title="Path Signature的实际应用"></a>Path Signature的实际应用</h2><p>签名变换的实际应用之一是机器学习算法。正如之前所述，路径签名总结了关于路径的重要信息。当路径由一个顺序的数据流${Xi}$组成时，其签名$S(X)^{ijk\cdots}$的项是数据流的特征的极佳候选项。洗牌积性质允许我们将签名中低阶项的非线性函数表示为签名中高阶项的线性组合。这类似于基函数扩充，自然适用于回归模型的计算。下面就介绍一些具体的例子：</p><h3 id="1、二阶路径签名及二阶对数签名的例子："><a href="#1、二阶路径签名及二阶对数签名的例子：" class="headerlink" title="1、二阶路径签名及二阶对数签名的例子："></a>1、二阶路径签名及二阶对数签名的例子：</h3><p>$$<br>X_i^1&#x3D;{1,3,5,8}\\X_i^2&#x3D;{1,4,2,6}\\t_i&#x3D;{0,1,2,3}<br>$$</p><p>则其二阶路径签名及二阶对数签名为：<br>$$<br>\begin{aligned}<br>Sig(X)&amp;&#x3D;(1,S^{(1)},S^{(2)},S^{(1,1)},S^{(1,2)},S^{(2,1)},S^{(2,2)})\\&amp;&#x3D;(1,7,5,24.5,19,16,12.5)\\log Sig(X)&amp;&#x3D;(S^{(1)},S^{(2)},S^{[1,2]})&#x3D;(7,5,1.5)\\其中S^{[1,2]}&amp;&#x3D;\frac{1}{2}(S^{(1,2)}-S^{(2,1)})<br>\end{aligned}<br>$$<br>以$S^{(1,1)}$为例：<br>$$<br>\begin{aligned}<br>S^{(1,1)}&amp;&#x3D;\int_0^3\int_0^tdX_s^1dX_t^1\\&amp;&#x3D;\int_0^3(X_t^1-1)dX_t^1\\&amp;&#x3D;\frac{(X_t^1)^2}{2}-X_t^1|_0^3\\&amp;&#x3D;(32-8)-(0.5-1)\\&amp;&#x3D;24.5<br>\end{aligned}<br>$$</p><h3 id="2、路径所围绕区域的面积和方向"><a href="#2、路径所围绕区域的面积和方向" class="headerlink" title="2、路径所围绕区域的面积和方向"></a>2、路径所围绕区域的面积和方向</h3><p>对于$S^{(1,2)}$，内层积分是横坐标，外层积分是纵坐标，因此是左图；对于$S^{(2,1)}$内层积分是纵坐标，外层积分是横坐标，因此是右图。</p><p><img src="/posts/2710/direction1.png" alt="direction1"></p><p>可以使用右手螺旋定则判定方向。</p><p><img src="/posts/2710/direction2.png" alt="direction2"></p><h3 id="3、签名方法在机器学习中的应用"><a href="#3、签名方法在机器学习中的应用" class="headerlink" title="3、签名方法在机器学习中的应用"></a>3、签名方法在机器学习中的应用</h3><p>比如用于时间序列分析、处理时间序列中的缺失值等。</p><h3 id="4、近年来的一些进展"><a href="#4、近年来的一些进展" class="headerlink" title="4、近年来的一些进展"></a>4、近年来的一些进展</h3><ul><li><p>从财务数据流的签名中提取信息</p></li><li><p>使用基于粗糙路径的方法对声音进行压缩</p></li><li><p>数字识别</p><p>在图像识别任务中，路径是几何对象的一个很好的候选。比如在手写数字识别任务中，可以将数字看做是连续的路径，然后签名方法就成为了解决分类问题的一个自然的方法。将签名方法和深度神经网络相结合的方法，在ICDAR2013汉字识别大赛中达到了0.9553的准确率。</p></li><li><p>从过去进行学习，预测未来的统计数据，学习一个不断发展的系统</p></li><li><p>MEG扫描中的模式识别</p></li><li><p>学习治疗对双向情感障碍患者行为模式的影响</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Path Signature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Path Signature </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Task Learning as Multi-Objective Optimization</title>
      <link href="/posts/40879.html"/>
      <url>/posts/40879.html</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-Task-Learning-as-Multi-Objective-Optimization"><a href="#Multi-Task-Learning-as-Multi-Objective-Optimization" class="headerlink" title="Multi-Task Learning as Multi-Objective Optimization"></a>Multi-Task Learning as Multi-Objective Optimization</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>多任务学习可以看做是一个多目标优化问题，因为不同的任务可能会互相冲突，需要进行权衡。一个折中的办法是优化一个代理目标函数，让它可以最小化每个任务的loss的线性加权组合；然而这种方法只有在它们不竞争的时候才可以使用。</li><li>以往有许多相关工作是基于梯度的多目标优化，但是他们并不适合直接用于大规模的学习问题，因为它们随着梯度维度的上升和数量的增加变得难以扩展。</li><li>Stein认为，如果要估计高斯随机变量，最好是从所有样本中估计三个或三个以上变量的均值，而不是分别单独进行估计，即使这些高斯变量是相互独立的。这就是Stein悖论，也是探索多任务学习的早期动机。但是MTL 的潜在优势超出了 Stein 悖论的直接含义，因为即便是真实世界中看似无关的任务也因数据共享的过程而存在很强的依赖性。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>明确地将多任务学习转换成多目标优化，总目标是找到帕累托最优解。鉴于背景2，作者提出了多目标损失的上界，并证明了它可以被有效地优化，然后进一步证明了优化这个上界会产生帕累托最优解。</p></li><li><p>基础知识：</p><ul><li><p>如果一个解的损失函数小于等于另一个解的损失函数，那么我们说这个解支配另一个解。</p></li><li><p>如果没有其他解能够支配这个解，那么这个解就是帕累托最优解。</p></li><li><p>由密集的帕累托最优解构成的曲线就是帕累托前沿。</p></li><li><p>作者使用向量值loss定义了MTL的多目标优化公式：<br>$$<br>\min_{\substack{\pmb{\theta}^{sh},\\ \pmb{\theta}^1,\cdots,\pmb{\theta}^T} }\pmb{L}(\pmb{\theta}^{sh},\pmb{\theta}^1,\cdots,\pmb{\theta}^T)&#x3D;\min_{\substack{\pmb{\theta}^{sh},\\ \pmb{\theta}^1,\cdots,\pmb{\theta}^T} }(\pmb{\hat{\mathcal{L} } }^1(\pmb{\theta}^{sh},\pmb{\theta}^1),\cdots,\pmb{\hat{\mathcal{L} } }^T(\pmb{\theta}^{sh},\pmb{\theta}^T))^T<br>$$<br>其中，$\theta^{sh}$和$\theta^t$分别指的是在多个任务之间共享的参数和每个任务所特有的参数。</p></li></ul></li><li><p>多梯度下降算法(MGDA，2012)</p><ul><li><p>关于KKT最优化条件：KKT条件的引入推广了拉格朗日乘数法，拉格朗日乘数法原本只是解决等式约束下的优化问题，而引入KKT条件的拉格朗日乘数法可用于更普遍的有不等式约束的情况。</p></li><li><p>如何将等式约束+不等式约束转换为无约束的简单优化问题：先把不等式约束条件转化为等式约束条件——引入松弛变量(比如在小于等于的约束条件左侧加上一个平方项，将不等式变成等式)，即KKT乘子。再把等式约束转化为无约束优化问题——引入拉格朗日乘子。</p></li><li><p>关于不等式约束优化问题：</p><p>假设我们希望最小化$f(x)$，不等式约束条件为$g(x)\le0$，然后引入松弛变量将不等式转化为等式约束$g(x)+a^2&#x3D;0$。</p><p>约束不等式$g(x)\le0$ 称为**原始可行性(primal feasibility)**，据此我们定义可行域(feasible region) $K&#x3D;{x∈R^n|g(x)\le 0}$。由Lagrange乘数法中对松弛变量a的求导有$2a\lambda&#x3D;0$，分开两种情况讨论：</p><p>(1) $\lambda&#x3D;0,a\ne 0$，这时约束条件是无效的(inactive)，那么$g(x)&lt;0$，最佳解位于 $K$ 的内部，称为内部解(interior solution)；</p><p>(2) $\lambda\ge0,a&#x3D;0$，$\lambda$必定不会小于0，此结论后续会说明，此时约束条件是有效的(active)，$g(x)&#x3D;0$ ，最佳解落在 $K$ 的边界，称为边界解(boundary solution)。</p><p><strong>因为我们希望最小化</strong> f <strong>，梯度</strong> $\nabla f$ <strong>(函数</strong> f <strong>在点</strong> x <strong>的最陡上升方向)应该指向可行域</strong> K <strong>的内部(因为你的最优解最小值是在边界取得的)，但</strong> $\nabla g$ <strong>指向</strong> K <strong>的外部(即</strong> g(x)&gt;0 <strong>的区域(因为你的约束是小于等于0)，因此为了满足拉格朗日数乘法必有</strong>$\lambda \ge0$ **，称为对偶可行性(dual feasibility)**。</p><p>合并两种情形，当有：$\lambda g(x)&#x3D;0$，且在约束起作用时$\lambda&gt;0，g(x)&#x3D;0$，约束不起作用时$\lambda&#x3D;0，g(x)&lt;0$。不论是内部解或边界解， λg(x)&#x3D;0 恒成立，这称之为**互补松弛性(complementary slackness)**。整合上述两种情况，最佳解的必要条件包括拉格朗日函数 $L(x,λ)$ 的定常方程式、原始可行性、对偶可行性，以及互补松弛性：<br>$$<br>\nabla_xL&#x3D;\nabla f+\lambda\nabla g&#x3D;0\\g(x)\le 0\\ \lambda\ge 0\\ \lambda g(x)&#x3D;0.<br>$$</p><p>这些条件合称为Karush-Kuhn-Tucker (KKT)条件。如果我们要最大化 $f(x)$ 且受限于 $g(x)\le 0$ ，那么对偶可行性要改成 $λ\le 0$ 。</p></li><li><p><img src="/posts/40879/KKT.png" alt="KKT"></p><p>对于这个优化问题，如果结果为0则得出满足KKT条件的点；如果不为0则该解决方案给出了改善所有任务的下降方向。因此，最终的MTL算法将是针对特定任务参数的梯度下降，然后求解上图公式，并应用$\sum_{t&#x3D;1}^T\alpha^t\nabla_{\theta^{sh}}$作为共享参数的梯度更新策略。</p></li></ul></li><li><p>解决优化问题</p><ul><li><p>对于两个任务的情况，$\alpha、1-\alpha$分别为两个loss的权重，可以直接计算出解析解。而对于更普遍的多任务情况，可以使用Frank-Wolfe算法求解它。</p></li><li><p>Frank-Wolfe算法：</p><p><img src="/posts/40879/Frank-Wolfe.png" alt="Frank-Wolfe"></p></li><li><p>基于上述FW算法实际上已经可以解决MTL问题，但是并不高效：因为对于每个任务都需要将共享参数进行一次反向传播，这样的冗余重复了多次，降低了算法的运行速度，因此作者再次针对编码器解码器结构提出了更高效的优化，使得其优化了目标的上界，并且只需要反向传播参数一次。由链式法则显然有公式(6)中的上界，其中右式的第一个范数是z关于共享参数的雅克比矩阵。</p><p><img src="/posts/40879/newer.png" alt="newer"></p><p>这个上界有两个很好的属性：首先，对每个任务而言，loss关于z的导数可以在一次反向传播被计算完成；其次，雅克比范数矩阵不是待求权重的函数，因此目标函数中可以将其无视掉，进一步减小计算量。最终，我们的优化问题就变成了下图中的公式。</p><p><img src="/posts/40879/final.png" alt="final"></p></li><li><p>最后，作者证明了一个引理，说明了尽管MGDA-UB是原始优化问题的近似值，但是依旧产生了帕累托最优解。引理和证明过程不做关注。</p></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Multi-Task Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Multi-Task Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rethinking the U-shape Structure for Salient Object Detection</title>
      <link href="/posts/13303.html"/>
      <url>/posts/13303.html</url>
      
        <content type="html"><![CDATA[<h1 id="Rethinking-the-U-shape-Structure-for-Salient-Object-Detection"><a href="#Rethinking-the-U-shape-Structure-for-Salient-Object-Detection" class="headerlink" title="Rethinking the U-shape Structure for Salient Object Detection"></a>Rethinking the U-shape Structure for Salient Object Detection</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>对于现有的U型网络，工作大都集中在增强编码器的特征提取能力和增强解码器的多尺度特征聚合能力上，而忽略了他们之间的连接。</li><li>只要有空间插值就会带来不好的影响。</li><li>感受野的尺寸并不是越多越好，太多的多样性会分散后续层的注意力。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>整体流程。整体采用U型架构，不同点在于使用了CII模块将多尺度信息编码到共享filter，又因为CII的输入特征是多尺度的，因此又使用RGC模块通过自适应地利用与每个不同输入尺度有关的相对全局信息，实现了基本全局语义和局部纹理之间的平衡。</p><p><img src="/posts/13303/architecture.png" alt="architecture"></p></li><li><p>提出了中心化信息交互模块（centralized information interaction，CII），这是一种策略而非固定的模块，其核心思想是不将多尺度信息编码进特征，而是将多尺度信息编码进共享的可学习卷积核中。没有像经典U型网络那样直接将encoder提取的特征传递到decoder，CII使用了一系列相同的信息交互器（所谓相同其实是指参数共享）来与编码在它们中的信息进行交互。</p></li><li><p>提出了相对全局校准模块（relative global calibration module，RGC）。作者本来想使用PPM、ASPP、SE等作为CII中的信息交互器，但是发现效果都不好，于是提出了新模块。它包含两个并行分支，分别负责局部信息保留（左）和相对全局信息压缩（右）。</p></li><li><p>效果对比。</p><p><img src="/posts/13303/comparison.png" alt="comparison"></p></li><li><p>loss。BCELoss+IOULoss是总loss。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>PR、F-measure、S-measure、MAE。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Strip Pooling Rethinking Spatial Pooling for Scene Parsing</title>
      <link href="/posts/29174.html"/>
      <url>/posts/29174.html</url>
      
        <content type="html"><![CDATA[<h1 id="Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing"><a href="#Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing" class="headerlink" title="Strip Pooling Rethinking Spatial Pooling for Scene Parsing"></a>Strip Pooling Rethinking Spatial Pooling for Scene Parsing</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>在像素级预测任务中，空间池化被证明在捕捉长距离上下文信息时是十分有效的。</li><li>提升模型建模长距离依赖的方法有许多：自注意力，非局部模块，但是它们的计算量都太大了；还有空洞卷积，全局池化，金字塔池化，但是它们都使用方形窗口探查输入特征图，在应对多种形态的目标时不够灵活(比如观察柱状物体时会将方形窗口的其他部分的特征引入，形成信息污染)。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>借鉴空间分离卷积的思想，将N$\times$N池化也分离为1$\times$N和N$\times$1池化。这有两个好处：首先，可以捕捉孤立区域的长距离关联；其次，狭窄的核可以在捕捉局部上下文的同时防止不相关区域的信息造成污染。以此为创新点，构建了新的模型——SPNet。</p></li><li><p>引入了一个新的条状池化模块(Strip Pooling Module，SPM)，使得骨干网络可以有效地建模长距离依赖。具体来说，SPM有两条路径，分别关注水平和竖直的空间维度，然后用这两种编码来平衡它自己的权重来进行特征修复。</p><p><img src="/posts/29174/SPM.png" alt="SPM"></p></li><li><p>提出了一个具有多种空间池化作为核心的新的混合池化模块(Mixed Pooling module，MPM)，来在高维语义级别进一步建模长距离依赖。它通过利用具有不同核形状的池化操作来收集内容丰富的上下文信息，以探查具有复杂场景的图像。</p></li><li><p>系统地对比了条状池化和传统空间池化的性能表现。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>mIoU，Pixel Acc。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Pooling, Semantic Segmentation </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pooling, Semantic Segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>F3Net Fusion, Feedback and Focus for Salient Object Detection</title>
      <link href="/posts/61407.html"/>
      <url>/posts/61407.html</url>
      
        <content type="html"><![CDATA[<h1 id="F3Net-Fusion-Feedback-and-Focus-for-Salient-Object-Detection"><a href="#F3Net-Fusion-Feedback-and-Focus-for-Salient-Object-Detection" class="headerlink" title="F3Net Fusion, Feedback and Focus for Salient Object Detection"></a>F3Net Fusion, Feedback and Focus for Salient Object Detection</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>常用的特征融合策略比如加和、拼接，忽视了特征间存在着巨大的差异。</li><li>对于高精度SOD来说还有两个挑战：首先，不同级别的特征有不同的分布特征，高维特征有丰富的语义，但是失去了准确的位置信息，低维特征有丰富的细节，但是充满了背景噪声，如果不精细地控制信息流就会导致噪声或模糊边界的引入，使得性能下降。其次，大多现有方法都使用二元交叉熵作为loss，这是在平等的对待每个像素，但是从直觉上来说，边缘像素应该更富有判别性，应当被赋予更大的权重。</li><li>BCEloss有三个缺点：首先，只关注了像素，没有关注全局结构；其次，图像中的背景占据主导，前景像素会被稀释；最后，它平等的对待每一个像素。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了新的模型——F3Net，其结构如下图所示：</p><p><img src="/posts/61407/architecture.png" alt="architecture"></p></li><li><p>设计了交叉特征模块(cross feature module ，CFM)，其动机是为了消除特征之间的不一致。为了有选择性地聚合多级特征，它没有进行传统的拼接或者加和，而是自适应地选择互补的内容来进行融合，这样可以避免引入太多的冗余信息。CFM通过特征交叉来缓解两种特征之间的差异，并修复两种特征。首先通过像素级乘法获取高级特征和低级特征共有的部分，然后将结果与原始的高级特征和低级特征进行加和，这样的操作可以抑制背景噪声并锐化边界，可以看作是高级特征和低级特征进行了互补的学习。</p></li><li><p>设计了级联反馈解码器(cascaded feedback decoder ，CFD)，其动机是因为高维特征在传播中会有信息损失和信息失真。它使用多阶段的反馈机制，将接近监督的特征引入前一层的输出中来补充它们并消除不同特征之间的差异。直接将最后一个CFM输出的特征图下采样之后跟每一层的特征图相加来修复它们。然后用同样的方式迭代数次来产生令人满意的结果。</p><p><img src="/posts/61407/CFD.png" alt="CFD"></p></li><li><p>设计了像素位置感知loss(pixel position aware ，PPA)。它没有像二元交叉熵一样平等的对待每一个像素，它可以综合像素的局部结构信息来引导网络更关注局部细节，边界像素或者易出错像素会得到更多关注。PPA由加权BCE和加权IoU组成。每个CFD都进行一次监督，每一层也会进行一次监督。</p><p><img src="/posts/61407/wbce.png" alt="wbce"></p><p><img src="/posts/61407/wiou.png" alt="wiou"></p><p><img src="/posts/61407/alpha.png" alt="alpha"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>PR，MAE，F-measure，S-measure，E-measure。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>以往工作表明：低维特征带来了更多的计算代价，但是带来的性能提升却很少。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Feature Integration for Simultaneous Detection of Salient Object, Edge and Skeleton</title>
      <link href="/posts/19228.html"/>
      <url>/posts/19228.html</url>
      
        <content type="html"><![CDATA[<h1 id="Dynamic-Feature-Integration-for-Simultaneous-Detection-of-Salient-Object-Edge-and-Skeleton"><a href="#Dynamic-Feature-Integration-for-Simultaneous-Detection-of-Salient-Object-Edge-and-Skeleton" class="headerlink" title="Dynamic Feature Integration for Simultaneous Detection of Salient Object, Edge and Skeleton"></a>Dynamic Feature Integration for Simultaneous Detection of Salient Object, Edge and Skeleton</h1><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>显著目标检测、边缘检测和骨架提取是三个差异明显的低级的像素级任务。</li><li>以往的联合训练需要数据集支持多种标注。</li><li>储存多个任务各自的预训练模型在移动设备上是不高效且不方便的做法。</li><li>挑战一：如何同时学习多种任务。</li><li>挑战二：如何解决不同任务特征域和优化目标的分歧。</li><li>面对挑战一时，以往工作往往使用一种任务辅助另一种任务，但是作为辅助的任务的性能会被牺牲和忽视。当面对挑战二时，如果待解决的任务是矛盾的，直接使用上述方法往往会失败。</li><li>三个任务都需要多级特征。SOD需要提取同类区域的能力，因此更多依靠高维特征；边界检测意图检测出准确的边界，因此需要更多低维特征来锐化粗糙的边界图；骨架提取更偏爱低中高维信息的恰当组合，借此来检测变化尺度的骨架。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>说明了三种任务共有的相似性，并解释了三种任务是如何被应用在一个统一的框架之中进行端到端训练的。首先使用ResNet50作为特征提取器，conv5中的3$\times$3的膨胀卷积的膨胀比例设置为2，此外在ResNet50的顶部添加了金字塔池化模块来获得更多的全局语义信息。接下来，作者没有人为地固定网络的特征整合策略，而是使用了一系列的动态特征整合模块(dynamic feature integration modules,DFIMs)——六个特征图resize到同样尺度然后进行拼接并送入DFI来动态地选择特征进行融合。接下来再使用任务自适应的注意力模块(task-adaptive attention module,TAM)来智能的为每个任务分配信息，防止网络的倾向性优化(比如只优化SOD，边界任务不管了)。最后将TAM的输出上采样并加和，然后通过1$\times$1卷积来生成最后的预测。</p><p><img src="/posts/19228/architecture.png" alt="architecture"></p></li><li><p>设计了动态特征整合模块(dynamic feature integration modules，DFIM)，它允许每个任务动态地从它们共享的backbone的不同级别选择特征，设计此模块的动机是以往工作证明了不同任务需要的特征是变化极大的，而且往往需要在一个数据集中有多种标注。该网络使用多个不同任务的独立的数据集进行训练，但是更容易遇到不同任务之间所需特征互相冲突的问题因此需要DFIM来解决。backbone中的特征拼接起来之后送入DFI，DFI会先将他们加和，然后使用GAP层来创造一个全局特征(长度为C)。之后对于每个任务，都会将全局特征送入该任务独有的全连接层中，并将通道转换成M个，然后使用softmax函数激活得到概率值，这个概率值被用于选择特征——大于均值的概率不变，小于均值的概率置零，然后将概率与对应的特征值相乘。DFIM模块的示意图如下图所示。</p><p><img src="/posts/19228/DFIM.png" alt="DFIM"></p></li><li><p>设计了一个任务自适应的注意力模块，旨在根据图像内容先验智慧地分配信息给不同的任务。先使用卷积层减少上采样之后加和操作的混淆影响，激活之后再次使用卷积层来映射跨通道信息，接着再次激活得到空间注意力图。这两次卷积的参数在各个任务之间是共享的(这就是在交换信息)。最后，注意力图与特征的乘积作为残差与原特征图加和得到TAM模块的输出。</p></li><li><p>损失函数。对于SOD，使用的是标准的二元交叉熵；对于边缘检测和骨架提取，使用的是平衡二元交叉熵。总的loss就是这三者的加和。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，PR，F-measure，S-measure</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, “Pyramid scene parsing network,” in IEEE Conf. Comput. Vis. Pattern Recog., 2017.</li><li>J.-J. Liu, Q. Hou, M.-M. Cheng, J. Feng, and J. Jiang, “A simple pooling-based design for real-time salient object detection,” in IEEE Conf. Comput. Vis. Pattern Recog., 2019.</li><li>T. Wang, A. Borji, L. Zhang, P. Zhang, and H. Lu, “A stagewise refinement model for detecting salient objects in images,” in Int. Conf. Comput. Vis., 2017, pp. 4019–4028.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence</title>
      <link href="/posts/7443.html"/>
      <url>/posts/7443.html</url>
      
        <content type="html"><![CDATA[<h1 id="Structure-Consistent-Weakly-Supervised-Salient-Object-Detection-with-Local-Saliency-Coherence"><a href="#Structure-Consistent-Weakly-Supervised-Salient-Object-Detection-with-Local-Saliency-Coherence" class="headerlink" title="Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence"></a>Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Yu S ,  Zhang B ,  Xiao J , et al. Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence[C]&#x2F;&#x2F; 2020.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>近年来，稀疏标签一直备受关注。然而弱监督和全监督的SOD方法之间的性能差距是十分巨大的，并且以前的大多数弱监督方法都采用了复杂的训练过程与花哨的设计技巧。</li><li>对于稀疏标签，会有太多的像素是无标签的，只借助稀疏标签很难获得丰富的关于显著性区域的知识。而且由于没有类别信息，因此更难学习到物体结构。</li><li>一个朴素的想法是如果两个像素具有相似的特征或者相邻的位置，它们就会有相似的显著性分数。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>设计了一个单轮的端到端的训练方案，通过未经过前处理、后处理或额外数据监督的草图标注，来进行弱监督的显著目标检测。</p><p><img src="/posts/7443/architecture.png" alt="architecture"></p></li><li><p>提出了局部显著性一致损失函数，根据图像特征和像素距离将标签传播到无标签区域，以便于在没有额外数据监督以及复杂训练过程的前提下预测完整的显著性区域。作者试图借助背景中阐述的朴素想法来标注无标签像素，但是计算图像中每两个点之间的相似性<strong>会引入过多的背景噪声，并且计算量太大</strong>，因此作者在k$\times$k范围内计算参考点及其相邻点的差异。具体的方法是使用高斯核带宽滤波器来计算相似能量，其公式如下：<br>$$<br>L_{lsc}&#x3D;\sum_i\sum_{j\in K_i}F(i,j)D(i,j)<br>$$</p><p>$$<br>F(i,j)&#x3D;\frac{1}{w}exp(-\frac{||P(i)-P(j)||^2}{2\sigma_p^2}-\frac{||I(i)-I(j)||^2}{2\sigma_I^2})<br>$$</p><p>$$<br>D(i,j)&#x3D;|S_i-S_j|<br>$$</p><p>这样就可以使得范围内的相似像素共享一致的显著性分数，还可以将标签传播到每个像素点。</p></li><li><p>设计了一个显著性结构一致损失函数作为自洽(self-consistent)机制，用以确保以相同图像的不同尺寸作为输入得到的显著性图是一致的(可以看作是一种增强模型泛化能力的正则化技术)。其公式可以被写为：<br>$$<br>L_{ssc}&#x3D;\frac{1}{M}\sum_{u,v}\alpha\frac{1-SSIM(S_{u,v}^\Downarrow,S_{u,v}^\downarrow)}{2}+(1-\alpha)|S_{u,v}^\Downarrow-S_{u,v}^\downarrow|<br>$$</p></li><li><p>设计了一个聚合模块(AGGM)，以更好地整合高级特征、低级特征和全局上下文信息，供解码器聚合各种信息。每个AGGM的输入有三个：对应尺度的特征图、上一解码器层的输出以及编码器最高层的输出。如下图所示，AGGM可以学习对三个特征赋予不同的权重，然后跟着一个归一化操作，于是该模块的公式可以被写为：<br>$$<br>f_{out}&#x3D;\frac{w_hf_h+w_gf_g+w_lf_l}{w_h+w_g+w_l}<br>$$<br><img src="/posts/7443/AGGM.png" alt="AGGM"></p></li><li><p>关于损失函数。局部显著性一致损失函数、显著性结构一致损失函数以及部分交叉熵损失函数三者一起作为主loss，用于监督最终预测的显著性图。此外，局部显著性一致损失函数以及部分交叉熵损失函数两者作为辅助loss，在每一个阶段监督中间的低分辨率显著图。其中，部分交叉熵损失是对草图标注中那些被打了标签的像素进行交叉熵的计算。最终，模型的总loss是主loss加三层辅助loss之和。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>PR，MAE，F-measure，E-measure。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Uncertainty Inspired RGB-D Saliency Detection</title>
      <link href="/posts/38050.html"/>
      <url>/posts/38050.html</url>
      
        <content type="html"><![CDATA[<h1 id="Uncertainty-Inspired-RGB-D-Saliency-Detection"><a href="#Uncertainty-Inspired-RGB-D-Saliency-Detection" class="headerlink" title="Uncertainty Inspired RGB-D Saliency Detection"></a>Uncertainty Inspired RGB-D Saliency Detection</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Zhang J ,  Fan D P ,  Dai Y , et al. Uncertainty Inspired RGB-D Saliency Detection[J]. IEEE Transactions on Software Engineering, 2021, PP(99).</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>以往的工作都是将RGB-D SOD作为一个点估计问题，也就是找到一个图像的像素到gt中该像素标签的映射函数。作者认为这样的方法是不适定(ill-posed)的，会无法捕捉数据标注过程中的不确定性。</li><li>对人类视觉感知的研究表明，不同人对显著性目标会有偏向(一个人眼中的前景或许是其他人眼中的背景)，也就是说，显著性目标检测不应该是一个确定的过程，这跟类别感知的任务是不同的。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了一个随机框架，通过学习数据标注过程，将不确定性应用到RGB-D SOD。</p></li><li><p>设计了一个基于编码器-解码器架构的网络作为生成模型，将输入图像和隐式变量映射成显著性预测图。</p></li><li><p>设计了一个推断模型，通过从真实或者近似后验分布中采样来逐步更新隐式变量。</p></li><li><p>推断隐式变量采用了两种方法：使用带有额外编码器的条件变化自编码器来近似隐式变量的后验分布；采用交替反向传播技术，直接从真实后验分布采样隐式变量。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，F-measure，S-measure，E-measure。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>关于不适定(ill-posed)：适定问题(well-posed problem)和不适定问题(ill-posed problem)都是数学领域的术语。前者需满足三个条件，若有一个不满足则称为”ill-posed problem”：<ol><li>解必须存在</li><li>解必须唯一</li><li>解必须稳定(就是根据初始条件发生连续变化，不会跳变)</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Saliency Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Saliency Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UC-Net Uncertainty Inspired RGB-D Saliency Detection via Conditional Variational Autoencoders</title>
      <link href="/posts/58347.html"/>
      <url>/posts/58347.html</url>
      
        <content type="html"><![CDATA[<h1 id="UC-Net-Uncertainty-Inspired-RGB-D-Saliency-Detection-via-Conditional-Variational-Autoencoders"><a href="#UC-Net-Uncertainty-Inspired-RGB-D-Saliency-Detection-via-Conditional-Variational-Autoencoders" class="headerlink" title="UC-Net Uncertainty Inspired RGB-D Saliency Detection via Conditional Variational Autoencoders"></a>UC-Net Uncertainty Inspired RGB-D Saliency Detection via Conditional Variational Autoencoders</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Zhang J ,  Fan D P ,  Dai Y , et al. UC-Net: Uncertainty Inspired RGB-D Saliency Detection via Conditional Variational Autoencoders[C]&#x2F;&#x2F; 2020.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>现存的模型将SOD视作一种点估计任务，使用一条确定的学习流程，得到显著性图。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了第一个使用不确定性来进行RGB-D显著性检测的框架——UCNet。这是一个概率RGB-D显著性检测网络，它通过条件变分自编码器(CVAE)来建模人类标注的不确定性，并通过在隐式空间采样来为每一张输入图像生成多张显著性图(使用迭代隐藏策略，逐步隐藏显著性前景，借此来产生多种显著性预测，最后建模人类标注的多样性和不确定性)。最后，借助显著性一致处理，可以基于这些显著性图来生成最终的显著性预测。</p><p><img src="/posts/58347/architecture.png" alt="architecture"></p></li><li><p>条件变分自编码器。VAE相比AE的进步在于其不再试图学习如何将输入映射为数值编码，而是将输入映射为分布，这样就可以引入不确定性，使得模型更具创造力(例如用标签0和1训练的AE在遇到标签为0.5的情况下可能会不知道如何生成，但是VAE学习到的是分布——即越靠近0，则输出越像某个图像，越靠近1，输出越像另一张图，取0.5时，VAE会同时取到两个分布的交集部分，同时具有两个分布的特征——如满月与新月之间的半月)。CVAE将先验调整为高斯分布，其C，即conditional，指的是其分布的参数随着输入的变化而变化。该AE有三个变量：输入变量x，隐式变量z和输出变量y。对于从高斯分布z|x之中采样得到的隐式变量z来说，y从y|x,z之中生成，于是z的后验公式可以被重新改写为z|x,y。CVAE的loss下所示：<br>$$<br>L_{CVAE}&#x3D;E_{z\sim Q_\phi(z|x,y)}[-logP_\omega (y|x,z)]+D_{KL}(Q_\phi (z|x,y)\parallel P_\theta (z|x))<br>$$<br>其有两个目的，第一项是希望输入和输出的差距尽量小(编码解码不损失有效信息)，第二项是为了避免VAE学习到的分布的σ趋近于0，退化为AE这样的特殊情况，产生类似模式崩溃这样的问题，因此通过计算学习到的正态分布和标准正态分布之间的KL散度(这里应该是关于均值和方差的函数)来反应二者的接近&#x2F;离散程度。</p></li><li><p>设计了隐式网络模块，包含先验网络和后验网络，前者($P_\theta$)将RGB-D输入映射为隐式变量z，后者($Q_\phi$)将输入和gt一起映射为隐式变量。</p><p><img src="/posts/58347/LatentNet.png" alt="LatentNet"></p></li><li><p>迭代隐藏策略，每一组图像会进行三次迭代，每次将显著目标隐藏之后在剩下的目标中寻找显著目标(用已有SOD模型)，这样便可以获得具有多样性和不确定性的显著性目标标注了。</p></li><li><p>设计了一个深度修正网络，它作为一个辅助组件，可以抑制深度图像中的噪声，并产生具有丰富语义和几何信息的深度图像。该模块使用smooth L1 loss和IoU loss之和进行训练</p></li><li><p>设计了一个显著性网络，以RGB图像和修正之后的深度图像作为输入来生成显著性特征图。使用VGG16作为编码器，使用DenseASPP来扩大感受野，其具体结构如下图所示。</p><p><img src="/posts/58347/SaliencyNet.png" alt="SaliencyNet"></p></li><li><p>设计了一个预测网络，使用隐式网络的随机特征和显著性网络的确定特征来产生多样性的显著性预测图。隐式网络可以学习到一个分布($\mu,\sigma$)，然后在其基础上通过在正态分布上重采样一个参数$\eta$来得到抽样样本$z&#x3D;\eta\times\sigma+\mu$，根据z即可获得和显著性网络输出同尺寸的具有随机特征的显著性特征图。两个特征图进行拼接之后，在通道维度进行打乱，防止网络只关注确定的显著性特征。最后便是简单的生成显著性图。在测试阶段，通过对隐式网络的结果进行多次采样，可以生成多种不同的显著性图，然后送入显著性一致模块进行最终的投票。</p><p><img src="/posts/58347/FE.png" alt="FE"></p></li><li><p>设计了一个显著性一致模块(在测试阶段)来模拟多数投票机制来生成最终的显著性预测。</p><p><img src="/posts/58347/test.png" alt="test"></p></li><li><p>总的loss是CVAE的loss、depth的loss以及smooth的loss之和。其中CVAE的loss以及depth的loss已经提及，smooth的loss是基于类间区别类内相似的假设来关注边界进行SOD。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，F-measure，E-measure，S-measure。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>Zhiming Luo, Akshaya Mishra, Andrew Achkar, Justin Eichel, Shaozi Li, and Pierre-Marc Jodoin. Non-Local Deep Features for Salient Object Detection. In IEEE CVPR, 2017.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Uncertainty-Aware Joint Salient Object and Camouflaged Object Detection</title>
      <link href="/posts/49234.html"/>
      <url>/posts/49234.html</url>
      
        <content type="html"><![CDATA[<h1 id="Uncertainty-Aware-Joint-Salient-Object-and-Camouflaged-Object-Detection"><a href="#Uncertainty-Aware-Joint-Salient-Object-and-Camouflaged-Object-Detection" class="headerlink" title="Uncertainty-Aware Joint Salient Object and Camouflaged Object Detection"></a>Uncertainty-Aware Joint Salient Object and Camouflaged Object Detection</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Li A ,  Zhang J ,  Lv Y , et al. Uncertainty-aware Joint Salient Object and Camouflaged Object Detection[C]&#x2F;&#x2F; 2021 IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li><p>SOD——找出一张图像中最显著的目标，COD——找出一张图像中通过伪装隐藏在环境中的目标，两种任务的目标正好是相反的。然而冰天雪地中的北极熊既可以被分为显著目标也可以被分为伪装目标，因此，这两个任务也是部分正相关的，这就符合了多任务学习的基本假设——不同任务之间存在共享的信息。</p><p><img src="/posts/49234/transition.png" alt="transition"></p></li><li><p>作者试图使用对立的信息来同时加强SOD和COD。</p></li><li><p>SOD的不确定性来自于：一个目标在某人眼中是显著的，在另一人眼中是非显著的。COD的不确定性来自于：伪装目标的边界到底在哪里。因此使用对抗性学习来估计这种不确定性。</p><p><img src="/posts/49234/uncertainty.png" alt="uncertainty"></p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><h3 id="模型整体思路"><a href="#模型整体思路" class="headerlink" title="模型整体思路"></a>模型整体思路</h3><p>将COD数据集中的一个简单正样本作为SOD任务的艰难正样本，作为一种对比级别的数据增强，借此来提升SOD模型的鲁棒性。然后使用相似性衡量模块来明确地建模来自两个任务的对立属性。考虑到两个任务标注时的不确定性，又使用对抗性学习网络来实现高阶相似性度量和网络置信度估计。整个模型有两个亮点：<strong>首先使用对立任务进行多任务学习，其次使用GAN来建模不确定性</strong>。</p><p><img src="/posts/49234/architecture.png" alt="architecture"></p><h3 id="数据增强方法"><a href="#数据增强方法" class="headerlink" title="数据增强方法"></a>数据增强方法</h3><p>作者认为COD数据集中同时具有显著性和伪装性的样本都可以作为SOD中的困难正样本，来增加模型的鲁棒性。实际操作是用训练好的SOD模型计算MAE，选400张MAE最小的COD数据集图像随机代替SOD数据集中的400张图像。</p><h3 id="对立属性建模"><a href="#对立属性建模" class="headerlink" title="对立属性建模"></a>对立属性建模</h3><ol><li>引入了第三个数据集(连接建模数据集)——PASCAL VOC2007来实现相似性度量和关注区域的分离。</li><li>ResNet50作为backbone来提取特征(参数不一样)。来自SOD的图像可以提取出自己的显著性特征，来自COD的图像可以提取出自己的伪装特征，来自连接建模数据集的图像分别送入两个backbone同时得到其显著性特征和伪装特征。</li><li>连接建模数据集图像的两种特征同时输入相似性度量模块来判断两种特征的相似性(希望通过这一模块的反馈，让两个backbone分别学会提取显著特征和伪装特征，并捕捉两种任务之间的关系)，其loss为两个向量的余弦相似度。</li></ol><h3 id="不确定性感知的对抗性学习"><a href="#不确定性感知的对抗性学习" class="headerlink" title="不确定性感知的对抗性学习"></a>不确定性感知的对抗性学习</h3><ol><li><p>SOD的不确定性在于显著性的歧义问题(不同人找到的显著目标不同)，COD的不确定性在于标注的困难性(不同人找到的边界不一样)。</p></li><li><p>预测解码器模块：用于产生特定任务的预测。将特定任务的特征与它们对应的低级别特征整合起来产生预测。在这里一共使用了三个注意力模块：一个残差通道注意力模块来提取精细的特征，双注意力模块来有效地融合高级语义信息和低级结构信息来获取初始预测，全部注意力模块来整合特征。</p></li><li><p>置信度估计模块：用于估计每个预测的置信度。由五个卷积层组成的全卷积判别器，对于预测输入希望输出全零矩阵，对于gt输入希望输出全1矩阵。</p></li><li><p>对抗性学习：用于实现鲁棒的模型训练，学习预测解码器模块和置信度估计模块的参数。对于预测解码器模块(生成器)——结构感知loss是加权的交叉熵loss和IoUloss之和，其公式如下所示：<br>$$<br>L_{str}\left(Pred,Y\right)&#x3D;w\times L_{ce}\left(Pred,Y\right)+L_{iou}\left(Pred,Y\right)<br>$$<br>其中$w&#x3D;1+5\times|\left(avg_pool\left(Y\right)-Y\right)|$，$L_{iou}$的定义如下：<br>$$<br>L_{iou}&#x3D;1-\frac{w\times inter+1}{w\times union-w\times inter+1}<br>$$<br>其中，$inter&#x3D;Pred\times Y,union&#x3D;Pred+Y$，</p><p>SOD和COD的结构感知loss具有相同的形式：<br>$$<br>L_{str}^s&#x3D;0.5\times[L_{str}\left(G_{init}\left(F_{\alpha_s}\right),Y^s\right)+L_{str}\left(G_{\beta}\left(F_{\alpha_s}\right),Y^s\right)]\\L_{str}^c&#x3D;0.5\times[L_{str}\left(G_{init}\left(F_{\alpha_c}\right),Y^c\right)+L_{str}\left(G_{\beta}\left(F_{\alpha_c}\right),Y^c\right)]<br>$$<br>对抗loss是交叉熵loss，SOD和COD的对抗loss也具有相同的形式：<br>$$<br>L_{adv}^s&#x3D;L_{ce}\left(D_{\gamma}^f\left(G_\beta\left(F_{\alpha_s}\right)\right),1\right)\\L_{adv}^c&#x3D;L_{ce}\left(D_{\gamma}^f\left(G_\beta\left(F_{\alpha_c}\right)\right),1\right)<br>$$<br>对于置信度估计模块(判别器)，SOD和COD的判别loss也具有相同的形式。<br>$$<br>L_{dis}^s&#x3D;L_{ce}\left(D_\gamma^f\left(G_\beta\left(F_{\alpha_s}\right)\right),0\right)+L_{ce}\left(D_\gamma^f\left(Y^s\right),1\right)\\L_{dis}^c&#x3D;L_{ce}\left(D_\gamma^f\left(G_\beta\left(F_{\alpha_c}\right)\right),0\right)+L_{ce}\left(D_\gamma^f\left(Y^c\right),1\right)<br>$$</p></li><li><p>目标函数：SOD的loss是结构loss和对抗loss之和，COD的loss是结构loss和对抗loss之和，置信度估计模块的loss是两个判别器loss之和。<br>$$<br>L_{sod}&#x3D;L_{str}^s+\lambda_1L_{adv}^s\\L_{cod}&#x3D;L_{str}^c+\lambda_2L_{adv}^c\\L_{conf}&#x3D;L_{dis}^s+L_{dis}^c<br>$$</p></li><li><p>整体训练过程如下图所示：</p><p><img src="/posts/49234/algorithm.png" alt="algorithm"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，F-measure，E-measure，S-measure</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>F3Net，AFNet，CSNet，ITSD。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection, Camouflaged Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection, Camouflaged Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pyramidal Feature Shrinking for Salient Object Detection</title>
      <link href="/posts/41900.html"/>
      <url>/posts/41900.html</url>
      
        <content type="html"><![CDATA[<h1 id="Pyramidal-Feature-Shrinking-for-Salient-Object-Detection"><a href="#Pyramidal-Feature-Shrinking-for-Salient-Object-Detection" class="headerlink" title="Pyramidal Feature Shrinking for Salient Object Detection"></a>Pyramidal Feature Shrinking for Salient Object Detection</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Ma M ,  Xia C ,  Li J . Pyramidal Feature Shrinking for Salient Object Detection[C]&#x2F;&#x2F; National Conference on Artificial Intelligence. 2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>各种各样的特征融合策略极大地提高了SOD的性能。但是现有的融合方式大都对高级语义信息和低级细节信息进行了大跨度的融合，这会引入噪音。</li><li>生物进化有两个特点：只有特性相似的生物才能繁衍后代(生殖隔离)，自然选择会增强合适的基因，筛除不合适的基因。作者以此为灵感提出了PFSNet。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了新的金字塔特征收缩网络(PFSNet)。模型旨在通过逐层收缩的方式将相邻特征结点成对聚合，使聚合后的特征融合有效的细节和语义，并丢弃干扰信息。模型结构图如下所示。</p><p><img src="/posts/41900/architecture.png" alt="architecture"></p></li><li><p>设计了金字塔收缩解码器(pyramidal shrinking decoder，PSD)模块，逐层地收缩相邻特征，拒绝独立特征的融合来防止跳跃特征融合(跳跃连接式的大跨度特征融合)。其整个结构类似一个倒立的金字塔。</p></li><li><p>设计了WCAT模块作为工具模块，用于融合特征。该模块中，使用GAP操作获取通道级的注意力，经过卷积作为权值向量，与拼接好的父母特征相乘，这样就可以让孩子特征继承重要的特征，丢弃不重要的特征。</p></li><li><p>设计了相邻融合(adjacent fusion module，AFM)模块，用于融合成对的相邻特征。可以实现相邻特征之间互相的空间增强，从而动态的加权特征并自适应地融合合适的信息，抑制不合适的信息。AFM模块主要关注父母特征中共享的特征，通过像素级的相乘，可以很容易地提取出他们，用以增强父母特征。</p></li><li><p>设计了尺度感知丰富(scale-aware enrichment module，SEM)模块，是为了获取丰富的尺度信息，并利用膨胀卷积生成多样化的初始特征。</p></li><li><p>总的loss是BCEloss和IoUloss之和。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，F-measure，E-measure</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Residual Learning for Salient Object Detection</title>
      <link href="/posts/56268.html"/>
      <url>/posts/56268.html</url>
      
        <content type="html"><![CDATA[<h1 id="Residual-Learning-for-Salient-Object-Detection"><a href="#Residual-Learning-for-Salient-Object-Detection" class="headerlink" title="Residual Learning for Salient Object Detection"></a>Residual Learning for Salient Object Detection</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Feng M ,  Lu H ,  Yu Y . Residual Learning for Salient Object Detection[J]. IEEE Transactions on Image Processing, 2020, 29:4696-4708.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li><p>很难直接学到富有判别力的特征和卷积核。</p></li><li><p>尺度变换会引入错误或者冗余的值。</p><p><img src="/posts/56268/architecture_comparison.png" alt="architecture_comparison"></p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出新的模型——$R^2Net$。不直接预测显著性图，而是预测显著性图和gt之间的残差。模型有三个部分组成：R-VGG模块，DCPP模块，以及Residual模块。其中R-VGG模块没有什么创新，就是简单的编码器。</p><p><img src="/posts/56268/architecture.png" alt="architecture"></p></li><li><p>膨胀卷积金字塔池化(Dilated Convolutional Pyramid Pooling ，DCPP)。用于生成粗糙预测。考虑到R-VGG提取出的最高层特征图是28的分辨率，为了获取全局信息，在kernel_size&#x3D;3的时候最大膨胀率应当为13——3+(3-1)*(13-1)&#x3D;27。同时为了获取局部信息，还要有低膨胀率的膨胀卷积，于是DCPP设置了四个平行分支，膨胀率分别为1,5,9,13，然后进行拼接，再使用1$\times$1卷积进行特征的融合，并改变通道数，最后送入残差模块部分即可。</p></li><li><p>注意力残差模块(Attentional Residual Modules ，ARMs)。用于学习粗糙预测和gt之间的残差，其motivation是残差比精准预测要好学习。每个ARM模块的输入有三个：DCPP产生的粗糙预测图的rescale，前一个ARM模块产生的残差的上采样，已经对应尺度的R-VGG块的特征图。ARMs分为两种：拼接注意力和截断注意力。拼接注意力类似我们一般的注意力，但是仍旧对边界不敏感，因此，截断注意力的目的就是为了更关注边界像素。截断注意力主要思想是<strong>使用显著性图和翻转的显著性图进行像素级乘法，其motivation在于假设对于显著性图有前景部分概率0.9，背景部分概率0.1，边缘部分0.5，那么其翻转则是0.1,0.9,0.5。分别相乘变为0.09,0.09,0.25。这显然抑制了确定的区域，而更关注不确定的边界部分。之前的翻转是通过进行“1-显著性图”实现的，但是对于当前scale来说，这种对上采样显著性图的翻转操作缺少细节，因此作者使用“1-当前尺度gt”作为新gt来学习这个翻转的显著性图</strong>。</p><p><img src="/posts/56268/ARM.png" alt="ARM"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>PR、maximum F-measure、MAE、S-measure。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>camouflaged object detection</title>
      <link href="/posts/1643.html"/>
      <url>/posts/1643.html</url>
      
        <content type="html"><![CDATA[<h1 id="camouflaged-object-detection"><a href="#camouflaged-object-detection" class="headerlink" title="camouflaged object detection"></a>camouflaged object detection</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] FAN, Deng-Ping, et al. Camouflaged object detection. In: <em>Proceedings of the IEEE&#x2F;CVF conference on computer vision and pattern recognition</em>. 2020. p. 2777-2787.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>伪装目标检测(Camouflaged Object Detection)，与显著目标检测(SOD)一样，虽名为检测，但实际是做了分割的工作。COD的作者范登平在SOD领域也做了许多工作。COD的目标是检测出那些无缝地嵌入他们周围环境里的物体。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>首先提出了新的COD数据集——COD10K，有10000张图片，分为78个类别。每张图像都标注了类别，边界框，目标&#x2F;实例级别，还有抠图级的标签(应该是指像素级的mask)以及挑战属性。</p></li><li><p>提出了新的网络——Search Identification Network(SINet)。其结构如下图所示。模型分为两个大阶段：搜索阶段和识别阶段，前者大致搜索到伪装目标，后者精细地捕捉它。</p><p><img src="/posts/1643/architecture.png" alt="architecture"></p></li><li><p>在搜索阶段中，将特征分为两层低级，一层中级和两层高级。浅两层size相同，直接拼接送入RF模块，深三层采用密集连接的方式分别送入三个RF模块。RF模块可以扩大感受野，其采用了一种类似空间分离卷积+空洞卷积的方式。</p></li><li><p>在识别阶段中，首先使用SA(search attention)模块增强中级特征，它实际上是一个高斯滤波器加一个归一化操作。然后用增强的中级特征再次生成高级特征，并分别送入RF模块。最后使用PDC模块对两个分支(分支一：两个浅层，一个中层，两个深层，产生的是搜索阶段的结果；分支二：增强之后的中层，两个增强中层生成的深层，产生的是识别阶段的结果)进行解码。</p></li><li><p>总的loss是搜索阶段结果和gt的loss与识别阶段结果和gt的loss之和。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE(像素级准确率)，E-measure，S-measure以及weighted F-measure。</li></ul>]]></content>
      
      
      <categories>
          
          <category> camouflaged object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> camouflaged object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SAMNet Stereoscopically Attentive Multi-scale Network for Lightweight Salient Object Detection</title>
      <link href="/posts/33680.html"/>
      <url>/posts/33680.html</url>
      
        <content type="html"><![CDATA[<h1 id="SAMNet-Stereoscopically-Attentive-Multi-scale-Network-for-Lightweight-Salient-Object-Detection"><a href="#SAMNet-Stereoscopically-Attentive-Multi-scale-Network-for-Lightweight-Salient-Object-Detection" class="headerlink" title="SAMNet Stereoscopically Attentive Multi-scale Network for Lightweight Salient Object Detection"></a>SAMNet Stereoscopically Attentive Multi-scale Network for Lightweight Salient Object Detection</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Liu Y ,  Zhang X Y ,  Bian J W , et al. SAMNet: Stereoscopically Attentive Multi-Scale Network for Lightweight Salient Object Detection[J]. IEEE Transactions on Image Processing, 2021, PP(99):1-1.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>SOD模型的效果在提升，但是模型越来越大，不易于部署在移动设备上面。</li><li>SOD同时需要高维语义信息和低维细节信息，因此直接使用类似MobileNet和ShuffleNet的轻量级网络作为backbone是不合适的。</li><li>轻量级SOD模型的关键在于如何在有限的参数下高效地学习多级别、多尺度的的特征，而不是去融合backbone的不同侧链，亦或通过不同尺寸的膨胀卷积来汇总不同尺度的卷积特征。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了极轻量级的网络——SAMNet。对于336$\times$336的输入图像，在TITAN XP上可以达到343fps的速度，而且只有1.33M的参数。整个模型还是类似UNet，前两层使用普通的膨胀深度可分离卷积，后三层使用提出的立体感注意力多尺度模块进行堆叠，在第五层之后使用金字塔池化模块。整体使用深度监督思想，总的loss是五个BCELoss之和，后四层的loss需要乘以系数0.4。</p><p><img src="/posts/33680/architecture.png" alt="architecture"></p></li><li><p>设计了膨胀深度可分离卷积作为基础的卷积操作，它使用不同膨胀比例的膨胀卷积来捕捉多尺度信息，使用深度可分离卷积来减少浮点数操作并减少模型参数量，使用像素级的加和代替通道维度的拼接来显著减少参数量和计算代价。其具体操作是先对图像使用3$\times$3的深度可分离卷积，然后并联的使用某种膨胀比例的空洞卷积，然后对这些并联的分支进行像素级的加和。</p><p><img src="/posts/33680/PPM.png" alt="PPM"></p><p><img src="/posts/33680/depth-wise.png" alt="depth-wise"></p><p><img src="/posts/33680/point-wise.png" alt="point-wise"></p></li><li><p>设计了新颖的立体感注意力多尺度模块。上面的操作中有一个问题：平等地对待每一个分支，这是不合理的，有可能一些分支的信息更重要，一些分支的信息则是纯粹的噪音，因此设计了立体感注意力多尺度模块，来允许每个通道的每个空间位置自适应地调整其权重。上一步获得的加和特征分为两个分支进行处理，一个分支进行GAP，然后使用两层的多层感知机得到通道级注意力，另一个分支先使用1$\times$1卷积将加和特征投影到低维空间，然后使用两个膨胀深度可分离卷积，最后在使用1$\times$1卷积降维得到空间级注意力。将空间注意力和通道注意力扩展到相同尺寸，然后进行像素级相乘，接着对结果使用softmax，得到立体注意力，该注意力与膨胀卷积得到的特征对应相乘，最后进行1$\times$1的卷积并进行残差链接得到SAM模块的输出。</p><p><img src="/posts/33680/SAM.png" alt="SAM"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>F-measure，MAE，weighted F-measure，S-measure，FPS，FLOPS。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>可以同MobileSal网络对比着看下。</li><li>理想的注意力模块应该具有以下功能：<ol><li>由于各通道是独立的，因此最终的注意力也应当具有很强的通道内依赖性。</li><li>最终的注意力应当具有很强的空间级的依赖性。</li><li>注意力的计算应当是十分高效的。</li></ol></li><li>关于卷积和多尺度的一些博文：<ol><li><a href="https://zhuanlan.zhihu.com/p/50369448">总结-空洞卷积(Dilated&#x2F;Atrous Convolution)</a></li><li><a href="https://www.zhihu.com/question/54149221/answer/323880412">如何理解空洞卷积</a></li><li><a href="https://zhuanlan.zhihu.com/p/62261970">语义分割模型之DeepLabv3+</a></li><li><a href="https://www.zhihu.com/question/336310048/answer/758131125">计算机视觉中的多尺度模型都有哪些设计？ - 龙鹏-笔名言有三的回答 - 知乎 </a></li><li><a href="https://zhuanlan.zhihu.com/p/343605155">真正的即插即用！盘点11种CNN网络设计中精巧通用的“小”插件</a></li><li><a href="https://zhuanlan.zhihu.com/p/381839221">一文看尽深度学习中的20种卷积（附源码整理和论文解读）</a></li><li><a href="https://zhuanlan.zhihu.com/p/28749411">变形卷积核、可分离卷积？卷积神经网络中十大拍案叫绝的操作。</a></li><li><a href="https://zhuanlan.zhihu.com/p/92134485">深度可分离卷积</a></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SaliencyGAN Deep Learning Semi-supervised Salient Object Detection in the Fog of IoT</title>
      <link href="/posts/18411.html"/>
      <url>/posts/18411.html</url>
      
        <content type="html"><![CDATA[<h1 id="SaliencyGAN-Deep-Learning-Semi-supervised-Salient-Object-Detection-in-the-Fog-of-IoT"><a href="#SaliencyGAN-Deep-Learning-Semi-supervised-Salient-Object-Detection-in-the-Fog-of-IoT" class="headerlink" title="SaliencyGAN Deep Learning Semi-supervised Salient Object Detection in the Fog of IoT"></a>SaliencyGAN Deep Learning Semi-supervised Salient Object Detection in the Fog of IoT</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Wang C ,  Dong S ,  Zhao X , et al. SaliencyGAN: Deep Learning Semisupervised Salient Object Detection in the Fog of IoT[J]. IEEE Transactions on Industrial Informatics, 2020, 16(4):2667-2676.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>IoT中的边缘设备并不是都拥有足够的算力，导致只能在云端进行推理，然后进行传输，时间代价和传输代价都很大。</li><li>现有的SOD大多数都是全监督的，需要手动进行像素级的标注，虽然也有一些半监督和弱监督的方法，但是性能表现无法和全监督方法比较，而且需要大量的图像级的标注。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了半监督对抗学习的方法，只要标签数据量达到全监督学习的30%，便可以获得同样的性能表现，而且对于模式崩溃更为鲁棒。这是SOD领域第一个半监督方法。SaliencyGAN拥有捕获跨模态数据分布的能力，并且论文中的结果显示其分布捕获能力在小数据集上比vanillaGAN，CycleGAN，WGAN-GP要好。</p></li><li><p>模型在云端进行训练和微调，测试时，在雾设备上进行SOD推理，如果需要进一步的高级任务，再将检测到的显著性内容传输到云端设备进行处理。</p></li><li><p>设计了拼接和互相增强的双GAN架构，并同时优化无监督的GANloss和有监督的分类loss。模型由两个GAN组成，第一个GAN以随机噪声作为输入，经过生成器生成图像，再将生成图像和真实图像送入判别器判断真假。第二个GAN以真实图像的有标签类和无标签类为输入，生成显著性图，然后将显著性图送入判别器判断显著性图来自有标签数据还是无标签数据。其中第一个GAN的判别器和第二个GAN的生成器共享参数，这强迫第一个判别器可以使用输入图像的显著性特征进行判断。</p><p><img src="/posts/18411/architecture.png" alt="architecture"></p></li><li><p>loss一共有五个部分，$G^I$和$D^I$的对抗loss，$G^S$和$D^S$的对抗loss，以及$G^S$的监督loss。$G^I$的对抗loss希望可以使得生成器生成的图像尽量真实，因此该loss分成两个部分：第一部分要求真假图像提取的特征尽量相似，第二部分要求判别器将生成的图像预测为真实图像。$D^I$的对抗loss使用Wasserstein distance，希望可以尽量区分真实图像和生成图像，因此也分为两个部分：第一部分要求判定真实图像为真，生成图像为假，第二部分加入了一个梯度惩罚项，惩罚出一个利普希茨条件，只要梯度不为1就进行惩罚，离1越远惩罚越大。$G^S$的对抗loss希望可以生成难以区分是否有标签的显著性图，因此也分成两部分：第一部分要求有标签数据的显著性图和无标签数据的显著性图提取的特征尽量相似，第二部分要求判别器判定该显著性图来自有标签数据。$D^S$的对抗loss希望可以尽量区分有标签和无标签的显著性图，因此也分成两部分：第一部分判定来自有标签数据的显著性图是来自有标签数据的，第二部分判定来自无标签数据的显著性图是来自无标签数据的。此前四个都可以看作无监督loss，因为他们使用的都是$G^S$预测的显著性图而不是gt，但这样是不够的，我们还需要$G^S$生成的显著性图尽量准确，因此$G^S$的监督loss就是用来做这个的——使得有标签数据和无标签数据生成的显著性图尽量相似，该loss是generalised dice loss。</p></li><li><p>整个算法的流程图如下所示：</p><p><img src="/posts/18411/algorithm.png" alt="algorithm"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，max F-measure，PR曲线</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SalGAN Visual Saliency Prediction with Generative Adversarial Networks</title>
      <link href="/posts/8240.html"/>
      <url>/posts/8240.html</url>
      
        <content type="html"><![CDATA[<h1 id="SalGAN-Visual-Saliency-Prediction-with-Generative-Adversarial-Networks"><a href="#SalGAN-Visual-Saliency-Prediction-with-Generative-Adversarial-Networks" class="headerlink" title="SalGAN Visual Saliency Prediction with Generative Adversarial Networks"></a>SalGAN Visual Saliency Prediction with Generative Adversarial Networks</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Pan J ,  Canton C ,  Mcguinness K , et al. SalGAN: Visual Saliency Prediction with Generative Adversarial Networks[J].  2017.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>这个模型是第一篇提出使用基于对抗性方法来进行显著性预测的模型</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>生成器的编码器部分和VGG一样，只是去掉了最后的池化和全连接层。</p></li><li><p>生成器的解码器部分是倒序的VGG，并使用上采样层代替了池化层。使用ReLU函数作为全部卷积层的激活函数，只有最后的卷积层使用sigmoid进行激活。</p></li><li><p>判别器部分的卷积层使用ReLU作为激活，全连接层使用tanh作为激活，最后一层使用sigmoid作为激活。</p></li><li><p>总的生成器loss分为内容loss——BCEloss以及对抗loss——也是BCEloss。总的判别器loss分为判真loss——BCEloss和判假loss——BCEloss。</p></li><li><p>模型的结构如下所示：</p><p><img src="/posts/8240/architecture.png" alt="architecture"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>IG等</li></ul>]]></content>
      
      
      <categories>
          
          <category> Salient Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Salient Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Salient Object in Clutter</title>
      <link href="/posts/31805.html"/>
      <url>/posts/31805.html</url>
      
        <content type="html"><![CDATA[<h1 id="Salient-Object-in-Clutter"><a href="#Salient-Object-in-Clutter" class="headerlink" title="Salient Object in Clutter"></a>Salient Object in Clutter</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Fan D P ,  Zhang J ,  Xu G , et al. Salient Objects in Clutter[J].  2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li><p>过去的SOD数据集存在一个严重的问题：不切实际地假设每一张图片中都需要包含至少一个清晰且不杂乱的显著性目标，这种设计偏差使得SOTA的模型在现有数据集上测试的时候达到了性能的饱和区——而应用在现实场景中的时候，它们还远不能令人满意。</p></li><li><p>作者认为提高数据集质量获得的模型的性能提升比设计精巧复杂的解码器获得的模型的性能提升更多，因此作者研究了许多数据集增强策略。</p></li><li><p>显著性检测任务分类。</p><p><img src="/posts/31805/taxonomy.png" alt="taxonomy"></p></li><li><p>2015年来的DL-SOD模型总结。</p><p><img src="/posts/31805/summary.png" alt="summary"></p><p><img src="/posts/31805/summary2.png" alt="summary2"></p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li>首先贡献了一个全新的高质量数据集——SOC。该数据集有如下特点：首先，包含有显著性目标和无显著性目标两种图片，且显著性目标分为许多常见的种类。其次，除了目标的类别标注和实例级的gt之外，每张包含显著性目标的图片还标注了图片中包含的富有挑战性的属性(AC-外观改变，BO-大目标,CL-杂乱、前景背景相似,HO-目标的组成部分不相似,MB-运动模糊,OC-遮挡,OV-目标超过图像边界,SC-形状复杂,SO-小目标)。该数据集包含6000张图片，拥有超过80个类别。</li><li>研究了三种数据集增强策略：标签平滑——为了隐式强调突出显著性边界、防止过拟合；随机图像增强——为了使显著性模型适应各种场景；自监督学习——作为正则化策略从小数据集学习。</li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE、max E-measure、S-measure</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li><p>本文和A survey以及An In-Depth Survey三篇论文可以再次回顾，都是很好的综述文章。综述文章和SOTA模型可以一起看，了解各个SOTA模型为什么可以在某个属性上表现良好。</p></li><li><p>SOTA:</p><ol><li><p>traditional（1-5按序排列）：HCCH, RBD, COV, DRFI, WSC</p></li><li><p>DL-based（1-10按序排列）：EGNet, CPDVgg, CVAE, R2Net, DFI, ABP, BAS, CAGVgg, RASNet, LDF</p></li><li><p>整体排名表格如下所示：</p><p><img src="/posts/31805/benchmark.png" alt="benchmark"></p></li><li><p>对于不同属性的排名表格如下所示：</p><p><img src="/posts/31805/attribute_benchmark.png" alt="attribute_benchmark"></p></li></ol></li><li><p>未来方向：</p><p><img src="/posts/31805/direction.png" alt="direction"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Democracy Does Matter：Comprehensive Feature Mining for Co-Salient Object Detection</title>
      <link href="/posts/36376.html"/>
      <url>/posts/36376.html</url>
      
        <content type="html"><![CDATA[<h1 id="Democracy-Does-Matter：Comprehensive-Feature-Mining-for-Co-Salient-Object-Detection"><a href="#Democracy-Does-Matter：Comprehensive-Feature-Mining-for-Co-Salient-Object-Detection" class="headerlink" title="Democracy Does Matter：Comprehensive Feature Mining for Co-Salient Object Detection"></a><strong>Democracy Does Matter：Comprehensive Feature Mining for Co-Salient Object Detection</strong></h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Yu S ,  Xiao J ,  Zhang B , et al. Democracy Does Matter: Comprehensive Feature Mining for Co-Salient Object Detection[J].  2022.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>CoSOD，共显著性目标检测，目标是检测出一组图像中共同存在的显著性目标，最近工作使用的注意力机制和额外信息的效果并不理想。前者一方面获取的共享特征不完整，只能覆盖到一部分内容，另一方面对于复杂场景往往关注到错误的目标区域，而后者过于依赖额外的数据集。</li><li>该工作的目标是使用民主性挖掘全面的共显著特征，并在不引入任何额外信息的情况下减少背景干扰。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>设计了新颖的民主共显著特征挖掘框架(Democratic Co-salient-Feature-Mining framework，DCFM)，其结构如下图所示。</p><p><img src="/posts/36376/architecture.png" alt="architecture"></p></li><li><p>设计了民主原型生成模块( democratic prototype generation module，DPG)，目的是为了生成民主的响应图，作为最终预测的指导。它可以覆盖足够的共显著区域，因此生成的原型包含了完整的共享属性，可以用于引导预测。DPG由三个部分组成：残差块(residual block)——用于增强提取到的特征，种子选择块(seed selection block，SSB)——用于为每张图片中的共显著性目标选择最富有判别力的种子，民主响应块 (democratic response block，DRB)——将选择好的种子和增强特征图相关联，生成响应图，最后，将响应图与增强特征相乘并进行平均，生成原型(包含全面的共显著性特征信息，指导后续预测)。</p><p><img src="/posts/36376/SSB_DRB.png" alt="SSB_DRB"></p></li><li><p>设计了自对比学习模块(self-contrastive learning module，SCL)，目的是为了抑制原型中背景信息的噪声，其中正负对的生成都不依赖于额外的分类信息。将提取的特征分别和label以及1-lable相乘，得到前景和背景对应区域的特征，然后分别计算他们和原型的余弦相似度，我们希望原型和前景区域特征的余弦相似度大，和背景区域特征的余弦相似度小。</p></li><li><p>设计了民主特征增强模块( democratic feature enhancement module，DFE)，目的是为了通过调整注意力值来进一步增强共显著性特征。经观察发现，注意力机制总是趋向于关注有限数目的相关像素，无法包含所有共显著性目标，因此试图放大小的正值来将更多像素纳入考虑，而负的注意力值则无需考虑。整体流程是以原型和响应图作为注意力矩阵，分别和增强特征相乘再相加，得到融合特征，然后将此特征送入DFE做类似自注意力的操作得到最后的特征。</p><p><img src="/posts/36376/DFE.png" alt="DFE"></p></li><li><p>总的loss是IOU_loss和SC_loss(自对比)之和</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>MAE，F-measure，E-measure，S-measure曲线等</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Modifification of Gradient Vector Flow using Directional Contrast for Salient Object Detection</title>
      <link href="/posts/44604.html"/>
      <url>/posts/44604.html</url>
      
        <content type="html"><![CDATA[<h1 id="Modifification-of-Gradient-Vector-Flow-using-Directional-Contrast-for-Salient-Object-Detection"><a href="#Modifification-of-Gradient-Vector-Flow-using-Directional-Contrast-for-Salient-Object-Detection" class="headerlink" title="Modifification of Gradient Vector Flow using Directional Contrast for Salient Object Detection"></a><strong>Modifification of Gradient Vector Flow using Directional Contrast for Salient Object Detection</strong></h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Srivastava G, Srivastava R. Modification of gradient vector flow using directional contrast for salient object detection[J]. IEEE MultiMedia, 2019, 26(4): 7-16.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>MDC：minimum directional contrast，最小方向对比度，是一种先验知识，前景目标将在所有方向都有很高的对比度，而背景对象至少会在一个方向对比度很低，因为它要连接到背景之中，因此前景目标的MDC会比背景目标的高一些。MDC将图像根据每个像素点分为左上、左下、右上、右下四个部分，每个部分的方向对比度是该部分所有像素点的所有channel跟该像素点的对应channel的差的平方的双重求和，该计算可以通过使用integral image的概念在$O(1)$时间内完成(QVGA分辨率下1.5ms即可计算完成)。</li><li>integral image(积分图像)：其原理是将原图像中的像素值转化为其前所有像素值之和，以四个像素为例，则$S’(x,y)&#x3D;S(x-1,y-1)+S(x,y-1)+S(x-1,y)+S(x,y)$，这样的方式计算速度很快。</li><li>GVF：gradient vector flow，梯度向量流，是一种矢量场，该场通过在变分框架中最小化能量泛函而从图像中导出的。其中最小化采用解耦的线性偏微分方程实现。使用这些场进行分割的snakes(也称作active contour model，主动轮廓模型，是指将图像分割问题转换为求解能量泛函最小值的问题的算法)被称为GVF snakes。snake，也就是主动轮廓模型，被定义为一条曲线$y(u)&#x3D;|x(u),y(u)|,u\in[0,1]$，然后通过最小化能量泛函，将这条曲线向显著性目标的边界逼近。关于snake可以参考下面两个网址进行学习：<a href="https://blog.csdn.net/cfan927/article/details/108884457">主动轮廓模型(一)</a>以及<a href="https://blog.csdn.net/cfan927/article/details/109114884">主动轮廓模型(二)</a>。</li><li>二者单独使用都不能得到很好地效果，单独使用GVF不能得到很好地边界，而MDC在前景背景相似时会发生“泄露”现象(比如水面倒影)。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>希望通过背景信息增强显著目标信息，借此来分析场景信息。将MDC(最小方向对比度)的梯度添加到了GVF的能量泛函的数据项中。</p></li><li><p>生成一个边缘图，用于保留图像的边缘特征，但是并非所有边都与我们的任务有关，因此，一些边缘信息需要被删除。边缘图的计算方法如下：首先计算图像的梯度:<br>$$<br>F&#x3D;avg|\nabla I_{ch}|,ch&#x3D;R,G,B<br>$$<br>然后生成边缘图：<br>$$<br>g(i,j)&#x3D;\begin{cases} F(i,j),\text{if F(i,j)&gt;mean(F)} \\ 0,\text{otherwise}\end{cases}<br>$$</p></li><li><p>整体的算法如下图所示：</p><p><img src="/posts/44604/algorithm.png" alt="algorithm"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>F-measure，PR曲线等</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bi-directional Object-Context Prioritization Learning for Saliency Ranking</title>
      <link href="/posts/21086.html"/>
      <url>/posts/21086.html</url>
      
        <content type="html"><![CDATA[<h1 id="Bi-directional-Object-Context-Prioritization-Learning-for-Saliency-Ranking"><a href="#Bi-directional-Object-Context-Prioritization-Learning-for-Saliency-Ranking" class="headerlink" title="Bi-directional Object-Context Prioritization Learning for Saliency Ranking"></a><strong>Bi-directional Object-Context Prioritization Learning for Saliency Ranking</strong></h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Tian X ,  Xu K ,  Yang X , et al. Bi-directional Object-context Prioritization Learning for Saliency Ranking[J].  2022.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>显著性排名任务用于研究这样一种视觉行为：人类根据场景中物体显著性的不同而转移注意力。</li><li>现有方法都遵循基于目标的注意力，但其实人类还有空间注意力机制，在识别过程中会从一个区域移动到另一个区域。</li><li>以往的注意力机制常常强调富有鉴别力的特征同时抑制来自其他通道的特征，但是这样的手段对于显著性排序来说是不合适的，因为这些鉴别力低的特征或许在排序上有意义(比如是联系两个物体的上下文)。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出双向的基于目标上下文的优先次序学习方法。使用基于查询的目标检测方法提取全局特征，并生成一系列目标特征。然后将它们送入SOS和OCOR模块，最后学习目标的优先次序知识。</p><p><img src="/posts/21086/architecture.png" alt="architecture"></p></li><li><p>提出了目标显著性选择模块(selective object saliency，SOS)，通过推断显著性目标的语义表征来建模基于目标的注意力机制。该模块希望可以捕捉和增强显著目标的语义表征，以往的工作显示了深度特征的不同通道对不同的语义成分有响应，因此要对channel维度做研究。基于背景3，先要使用全局协方差池化来学习物体表示以及他们跟局部和全局上下文的关联，其次学习了一组动态校正函数，基于高阶特征统计量的计算来对通道重新分配注意力。这样该模块就可以学习到细粒度的目标特征表示。在全局协方差池化中，对上下文特征使用ROIAlign提取目标特征，然后将目标特征沿通道维度分割([C,H,W]的特征变成W$\times$H个C维的特征)，最后通过如下公式计算协方差归一化矩阵及其全局协方差池化：<br>$$<br>\mathcal M&#x3D;\left(\frac{1}{K}\sum_{k&#x3D;1}^{K}\left(\mathcal F_{obj}^k-\mu\right) \left(\mathcal F_{obj}^k-\mu\right)^T\right)^\alpha<br>$$</p><p>$$<br>S_C&#x3D;\mathcal{GCP}(\mathcal{M_C})&#x3D;\frac{1}{C}\sum_{c&#x3D;1}^C\mathcal{M_C},其中\mathcal{S}&#x3D;[S_1,S2,\cdots,S_C]就是通道维度的高阶统计量。<br>$$</p><p>接着，通过如下方式实现对特征的校正即可。</p><p><img src="/posts/21086/equation.png" alt="equation"></p><p><img src="/posts/21086/sos.png" alt="sos"></p></li><li><p>提出目标上下文目标关联模块(object-context-object relation，OCOR)，通过同时建模目标-上下文和上下文-目标交互来确定显著性排名。将SOS模块产生的N个对象特征分别和上下文特征进行拼接，得到一系列的对象-上下文关系。在此基础上，使用线性投影来计算不同对象-上下文关系之间的远程相互作用。</p><p><img src="/posts/21086/ocor.png" alt="ocor"></p></li><li><p>最后就是学习显著性排名。这是一个多阶段的基于查询的检测过程，其优点在于框、查询对象以及对应的目标特征可以逐阶段的改善。每个阶段又分为三个子任务。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>SOR，SA-SOR，MAE等</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>Md Amirul Islam, Mahmoud Kalash, and Neil DB Bruce. Revisiting salient object detection: Simultaneous detection, ranking, and subitizing of multiple salient objects. In <em>CVPR</em>, 2018.</li><li>Nian Liu, Long Li, Wangbo Zhao, Junwei Han, and Ling Shao. Instance-level relative saliency ranking with graph reasoning. <em>TPAMI</em>, 2021.</li><li>Avishek Siris, Jianbo Jiao, Gary KL Tam, Xianghua Xie, and Rynson WH Lau. Inferring attention shift ranks of objects for image saliency. In <em>CVPR</em>, 2020.</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization</title>
      <link href="/posts/62314.html"/>
      <url>/posts/62314.html</url>
      
        <content type="html"><![CDATA[<h1 id="Generalizable-Cross-modality-Medical-Image-Segmentation-via-Style-Augmentation-and-Dual-Normalization"><a href="#Generalizable-Cross-modality-Medical-Image-Segmentation-via-Style-Augmentation-and-Dual-Normalization" class="headerlink" title="Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization"></a><strong>Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization</strong></h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Zhou Z ,  Qi L ,  Yang X , et al. Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization[J].  2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>训练数据和测试数据之间的分布转变通常会在部署训练好的分割模型期间导致严重的性能退化，这种分布转变可能是因为采集参数的不同，模态的不同亦或成像方法的不同。</li><li>泛化的跨模态分割(指的是给定单一源域，希望可以模拟不可见目标源域可能发生的变化，例如将用MRI训练的模型直接用于分割CT图像)，具有重要的临床意义，是一项很有挑战性的任务。</li><li>当前用于泛化跨模态分割的方法有域自适应(对测试集的要求很高)和域泛化(当前只能接受小的域转变，如cross-center，大的域转变不可以，如cross-modality)，作者希望建立一个域分布变换不敏感的模型。</li><li>在医学图像中，模态差异通常表现为灰度分布差异。IN可以保留不变的表示，BN可以保留富有鉴别力的特征。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出了一种在泛化分割中使用增强后的源相似和源不相似影像的双重归一化模型。首先用非线性变换(贝塞尔曲线)产生源相似和源不相似图像，接着使用基于双重归一化的模型(该模型使用共同的骨干网络，但是使用独立的BN层)，然后使用一种基于风格的选择机制来在测试阶段自动选择合适的路径。模型的整体架构如下图所示。</p><p><img src="/posts/62314/architecture.png" alt="architecture"></p></li><li><p>提出了风格增强模块。由于常见的医学图像模态都使用灰度图像，所以直接想到通过调整灰度值的分布来改变图像的风格。该模块使用<a href="https://blog.csdn.net/xiaozhangcsdn/article/details/98963937">贝塞尔曲线</a>作为单调的非线性变换函数，将每个像素值从旧值映射到新值，且该变换只对前景区域进行。根据控制点位置的不同，分别生成了两个增函数和两个减函数，用增函数生成的新图就是源相似域，用减函数生成的新图就是源不相似域。</p><p>$$<br>B(t)&#x3D;\sum_{i&#x3D;0}^n\binom{n}{i}P_i(1-t)^{n-i}t^i,n&#x3D;3,t\in[0,1]<br>$$<br><img src="/posts/62314/bezier_result.png" alt="bezier_result"></p></li><li><p>提出了基于双重归一化的网络。直接使用BN进行归一化可能会损失域特定的分布信息，导致泛化能力差，因此为了捕捉不同的域分布信息，采用两个不同的BN层来进行归一化，这就是双重归一化(dual-normalization，DN)。</p></li><li><p>提出了基于风格的路径选择模块。DN模块会保留统计参数$\mu_d和\sigma_d$和仿射参数$\gamma_d和\beta_d$，于是某个域的style embedding可以被表示为：$e_d&#x3D;[e_d^1,e_d^2,e_d^3,\dots,e_d^L]&#x3D;[(\mu_d^1,{\sigma_d^1}^2),(\mu_d^2,{\sigma_d^2}^2),(\mu_d^3,{\sigma_d^3}^2),\dots,(\mu_d^L,{\sigma_d^L}^2)]$，其中1到L指的是L个BN层，d指的是某个域。同理，我们可以通过对目标域的样本进行前向传播得到其统计信息，于是可以得到$e_t$，然后通过衡量$e_t和e_d$的距离，我们就可以衡量两个域的相似性，距离的计算公式如下：<br>$$<br>W(e_t^l,e_d^l)&#x3D;{\parallel\mu_t^l-\mu_d^l\parallel}_2^2+{\parallel\sigma_t^l-\sigma_d^l\parallel}_2^2<br>$$</p><p>$$<br>Dist(e_t,e_d)&#x3D;\sum_{l\in{1,2,\dots,L}}W(e_t^l,e_d^l)<br>$$</p><p>当所有距离计算完成后，可以选择和目标域距离最近的源域的style embedding和仿射参数对目标域进行归一化。</p></li><li><p>模型的总loss是$D^{ss}$域上的Dice和$D^{sd}$域上的Dice之和。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>Dice，Hausdorff  Distance</li></ul>]]></content>
      
      
      <categories>
          
          <category> medical image segmentation </category>
          
      </categories>
      
      
        <tags>
            
            <tag> medical image segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pyramid Grafting Network for One-Stage High Resolution Saliency Detection</title>
      <link href="/posts/33337.html"/>
      <url>/posts/33337.html</url>
      
        <content type="html"><![CDATA[<h1 id="Pyramid-Grafting-Network-for-One-Stage-High-Resolution-Saliency-Detection"><a href="#Pyramid-Grafting-Network-for-One-Stage-High-Resolution-Saliency-Detection" class="headerlink" title="Pyramid Grafting Network for One-Stage High Resolution Saliency Detection"></a><strong>Pyramid Grafting Network for One-Stage High Resolution Saliency Detection</strong></h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h2><p>[1] Xie C ,  Xia C ,  Ma M , et al. Pyramid Grafting Network for One-Stage High Resolution Saliency Detection[J].  2022.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a>研究的背景</h2><ol><li>网络的采样深度和感受野之间的矛盾导致为低分辨率输入设计的模型在高分辨率图片上表现一般。此矛盾在于当前多数SOD模型基于编码-解码器架构设计，当输入图像的分辨率增加时，捕获的特征的尺寸也在增加，但由网络决定的模型感受野的大小是固定的，因此可能会无法捕捉全局语义，这是很致命的。</li><li>多阶段高分辨率SOD方法：HRSOD和DHQSOD。</li><li>transformer可以获得更准确的全局语义信息，CNN可以获得更丰富的细节信息。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a>使用的方法（创新点）</h2><ol><li><p>提出金字塔移植网络(pyramid grafting network，PGNet)。使用transformer和CNN骨干网络从不同分辨率图像中独立地提取特征，然后将特征信息从transformer分支移植到CNN分支。整个网络分为三个阶段：swin-transformer解码阶段、移植特征解码阶段和Resnet解码阶段。</p><p><img src="/posts/33337/PGNet.png" alt="PGNet"></p></li><li><p>设计了基于注意力的跨模态移植模块(Cross-Model Grafting Module，CMGM)，使CNN分支可以在解码的过程中，在不同源特征的引导下，更完整地结合碎片化的细节信息。在上图中可以看到，swin的输入尺寸经过了缩小，而S2和R5的尺寸相近，因此在这两个阶段使用CMGM。transformer拥有捕获远距离信息的能力，所以它可以捕获全局语义信息；相反的，CNN在提取局部信息时表现出色。现有的特征融合策略在两种特征都正确或者一个正确一个错误的情况下可以起作用，但是对于两个特征都错误时便无法起效，CMGM便解决了这个问题。其并没有进行像素级加和或乘积亦或拼接，而是重新计算了两个特征之间的像素级的关系，然后再将全局语义信息移植到resnet分支来弥补两种特征共同的错误。模型使用错误图来描述预测结果犯的错，其为gt和预测图之差的绝对值(因此错误图每个像素的值都在0-1之间)，CMGM的有效性也可以通过下图说明。具体而言，先将R5和S2打平到[1，c，H$\times$W]，然后分别进行layer normalization和linear projection，最后矩阵相乘、softmax激活、矩阵相乘、linear projection、卷积即可得到输出。此外Cross Attention Matrix(CAM)由第一次矩阵乘法的结果进行图中的处理获得。</p><p><img src="/posts/33337/errormap.png" alt="errormap"></p><p><img src="/posts/33337/CMGM.png" alt="CMGM"></p></li><li><p>设计了注意力引导损失( Attention Guided Loss，AGL)来明确地监督CMGM生成的注意力矩阵，以此来帮助网络更好地同来自不同模型的注意力进行交互。该loss的目标是让CAM与gt生成的注意力矩阵尽量相似，这是因为显著性特征应该具有较高的相似性。具体来说，先将显著性图打平成行向量和列向量，然后将两个向量进行向量乘法得到注意力矩阵。模型需要从gt、S2的显著性预测图、R5的显著性预测图分别获得一个注意力矩阵$G^a,SP^a,RP^a$，然后可以通过下述公式获得AG loss：<br>$$<br>\ell_{AG}&#x3D;\frac{\sum_{i&#x3D;1}^{H}\sum_{j&#x3D;1}^{W}(1+\beta\omega_{ij})\cdot\ell_{bce}(G^a_{ij},CAM_{ij})}{\sum_{i&#x3D;1}^{H}\sum_{j&#x3D;1}^{W}(1+\beta\omega_{ij})}<br>$$</p><p>$$<br>\omega_{ij}&#x3D;\frac{1}{2}(\mid(G^a_{ij}-RP^a_{ij})\mid+\mid(G^a_{ij}-SP^a_{ij})\mid)+1<br>$$</p><p>其中$\beta$是一个用于调整$\omega$影响的超参数，该权重有两个目的：通过加权缓解被矩阵乘法平方倍放大的正负样本的不均衡问题；以及使网络更关注两个特征共同的错误。最终总的loss定义如下，其中b+i意味着bce loss加iou loss，auxiliary意味着对RP和SP做loss：<br>$$<br>\ell_{total}&#x3D;\ell^P_{b+i}+\ell_{AG}+\frac{1}{8}\ell^{auxiliary}_{b+i}<br>$$</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul><li>F-measure，MAE，S-measure，E-measure，BDE等</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICON论文笔记</title>
      <link href="/posts/40938.html"/>
      <url>/posts/40938.html</url>
      
        <content type="html"><![CDATA[<h1 id="ICON论文笔记"><a href="#ICON论文笔记" class="headerlink" title="ICON论文笔记"></a>ICON论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Zhuge M ,  Fan D P ,  Liu N , et al. Salient Object Detection via Integrity Learning[J].  2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li>SOD有着显著的进步，但是在完整性上还有着不小的差距。关于完整性：在微观上，指的是模型应当突出表示某一显著性目标的所有部分；在宏观上，模型应当发现所给图像中所有的显著性目标。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>提出了完整性认知网络(Integrity Cognition Network，ICON)，它设计了三个重要的组件来学习强完整性的特征。</p><p><img src="/posts/40938/architecture.png" alt="architecture"></p></li><li><p>没有像许多工作一样关注提取特征的判别力，而是提出了多样特征聚合模块(diverse feature aggregation，DFA)来聚合具有多种感受野的特征，并增加特征的多样性。由以往工作可知丰富的感受野可以帮助网络捕捉不同尺寸大小的显著性目标。该模型则更进一步，使用了不同尺寸且不同形状的卷积核，分别解决目标不同大小不同形状的问题。该模块中使用了三种卷积块：非对称卷积、空洞卷积和原始卷积来实现尺寸和形状的多样性——将backbone提取的特征分别使用三个卷积块处理，然后进行拼接。其中非对称卷积分别使用3$\times$3,1$\times$3,3$\times$1的卷积核，然后将三者进行像素级加和。</p><p><img src="/posts/40938/DFA_ICE.png" alt="DFA_ICE"></p></li><li><p>在DFA的基础上提出了完整性通道增强模块(integrity channel enhancement，ICE)来增强特征通道，借此突出显著目标并抑制其他部分。由第一幅图可知，ICE的输入是多个不同尺度的特征图，以三个为例，通过上下采样将三者缩放到统一尺寸，然后进行拼接得到初步融合特征。对其使用L2-Norm、卷积、Layer-Norm、卷积，然后同其本身相乘，即得到最后的融合特征。其效果类似于空间和通道注意力，效果如下所示。</p><p><img src="/posts/40938/effective.png" alt="effective"></p></li><li><p>提出了部分-整体验证方法，来确定部分目标特征和整体目标特征是否有较强的一致性，这样的一致性可以进一步提高每个显著性目标微观级别的完整性。该模块使用了胶囊网络，因为其被证明在建模局部-整体关系上是有效的。在聚合低级胶囊的对象部分来形成高级胶囊的整体表示时，使用了EM routing的方式。初级胶囊由八个姿态向量来构建姿态矩阵，再加上一个激活，便构成了一个胶囊，其中，姿态矩阵表示的是对象的属性，如旋转，大小等等，模长则表示了对象的存在概率。该模块使用EM routing机制来传递信息，具体来说就是根据低级姿态矩阵和学习到的变换矩阵的乘积作为投票(votes),然后根据vote获得高级胶囊。</p><p><img src="/posts/40938/PWV.png" alt="PWV"></p></li><li><p>该模型的loss除了bceloss之外还有IoUloss，此外该模型使用了深度监督机制。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>F-measure，MAE，weighted F-measure，S-measure，E-measure，FNR。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li><p>SOTA：Condinst、PointRend、PiCANet、RAS、AFNet、BASNet、CPD、EGNet、SCRN、F3Net、MINet、ITSD、GateNet、VST。</p></li><li><p>当前技术：多尺度特征融合(如跳跃连接)，上下文建模(如attention)，自顶向下建模，边界引导学习。</p></li><li><p>ACNet: Strengthening the kernel skeletons for powerful cnn via asymmetric convolution</p><p>blocks,</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DetectoRS论文笔记</title>
      <link href="/posts/47125.html"/>
      <url>/posts/47125.html</url>
      
        <content type="html"><![CDATA[<h1 id="DetectoRS论文笔记"><a href="#DetectoRS论文笔记" class="headerlink" title="DetectoRS论文笔记"></a>DetectoRS论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Qiao S ,  Chen L C ,  Yuille A . DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution[J]. arXiv, 2020.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li>小</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li>H</li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>PR曲线，F-measure，MAE。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>Z</li></ul>]]></content>
      
      
      <categories>
          
          <category> object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HarDNet-MSEG论文笔记</title>
      <link href="/posts/13669.html"/>
      <url>/posts/13669.html</url>
      
        <content type="html"><![CDATA[<h1 id="HarDNet-MSEG论文笔记"><a href="#HarDNet-MSEG论文笔记" class="headerlink" title="HarDNet-MSEG论文笔记"></a>HarDNet-MSEG论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] HUANG, Chien-Hsiang; WU, Hung-Yu; LIN, Youn-Long. Hardnet-mseg: a simple encoder-decoder polyp segmentation neural network that achieves over 0.9 mean dice and 86 fps. <em>arXiv preprint arXiv:2101.07172</em>, 2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li>小目标可能漏检，边界分割不清晰，训练成本高，推理时间长。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>HarDNet-MSEG由一个backbone和一个解码器组成，backbone是HarDNet68，解码器是Cascaded Partial Decoder。</p><p><img src="/posts/13669/architecture.png" alt="architecture"></p></li><li><p>HarDNet是DenseNet的改进，它们的区别如下图所示。相比于DenseNet，HarDNet进行了稀疏化链接，如果2^n整除了 k，就让层 k 连接到层 k-2的n次方，其中n是非负整数，且k-2^n≥0。特别的，层0是输入层。在这种连接方案下，一旦第 2^n 层被处理，第 1 层到第 2^n–1 层就可以从内存中清除。此外，HarDNet还加权了关键层：指数被较大的2次方除以的层比指数被较小的2次方除以的层更有影响力。我们通过增加通道来放大这些关键层，这样可以平衡某层的输入和输出之间的通道比。</p><p><img src="/posts/13669/HarDNet.png" alt="HarDNet"></p></li><li><p>使用RFB模块加强了从轻量级网络中学到的深层特征。不同卷积核尺寸的卷积和空洞卷积被用于产生不同感受野的特征，然后使用1$\times$1卷积来合并所有特征。</p><p><img src="/posts/13669/RFB.png" alt="RFB"></p></li><li><p>使用密集聚合的方式代替了原本HarDNet网络中的decoder。</p><p><img src="/posts/13669/Dense_Aggregation.png" alt="Dense_Aggregation"></p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>PR曲线，F-measure，MAE。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>Zhe Wu, Li Su, and Qingming Huang. Cascaded partial decoder for fast and accurate salient object detection.</li><li>Fisher Yu, Dequan Wang, Evan Shelhamer, and Trevor Darrell. Deep layer aggregation.</li><li>Liang-Chieh Chen, Yi Yang, Jiang Wang, Wei Xu, and Alan L Yuille. Attention to scale: Scale-aware semantic image segmentation</li><li>Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei Fang, and Hanqing Lu. Dual attention network for scene segmentation</li><li>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. </li><li>Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroffff, and Hartwig Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation</li><li>Long Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie, Jian Shao, Wei Liu,and Tat-Seng Chua. Sca-cnn: Spatial and channel-wise attention in convolutional networks for image captioning</li><li>Songtao Liu, Di Huang, et al. Receptive fifield block net for accurate and fast object detection.</li><li>ResUNet，ResUNet++，DoubleU-Net，PraNet，ABCNet。</li></ul>]]></content>
      
      
      <categories>
          
          <category> image segmentation </category>
          
      </categories>
      
      
        <tags>
            
            <tag> image segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Detect Salient Object with Multi-source Weak Supervision</title>
      <link href="/posts/50800.html"/>
      <url>/posts/50800.html</url>
      
        <content type="html"><![CDATA[<h1 id="Learning-to-Detect-Salient-Object-with-Multi-source-Weak-Supervision"><a href="#Learning-to-Detect-Salient-Object-with-Multi-source-Weak-Supervision" class="headerlink" title="Learning to Detect Salient Object with Multi-source Weak Supervision"></a>Learning to Detect Salient Object with Multi-source Weak Supervision</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] ZHANG, Hongshuang, et al. Learning to detect salient object with multi-source weak supervision. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li><p>像素级标注的高成本使得基于弱监督学习的显著性目标检测变得引人注目，然而一个弱监督源很难包含足够的信息来训练一个好的模型。</p></li><li><p>像素级别的标注精准但是成本太高；图像级别的分类则太过简单，不能传递足够的信息，使得网络只能突出最富有判别力的区域，而不是整个目标；图像标题用一个短句描述图像的内容，因此比图像级分类标签包含了更多的信息，但是往往会不止描述显著性区域还会描述背景，导致网络还会突出一部分背景。总而言之，这些图像级别的监督往往会导致边界不清晰以及边界一些像素的分类错误。</p><p><img src="/posts/50800/category_caption.png" alt="category_caption"></p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>提出了一个统一的两阶段框架，从类别标签，标题，网络图像和无标签图像中学习。</p><p><img src="/posts/50800/architecture.png" alt="architecture"></p></li><li><p>在第一阶段中，设计了一个分类网络(CNet)和一个标题生成网络(PNet)，分别负责预测目标类别以及生成标题，同时该阶段会突出潜在的前景区域。多标签分类网络CNet由卷积特征提取器(DenseNet，可共享也可单独，差别很小)、注意力模块和一个全连接层组成。特征提取器为输入图像的每个区域提取特征，注意力模块对所有区域使用空间注意力来找到对分类最重要的区域。标题生成网络PNet的结构与CNet相似，只是把全连接层改为了LSTM层，它的注意力模块可以找到对生成标题最重要的区域。此外，提出了一个注意力迁移loss来在网络之间传递监督，提出了一个注意力一致性loss来促使网络能够检测出一般性显著区域而不是特定任务的显著区域。这一阶段中用到的数据集是分类数据集，标题数据集以及无标签数据集。</p><p><img src="/posts/50800/attention.png" alt="attention"></p></li><li><p>由于CNet和PNet都使用图像级别的监督进行训练，因此不能得到清晰的边界，于是在第二阶段中，使用CNet和PNet创造了合成训练数据集。具体来说，除了使用带有噪声标签的自然图像数据集，让显著性预测网络(SNet)适应于自然图像输入以外，还要通过在背景图片上粘贴目标物体来合成图像数据集，送入SNet进行训练，当然，在测试阶段只需要SNet一个模型即可。</p></li><li><p>提出了一种迭代的方法来联合优化模型和数据集。首先将CNet和PNet区分出的前景和背景作为无标签数据集的标签，然后合成图像的标签是显而易见的。SNet会在两个数据集中进行训练并优化模型，然后SNet的预测结果又会反向重构数据集。</p><p><img src="/posts/50800/recurrent.png" alt="recurrent"></p></li><li><p>用分类标签训练时，CNet的loss是分类损失，PNet的loss是注意力迁移loss；用标题进行训练时，Pnet的loss是标题损失，CNet的loss是注意力迁移loss(传递监督信号，用一个网络产生的显著图中的前景和背景去监督另一个网络的显著图)；用无标签数据训练时，loss是注意力一致性loss(泛化学习普通显著区域而非特定任务显著区域，用的是超像素之间的颜色相似度)；CNet和PNet训练好后，用它们生成假的标签(无标签数据上跑CNet和PNet)，并和合成图像(前景贴到背景上，所以有清晰边界)一起用于训练SNet(两个数据集互补，一个真实，一个边界清晰)。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>PR曲线，F-measure，MAE。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>SOTA：<ol><li>Amulet: Aggregating multi-level convolutional features for salient object detection</li><li>Structured modeling of joint deep feature and prediction refifinement for salient object detection</li><li>A mutual learning method for salient object detection with intertwined multi-supervision</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPN与U-Net对比</title>
      <link href="/posts/32507.html"/>
      <url>/posts/32507.html</url>
      
        <content type="html"><![CDATA[<h1 id="FPN与U-Net对比"><a href="#FPN与U-Net对比" class="headerlink" title="FPN与U-Net对比"></a>FPN与U-Net对比</h1><h2 id="相同点："><a href="#相同点：" class="headerlink" title="相同点："></a>相同点：</h2><ul><li>都采用了bottom-up和top-down的结构，并且都采用了横向连接的结构。</li></ul><h2 id="不同点："><a href="#不同点：" class="headerlink" title="不同点："></a>不同点：</h2><ul><li>FPN用于检测任务，U-Net用于分割任务。</li><li>FPN大多作为一个可嵌入的模块嵌入网络，U-Net本身就是网络，可以被其他模块嵌入。</li><li>FPN融合多尺度特征图使用的是像素级的加和之后跟一个1$\times$1的卷积，U-Net采用的是拼接之后跟一个1$\times$1的卷积层。</li><li>FPN对top-down过程中的每个stage都进行了预测，而U-Net只使用了top-down过程中的最后一个stage来进行预测。</li><li>FPN上采样的方式是插值，无需学习，U-Net上采样的方式是deconv，可以学习。</li><li>FPN的高层特征放大2倍后与低层的尺寸恰好一致，而在UNet中通常不一致，还需要对低层特征做crop使得与放大后的高层特征尺寸一致。</li><li>上采样时无论是使用插值还是转置卷积，都无法还原真实的特征值，有一定程度失真。上采样后再做特征融合，就会导致特征产生混叠。从信号学的角度来看，若要还原，可以改变采样频率或者使用滤波器。而卷积本身就是一种滤波器，因此FPN特征融合后就使用卷积对融合后的特征进行处理。而在U-Net中除了对融合特征进行滤波外，还起到了压缩通道的作用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> image segmentation </category>
          
      </categories>
      
      
        <tags>
            
            <tag> image segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobileSal论文笔记</title>
      <link href="/posts/57400.html"/>
      <url>/posts/57400.html</url>
      
        <content type="html"><![CDATA[<h1 id="MobileSal论文笔记"><a href="#MobileSal论文笔记" class="headerlink" title="MobileSal论文笔记"></a>MobileSal论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Wu Y H ,  Liu Y ,  Xu J , et al. MobileSal: Extremely Efficient RGB-D Salient Object Detection[J].  2020.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li>高昂的计算代价阻碍了RGBD SOD在现实世界的应用。因此本文目标是搭建极轻量级的模型。</li><li>像素级的加和或者拼接只能通过平等的对待每个特征来聚合两个特征</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>提出了轻量级模型MobileSal。其只在最粗糙的水平上传导RGB和depth信息来降低计算成本，此外，使用了IDR和CPR模块。整个模块分为RGB流和depth流，RGB流使用MobileNetV2作为backbone，在depth流中，每个阶段使用两个倒残差块(Inverted Residual Blocks，IRB)。每个IRB模块中，通过1$\times$1卷积将通道维度扩张M次，接着使用3$\times$3的深度分离卷积，然后通过另一个1$\times$1卷积压缩通道为原来的1&#x2F;M，最后将得到的结果和初始输入相加即可得到输出，值得注意的是每个卷积操作之后都有一个BN操作。两个流的最后输出进行融合特征，在IDR中，该特征与RGB流的前四层特征联合起来修复深度图，该深度图以输入深度图作为监督，以此增强特征表示能力。</p><p><img src="/posts/57400/architecture.png" alt="architecture"></p></li><li><p>提出了跨模态融合模块(Cross-Modal Fusion，CMF)，RGB特征中包含了很多语义信息，而depth特征可以近似的表示完整物体的形状，因此将深度特征作为门单元，通过乘积来增强RGB图的语义特征。如上图所示，CMF中先将两个特征进行像素级乘积，然后送入IRB模块，同时使用GAP和两个全连接层来计算RGB的注意力向量，最后将注意力向量，特征乘积，深度特征一起送入IRB得到最终的融合特征。</p></li><li><p>提出了隐式深度恢复技术(implicit depth restoration，IDR)，借助深度信息来增强Mobile Network的特征表示能力(该模块仅在训练阶段使用，测试阶段省略，因此实现了推理阶段的计算自由)。IDR的结构很简单，仅仅将前四层的RGB特征和CMF输出的融合特征进行拼接和融合。首先通过1$\times$1卷积来改变五个输入的通道数，然后进行resize并进行通道维度的拼接，再次通过1$\times$1卷积改变通道数之后送入一系列的IRB模块，并在最后通过1$\times$1卷积将结果变为单通道。该结果通过sigmoid和双线性插值可以与深度输入图求SSIM，并用1-SSIM作为loss，来衡量结构相似度。</p><p><img src="/posts/57400/IDR_CPR.png" alt="IDR_CPR"></p></li><li><p>提出了紧凑金字塔改进(compact pyramid refinement，CPR)模块来实现高效的多级特征融合。为了高效性，使用深度分离卷积代替普通卷积，对于输入x，先用1$\times$1卷积改变通道数，然后平行地使用三个膨胀率为1,2,3的深度分离卷积，然后将三者进行像素级加和，接着进行BN，relu，接着使用1$\times$1卷积压缩通道之后与原始输入进行加和，形成一个残差结构。同时，在另一个分支中，使用GAP和两个全连接层以及一个激活函数来得到注意力向量，将二者相乘即可得到输出。</p></li><li><p>解码器的每一个阶段都产生一个由BCE和Dice组成的loss，这五个loss跟IDR的loss一起组成了模型的总loss。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>F-measure，MAE和S-measure</li><li>320$\times$320的输入达到450fps，共6.5M参数</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>SOTA：<ol><li>Uncertainty inspired RGB-D saliency detection</li><li>Siamese network for RGB-D salient object detection and beyond</li><li>Bilateral attention network for rgb-d salient object detection</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>E2Net论文笔记</title>
      <link href="/posts/56341.html"/>
      <url>/posts/56341.html</url>
      
        <content type="html"><![CDATA[<h1 id="E2Net论文笔记"><a href="#E2Net论文笔记" class="headerlink" title="E2Net论文笔记"></a>E2Net论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Tang Y ,  Tang Y ,  Zhu Y , et al. E$^2$Net: An Edge Enhanced Network for Accurate Liver and Tumor Segmentation on CT Scans[C]&#x2F;&#x2F; 2020.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li>3D模型计算代价很大，而且相比2D模型存在重采样问题。例如LiTS数据集中切片厚度从0.45~6.0mm变化，不利于分割，因此一种解决方案是在训练时将扫描结果采样到一个固定的厚度，但是那些小于此厚度的片会丢失重要的片间信息，同时那些厚于此厚度的片又会引入额外的误差。</li><li>使用边缘作为监督时，边缘像素和其他像素严重不平衡，会阻碍模型学习具有鉴别力的特征。以往工作使用加权loss来缓解这个问题。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>提出了一种两阶段的肝脏及肿瘤分割框架。第一阶段粗糙地分割肝脏，使用Res2Net作为backbone，并采用类似UNet的架构，此阶段使用的模型叫做R2UNet。第二阶段是一个边界增强网络，用于进行更准确的肝脏及肿瘤分割，其根据第一阶段的分割结果对原始图片进行剪切，然后将剪切后的图片作为输入。</p><p><img src="/posts/56341/overview.png" alt="overview"></p></li><li><p>设计边缘预测模块作为额外的分支来为分割分支提供互补信息，其架构也是R2UNet。</p><p><img src="/posts/56341/architecture.png" alt="architecture"></p></li><li><p>设计了一个肝脏和肿瘤边界之间的边界距离图，用于作为一个额外的监督信号来训练网络。如背景所述，边界像素和其他像素的严重不平衡导致难以学习到高鉴别力的特征，此模块便是为了解决这个问题而设计的。首先，通过对边缘图像进行距离变换(distance transformation，每个像素的值表示该点到最近背景点的距离)得到一个距离图，然后将其和二值的mask相乘，并归一化到[0,1]之间，最后用1减去标准化之后的距离图作为监督，其中越靠近边缘的像素就拥有越大的值（这是因为解决越靠近边缘越难分割的问题）。</p></li><li><p>设计了一个深度交叉特征融合模块(DCFF)，用于精细化多尺度特征并交互边界特征和分割特征。此模块的设计是基于一种观察：相比于边界特征图，分割特征图$\times$边界特征图可以通过抑制非边缘区域来更好地表示边缘，相比于分割特征图，分割特征图+边界特征图可以通过抑制背景特征来更好地代表肝脏或中流区域。DCFF模块中，一个分支某个尺度的特征图会由另一个分支中所有大于等于此尺度的特征图进行精细化。例如$F_1^1$的精细化结果由$F_1^1,F_2^1,F_2^2,……,F_2^5$共同得到，使用F2改进F1时，要将F1下采样到F2的尺寸然后拼接，接着进行一系列的拼接卷积上采样，最后和F1直接加和得到改进的结果。使用F1改进F2的时候，只需要将拼接操作改为乘积即可。</p></li><li><p>模型的分割分支和边界预测分支的loss都是bce，但是bce只有像素级损失，因此还添加了IOU作为全局结构的损失。于是第一阶段的总loss就是bce和iou的和，第二阶段的总loss则有五项：分割的bce和iou，融合的bce和iou，以及边界的bce。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>Dice per case score、global Dice score以及RMSE</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>LiTS和3DIRCADb数据集，The liver tumor segmentation benchmark(LiTS)，3D image reconstruction for comparison of algorithm database: a patient-specifific anatomical and medical image database</li><li>Automatic liver lesion segmentation using a deep convolutional neural network method</li><li>H-DenseUNet: hybrid densely connected UNet for liver and tumor segmentation from CT volumes</li><li>Automatic liver tumor segmentation in ct with fully convolutional neural networks and object-based postprocessing</li><li>Liver lesion segmentation informed by joint liver segmentation</li><li>Volumetric attention for 3d medical image segmentation and detection</li><li>Res2Net效果比resnet效果好，Res2Net+UNet&#x3D;R2UNet</li></ul>]]></content>
      
      
      <categories>
          
          <category> image segmentation </category>
          
      </categories>
      
      
        <tags>
            
            <tag> image segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>U2Net论文笔记</title>
      <link href="/posts/6424.html"/>
      <url>/posts/6424.html</url>
      
        <content type="html"><![CDATA[<h1 id="U2Net论文笔记"><a href="#U2Net论文笔记" class="headerlink" title="U2Net论文笔记"></a>U2Net论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Qin X ,  Zhang Z ,  Huang C , et al. U2-Net: Going deeper with nested U-structure for salient object detection[J]. Pattern Recognition, 2020, 106:107404.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li><p>以往的工作都使用在ImageNet上为图像分类而训练的backbone作为特征提取器。</p></li><li><p>以往的SOD模型过于复杂，一部分是因为添加了额外的特征聚合模块来从backbone中提取多级特征，一部分是因为现有的backbone通常通过牺牲高分辨率来换取更深的网络结构。</p></li><li><p>当前工作集中于多级特征集成和多尺度特征提取两个任务。</p></li><li><p>局部和全局特征都很重要，小核滤波在浅层无法捕捉全局特征，因此为了获取全局特征，最直接的想法就是在深层扩大感受野（例如使用空洞卷积），但是多次的空洞卷积代价太大。</p><p><img src="/posts/6424/convolution_blocks.png" alt="convolution_blocks"></p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>设计了两级嵌套U型架构的新模型——U2Net。该模型无需使用预训练网络作为backbone，而是从头开始进行训练。在底层，新颖的RSU块可以在不降低特征分辨率的同时提取阶段内的多尺度特征；在顶层，有一个类似U-Net的结构，它的每一个阶段都由RSU块进行填充。外层的U-Net架构由11个阶段组成，每个阶段的RSU都可以更有效地提取阶段内的多尺度特征并进行更高效的聚合。</p><p><img src="/posts/6424/architecture.png" alt="architecture"></p></li><li><p>提出了残差U型模块(RSU)，该模块可以混合不同大小的感受野以从不同尺度捕获更多的上下文信息，此外该模块中使用了池化操作，在不增加计算成本的前提下增加了整个架构的深度。该模块由三部分组成：一个普通卷积层，用于提取局部特征并将通道数改为$C_{out}$；一个用于提取多尺度特征的类似U-Net的结构；一个将多尺度特征和局部特征融合的残差结构。</p><p><img src="/posts/6424/RSU.png" alt="RSU"></p></li><li><p>模型的总loss是6个side loss和一个fuse loss的加权和。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>PR，F-measure，MAE，weighted F-measure，S-measure，relax boundary F-measure.</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>除了提高performance，也可考虑构建从零开始训练的轻量级模型。</li><li>这篇论文的related work可以作为一个简单的综述整理一遍。</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-phase Liver Tumor Segmentation with Spatial Aggregation and Uncertain Region Inpainting</title>
      <link href="/posts/41863.html"/>
      <url>/posts/41863.html</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-phase-Liver-Tumor-Segmentation-with-Spatial-Aggregation-and-Uncertain-Region-Inpainting"><a href="#Multi-phase-Liver-Tumor-Segmentation-with-Spatial-Aggregation-and-Uncertain-Region-Inpainting" class="headerlink" title="Multi-phase Liver Tumor Segmentation with Spatial Aggregation and Uncertain Region Inpainting"></a>Multi-phase Liver Tumor Segmentation with Spatial Aggregation and Uncertain Region Inpainting</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Zhang Y ,  Peng C ,  Peng L , et al. Multi-phase Liver Tumor Segmentation with Spatial Aggregation and Uncertain Region Inpainting[J].  2021.</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li>SOTA的LiTS(liver tumor segmentation)通常通过期加权求和或基于通道注意力的拼接来融合跨期的特征。</li><li>这些SOTA的方法忽视了不同期间的像素级的空间联系，从而导致了差强人意的特征整合。</li><li>基于多期图像的分割可以综合不同期的互补信息，有助于进行更好的分割。</li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>设计了新的LiTS方法来充分聚合多期信息（用动脉期图像促进静脉期的LiTS）并精细化不确定区域的分割。相互引导编码器部分以ResNeXt-50为backbone，使用PV流和ART流提取特定期的特征，并用SAM进行双向聚合，使得二者可以互相指导特征的提取。解码器部分以四层聚合特征作为输入，产生初始概率图，此外通过双线性插值将所有输入上采样，再通过拼接和卷积进行融合。解码器顶端的不确定区域修复部分借助局部置信卷积操作，使用确定像素来修复相邻的不确定像素。</p><p><img src="/posts/41863/architecture.png" alt="architecture"></p></li><li><p>设计了空间聚合模块SAM，它鼓励每个像素同不同期交互，来充分利用跨期信息。SAM挖掘宏观和局部的期间关系，并为每个期生成像素级的响应图，最后根据响应图逐像素地调制和融合多相位特征。对PV和ART期的输入使用通道维度的平均池化和最大池化操作，四者凭借组成描述器提取模块，目的是为了减少维度并保留信息特征。接着，分别对两个描述器使用GAP及三个卷积来学习局部和全局的期间互补关联。接着使用softmax生成两个响应图，这两个响应图作为权重矩阵，即可获得PV和ART输入的加权和$F_{Aggr}$，其会被送入解码器进行预测，此外，其还会被用于引导特征的提取：<br>$$<br>F_{PV}&#x3D;(F_{Pv}+F_{Aggr})&#x2F;2 \\<br>F_{ART}&#x3D;(F_{ART}+F_{Aggr})&#x2F;2<br>$$<br>SAM和URIM模块的结构如下图所示：</p><p><img src="/posts/41863/SAM_URIM.png" alt="SAM_URIM"></p></li><li><p>设计了不确定区域修复模块URIM，它使用临近的富有判别性的特征精细化不确定的像素。URIM的核心思想是使用确信的像素来修复周围不确定的像素：在LC-Conv中，一个滑动窗口内置信度较高的像素对滤波结果的贡献更大。其中，每个像素的分类置信度计算公式和局部置信卷积LC-Conv的计算公式为：<br>$$<br>M_{conf}&#x3D;1-exp(1-S_{max}&#x2F;S_{min}) \\<br>x’&#x3D;(W^T(X\otimes M_{conf}))&#x2F;sum(M_{conf})+b<br>$$<br>其中x是当前滑动窗口的输入特征，w是卷积滤波器的权重，b是偏差。</p></li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>DPC，DG，VOE，RVD，ASSD，RMSD.</li><li><img src="/posts/41863/ablation.png" alt="ablation"></li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>融合方法：<ol><li>输入级融合(ILF)： Liver tissue segmentation in multiphase ct scans using cascaded convolutional neural networks.</li><li>决策级融合(DLF)： Co-heterogeneous and adaptive segmentation from multi-source and multi-phase ct imaging data: A study on pathological liver and lesion segmentation 、MC-FCN</li><li>特征级融合(FLF)：<ol><li>期加权融合：MW-UNet</li><li>期注意力机制：PA-ResSeg</li></ol></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> image segmentation </category>
          
      </categories>
      
      
        <tags>
            
            <tag> image segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CoNet论文笔记</title>
      <link href="/posts/54286.html"/>
      <url>/posts/54286.html</url>
      
        <content type="html"><![CDATA[<h1 id="CoNet论文笔记"><a href="#CoNet论文笔记" class="headerlink" title="CoNet论文笔记"></a>CoNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Ji W ,  Li J ,  Zhang M , et al. Accurate RGB-D Salient Object Detection via Collaborative Learning[J].  2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ol><li>池化和上采样操作会模糊目标的边界，低维的特征又包含了太多的背景噪声。</li><li>使用额外的深度网络从深度图中提取深度特征会带来额外的计算和存储成本。</li><li>深度图像的空间信息可以更好地表达三维场景，借此帮助定位显著性目标。</li><li>以往的工作使用的是双流的架构，借助跨模态的融合策略分别处理RGB和深度图像，或者使用专门为深度图像设计的子网络，来为RGB表示进行补偿。在带来额外代价的同时，无法在没有深度输入的情况下使用。</li><li>在推理阶段对深度图像的依赖限制了RGB-D方法的实际应用。</li></ol><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ol><li><p>设计了一个新颖的协作学习网络。五个transition层跟在encoder之后是要对提取的特征进行预处理。</p><p><img src="/posts/54286/architecture.png" alt="architecture"></p></li><li><p>设计了一个全局引导模块(GGM)，应用于深三层，其目的是为了获取更丰富的全局语义并减缓解码器中高维语义信息的稀释。GGM的关键组件是GPM，即全局感知模块，其由四个平行的不同膨胀比例的空洞卷积和一个等价映射组成，借此获得丰富的全局语义。接着​每一个高层GPM的输出会和下一层的特征像素级加和，再送入这一层的GPM，这边是GGM的整体流程，通过这样的方式可以减缓高维语义的稀释。</p><p><img src="/posts/54286/GGM.png" alt="GGM"></p></li><li><p>边界检测模块。作用是从过于丰富的低级特征中提取边缘信息，然后与显著性知识结合，共同强调显著性区域和目标边界。低两层特征经过预处理并整合之后，送入该模块。该模块输出的显著性边界会与canny提取的gt求一个loss，此外该模块学习到的特征(softmax之前)会被送入KC模块。</p></li><li><p>粗糙显著性目标检测模块。与深度估计模块合作，以经过预处理并整合的高三层特征作为输入，作用是增强提取出的高维语义特征。这里输出的粗糙显著性图会与gt求二元交叉熵，此外，该模块学习到的粗糙特征(softmax之前)会作为空间注意力传递给KC，该空间注意力跟输入的整合后的高维特征进行像素级乘法再以剩余连接形式加上该特征即可得到深度估计模块的输入。</p></li><li><p>深度估计模块。作用是将深度和显著性学习以相互促进的方式整合到高级特征的学习过程中，而不是将深度图像作为一个单独的输入。将上一步的输出进行三次卷积使得特征适用于深度估计，接着再进行一个卷积来生成用于跟深度gt求loss的特征。由过往工作可知，特征图的每一个通道都可以看做是一个特征检测器，该深度特征可以作为通道注意力，跟粗糙显著性检测模块输出的特征进行像素级乘法再以剩余连接形式加上该特征，即可得到该模块的输出。</p></li><li><p>设计了一个知识收集器(knowledge collector)。将低级融合特征和经过两次注意力的高级融合特征拼接得到新的融合特征。将边界和显著模块的特征拼接，然后卷积激活得到融合特征。前面的融合特征同深度特征做剩余连接，其结果在和后面的融合特征做剩余连接。</p></li><li><p>总的loss是边界，显著，深度，融合共四部分的加权和。</p></li></ol><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE，weighted F-measure，S-measure和E-measure.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ol><li>SOTA： Depth-induced multi-scale recurrent attention network for saliency detection.</li></ol>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Towards High-Resolution Salient Object Detection</title>
      <link href="/posts/36258.html"/>
      <url>/posts/36258.html</url>
      
        <content type="html"><![CDATA[<h1 id="Towards-High-Resolution-Salient-Object-Detection"><a href="#Towards-High-Resolution-Salient-Object-Detection" class="headerlink" title="Towards High-Resolution Salient Object Detection"></a>Towards High-Resolution Salient Object Detection</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Zeng Y ,  Zhang P ,  Lin Z , et al. Towards High-Resolution Salient Object Detection[J]. arXiv, 2019.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ol><li>边界模糊的问题始终没有解决。</li><li>现在拍摄的照片分辨率越来越高。</li><li>高分辨率SOD有三种方法：简单地增加输入图像的大小，但是极耗内存；划分成块，一块一块地进行预测，但是极耗时间且容易被背景噪声影响；使用后处理方法比如CRF或者graph cuts.</li></ol><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ol><li><p>设计了第一个高分辨率显著性目标检测模型。在第一条路径中，原始输入图像下采样送入GSN，输出结果在进行上采样，送入GLFN。第二条路径中，原始图像送入APS来生成一组关注不确定区域的子图，这些子图被送入LRN，在GSN的引导下改善细节并将输出送入GLFN。第三条路径中，为了尽可能多地保留细节，直接将原图送入GLFN。</p><p><img src="/posts/36258/architecture.png" alt="architecture"></p></li><li><p>设计了Global Semantic Network，用于提全局语义信息。GSN和LRN都使用VGG作为backbone。为了在不增加参数的前提下扩大感受野，使用空洞卷积来捕捉上下文信息(也可以使用recurrent的方法)。GSN负责容易区分的区域，LRN负责艰难的部分，GSN生成的特征图可以用来引导LRN。</p><p><img src="/posts/36258/GSN_LRN.png" alt="GSN_LRN"></p></li><li><p>设计了Local Refinement Network，用于优化目标细节。当输入图像的尺寸很大的时候，想要定位显著目标需要进行多次或者大比例的下采样，这样会丢失太多细节，无法生成准确的边界，而使用局部子图作为输入虽然保留了细节信息，但是无法知道哪里是显著区域，因此LRN要在GSN的引导下进行以综合两者的优点。相比过去基于patch的方法使用类似滑动窗口的手段进行遍历，本模型只关注那些“艰难”的区域，因此并不耗时。</p></li><li><p>Attended Patch Sampling可以强迫LRN关注不确定的区域。其通过两个阈值找到了那些不确定的像素，生成了一个注意力矩阵。然后使用如下算法生成一组patch。</p><p><img src="/posts/36258/APS.png" alt="APS"></p></li><li><p>设计了Global-Local Fusion Network，用于融合预测。</p><p><img src="/posts/36258/GLFN.png" alt="GLFN"></p></li></ol><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Progressively Guided Alternate Refinement Network for RGB-D Salient Object Detection</title>
      <link href="/posts/57618.html"/>
      <url>/posts/57618.html</url>
      
        <content type="html"><![CDATA[<h1 id="Progressively-Guided-Alternate-Refinement-Network-for-RGB-D-Salient-Object-Detection"><a href="#Progressively-Guided-Alternate-Refinement-Network-for-RGB-D-Salient-Object-Detection" class="headerlink" title="Progressively Guided Alternate Refinement Network for RGB-D Salient Object Detection"></a>Progressively Guided Alternate Refinement Network for RGB-D Salient Object Detection</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Chen S ,  Fu Y . Progressively Guided Alternate Refinement Network for RGB-D Salient Object Detection[J].  2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ol><li>backbone在理论上有足够大的感受野来覆盖大部分的显著目标，但是有效的感受野比理论上的少很多[ Understanding the effffective receptive fifield in deep convolutional neural networks.]</li><li>在融合多尺度特征时，高维的语义信息会被逐渐稀释。</li></ol><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ol><li><p>提出了渐进式引导，交替式改进的网络，来改善多尺度残差模块生成的粗糙的初始显著性预测图。同程明明等人的100k参数模型一样，没有使用预训练网络作为backbone(depth流中)，而是从头构建了一个轻量级的深度流(只有4个级联的卷积层)，它可以在更少冗余的前提下更有效的提取互补特征(64.9MB)。</p><p><img src="/posts/57618/architecture.png" alt="architecture"></p></li><li><p>提出了MSR模块来解决背景中所述的尺度问题。MSR有三个分支，除了膨胀率不一样外其他都相同。同之前一样，为了在保持参数数量不变的前提下增大感受野，使用了循环递归的方式来使用残差模块。</p><p><img src="/posts/57618/MSR.png" alt="MSR"></p></li><li><p>提出了guided residual(GR)模块，以RGB和depth特征交替作为输入，用前一步的输出预测图作为辅助输入，目的是为了减少二者的互相退化(解决背景2的问题)。GR模块由两部分组成：split-and-concatenate(SC)操作以及dual residual learning(双残差学习)。SC操作实际上就是向特征图中平均的插入几层输出预测图。双残差学习分两步，首先将SC的输出进行卷积并和输入进行加和；其次对这个加和的结果进行卷积然后与上一步的输出预测图进行加和，得到这一步的输出预测图。</p><p><img src="/posts/57618/GR.png" alt="GR"></p></li><li><p>对每个侧链的堆叠GR模块进行渐进式引导来弥补错误检测或者检测缺失。所谓渐进，指的是通过设置SC中的分组数目来调整预测引导作用的强弱。</p></li></ol><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE，S-measure和E-measure.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ol><li><p>SOTA：</p><p>DF [45], CTMF [20], MMCI [3], TAN [2], PCAN [1], CPFP [62], DMRA [42],ICNet [26], UCNet [55], JL-DCF [18], A2dele [44], and SSF [59]</p></li><li><p>要看： </p><ol><li>Contrast prior and fluid pyramid integration for rgbd salient object detection.</li><li>Scale-aware trident networks for object detection.</li></ol></li><li><p>融合多尺度特征的方式：</p><ol><li>short connection：Deeply supervised salient object detection with short connections.</li><li>skip connection： Feature pyramid networks for object detection.</li><li>residual connection： R3net、 Deep residual learning for image recognition、Residual dense network for image restoration</li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Single Stream Network for Robust and Real-time RGB-D Salient Object Detection</title>
      <link href="/posts/35369.html"/>
      <url>/posts/35369.html</url>
      
        <content type="html"><![CDATA[<h1 id="A-Single-Stream-Network-for-Robust-and-Real-time-RGB-D-Salient-Object-Detection"><a href="#A-Single-Stream-Network-for-Robust-and-Real-time-RGB-D-Salient-Object-Detection" class="headerlink" title="A Single Stream Network for Robust and Real-time RGB-D Salient Object Detection"></a>A Single Stream Network for Robust and Real-time RGB-D Salient Object Detection</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Zhao X ,  Zhang L ,  Pang Y , et al. A Single Stream Network for Robust and Real-time RGB-D Salient Object Detection[J].  2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ol><li>现存的RGB-D SOD模型关注RGB流和depth流的融合，但是并没有充分挖掘深度图本身，此外，分别从rgb图像和深度图像中提取特征会显著增加参数量。</li><li>rgb图像和深度图像具有较大差异，如果将二者拼接起来送入网络，就会使得网络难以训练。</li><li>深度图中所展示的稳定几何结构对光照和纹理的变化具有鲁棒性，可以为处理复杂的环境提供重要的补充信息。</li></ol><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ol><li><p>提出单流网络来实现早期和中期的融合，充分利用预训练模型的特征提取能力，并节省参数。网络采用FCN架构，vgg-16作为backbone，输入是四通道的图像矩阵。</p><p><img src="/posts/35369/DANet%E2%80%94%E2%80%94architecture.png" alt="DANet——architecture"></p></li><li><p>在编码器和解码器之间设计了新颖的深度增强双注意力机制(DEDA)，同时采用mask进行监督，以及深度信息来进行指导，以此来过滤 噪声特征。从T、S以及D的拼接矩阵中通过卷积激活得到注意力矩阵。</p><p>为了防止背景被分类为显著性目标，引入了深度信息来改进注意力矩阵，显著性分支的深度增强注意力公式如下：<br>$$<br>A_{sd}&#x3D;A_m\cdot A_m+A_m\cdot D<br>$$<br>为了防止显著性目标被分类为背景，设计了背景分支的深度增强注意力，其计算公式如下：<br>$$<br>A_{bd}&#x3D;(1-A_m)\cdot (1-A_m)+(1-A_m)\cdot D<br>$$<br>这两个处理有三个好处：首先，当深度图的值很小的时候，注意力机制仍然可以正常工作，因为第一项都与深度图无关；其次，深度图没有前景和背景之间的语义区分，因此在进行分割时可能会引入噪声和干扰，但是使用了DEDA进行处理之后，第二项可以限制D只优化前景或者只优化背景，因此可以保持前景和背景之间的高对比度；最后，在反向传播过程中，两个注意力矩阵可以获得动态的梯度，从而帮助网络学习最优参数。</p><p><img src="/posts/35369/DANet%E2%80%94%E2%80%94DEDA.png" alt="DANet——DEDA"></p></li><li><p>通过使用自注意力机制，提出了金字塔式的特征提取模块，可以描述特征图中两个位置之间的空间依赖关系。恒等映射分支和全局平均池化层不使用注意力机制，这是为了保持最大和最小感受野下，图像所固有的属性。其余三个分支分别进行不同膨胀比例的卷积，然后借助注意力矩阵得到新的特征图，最后五个分支拼接得到输出。此外，此模型的注意力机制虽然也试图找到每两个点中间的关联，但是与之前遇到过的一种方法不同。之前是每个点生成一个通道，该通道代表了这个点和其他所有的的关联程度。而此次则是直接生成一个宽和高都为H<em>W的巨大的矩阵，借此得到每对像素点之间的关联程度。其计算公式如下：<br>$$<br>A&#x3D;softmax(R_1(Conv(F_{in}))^T\times R_1(Conv(F_{in})))<br>$$<br>其中，R1是将shape为C、H、W的矩阵变形成C、H</em>W的矩阵。而注意力矩阵A的使用方式如下：<br>$$<br>F_{out}&#x3D;F_{in}+R_2(R_1(Conv(F_{in}))\times A^T)<br>$$<br><img src="/posts/35369/DANet%E2%80%94%E2%80%94PAFE.png" alt="DANet——PAFE"></p></li></ol><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE，S-measure和E-measure.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ol><li>SOTA：DES [7], DCMC [8],CDCP [51], DF [28], CTMF [16], PCA [2], MMCI [4], TANet [3], CPFP [46],DMRA [26].</li><li>本文通过实验指出进行通道维度拼接相比于进行像素级加和的好处是如果某个通道（depth）的质量较差，那么拼接的方法可以通过训练抑制该通道的特征响应，而不影响颜色通道的特征计算；如果使用像素级加和，那么颜色通道和深度通道会同时被抑制。</li></ol>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>R3Net论文笔记</title>
      <link href="/posts/47211.html"/>
      <url>/posts/47211.html</url>
      
        <content type="html"><![CDATA[<h1 id="R3Net论文笔记"><a href="#R3Net论文笔记" class="headerlink" title="R3Net论文笔记"></a>R3Net论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Deng Z ,  Hu X ,  Zhu L , et al. R^3 Net: Recurrent Residual Refinement Network for Saliency Detection[C]&#x2F;&#x2F; International Joint Conference on Artificial Intelligence (IJCAI), 2018. 2018.</p><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>提出了新颖的循环递归残差改进网络(recurrent residual refinement network)。如之前论文笔记中所述，用vgg作为backbone的时候，前三层包含了更多的低维细节信息，而后两层则是包含了更多的高维语义信息，本模型也使用了这个结论，但是使用的是ResNeXt，并将其分成了两部分，浅层部分会被整合，用于生成低维整合特征，深层部分同样会被整合，生成高维整合特征，他们分别被记为L和H。整合的时候，先进行上采样，通道维度的拼接以及由三个卷积层跟随三个激活函数构成的特征融合网络。接着，模型会从H中生成初始显著性图，并送入一系列的RRB模块中。</p><p><img src="/posts/47211/R3Net.png" alt="R3Net"></p></li><li><p>引入了残差改进模块(RRB)，该模块通过交替利用低级特征和高级特征来学习显著性预测和gt之间的残差。该模块的输入是来自上一步的输出以及低维整合特征和高维整合特征的交替；该模块的输出是一个叠加了上一步的输出和一个学习到的残差(指的是gt和输出预测图之间的差异)的显著性图。该模块首先将上一步输出的显著性图和交替的高维整合特征、低维整合特征进行通道维度的拼接，接着进行三次卷积，得到这一步的残差。然后将残差和上一步输出的显著性图进行像素级的加和，即可得到这一步的输出。</p></li><li><p>该模型采用了深度监督机制，每一个RRB模块的输出都需要进行一次监督。因此，总的loss是这些loss的加权和。</p></li></ol><h2 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h2><ol><li>提出了R3Net，通过引入一系列的RRB模块渐进地改善、精细化显著性图。</li><li>引入了RRB模块，通过交替利用低级特征和高级特征来学习显著性预测和gt之间的残差。</li><li>在五个数据集上对比了16个sota的模型，实现了最好的效果。</li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>PR曲线，F-measure，MAE，S-measure和E-measure.</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>SRM，Amulet，NLDF</li><li>学习残差更容易，而且往往可以获得更好的效果。</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BCNet论文笔记</title>
      <link href="/posts/39235.html"/>
      <url>/posts/39235.html</url>
      
        <content type="html"><![CDATA[<h1 id="BCNet论文笔记"><a href="#BCNet论文笔记" class="headerlink" title="BCNet论文笔记"></a>BCNet论文笔记</h1><h2 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h2><p>[1] Dong B ,  Zhou Y ,  Hu C , et al. BCNet: Bidirectional Collaboration Network for Edge-Guided Salient Object Detection[J]. Neurocomputing, 2021, 437(4).</p><h2 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h2><ol><li><p>边缘的质量是决定精准检测显著性目标成功与否的关键因素。</p></li><li><p>现在有许多基于边界引导的SOD模型，但是效果不尽如人意，这主要是因为缺乏对多级特征融合和多类特征聚合的综合考虑。</p></li><li><p>SOD面临两大问题，一个是难以将显著性目标从复杂背景中分离出来。</p></li><li><p>另一个是显著目标边缘处的检测效果往往不好。</p></li><li><p>对于多类型特征的聚合，前人的工作往往只是采用简单的拼接或者像素级的加法或乘法来实现。</p><p><img src="/posts/39235/BCNet%E2%80%94%E2%80%94type.png" alt="BCNet——type"></p></li></ol><h2 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h2><ol><li><p>提出了新颖的双向协作网络(bidirectional collaboration network)，它可以将有效的多级特征融合和多类特征聚合操作整合到一个统一的边界引导的SOD框架中。该模型使用了深度监督的思想，但是除了CSM-1使用了边界进行监督，其余都使用mask作为监督。</p><p><img src="/posts/39235/BCNet%E2%80%94%E2%80%94architecture.png" alt="BCNet——architecture"></p></li><li><p>提出了一致显著性最大模块(consistency saliency maximization，CSM)，其灵感来源于空间注意力机制，目标是告诉我们显著性区域在哪。其功能是在自顶向下的渐进路径中传播最高层语义特征，并产生全局边界表示和一系列的区域表示。CSM模块的输入包括上一模块的输出，最高层的特征图和对应层的特征图；在被送入模块进行处理之前，特征图会根据需要进行上采样和卷及操作，调整尺寸和通道数。CSM模块需要进行边界和显著性两种监督。CSM模块有三个主要步骤：生成信息特征图，生成协作图，显著性特征最大化。</p><ol><li><p>产生信息特征图。</p><p>将三个输入进行像素级的加和，然后用叠加后的特征图产生平均信息特征图和最大信息特征图(分别计算跨通道维度的平均和最大)。我的理解是类似AMPNet论文里面同时使用平均池化和最大池化的思想，既可以抑制背景噪声，又可以保留边界特征。</p></li><li><p>产生协作图。</p><p>最大信息特征图可以强调显著性区域的位置，平均信息特征图可以抑制背景噪声。首先将他们拼接起来，然后使用卷积层来产生单通道的表示，再送入sigmoid函数进行激活。</p></li><li><p>显著性特征最大化。</p><p>将协作图和三个输入加和的特征图进行像素级乘积以得到输出结果。</p></li></ol><p><img src="/posts/39235/BCNet%E2%80%94%E2%80%94CSM.png" alt="BCNet——CSM"></p></li><li><p>提出了多边界特征融合模块(multiple bounded feature fusion，BFF)，其功能是使用边界特征来改善、精细化区域特征。BBF模块的输入包括对应CSM的输出的上采样，和来自CSM-1的边界特征。BFF模块需要进行显著性监督。对CSM模块的输出进行上采样，让它和CSM-1输出的边界特征图具有同样的大小，然后将两者简单的加和，再将其卷积，BN，Relu，接着将其和原边界特征图以及原CSM特征图再进行加和。接下来，要对这个融合之后的矩阵进行全局平均池化，卷积，激活，卷积，sigmoid激活。最后将其与三项融合矩阵进行像素级乘积再进行像素级加和即可得到BBF模块的输出。显然，BBF模块使用的是通道注意力机制，用其选择和融合不同类型的特征，其本质上是告诉我们什么特征是重要的。</p><p><img src="/posts/39235/BCNet%E2%80%94%E2%80%94BFF.png" alt="BCNet——BFF"></p></li><li><p>BCNet同边界损失和区域损失进行联合训练。总损失函数分为四个部分：CSM-1的边界损失，其余CSM的损失，BBF的损失还有最后显著性预测图的损失。</p></li></ol><h2 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h2><ol><li>提出了新颖的针对边界引导SOD的双向协作网络，有效的解决了多级特征融合和多类特征聚合的问题。</li><li>引入了CSM和BFF模块，首先传播最高层的语义表示，然后使用边界特征改善区域特征。</li></ol><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><ul><li>PR曲线，F-measure，MAE，S-measure和E-measure.</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><ul><li>edge-guided models<ol><li>结合特殊的边界损失函数<ol><li>Non-local deep features for salient object detection</li><li>Basnet: boundary-aware salient object detection</li><li>Attentive feedback network for boundary-aware salient object detection</li></ol></li><li>使用多任务学习方式引入边界监督，并用边界特征加强区域特征<ol><li>Focal boundary guided salient object detection</li><li>A simple pooling-based design for real-time salient object detection</li><li>Salient object detection with pyramid attention and salient edges</li><li>Egnet: edge guidance network for salient object detection</li><li>Stacked cross refifinement network for edge-aware salient object detection</li><li>A mutual learning method for salient object detection with intertwined multi-supervision,</li></ol></li></ol></li><li>] S. Woo, J. Park, J.-Y. Lee, I. So Kweon, Cbam: Convolutional block attention module, in: Proceedings of the European Conference on Computer Vision,2018, pp. 3–19.</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AMPNet论文笔记</title>
      <link href="/posts/32639.html"/>
      <url>/posts/32639.html</url>
      
        <content type="html"><![CDATA[<h1 id="AMPNet论文笔记"><a href="#AMPNet论文笔记" class="headerlink" title="AMPNet论文笔记"></a>AMPNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Sun L ,  Chen Z ,  Wu Q , et al. AMPNet: Average-and Max-Pool Networks for Salient Object Detection[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2021, PP(99):1-1.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ol><li>非显著区域被误识别为显著目标，是因为多级卷积特征中包含冗余信息。</li><li>检测到的显著目标往往不完整，缺乏局部细节。</li></ol><p><img src="/posts/32639/AMPNet%E2%80%94%E2%80%94current_CNN.png" alt="AMPNet——current_CNN"></p><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ol><li><p>整体结构</p><p>我们提出了平均——最大池化网络(AMPNet)，利用平均池化模块与最大池化模块，分别在空间和通道维度上整合多级、互补的上下文特征，并采用深度监督机制，得到精细的显著性预测结果。整个模型分为四个阶段：自底向上阶段，平均——最大池化阶段(池化模块在这里)，自顶向下阶段(两条路径在这里)，特征融合阶段。</p><p><img src="/posts/32639/AMPNet%E2%80%94%E2%80%94architecture.png" alt="AMPNet——architecture"></p></li><li><p>自底向上阶段</p><p>采用了魔改的VGG16模型(将最后的全连接层替换成卷积层)作为骨干网络，用于学习并提取多尺度特征。骨干网络共有6个卷积块，与之前工作不同的是，本模型没有从最大池化之后的结果提取特征，而是从最后一个卷积层的结果提取特征，目的是为了保留更多的空间结构和边界细节信息。</p></li><li><p>平均——最大池化阶段</p><p>平均池化模块由一个平均池化层，一个具有四个平行层的并行卷积块以及一个通道转换卷积层组成。具有四个尺度卷积核的并行卷积块被用于编码多尺度空间结构上下文并扩大感受野；使用小尺寸的卷积核可以很好地保留特征细节，而大尺寸的卷积核可以很好地抑制噪声。尽管卷积核的尺寸不同，但是由于步长均为1，且配以不同的padding，四层的输出结果具有相同的尺寸，直接在channel维度进行拼接之后送入最后的卷积层即可。最大池化模块由一个最大池化层，一个精细化改进卷积块(就是卷积层的堆叠，可以看作VGG块的延续)以及两个通道转换卷积层组成。最大池化模块是串行结构，这是为了提高检测特征的鲁棒性。</p><p><img src="/posts/32639/AMPNet%E2%80%94%E2%80%94AM.png" alt="AMPNet——AM"></p></li><li><p>自顶向下阶段</p><p>引入了两种自顶向下的反馈路径：使用最大池化的路径和使用平均池化的路径，在图中分别用绿色和橙色表示。对于提取出的最高层的特征，会被直接使用，其余层的特征会使用上一层特征的上采样和本层特征进行channel维度的拼接，最后进行upconv操作。具体公式如下所示：<br>$$<br>D^i_T&#x3D;<br>\begin{cases}<br>T^i, &amp; \text{if $i$&#x3D;5} \\<br>UpConv(cat(T^i,Up(D^{i+1}_T,T^i))), &amp; \text{if $i$&#x3D;1,2,3,4}<br>\end{cases}<br>$$<br>其中，T如果是A则代表平均池化路径，T如果是M则代表最大池化路径，Up是双线性插值上采样，UpConv是三个连续的卷积层，目的是为了增强拼接后特征的鲁棒性。</p></li><li><p>特征融合阶段</p><p>仅仅只是对平均池化特征和最大池化特征进行像素级的加和，然后将通道数压缩为1，接着上采样到输入图片的尺寸作为输出。此外，平均池化、最大池化、融合特征三部分分别有五个输出，将他们分类之后分别进行统一尺度，通道维度拼接和两次卷积得到三个输出，这三个输出也要计算loss。</p></li><li><p>深度监督机制</p><p>如上一节所述，除了五个层次的输出需要进行监督，还有最后分类融合之后的结果需要监督，故而总的loss一共有6个部分，它们的加权和就是整个模型的损失函数。</p></li></ol><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ol><li>提出了AMPNet，整合空间维度和通道维度的互补信息。</li><li>设计了自顶向下路径，用高维特征进行指导(类似全局引导流)。</li></ol><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE和S-measure.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ul><li><p>NLDF，RFCN，Multi-scale interactive</p><p>network for salient object detection，R3net，Detect globally, refifine locally: A novel approach to</p><p>saliency detection，Non-local deep features for salient object detection要看</p></li><li><p>本文总结了一些bottom-up pathway和top-down pathway(跳跃连接，渐进连接，二者混合)的相关工作。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PFANet论文笔记</title>
      <link href="/posts/10385.html"/>
      <url>/posts/10385.html</url>
      
        <content type="html"><![CDATA[<h1 id="PFANet论文笔记"><a href="#PFANet论文笔记" class="headerlink" title="PFANet论文笔记"></a>PFANet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Zhao T ,  Wu X . Pyramid Feature Attention Network for Saliency detection[J].  2019.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ol><li><p>在以往的工作中，来自不同层的特征总是被无差别地整合在一起，然而不同的特征图或者同一图中不同的特征显然在SOD中扮演了不同的角色。</p></li><li><p>深层包含全局上下文关注信息，适合用于定位显著性区域，浅层包含空间结构细节，适合用于定位边界。</p></li><li><p>为了解决不同特征对显著性检测贡献不同却被用同样方式处理的问题，以往的工作提出了注意力模型和门函数。</p><p><img src="/posts/10385/PFANet%E2%80%94%E2%80%94high_low_level.png" alt="PFANet——high_low_level"></p></li></ol><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ol><li><p>提出了PFANet，用于增强高维度的上下文特征和低维度的空间结构特征。</p><p><img src="/posts/10385/PFANet%E2%80%94%E2%80%94architecture.png" alt="PFANet——architecture"></p></li><li><p>提出了上下文感知的金字塔特征提取模块(CPFE)，让高维度特征图可以捕捉丰富的上下文特征——多尺度、多感受野、高维度的特征。该模块以VGG16中深三层的特征图 作为输入，使用三个不同膨胀率的空洞卷积以及一个1x1的卷积层来捕捉多感受野的上下文信息。接着将四个结果统一到最大尺度(下图红色)，然后在channel维度进行拼接。最后将三个结果再次统一到最大尺度(下图中为64x64x32x4)，并在channel维度进行拼接，即可得到CPFE的输出。</p><p><img src="/posts/10385/PFANet%E2%80%94%E2%80%94CPFE.png" alt="PFANet——CPFE"></p></li><li><p>提出了channel维度的注意力模块(CA)和空间注意力模块(SA)，分别应用到CPFE特征图和低维度特征图，然后进行混合来检测显著性区域。CA负责选择合适的尺度和感受野来生成显著性区域——在训练过程中，CA分配各不同的权重给不同的channel。SA负责更好地找到有效的低维度特征——只有显著性区域和背景之间的边界是有效的。由前人的工作可知：CNN中特征的不同通道会对不同的语义产生响应，CA的作用就是为对显著性区域产生响应的通道赋予更大的权重。我们还知道一张图片中会有复杂的背景和前景的细节，而其中只有显著性目标和背景之间的边界是对我们有意义的，SA的作用就是筛除掉无用的细节信息减少干扰。SA中为了增大感受野的同时不增加参数，使用了前人的分部卷积的方法。</p><p><img src="/posts/10385/PFANet%E2%80%94%E2%80%94CA_SA.png" alt="PFANet——CA_SA"></p></li><li><p>提出了边界保留损失函数，来获得精确的显著性区域边界。一般SOD的loss使用的是gt和输出之间的交叉熵，本文做了进一步的改进：首先使用拉普拉斯算子获得gt和输出的边界，然后再对二者计算交叉熵损失。模型的总损失函数是正常交叉熵和边界交叉熵的加权和。</p></li></ol><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ol><li><p>提出了PFANet，用于增强高维度的上下文特征和低维度的空间结构特征。对于高维特征，使用CPFE和CA来捕捉丰富的上下文信息，对于低维特征，使用SA来过滤掉噪声细节特征(如背景中的细节特征)。</p></li><li><p>设计了新颖的边界保留损失函数来指导网络的训练，使得网络可以学习到更多的边界相关的细节信息。</p></li></ol><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ol><li><p>X. Zhang, T. Wang, J. Qi, H. Lu, and G. Wang. Progressive attention guided recurrent network for salient object detection</p></li><li><p>L. Zhang, J. Dai, H. Lu, Y. He, and G. Wang. A bi-directional</p></li></ol><p>   message passing model for salient object detection.</p>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MLMNet论文笔记</title>
      <link href="/posts/58660.html"/>
      <url>/posts/58660.html</url>
      
        <content type="html"><![CDATA[<h1 id="MLMNet论文笔记"><a href="#MLMNet论文笔记" class="headerlink" title="MLMNet论文笔记"></a>MLMNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Wu R ,  Feng M ,  Guan W , et al. A Mutual Learning Method for Salient Object Detection With Intertwined Multi-Supervision[C]&#x2F;&#x2F; 2019 IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>显著性预测图依然不够准确，这是目标内部的复杂性和卷积、池化操作步长引起的边界不准确共同导致的。</li><li>显著性目标内部结构复杂，很难做到均匀地高亮整个目标。</li><li>由于卷积、池化带来了信息的损失，导致边界附近预测不准。</li><li>为了得到好的结果，以往的工作主要使用跳跃连接结构(skip-connection)或者循环递归结构(recurrent architecture)来整合语义信息和细节信息。为了解决仍然存在的边界模糊问题，前人开始引入额外的边界信息进行共同训练。</li><li>以往的工作显示VGG的前三个块适合于同时捕捉边缘信息和显著性信息。因此在前三个VGG块上进行额外的边缘检测任务来帮助MLM中的前景轮廓检测任务。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>整体思路是使用显著目标检测、前景轮廓检测、边界检测共同监督模型的训练。整个模型采用U-Net架构，使用VGG16作为骨干网络。在编码器部分，去掉pool5层之后的所有层，并将剩下的层分为6个块(pool5单独一个块)，在每一个块的顶部使用MLM模块提取前景轮廓特征和显著性特征。除此之外还有EM模块去提取边界特征，EM模块和对应的组合块的所有卷积层相连。组合块和EM块之间的特征传递使用残差架构完成。在解码器部分使用深度监督思想来混合多尺度特征。</li></ul><p><img src="/posts/58660/MLMNet%E2%80%94%E2%80%94architecture.png" alt="MLMNet——architecture"></p><ul><li>首先，以一种交互的方式使用显著目标检测和前景轮廓检测来生成均匀的高亮显著性图，使用这二者的原因是它们都需要准确的前景检测。两者的区别在于SOD需要密集标注，更容易被目标内部的复杂结构所影响，使得结果内部出现不均匀的亮点；而后者的结果是从低级特征中提取出来的，因此对内部特征更鲁棒，但是更容易被轮廓附近的特征所影响。为了实现上述目标，作者提出了新颖的相互学习模块(mutual learning module，MLM)，作为一个功能模块(比如残差模块)，来为模型提供服务(提升SOD和前景轮廓检测的性能)。每个MLM由多个网络分支构成，并且采用相互学习的方式进行训练。MLM来源于DML方法，DML针对同一个任务，有多个学生网络，在原有的监督基础上，各个学生网络的预测输出会被作为互相的次级监督，每个学生网络都是一个完整模型，可以独立工作。在MLM中使用L2距离损失代替了DML中的KL散度，此外每个学生网络实际上就是三个连续的卷积层。MLM的输入是各个block的输出特征图，通过MLM的各个学生网络可以生成不同的预测结果，从而实现各种监督——浅层的三个block进行前景轮廓监督，深层的三个block进行显著性监督。</li></ul><p><img src="/posts/58660/MLMNet%E2%80%94%E2%80%94MLM_module.png" alt="MLMNet——MLM_module"></p><ul><li>其次，前景轮廓检测和边界检测互相指导彼此的训练，从而实现了精准的轮廓检测，并同时降低了边界预测的局部噪声。在EM模块中，它的输入包含了对应的block中所有层的特征，一个VGG块的每个卷积层的输出都连接到其它卷积层的输出，用以融合多层次特征，生成边界概率图。每个EM模块都会生成一个边界概率图，这个图会被整合成最后的边界预测图，此外每个EM模块也会通过残差结构将边界特征图传递给MLM模块，促进MLM模块中的前景轮廓检测任务的进行。边界概率图是送入sigmoid的边界特征图。EM模块的输入是两张不同的图片，分别来自边界数据集和显著性数据集，EM的输出是经过激活的边界概率图(来自于边界数据集)和未经过激活的边界特征图(来自显著性数据集)，前者将与其他两个EM模块的输出拼接得到最后的边界预测图，后者将被经过处理后送入MLM模块，促进前景轮廓任务的执行。</li></ul><p><img src="/posts/58660/MLMNet%E2%80%94%E2%80%94EM_module.png" alt="MLMNet——EM_module"></p><ul><li>最后使用交替监督的方式进行训练。在MLM中，浅三层进行前景轮廓监督，深三层进行显著性监督。类似的，在解码器的五个block中，0、2、4块进行显著性监督，1、3块进行前景轮廓监督。高级语义信息在前景轮廓的监督下筛除了内部的噪声，并且使得轮廓特征更清晰；而前景轮廓特征在显著性检测监督下为轮廓的内部填充均匀的显著性分数。每一个解码器的block的任务是融合前一个block的特征和对应的MLM模块的特征。这样交替监督的训练方法生成了具有均匀高亮的显著性预测，并且保持了较好的前景轮廓。</li><li>整个模型的loss分为编码器loss和解码器loss，编码器loss又分为显著性loss，边界loss和MLMloss三部分。其中显著性loss，边界loss和解码器loss均使用BCEloss，MLMloss使用MSEloss。</li></ul><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>使用SOD、前景轮廓检测任务共同学习的方法训练模型来得到更准确地显著区域结果。</li><li>使用前景轮廓检测和边界检测任务共同学习的方法生成更准确的前景轮廓并降低边界检测的噪声。</li><li>设计了新颖的MLM模块，可以更好地利用三个任务之间的联系，并得到更好的结果。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE和S-measure.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ul><li><p>一些SOTA模型：DCL，DSS，Amulet，SRM，DGRL，RAS，PAGE，BMPM，R3Net，HRS，BANet，BASNet，PAGRN，MLMS，ICNet，CPD等。</p></li><li><p>整合层次特征：</p><ol><li>跳跃连接(skip-connection)：HED，DSS，SRM。</li><li>循环递归结构(recurrent architecture)：RFCN，RCL，DHS</li></ol></li><li><p>利用边界信息(edge、boundary、contour)：deep edge-aware saliency detection将二分类变成显著目标，边缘，背景三类。</p></li><li><p>待看参考文献：S. He and N. Pugeault. Deep saliency: What is learnt by a</p></li></ul><p>  deep network about saliency? abs&#x2F;1801.04261, 2018.</p>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么大半生要为买房而奋斗？</title>
      <link href="/posts/46428.html"/>
      <url>/posts/46428.html</url>
      
        <content type="html"><![CDATA[<h1 id="为什么大半生要为买房而奋斗？"><a href="#为什么大半生要为买房而奋斗？" class="headerlink" title="为什么大半生要为买房而奋斗？"></a>为什么大半生要为买房而奋斗？</h1><p><strong>一生劳劳碌碌，房贷一下数十年，期间战战兢兢，如履薄冰，就为了几十米之地付出半生年华，值得吗？</strong></p><p><em><code>作者：飞花落雪</code></em><br><em><code>链接：https://www.zhihu.com/question/419506370/answer/1499970924</code></em><br><em><code>来源：知乎</code></em><br><em><code>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</code></em></p><p>因为大多数人没有想明白。</p><p>当你一个人无欲无求的时候，你就会发现其实房子并不重要。因为，没什么重要的。</p><p>尤其在你想明白了，抚养后代只不过基因给你的动物本能，而实际上你留传的后代过了三代，连你的名字你的样子都不知道以后，你就会发现殚精竭虑的让自己儿女跃迁到更高的阶层，那不过是社会赋予你的自我焦虑，你就会彻底解脱自我。毕竟，我们所有人，都是二十万年以前一只女智人的后代。至于那时代的其他人类，他们或许曾经留下过后代，或许留下后代死亡了，但那与现在并没有关系，我们也只知道这个不知道名字的女智人。</p><p>你费尽心机所养育的后代，过了若干代连你的名字也不知道，所以抚养后代阶层跃迁完全是个笑话。抚养后代对于整个物种种群来说，是极其有意义的，因为物种要延续，而对于个体来说，没有任何意义。个体只不过是基因的奴隶，就如同你现在是这个社会房价的奴隶一样。</p><p>基因的延续要求你生儿育女，要求你与其他同类竞争，要求你与其他雄性争夺配偶，而毫不考虑你在争夺配偶的时候是否会受伤，是否会死亡，是否内心很恐慌。无独有偶，房价也要求你这样，要求一辈子就像一条狗一样辛辛恳恳为了房子挣扎拼命奋斗，实现所谓的人生的价值，而实际上，挣扎一辈子只得到了一堆完全不属于你的钢筋混泥土，等到你没有压榨价值，对社会没有啥贡献的时候，就像一片被榨干血与肉的落叶一样，把你扫入社会的垃圾堆，不起一尘一土。</p><p>而这些被榨干的人在活着的时候，想的是如何让那些不知道名字的后代活得更好，怎么样供养一套更好房子。</p><p>只要你懂得了这个道理，那么你便不必担心，因为连生育并且抚育后代这样的事情都是如此的毫无意义，那么一套缥缈的房子就想让我费尽一生的精力，想榨干我的生命？</p><p>NO。</p><p>我们不结婚，我们不生育，当然我们也不买房。你涨任你涨，明月照大江，你狂任你狂，清风拂山岗，你房价飞速狂飙，我只在床上自在躺。</p><p>买不起房就租房呗，租售比如此性感，谁买房谁显然没搞清楚情况。我宁愿旅游自在狂放为理想奋斗一生，也不会给房地产贡献一文。社会以房价吻我，我就以佛系歌之，谁怕谁。</p><p>社会女青年以有车有房筛选求偶对象，你发现如果你不在意生育抚育后代这件事，买房根本不对你造成任何困扰，谈恋爱不结婚不就对了。实在不行，三和大神打开王者荣耀，游戏不好玩还是旅游不好逛还是床上躺着不舒服？</p><p>养好父母，为理想奋斗就可以了。达则兼济天下，不是达则多买几套房，穷则独善其身，不是穷则一辈子背着沉重的房贷做房奴，让吸血炒房客压榨，而是守好自己的品行，养好自己养好父母，不为社会添乱。</p><p>为了大半生奋斗而买房，纯粹就是舍本逐末的行为。</p><p>为了大半生而奋斗的有且仅有一件事，那就是理想。而理想不值钱。</p>]]></content>
      
      
      <categories>
          
          <category> 一语惊醒梦中人 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 一语惊醒梦中人 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GateNet论文笔记</title>
      <link href="/posts/5313.html"/>
      <url>/posts/5313.html</url>
      
        <content type="html"><![CDATA[<h1 id="GateNet论文笔记"><a href="#GateNet论文笔记" class="headerlink" title="GateNet论文笔记"></a>GateNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Zhao X ,  Pang Y ,  Zhang L , et al. Suppress and Balance: A Simple Gated Network for Salient Object Detection[J].  2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>以往的显著性检测方法使用U-Net或者FPN作为基础结构，但是有两个问题：第一点是编码器和解码器交换信息的时候缺乏对干扰的控制(筛除噪声冗余)，以往的工作多使用all-pass的跳跃结构，引入了噪声特征，并且难以充分利用有效特征，因此作者试图在每对编码器块和解码器块之间建立一个信息筛选单元来强化显著性特征，抑制背景干扰；第二点是没有考虑不同编码器块的贡献的差异。</li><li>为了获得更大的感受野并结合多尺度信息，前人使用了ASPP模块(atrous spatial pyramid pooling module)，但是过大的膨胀率会因为插入了过多的零使得点之间的相关性严重缺乏，这不利于微小结构的识别。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>整个网络分为编码器网络和解码器网络，前者由去掉全连接层和最后池化层的VGG16组成。后者由FPN分支，Parallel分支和Fold-ASPP模块构成。用E，T，D，G分别代表编码器，transition，解码器和门控单元的特征图。FPN分支通过进行像素级加和逐渐整合多级特征，目的是预测显著性目标的主体，Parallel分支通过通道维度的拼接作为残差模块辅助改进FPN的结果，Fold-ASPP模块利用从E5中学到的语义特征为解码器提供多尺度信息。</li></ul><p><img src="/posts/5313/GateNet%E2%80%94%E2%80%94gated_architecture.png" alt="GateNet——gated_architecture"></p><ul><li>提出了新的门控双分支结构来建立不同层次特征之间的协作，提高整个网络的鉴别能力，并进一步恢复显著性图的更多细节。门控单元以$E^i$和$D^{i+1}$作为输入，进行尺度的对齐之后进行拼接，得到$F^i$，将其分别送入两个分支，进行一系列的卷积激活池化操作，得到一对门值$G^i$。该模块公式如下：<br>$$<br>G^i&#x3D;<br>\begin{cases}<br>P(S(Conv(Cat(E^i,D^{i+1})))), &amp; \text{if $i$&#x3D;1,2,3,4} \\<br>P(S(Conv(Cat(E^i,T^i)))), &amp; \text{if $i$&#x3D;5}<br>\end{cases}<br>$$<br>卷积操作的输出的通道数为2，正好分别对应于两个门值G。这两个门值分别是两个矩阵，我的理解是，这两个矩阵的作用类似于注意力图，与特征图进行像素级乘积，保留并强化显著性特征，抑制不相关的噪声特征。</li></ul><p>渐进式结构加上门控单元构成了门控双分支结构。渐进式结构不利于细节信息的恢复，并行结构则容易导致显著性目标的定位不准，因为没有语义信息的低级特征干扰了全局信息的捕捉。而门控双分支结构一定程度上缓解了这两个问题。</p><p><img src="/posts/5313/GateNet%E2%80%94%E2%80%94gated_unit.png" alt="GateNet——gated_unit"></p><p><img src="/posts/5313/GateNet%E2%80%94%E2%80%94decoder_architecture.png" alt="GateNet——decoder_architecture"></p><ul><li><p>在FPN分支中，其公式如下所示：<br>$$<br>D^i&#x3D;<br>\begin{cases}<br>Conv(G_1^i\cdot T^i+Up(D^{i+1})), &amp; \text{if $i$&#x3D;1,2,3,4} \\<br>Conv(G_1^i\cdot T^i), &amp; \text{if $i$&#x3D;5}<br>\end{cases}<br>$$<br>在Parallel分支中，其公式如下所示：<br>$$<br>F_{Cat}&#x3D;Cat(D^1,Up(G_2^1\cdot T^1),Up(G_2^2\cdot T^2),Up(G_2^3\cdot T^3),Up(G_2^4\cdot T^4),Up(G_2^5\cdot T^5))<br>$$<br>最后的显著性图$S^F$由两个分支的结果通过残差链接整合而成，其公式如下所示：<br>$$<br>S^F&#x3D;S(Conv(F_{Cat})+D^1)<br>$$</p></li><li><p>采用了基于所提出的“折叠”操作(Fold-ASPP)的膨胀空间金字塔池化来精确地定位不同尺度的显著对象。这种操作在扩大感受野的同时保留了局部采样点之间的相关性。首先将图中的点堆砌起来，得到$N&#x2F;2 \cdot N&#x2F;2 \cdot 4C$的特征图，接着进行空洞卷积，最后进行展开操作，得到最终结果。</p></li></ul><p><img src="/posts/5313/GateNet%E2%80%94%E2%80%94Fold_ASPP.png" alt="GateNet——Fold_ASPP"></p><ul><li>该模型没有采用深度监督思想，而是对FPN的结果和融合结果进行了监督，两种监督都使用交叉熵作为loss，最终loss是两个loss的加和。</li></ul><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>提出了一个简单的门控网络来自适应地控制从每个编码器块流入解码器的信息量。通过多级门控单元，网络可以平衡每个编码器块对解码器块的贡献，并抑制非显著区域的特征。</li><li>设计了一个Fold-ASPP模块来捕获更丰富的上下文信息，并定位不同大小的显著对象。通过“折叠”操作，可以得到更有效的特征表示。</li><li>建立了一个双分支架构。它们形成一个残差结构，通过门控处理相互补充，产生更好的结果。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE和S-measure.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ul><li>一些SOTA模型：DCL，DSS，Amulet，SRM，DGRL，RAS，PAGE，BMPM，R3Net，HRS，BANet，BASNet，PAGRN，MLMS，ICNet，CPD等。</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSNet论文笔记</title>
      <link href="/posts/50463.html"/>
      <url>/posts/50463.html</url>
      
        <content type="html"><![CDATA[<h1 id="CSNet论文笔记"><a href="#CSNet论文笔记" class="headerlink" title="CSNet论文笔记"></a>CSNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Gao S H ,  Tan Y Q ,  Cheng M M , et al. Highly Efficient Salient Object Detection with 100K Parameters[J].  2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>显著性目标检测需要花费大量的计算成本才能对每个像素进行精确的预测，因此这样的模型不适合用于低功率设备。因此作者试图通过提升模型的效率来缓解计算成本和模型性能表现之间的矛盾。</li><li>SOD任务需要为每个图像像素生成准确的预测分数，因此既需要大尺度的高级特征表示以正确定位显著对象，又需要精细的低级特征表示以进行精确的边界细化。</li><li>如何构建具有SOTA性能的超轻量级SOD模型是一个重要但研究较少的领域，它主要面临两个挑战：第一点是当高级特征的低频特性满足输出的显著性图的高分辨率时，可能会出现严重的冗余问题；第二点是SOTA的SOD模型通常使用在ImageNet数据集上预训练的分类模型作为骨干网络来提取特征，但是这些骨干网络本身就是十分耗费资源的。</li><li>前人也注意到了低频特征的空间冗余问题，因此设计了OctConv操作来代替普通的卷积操作，并用其处理低分辨率上变化较慢的特征图，从而减少了计算成本。但是直接使用OctConv仍有两个问题：第一点是OctConv只使用了低分辨率和高分辨率两个尺度的特征是难以完全减少SOD任务中的冗余问题的，SOD任务比分类任务需要更强的多尺度特征表示能力；第二点是OctConv中每个尺度的通道数目是人为手动设置的，由于SOD任务需要的类别信息较少，因此需要花费大量工作来重新调整显著性模型。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>提出了一种灵活的卷积模块，即广义的OctConv(generalized OctConv，gOctConv)来高效地使用同一阶段内和跨阶段的多尺度特征。该模块有如下优点：<ol><li>任意数量的输入和输出尺度可以支持更大范围的多尺度表示。</li><li>除了级内的特征外，gOctConv还可以从特征提取器以任意比例处理跨级的特征。</li><li>gOctConv通过本文提出的动态权重衰减方案可以学习每个尺度的通道数。</li><li>可以关闭跨尺度的特征交互，提升灵活性。</li></ol></li></ul><p><img src="/posts/50463/CSNet%E2%80%94%E2%80%94OctConv&gOctConv.png" alt="CSNet——OctConv&amp;gOctConv"></p><ul><li><p>提出了In-layer Multi-scale Block，即ILBlock。其作用是增强级内的多尺度特征表示。为了节省计算成本，在每一层中具有不同尺度的交互特征是不必要的；因此使用gOctConv，让每个输入通道对应一个同分辨率的输出通道来消除交叉尺度操作。ILBlock由一个OctConv和两个gOctConv组成，前者交互了两个尺度的特征，后者在单一尺度内提取特征，块内的多尺度特征被分别进行处理。</p></li><li><p>提出了新的跨级融合方法。常规方法通过保留高级特征并设计复杂的多级特征聚合模块来获得高分辨率输出，这不可避免的增加了计算冗余。作者使用最后三个阶段的输出作为gOctConv的输入，并进行分别处理，接着送入另一个gOctConv进行融合，以获得高分辨率的特征，最后经过一个卷积层得到显著性图。</p></li><li><p>提出了一种新颖的动态权重衰减方案来减少特征的冗余。这种有效的方案稳定地提高了训练期间参数的稀疏性，同时保持了通道之间的权重分布的稳定，支持gOctConv中每个尺度获取可学习的通道数，使得性能下降可以忽略不计的情况下减少了80%的参数。一般的权重衰减公式如下：<br>$$<br>L&#x3D;L_0+ \lambda \sum \frac{1}{2}(w_i)^2 \tag{1}<br>$$</p></li></ul><p>$$<br>  w_i \leftarrow w_i- \triangledown f_i(w_i)- \lambda w_i \tag{2}<br>$$</p><p>而新的动态权重衰减方案针对不同通道的不同特征会有不同的衰减权重，其公式如下：<br>  $$<br>w_i \leftarrow w_i- \triangledown f_i(w_i)- \lambda _dS(x_i)w_i \tag{3}<br>  $$</p><p>  $$<br>S(x_i)&#x3D; \frac{1}{HW} \sum_{h&#x3D;0}^H \sum_{w&#x3D;0}^Wx_{ih,w} \tag{4}<br>  $$</p><p>  其中$S(x_i)$是特征的某种指标，在本文中使用的是global average pooling(GAP)，其定义为公式4。在筛选通道的时候，使用BatchNorm中的$\gamma$作为通道重要性的指标，我们可以发现重要的通道和不重要通道的$\gamma$分布有一个明显的间隔，所有不重要通道的$\gamma$都被抑制到了0附近，因此我们可以很轻松地筛除不重要的通道。BatchNorm操作的公式如下：</p><p>  $$<br>  y&#x3D; \frac{x-E(x)}{ \sqrt{Var(x)+ \epsilon} } \gamma+ \beta \tag{5}<br>  $$<br>  其中$\gamma$和$\beta$是可以学习的参数。</p><p><img src="/posts/50463/CSNet%E2%80%94%E2%80%94distribution.png" alt="CSNet——distribution"></p><p>![CSNet——learn channels](CSNet——learn channels.png)</p><ul><li>使用gOctConv构建了轻量级的模型，即CSNet。该模型可以从头开始直接进行训练，无需再ImageNet上进行预训练，从而避免了不必要的特征表示。以往的工作是获得了全部(包括不必要的)特征表示之后使用注意力机制筛除掉任务无关的特征表示(噪声)，该模型是直接不去学习那些用于在识别任务中区分不同类别的特征。网络分为特征提取器和跨级的融合部分，前者与层内多尺度模块(ILBlocks)堆叠起来，并根据特征图的分辨率分为四阶段，分别具有3、4、6、4个ILBlock；后者有gOctConv模块组成，会处理来自特征提取器各个阶段的特征来获得高分辨率的结果。</li></ul><p><img src="/posts/50463/CSNet%E2%80%94%E2%80%94architecture.png" alt="CSNet——architecture"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li><p>提出了一种灵活的卷积模块，即gOctConv，它可以从同阶段特征和跨阶段特征中灵活地获得任意数量尺度的输入，从而实现更大范围的多尺度表示。</p></li><li><p>提出了一种新的动态权重衰减方案来减少特征的冗余。它支持gOctConv中每个尺度的可学习通道数，使得在性能下降可以忽略不计的情况下减少了80%的参数。</p></li><li><p>使用gOctConv构建了超轻量级的SOD模型——CSNet，仅使用大型模型0.2%的参数，就可以获得相同的性能。</p></li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>F-measure，MAE.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ul><li>该论文2.1节中对一些工作进行了分类：<ol><li>{ DSS,66,UCF,83,57}从骨干网络的不同阶段捕捉精细细节和全局语义。</li><li>{51,40,PAGENet,EGNet}引入边界线索来精细化显著性图的边界。</li><li>{UCF,86,70}通过优化网络来提升性能表现。</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAGENet论文笔记</title>
      <link href="/posts/20038.html"/>
      <url>/posts/20038.html</url>
      
        <content type="html"><![CDATA[<h1 id="PAGENet论文笔记"><a href="#PAGENet论文笔记" class="headerlink" title="PAGENet论文笔记"></a>PAGENet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Wang W ,  Zhao S ,  Shen J , et al. Salient Object Detection With Pyramid Attention and Salient Edges[C]&#x2F;&#x2F; CVPR19. 2019.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>多尺度显著性特征对SOD是十分重要的，以往的工作往往将注意力集中在如何组合中间层的结果上面。</li><li>CNNs通过重复的池化和下采样操作使得深的层可以获得更大的感受野和更强的表示能力，但是同时失去了细节的信息，这对高级任务来说是有用的，但是对于低级任务来说是不利的，因为低级任务往往需要精确到像素级别，例如SOD，在边界上面就需要精确的像素级分类结果。以往的工作使用的是densely connected或者bottom-up&#x2F;top-down网络架构，然后在top-down过程中逐渐恢复显著性目标的细节，但是锐度问题仍然是一个挑战。因此有感于语义分割中的先进技术，作者设计了一个显著边缘检测模块，来更好地分割显著性目标并锐化边界。</li><li>锐化度是一个挑战，边界不能做到像素级的精细分类，这主要是由于卷积核的平滑性和池化层的下采样。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>设计了一个基础的金字塔注意力结构(pyramid attention module)，目的是在利用多尺度显著性信息的时候更多地关注显著性区域。这种堆叠注意力的设计通过考虑多尺度注意力并且扩大了层的感受野来增强网络的层的表示能力。在骨干网络中，通过多次的下采样，我们得到了多尺度的特征，对于每一个特征图，都要使用soft attention mechanism来得到注意力图(归一化重要性权重)，图中每个位置的值代表该位置的重要性，在得到不同尺度的注意力图之后均进行上采样，恢复到该层图像的尺寸。最后将注意力图和原图加权求和，为了防止太多接近0的结果，因此需要与原图相加来方便反向传播$Y_j&#x3D;\frac{1}{N}\sum_{n&#x3D;1}^{N}(1+I_j^{‘n})X_j$。在图三中，可以看出该模块显著抑制了背景中的特征。</li></ul><p><img src="/posts/20038/PAGENet%E2%80%94%E2%80%94example_of_pyramid_attention.png" alt="PAGENet——example_of_pyramid_attention"></p><p><img src="/posts/20038/PAGENet%E2%80%94%E2%80%94example_of_architecture.png" alt="PAGENet——example_of_architecture"></p><p><img src="/posts/20038/PAGENet%E2%80%94%E2%80%94illustration_of_PAM.png" alt="PAGENet——illustration_of_PAM"></p><ul><li><p>添加了一个显著边缘检测模块(salient edge detection module)，这个模块强调了显著边缘信息的重要性——它为更好地分割显著性目标并精细化改进目标边界提供了强有力的线索。这个模块学习精确的显著边缘估计，从而更好地进行边界保持的显著目标分割。它以金字塔注意力模块的改进之后的结果作为输入，经过一系列的卷积层之后得到显著边缘预测，其损失函数被定义为：$\frac{1}{K}\sum_{k&#x3D;1}^{K}\Vert P_k-F(Y_{I_k})\Vert_2^2$.其中$I_k$是输入的图像，$Y_{I_k}$是精细化改进之后的特征，$F$是送入显著边缘检测模块进行处理，$P_k$是从ground truth得到的显著边缘。</p></li><li><p>总的损失函数由两部分组成，被定义为如下：</p><p>$$\frac{1}{K}\sum_{k&#x3D;1}^{K}(-\sum_i(\beta(1-G_i)log(1-S_i)+(1-\beta)G_ilog(S_i))+\Vert P_k-F(Y_{I_k})\Vert _2^2)$$</p></li><li><p>引入密集连接( Gao Huang, Zhuang Liu, Kilian Q Weinberger, et al. Densely connected convolutional networks. In <em>CVPR</em>, 2017)来综合使用不同层次的信息，第L层的结果将由前L-1层的显著性图和显著边界图共同得到。</p></li></ul><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>提出Pyramid Attentive and salient edGE-aware saliency model, 也就是PAGE-Net。</li><li>金字塔注意力模块继承了注意力机制的特征增强能力(选择与任务相关的特征，Fei Wang, Mengqing Jiang, Chen Qian, etal. Residual attention network for image classifification. In <em>CVPR</em>, 2017)，并成功的处理了多尺度显著性特征学习的问题。</li><li>显著边缘检测模块将边界信息嵌入到SOD模型中，帮助更好地分割并锐化结果。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE.</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ul><li><p>在深度学习中，获取具有很好代表能力的特征是最关键最为基础的，而具有多尺度空间的特征可以具有很好的代表能力，尤其是在显著性检测任务中，有很多工作可以表明多尺度特征具有很大的作用，因为很多工作中的模型都是通过组合各中间层的特征输出而获取较好的结果(不同中间层的特征的尺度是不一样的)。</p></li><li><p>基于CNN的用来解决不同任务的模型都具有一个统一的骨干网络(Vgg、ResNet或者其他)，骨干网络主要负责提取统一的特征，后续根据不同任务而设计的网络再利用这些统一提取到的特征进行各自的任务，所以骨干网络提取到的特征具有广泛性或者说是具有冗余性，而不同的任务可能只需要骨干网络中提取到的特征的一部分，一般后续设计的特定网络应该会自适应地选取自己所需的特征，但是最近的一些关于attention的工作的成功表明，我们获取在接受骨干网络提取到的特征时就可以先对其进行筛选，这样的筛选会取得更好的结果，这可能是由于神经网络的学习能力还不够强，靠我们后续自己设计的网络去学习需要的特征还是有困难的，因为那些冗余的特征可能还会造成干扰，其实从这个角度来看，attention就是将原始的特征进行一些过滤，将那些响应值不大的特征滤除，增强响应值大的特征，将解空间减小，这样有助于后续的神经网络通过学习选取适合自己任务的特征。在显著性目标检测任务中，采用attention模块可以使得模型更加关注于与显著性相关的图像中的区域，从而有效地滤除背景中的一些干扰区域，有效提高模型的性能。attention要滤除不相干的特征，如何判断哪些特征是不相干的则变成一个有待解决的问题，最开始的方法便是直接对原始特征进行softmax或者sigmoid后得到[0,1]的与原始特征同尺寸的权重矩阵，用该权重矩阵与原始特征进行相应像素相乘进行筛选，这样做的动机便是认为响应值大的特征便是重要的特征，那些响应值小的特征应该就是不相关的特征，这样筛选方式还不够具有任务导向性，后面就有人采用了门的结构，将原始特征与有关的特征进行融合然后再进行上述的attention，类似的操作还有很多，在本片论文中，作者将多尺度特征提取和attention相结合，提取后的特征既具有较大的感受野(多尺度)，而且还更加关注显著性区域(采用了attention)，作者的做法就是对当前层的原始特征进行不同尺寸的下采样，对原始特征以及下采样后的特征再进行attention操作，最后将这些过滤后的特征再融合起来，便得到了pyramid attention后的结果。</p></li><li><p>显著性目标检测的任务大多是通过语义分割的方式来进行的，我们知道语义分割自从FCN以来就有一个缺点，那就是空间信息的丢失问题，由于CNN中的池化和下采样的存在，高层特征能够获取更大的感受野和更强的表示能力但是代价则是丢失了很多细节性的空间信息，而这些空间信息对于像素精细分类的任务来说是非常必要的，在显著性目标检测领域中，尽管有skip connect或者编码解码结构来解决这些问题，比如U-Net，通过逐步融合上一层的具有更多的空间信息的特征来一步步细化分割结果，很好地解决了空间信息缺失的问题，但是我觉得尽管融合了底层的特征可以很好地恢复丢失的空间信息，这种方法看似完美地同时解决了分类精度和空间信息恢复的问题，但是我觉得还是有不足的地方，因为尽管底层的特征具有更多的空间信息，但它毕竟就是特征，他的表示性相较于高层特征还具有一定差距，也就是具有语义上的鸿沟，融合高层和底层的特征就需要网络来缩小它们之间的语义鸿沟，这增加了网络的负担，而且缩小语义鸿沟和恢复空间信息貌似是两个具有矛盾性的问题，因为网络在融合的过程中肯定会权衡某个像素的分类是根据高层特征来分类还是通过底层特征来分类，若是对显著性目标进行定位肯定考虑高层特征多些，若是细化显著性目标的边缘肯定是考虑底层特征多些，若网络对于底层特征考虑过多，那么可能就会直接导致显著性目标检测的错误，尽管边缘可能会很好，若是网络对于高层特征考虑过多，则得出的结果显著性目标会检测到，但其边缘可能会有模糊不清的表现，所以我们可能会看到，U-Net可能对于那些较为容易检测出来的显著性物体有很准确的定位以及边缘分割效果，但是对于那些背景比较复杂的难以分类的显著性物体来说，要么会检测出背景中的物体，要么检测出来的显著性物体边缘会有模糊的现象，这可能就是类似于U-Net方法对于特征的语义鸿沟处理不当所造成的结果，虽然我并不知道如何解决这个问题，但是U-Net的缺点应该就是这样的。在本文中作者将显著性物体的边缘信息融入到提取到的特征中，作者是通过网络预测显著性物体边缘来得到边缘信息的，有了边缘信息可以使得模型更好地定位显著性物体以及细化分割结果。之前的方法中还有增加边缘loss，可以使得模型更加注重于显著性物体边缘的像素的分类。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SCRN论文笔记</title>
      <link href="/posts/59772.html"/>
      <url>/posts/59772.html</url>
      
        <content type="html"><![CDATA[<h1 id="SCRN论文笔记"><a href="#SCRN论文笔记" class="headerlink" title="SCRN论文笔记"></a>SCRN论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Wu Z ,  Su L ,  Huang Q . Stacked Cross Refinement Network for Edge-Aware Salient Object Detection[C]&#x2F;&#x2F; 2019 IEEE&#x2F;CVF International Conference on Computer Vision (ICCV). IEEE, 2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>过往的研究主要集中在如何聚合预训练网络提取的富有判别力的多层次特征。</li><li>有研究者试图使用边界信息辅助训练，然而他们都只是使用边界信息来改进分割特征(比如使用边界损失)。</li><li>灵感来源于二元分割任务和边界图的逻辑关联：边界图中的边界区域是相对应的分割图中的目标区域的子集。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li><p>设$M_S$为显著性图，$M_e$为边界图，前者会高亮整个显著目标区域，后者只会高亮边界部分，因此后者的高亮部分是前者高亮部分的子集。于是有如下两式：<br>$$<br>M_s \wedge M_e&#x3D;M_e \tag{1}<br>$$</p><p>$$<br>M_s \vee M_e&#x3D;M_s \tag{2}<br>$$</p><p>其中，上下箭头分别表示按像素的逻辑与和逻辑或。</p></li><li><p>在CRU中设计了两个特定方向的集成操作，并在两个任务之间双向地传递信息。如下两个式子分别代表用边界特征改进分割特征和用分割特征改进边界特征：<br>$$<br>S^i_{n}&#x3D;S^i_{n-1}+f(S^i_{n-1},E_{n-1}) \tag{3}<br>$$</p><p>$$<br>E^i_{n}&#x3D;E^i_{n-1}+g(E^i_{n-1},S_{n-1}) \tag{4}<br>$$</p><p>i(1-4)表示四个残差模块分别提取出的特征。n(1-4)表示四个堆叠的CRU各自的输出。在设计f、g两种函数时，存在两个问题。一个问题是如何在各个方向上整合特征。另一个问题是应该选择一个任务的多少个级别的特征来改进另一个任务的某个级别的特征。于是有了下面三种模式的CRU。</p></li><li><p><strong>Point-to-Point style——一层优化一层</strong></p><p>一个任务的每个级别的特征，都直接用另一个任务的对应级别的特征去改进它。也就是说$E^i_{n-1}$和$S^i_{n-1}$相互改进。在使用分割特征改进边界特征的时候，使用像素级的乘积来近似逻辑与操作：<br>$$<br>g&#x3D;Conv(E^i_{n-1} \otimes S^i_{n-1}) \tag{5}<br>$$<br> $\otimes$是像素级别的乘积，Conv是32核的3×3的卷积层。在使用边界特征改进分割特征的时候，由于逻辑或是不可微的，因此不能直接用，于是提出了替换的策略：<br>$$<br>f&#x3D;Conv(Cat(S^i_{n-1},E^i_{n-1})) \tag{6}<br>$$<br>Cat是在channel维度进行拼接，Conv是32核的3×3卷积。</p></li><li><p><strong>Set-to-Point Style——所有层优化一层</strong></p><p>在使用四个层级的分割特征改进边界特征的时候,<br>$$<br>g&#x3D;Conv(E^i_{n-1} \otimes \prod_{k&#x3D;1}^4 CU(S^k_{n-1})) \tag{7}<br>$$<br>其中$CU$是一个使用32核1×1卷积的比例变换操作，其目的是为了使分割特征和边界特征的尺寸一致。$\otimes$是像素级的乘积，$\prod$表示在像素级对所有的四个特征求连乘积。此外，<br>$$<br>f&#x3D;Conv(Cat(S^i_{n-1},Cat^4_{k&#x3D;1}[CU(E^k_{n-1})])) \tag{8}<br>$$<br>$Cat[*]$表示拼接某个CRU的所有层次的经过比例变换之后的边界特征。</p></li><li><p><strong>Selective Set-to-Point Style</strong>——选择多层优化一层</p><p>在CNN提取多层次特征的过程中，随着网络的加深，特征中的干扰越来越少，于是由于低层次的特征中有太多的干扰，在SPS的基础上提出了SSPS，对特征进行选择，筛掉噪声多的特征。<br>$$<br>g&#x3D;Conv(E^i_{n-1} \otimes \prod_{k&#x3D;i}^4 CU(S^k_{n-1})) \tag{9}<br>$$</p><p>$$<br>f&#x3D;Conv(Cat(S^i_{n-1},Cat^4_{k&#x3D;i}[CU(E^k_{n-1})])) \tag{10}<br>$$</p><p>在SSPS中，一个任务某个层级的特征只由另一个任务中大于等于此层级的特征进行优化改进。比如$E^1_{n-1}$可以由$S^1_{n-1},S^2_{n-1},S^3_{n-1},S^4_{n-1}$进行优化，而$E^4_{n-1}$只能由$S^4_{n-1}$进行优化改进。</p></li><li><p>PPS、SPS、SSPS三种模式的效果对比如下：</p></li></ul><p><img src="/posts/59772/SCRN%E2%80%94%E2%80%94compare.png" alt="SCRN——compare"></p><ul><li>使用堆叠交叉改进单元同时优化显著目标检测和显著边缘检测的多层次特征，然后分别连接两个U-Net网络得到两张预测图。整个网络的损失函数为：<br>$$<br>L&#x3D;L_{ce}(P_s,GT_s)+L_{ce}(P_e,GT_e) \tag{11}<br>$$<br>其中，$L_{ce}$是标准交叉熵损失函数。</li></ul><p><img src="/posts/59772/SCRN.png" alt="SCRN"></p><ul><li>此外这是我看的第一篇使用SOC数据集测试模型面对不同属性时的性能表现，具体表格如下：</li></ul><p><img src="/posts/59772/SCRN%E2%80%94%E2%80%94attributes_performance.png" alt="SCRN——attributes_performance"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>发掘出了二元分割任务和边界图之间的关系，并依此提出了SCRN网络。</li><li>提出了CRU单元，该单元设计了两个特定方向的集成操作，并借此改进两个任务的多层次特征。</li><li>在SOC数据集上进行了测试，针对不同背景属性得到了不同的性能表现。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，maximum F-measure，MAE，weighted F-measure，FPS以及结构相似度量$S_{\alpha}$.</li><li>9种困难属性。</li></ul><p><img src="/posts/59772/SCRN%E2%80%94%E2%80%94SOC.png" alt="SCRN——SOC"></p>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BASNet论文笔记</title>
      <link href="/posts/51466.html"/>
      <url>/posts/51466.html</url>
      
        <content type="html"><![CDATA[<h1 id="BASNet论文笔记"><a href="#BASNet论文笔记" class="headerlink" title="BASNet论文笔记"></a>BASNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Qin X ,  Zhang Z ,  Huang C , et al. BASNet: Boundary-Aware Salient Object Detection[C]&#x2F;&#x2F; 2019 IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2019.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>人类视觉系统有一个有效的注意力机制，它可以从视觉场景中挑选出最重要的信息，计算机视觉通过两个研究分支来建模这种机制：人眼注视点预测和显著目标检测。</li><li>以往的SOD模型大多关注区域的准确性而非边界的质量。</li><li>为了更准确地进行显著目标检测，有两个挑战是我们需要面临的。第一点是显著性主要定义在整个图像的全局对比上，而不是局部或像素级特征。为了获得准确的结果，所显著性检测方法必须了解整个图像的全局信息以及显著性目标的详细细节。为了解决这个问题，需要模型能够聚合多层次特征。</li><li>第二点是大多数显著目标检测方法都使用交叉熵(CE)作为其训练损失。但采用CE损失训练的模型在区分边界像素方面的置信度较低，导致边界模糊。其他损失，如交并比(IoU)、f-measure和Dice-score损失是为了有偏差的训练集而提出的，但它们不是专门为捕获精细的细节而设计的。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>提出了预测-改进架构——BASNet，由一个深度监督的编码-解码网络和一个残差改进模块构成，二者通过捕捉全局粗糙上下文和局部精细上下文分别负责显著性预测和显著性图的改进(精细化)。</li><li>预测模块采用类似U-Net的架构，这种编码-解码网络可以同时捕捉高层次全局上下文和低层次局部上下文。为了缓解过拟合，还采取了深度监督的思想，用gt对加解码器的每层的输出进行监督。编码器中的层都是残差模块，下采样方法是最大池化，解码器中的层都是普通的卷积模块，上采样方式是双线性插值。解码器中每一层的输入都是前一层的上采样和对应的编码器中层的输出拼接而成的特征图。最后一个特征图将作为预测模块的输出被传送至改进模块中。</li></ul><p><img src="/posts/51466/BASNet.png" alt="BASNet"></p><ul><li>改进模块，也是采用编码-解码架构，采用了短链和对最终输出的监督。该模块之所以采用残差为名，不是因为使用了残差模块，而是因为该模块的输出在理论上是gt和coarse map的差，也就是说，该模块的输出与预测模块的粗糙输出相加才是最终结果。</li></ul><p><img src="/posts/51466/BASNet%E2%80%94%E2%80%94coarse.png" alt="BASNet——coarse"></p><p><img src="/posts/51466/BASNet%E2%80%94%E2%80%94RRM.png" alt="BASNet——RRM"></p><ul><li><p>为了得到高置信度的显著性预测图和清晰的边界，提出了针对边界感知SOD的新型混合损失函数，它混合了二元交叉熵(BCE)、结构相似度(SSIM)、交并比(IoU)，并指导网络在三个层次(像素级，区块级，特征图级)上学习从输入图像到ground truth的变换。如图所示，一共有八个监督，因此最终的损失函数是八个损失的加权和：<br>$$<br>L&#x3D;\sum_{n&#x3D;1}^{8}{a_n*l^{(n)}}<br>$$</p><p>且每个损失又有三个成分：<br>$$<br>l^{n}&#x3D;l^{n}<em>{bce}+l^{n}</em>{ssim}+l^{n}_{iou}<br>$$</p><p>其中，BCE是像素级的度量，SSIM是一种区块级的度量，IoU是特征图级的度量，将三者混合起来，利用BCE使每个像素都有平滑的梯度，利用IoU给予显著目标更多注意力，通过SSIM基于图像结构使得边界的loss更大</p></li></ul><p><img src="/posts/51466/BASNet%E2%80%94%E2%80%94loss.png" alt="BASNet——loss"></p><ul><li>混合损失函数没有显式地使用边界损失(像NLDF和C2S)，而是隐式地在其中注入了清晰预测边界的目标，目的是为了减少交叉传播从边界和其他区域学习到的信息时带来的误差。</li></ul><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>提出了新型的预测-改进架构——BASNet。</li><li>提出了针对边界感知SOD的新型混合损失函数。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE以及weighted F-measure</li><li>消融实验(每个组件)+对比实验(定量+定性)</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BANet论文笔记</title>
      <link href="/posts/63682.html"/>
      <url>/posts/63682.html</url>
      
        <content type="html"><![CDATA[<h1 id="BANet论文笔记"><a href="#BANet论文笔记" class="headerlink" title="BANet论文笔记"></a>BANet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Su J ,  Li J ,  Zhang Y , et al. Selectivity or Invariance: Boundary-aware Salient Object Detection[C]&#x2F;&#x2F; 2018.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>SOD是诸多计算机视觉任务(如目标识别，目标追踪等)的前置步骤。</li><li>大的显著目标内部可能会有大的外观改变，使得显著目标很难被检测为一个整体。</li><li>显著目标的边界可能会非常微弱，以至于不能区分显著目标和周围的背景。</li><li>SOD模型在处理物体的内部和边界的时候面临着对立的需求，这就是选择性-不变性困境(selectivity-invariance dilemma)：内部的特征应不随强烈的外观变化而变化，其目的是为了将整个目标划分为一个整体(即使是强烈的外观改变也不影响我们对目标整体的判断，不会一个整体被判断为两个部分)；而边缘特征应尽量对外观变化(即使是轻微的)有选择性(区分性)，其目的是为了区分显著目标和背景(即使背景和显著目标之间只有轻微的外观改变我们也能将其分割为背景和目标)。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>首先使用ResNet-50提取普通的视觉特征，只使用五个残差模块，后面的全局池化和全连接层都被舍弃。其中第四、五个模块的卷积步长设置为1，目的是为了防止过下采样。</li><li>通过加入一个边界定位流(boundary localization stream)增强了边界特征的选择性。该模块使用多尺度特征(显著边缘检测既需要高级的语义信息，也需要低级的细节边缘信息)和一个简单网络来检测具有高选择性的显著目标边界，生成选择性置信图(selectivity confidence map)。输入是ResNet的五个侧向输出经上采样之后的拼接结果，对于这五个侧向输出分别使用128核的3x3卷积以及一核的1x1卷积这两个卷积层来压缩普通特征，然后通过上采样得到与图像同样大小的结果，接着进行拼接，最后使用一核的1x1卷积并用sigmoid激活得到选择性置信图。</li><li>通过加入一个复杂内部感知流(complex interior perception stream)保证了内部特征的不变性。使用单尺度特征和一个复杂网络来保证显著目标内部特征的不变性，生成不变性置信图(invariance confidence map)。输入是ResNet的第五个模块的结果，使用集成连续扩张模块进行处理，得到的结果进行上采样和sigmoid激活，最终生成不变性置信图。</li><li>通过加入一个过渡补偿流(transition compensation stream)修正内部和边界之间的过渡区域可能发生的失败(不变性和选择性都不能很好地分割背景和目标)，在过渡区域中，特征需要实现从不变性到选择性的渐变。输入是蕴含高维语义信息的第五模块的侧向输出以及蕴含低维边缘信息的第二模块的侧向输出的像素级加和，这样可以提高过渡区域的特征的表示能力。将第五模块的输出上采样到第二模块输出的尺寸，然后使用集成连续扩张模块生成调节好选择性——不变性的过渡特征表示图。</li></ul><p><img src="/posts/63682/BANet.png" alt="BANet"></p><ul><li>这三个流分别强调了选择性，不变性和他们的权衡，因此直接使用简单的像素级加和会引入不可预期的噪声，因此作者提出了一种特征镶嵌方法来融合三者。运算符号代表两个矩阵之间的元素级乘积，M是特征镶嵌图。第一部分强调具有高选择性低不变性置信度的边界特征，第二部分强调具有高不变性和低选择性置信度的内部特征，第三部分强调的是不变性和选择性的置信度都中等的特征。最终，整个模型的总loss有三个部分：边界交叉熵损失函数，内部交叉熵损失函数，以及最后的过渡交叉熵损失函数。</li></ul><p><img src="/posts/63682/BANet%E2%80%94%E2%80%94feature_mosaic.png" alt="BANet——feature_mosaic"></p><ul><li>通过加入一个集成连续扩张模块(integrated successive dilation module)来增强内部和过渡区域特征的不变性。第一层使用1x1的卷积来压缩通道，第二层使用2的次方的比例的空洞卷积，并添加分支内部和分支间的短连接，这样做可以使的每个分支都能感知到不同大小的局部上下文信息，整个ISD模块能够在一个连续的尺度上汇集上下文信息。第三四层使用1x1的卷积来整合特征。</li></ul><p><img src="/posts/63682/BANet%E2%80%94%E2%80%94ISD.png" alt="BANet——ISD"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>从选择性-不变性困境的角度重新审视了SOD的问题，提供了新的思路。</li><li>提出了新颖的边界感知网络。</li><li>提出了一个可以提高提取不变性特征能力的模块——integrated successive dilation module(ISD)。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线，F-measure，MAE以及weighted F-measure</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EGNet论文笔记</title>
      <link href="/posts/27635.html"/>
      <url>/posts/27635.html</url>
      
        <content type="html"><![CDATA[<h1 id="EGNet论文笔记"><a href="#EGNet论文笔记" class="headerlink" title="EGNet论文笔记"></a>EGNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Zhao J ,  JJ  Liu,  Fan D P , et al. EGNet: Edge Guidance Network for Salient Object Detection[C]&#x2F;&#x2F; 2019 IEEE&#x2F;CVF International Conference on Computer Vision (ICCV). IEEE, 2020.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>人工选取特征有时可以定位最突出的物体，但当前景和背景之间的对比度不充分时，分割方法是不可取和不可靠的，因而产生了不规则形状的显著图。</li><li>目前性能较好的解决目标静态检测问题的网络大多是以FCN（全卷积神经网络）为基础的，但是这些方法目前在显著性目标与其边缘的区分方面仍存在问题（例如目标边缘粗糙）。例如有些方法忽略了边缘信息和显著性目标信息的相关性；还有一些方法使用超像素的预处理或条件随机场的后处理解决边缘信息问题但是推理速度很慢。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a><strong>研究的灵感</strong></h3><ul><li>基于FCN方法的显著性检测任务（分割也有是类似的）由于是像素级的判别，缺少结构信息，导致显著性目标检测的边界不够精确。这种像素级的SOD方法相比区域级的方法有了很大的提升，但是他们忽略了<em><strong>图像的空间相关性</strong></em>，之前的工作大多是通过融合多尺度信息或者使用CRF等后处理来解决这个问题。</li><li>NLDF提出了引入IOU损失来影响边缘周围位置的梯度，但是也没有注意到<em><strong>显著边缘检测和显著目标检测之间的互补性</strong></em>。因此考虑引入边缘信息作为监督，将边缘信息和显著性目标检测任务共同学习，并且互相特征复用、优势互补，能够取得更好的效果。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>三步法：第一步采用渐进融合的方法，基于U-Net提取多分辨率显著目标特征；第二步通过整合局部边缘信息和全局位置信息，得到显著边缘特征；第三步，为了充分利用这些互补特征，使用一对一的引导模块将相同的显著边缘特征和显著目标特征在不同分辨率下结合。</li></ul><p><img src="/posts/27635/EGNet.png" alt="EGNet"></p><ul><li><p>整体来看，以VGG作为主干网络，删去三个全连接层又添了三个卷积（因此才有conv6-3）。接着如DSS一般每个卷积块引出一个侧链，其中conv1-2感受野太小，因此丢弃此条侧链，还有五条。其中用较浅层的conv2-2的侧链提取边缘特征，其他用于提取显著目标特征。</p></li><li><p>显著目标特征：PSFEM( Progressive salient object features extraction)。采用可以产生多尺度特征的U-Net架构，但是每个侧链要通过三个卷积层(以及ReLU)来获取更鲁棒的显著目标特征。接着通过单核卷积生成单通道预测结果。然后像DHS一般采用深度监督思想监督每一条侧链，此为显著目标监督(PSFEM中的紫色箭头)。</p></li><li><p>显著边缘特征：NLSEM(Non-local salient edge features extraction)。由于要获得显著的边缘特征，仅靠局部信息是不够的，还需要高级语义信息或位置信息；因此有与PoolNet类似的目标：减轻自顶向下过程中高级语义信息和位置信息的稀释，且能充分利用最顶层的感受野最大，位置信息最充分的特性。于是将conv6-3的特征通过三层卷积增强后送入NLSEM，进行卷积改变通道数，然后激活，上采样到和conv2-2的特征相同的尺寸，再和conv2-2的特征相加，最后送入卷积得到显著边缘特征图。此外增加了一个额外的显著边缘监督(MLSEM中的绿色剪头)。</p></li><li><p>一对一的导向模块：O2OGM。在自底向上的融合过程中，一样存在显著边缘特征被稀释的问题，其解决方案依然是增加侧链。将显著边缘特征送入每一个侧链的侧链，将经过卷积增强之后的显著目标特征进行卷积改变通道数，然后激活，上采样到和显著边缘特征尺寸相同的大小，进行像素级别的加和。与PSFEM类似的，同样进行三次卷积增强特征，然后进行单核卷积将多通道特征图转换成单通道预测图。此外，对于这些增强之后的融合特征也需要进行深度监督。最后将四条侧链的单通道预测图融合，并同样计算loss。</p></li></ul><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>着重研究了显著边缘信息和显著目标信息之间的互补性，提出EGNet，采用三步法实现了两种互补信息在单个网络中的同步建模，更好地区分了边界。</li><li>EGNet通过让这两个互补的任务相互帮助，同时优化这两个任务，让预测结果更加好。（和PoolNet一样，亦是多任务）</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线和F-measure，MAE以及S-measure</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PoolNet论文笔记</title>
      <link href="/posts/59758.html"/>
      <url>/posts/59758.html</url>
      
        <content type="html"><![CDATA[<h1 id="PoolNet论文笔记"><a href="#PoolNet论文笔记" class="headerlink" title="PoolNet论文笔记"></a>PoolNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Liu J J ,  Hou Q ,  Cheng M M , et al. A Simple Pooling-Based Design for Real-Time Salient Object Detection[C]&#x2F;&#x2F; IEEE. IEEE, 2019.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>CNN在多尺度空间提取高维语义信息和低维细节特征的能力极大地促进了SOD的发展。</li><li>CNN有类似金字塔的结构特征，较浅的层有更大的空间尺寸，并且可以保留丰富的细节的低层信息，较深的层则包含更多的高维语义信息，并且在定位显著性目标的时候效果更好。</li><li>U型结构由于其可以在分类网络中创建自顶向下的通道，并借此构建出丰富的特征图（捕捉到的语义信息多），而最受人关注。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a><strong>研究的灵感</strong></h3><ul><li>U型结构中高维度的语义信息被逐步传输到浅层，因此，被深层捕捉的位置信息会在过程中被逐步稀释。（U型网络中bottom-up阶段产生高级语义信息，再通过top-down阶段上采样，并与bottom-up阶段横向连接，虽然会将粗糙信息和细致信息连接起来，但同样会导致高级语义信息中的位置信息逐渐被稀释。）</li><li>CNN的感受野大小和层深不成比例，尤其是对于更深层次的网络，CNN的实际感受野比理论上的要小很多，以至于实际网络不足以捕捉输入图像的全局信息，导致全局上下文不足。</li><li>现有的解决上述问题的方法，大致分为引入注意力机制（PiCANet），通过循环、递归的方式精炼特征图（DHSNet），结合不同尺度的特征信息以及向显著性图增加诸如边界损失(NLDF)之类的额外约束四种。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>使用U型网络，在自底向上的过程中添加了global guidance module（GGM全局引导模块），其目的是为了给处于不同特征级别的层提供潜在显著目标的位置信息。GGM包含一个魔改版的金字塔池化模块(pyramid pooling module，PPM)，以及一个全局引导流(global guiding flows，GGF)。PPM被放置在主干网络的顶部，用于获取全局引导信息（显著性目标的位置信息）。通过引入GGFs，被 PPM 收集到的高层次语义信息可以被传递到金字塔所有层次的特征图中，纠正了 U 型网络自顶向下信号逐渐被稀释的问题。</li></ul><p><img src="/posts/59758/PoolNet.png" alt="PoolNet"></p><ul><li>PPM由 4 个用于捕捉输入图像的上下文信息的副分支组成。第一和最后的副分支分别是一个恒等映射层(绿色)和一个全局平均池化层(红色)。对于中间的 2 个副分支，我们采用了自适应平均池化层以保证他们的输出特征图分别具有 3 <em>×</em> 3 与 5 <em>×</em> 5 的空间尺寸。池化之后通过1*1的卷积将通道数降低，接着通过双线性插值进行上采样，最后同原特征图在channel维度上进行拼接。其他工作中，往U型网络中插入多尺度上下文提取模块是比较常见的(插在encoder与decoder之间)，不过文中认为这么做有个问题，也就是这种信息的强化只对接近PPM的decoder块影响较大，而在逐步上采样过程中这种强化又被稀释了。因此，本文的做法是，把这个PPM模块给单独作为一个分支，然后以恒等映射的方式将特征送回解码器的各个阶段，这样就可以缓解稀释的问题。</li></ul><p><img src="/posts/59758/PoolNet%E2%80%94%E2%80%94PPM.png" alt="PoolNet——PPM"></p><ul><li>使用U型网络，在自顶向下的过程中添加了feature aggregation module（FAM特征聚合模块），其目的是为了将GGFs传播的粗糙的特征图与金字塔中不同尺度的精细的特征图更好地融合。FAM将融合后的特征图作为输入，使得从GGM中获得的粗糙特征可以同各种尺度的特征无缝融合。这个模块首先将融合的特征图转换到多个特征空间，以捕捉不同尺度下局部上下文信息；之后，将融合后的信息进行组合，以更好地对融合后的输入特征图的组成部分进行加权。</li></ul><p><img src="/posts/59758/PoolNet%E2%80%94%E2%80%94FAM.png" alt="PoolNet——FAM"></p><ul><li>FAM包含四个分支。它的输入包含三个部分：上一层的特征图的上采样，encoder中的同层次的特征图，以及来自PPM的高维特征图的上采样，三者叠加之后作为输入。将输入的特征图进行不同比例的下采样，然后进行平均池化，接着进行3x3的卷积和上采样，借此将特征图转换到不同的尺度空间，然后直接上采样，叠加到一起，最后进行3x3的卷积。FAM有两个优点：首先，有助于减小上采样产生的混叠效应；其次，其允许每个空间位置查看不同尺度空间下的局部上下文，进一步增大整个网络的感受野。我的理解是GGFs从基础网络最后得到的特征图经过金字塔池化之后需要最高是8倍上采样才能与前面的特征图融合，这样高倍数的采样确实容易引入杂质，作者就是因为这样才会提出FAM，进行特征整合，先把特征用不同倍数的下采样，池化之后，再用不同倍数的上采样，最后叠加在一起。因为单个高倍数上采样容易导致失真，所以补救措施就是高倍数上采样之后，再不同比例地下采样，再平均池化，再上采样，这样平均下来可以弥补错误。</li></ul><p><img src="/posts/59758/PoolNet%E2%80%94%E2%80%94FAM_res.png" alt="PoolNet——FAM_res"></p><ul><li><em><strong>与边缘检测任务联合训练</strong></em>。在FAMs之后增加了3个残差模块，分别进行边缘检测任务。（这个我觉得可以重点考虑将来也进行多任务学习。）</li></ul><p><img src="/posts/59758/PoolNet%E2%80%94%E2%80%94joint_train.png" alt="PoolNet——joint_train"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>以特征金字塔网络(FPNs)为基础，GGM和FAM两个模块将高维度的语义特征逐步改善、精细化，最后产生细节丰富的显著性图。</li><li>通过端到端的训练方式联合训练我们的网络和标准边缘检测任务可以极大地增强检测到的显著目标的细节。</li><li>PoolNet是第一篇通过研究如何设计多样的基于池化的模块以协助提升显著性物体检测性能的文章。</li><li>PoolNet的速度很快，且训练迅速（5000张400*300的训练集训练时间少于6小时，这是因为对池化技术的有效利用）。</li></ul><p><img src="/posts/59758/PoolNet%E2%80%94%E2%80%94FPS.png" alt="PoolNet——FPS"></p><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线和F-measure，MAE以及S-measure</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PiCANet论文笔记</title>
      <link href="/posts/58511.html"/>
      <url>/posts/58511.html</url>
      
        <content type="html"><![CDATA[<h1 id="PiCANet论文笔记"><a href="#PiCANet论文笔记" class="headerlink" title="PiCANet论文笔记"></a>PiCANet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Liu N ,  Han J ,  Yang M H . PiCANet: Learning Pixel-wise Contextual Attention for Saliency Detection[J].  2017.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>上下文信息对显著性目标检测很重要，但是对于一个上下文区域来说，不是所有上下文信息都是对我们的任务有意义的；因此希望可以学会有选择地关注每个像素的上下文位置。</li><li>SOD的最终目标是建模人类的视觉注意力机制，并借此检测最突出的区域或目标。</li><li>基于FCN的SOD模型中，有两种手段。第一种是从每个输入图像的区域提取上下文特征，第二种是从每个图像位置对应的感受野提取特征。但是这两种手段都会将每个上下文位置的信息整合起来，整体进行利用。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a><strong>研究的灵感</strong></h3><ul><li>许多工作将上下文区域的所有位置的视觉信息聚合成一个上下文特征来进行推断对比，但是其中不是所有信息都是有益的，一些相关区域的信息是有用的，其他的一些噪声不应该被提取。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>PiCANet为每个像素生成一个注意力图，其中每个注意力权重对应于每个上下文位置同该像素的相关性，接着就可以有选择地聚合上下文信息，构造一个加入了上下文信息的特征。</li></ul><p><img src="/posts/58511/PiCANet%E2%80%94%E2%80%94attention-map.png" alt="PiCANet——attention-map"></p><ul><li>为了整合具有不同范围的上下文，将模型分为全局和局部两种形式。上图(b)中显示的是学习到的全局注意力，它可以关注前景对象的背景或者背景中的前景物体，与全局对比机制相符合。上图(c)中显示的是学习到的局部注意力，它可以关注给定像素局部上下文中与给定像素表现相似的区域。下图(a)描述了全局PiCANet，先横向进行双向LSTM，合并(torch.cat)，再纵向进行双向LSTM，再次合并。此阶段合并了全局上下文。接着用卷积层将图像转化成[W*H，W，H]，每个channel是一个像素对全局的注意力图，然后使用softmax函数进行归一化，即可得到最终的注意力权重。接下来加权求和即可得结果（代码里不是求和，就是每个对应一点）。下图(c)描述了局部PiCANet，其他与全局类似，只是最开始只通过多层卷积让感受野符合我们的要求。</li></ul><p><img src="/posts/58511/PiCANet%E2%80%94%E2%80%94global-local.png" alt="PiCANet——global-local"></p><ul><li>将局部和全局PiCANet分层嵌入U-Net(编码解码结构，具有跳跃连接)。</li></ul><p><img src="/posts/58511/PiCANet.png" alt="PiCANet"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>提出了新的PiCANet来选择性地关注全局或局部上下文，并为每个像素构建富含信息的上下文特征。</li><li>以一种分层的方式来检测显著的对象，解码器中在多尺度的特征图上分别使用全局和局部PiCANet，使得模型可以获得从全局到局部，从粗糙到精细的加入上下文的特征。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线和F-measure以及MAE</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCF论文笔记</title>
      <link href="/posts/29592.html"/>
      <url>/posts/29592.html</url>
      
        <content type="html"><![CDATA[<h1 id="UCF论文笔记"><a href="#UCF论文笔记" class="headerlink" title="UCF论文笔记"></a>UCF论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a><strong>引用格式</strong></h3><p>[1] Zhang P , Dong W , Lu H , et al. Learning Uncertain Convolutional Features for Accurate Saliency Detection[C]&#x2F;&#x2F; 2017 IEEE International Conference on Computer Vision (ICCV). IEEE, 2017.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>显著性目标检测是计算机视觉的预处理程序，尽管有了一些进步，但是在现实场景中有许多复杂因素，因此还面临着许多困难。因此作者旨在提高模型的鲁棒性。</li><li>最初依靠的是手动制作的视觉特征和启发式的先验知识，后来使用的是基于深度学习的方法。但是DL方法缺乏可解释性，有许多不确定特征，如果不确定特征可以提供诸如显著物体的边界等信息，就可以极大地提升模型的表现。</li><li>奇怪的伪影(例如棋盘效应)对深度卷积网络可能是致命的，比如出现在FCN的输出层，训练就会失败，预测会完全错误。</li><li>dropout被证明可以提高全连接层的泛化能力，但是缺少对其它类型的层的影响的研究。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a><strong>研究的灵感</strong></h3><ul><li>棋盘效应来源于使用反卷积操作的上采样机制，如果卷积核大小不能被步长整除，反卷积操作会出现重叠问题，导致出现棋盘效应。<a href="https://distill.pub/2016/deconv-checkerboard/">https://distill.pub/2016/deconv-checkerboard/</a></li></ul><p><img src="/posts/29592/UCF%E2%80%94%E2%80%94checkerboard-artifacts.png" alt="UCF——checkerboard-artifacts"></p><ul><li>通常的反卷积操作可以看做是对输入插入零之后进行卷积操作。<a href="https://blog.csdn.net/dugudaibo/article/details/83109814">https://blog.csdn.net/dugudaibo/article/details/83109814</a></li></ul><p><img src="/posts/29592/UCF%E2%80%94%E2%80%94deconv.png" alt="UCF——deconv"></p><ul><li>伪影(artifacts)同样和深度卷积网络的不确定特征学习有关。</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法（创新点）</strong></h3><ul><li>引入reformulated dropout(R-dropout)，放在卷积层之后，二者结合可以构建一个不确定的内部特征单元的集成。dropout是在输出的结果上乘了一个二进制掩码矩阵，矩阵中的元素服从伯努利分布。R-dropout只是交换了顺序。</li></ul><p><img src="/posts/29592/UCF%E2%80%94%E2%80%94Dropout.png" alt="UCF——R-Dropout"></p><p><img src="/posts/29592/UCF%E2%80%94%E2%80%94R-Dropout.png" alt="UCF——R-Dropout"></p><ul><li>提出了有效的混合上采样方法来减轻解码器网络中反卷积操作的棋盘效应，使预测更平滑。第一个分支是将卷积核的尺寸严格限制为步长的倍数；第二个分支是通过插值方法将原图像转换到需要的尺寸，然后进行1*1的卷积；最后将两个分支叠加即可。</li></ul><p><img src="/posts/29592/UCF%E2%80%94%E2%80%94hybrid-upsample.png" alt="UCF——hybrid-upsample"></p><ul><li>模型很简单，由编码FCN（层次化的学习视觉特征）、解码FCN（渐进地上采样编码的特征图）以及softmax组成。</li></ul><p><img src="/posts/29592/UCF_model.png" alt="UCF_model"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a><strong>研究的成就</strong></h3><ul><li>本文的工作：提出了新型的深度全卷积网络，通过学习深度的不确定卷积特征，提高SOD的鲁棒性和准确性。</li><li>相比原有的显著性检测模型，UCF可以通过结合不确定特征，来更精确的进行目标边界推断。</li><li>不确定特征学习机制和混合上采样方法可以显著提升其他像素级别视觉任务的表现。</li><li>论文实现有个小trick可以尝试，最后输出channel为2的结果，一个channel是前景预测，一个channel是背景预测图，然后相减得到结果。可以将扩张和收缩之后的图（对二值图进行操作）分别和原二值图相减，即可得到扩张或收缩的部分。</li></ul><p><img src="/posts/29592/UCF%E2%80%94%E2%80%94trick.png" alt="UCF——trick"></p><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线和F-measure以及MAE</li></ul>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DSS论文笔记</title>
      <link href="/posts/14954.html"/>
      <url>/posts/14954.html</url>
      
        <content type="html"><![CDATA[<h1 id="DSS论文笔记"><a href="#DSS论文笔记" class="headerlink" title="DSS论文笔记"></a>DSS论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h3><p>[1] Hou Q , Cheng M M , Hu X , et al. Deeply Supervised Salient Object Detection with Short Connections[C]&#x2F;&#x2F; 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2017.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>近年的模型都是基于FCNs的，但是都没有特地处理尺度空间的问题。</li><li>可以精确处理尺度空间问题的整体嵌套边缘检测器（HED）为边缘检测任务提出了一个具有深度监督的跳层结构，相比通用FCNs实现了较大的提升，但 HED 在显著性检测方面性能提升不明显。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a>研究的灵感</h3><ul><li>深层的输出对高级语义特征进行编码，因此能够更好地定位显著物体所在的地方。</li><li>较浅层的输出可以捕获丰富的空间信息，保存更多的细节信息。</li><li>因此想法与FCNs中的跳跃连接结构相同，都是通过合理地结合多层次，多尺度的特征(既包括深层也包括浅层，既包括大尺寸也包括小尺寸)，来更好地改进显著性图。于是就在HED结构中将短连接引入到了跳层结构中，从较深的层引出到较浅的层，在深层语义信息的帮助下，浅层侧向输出可以既准确地预测到显著的物体又可以利用浅层侧向路径的细节特征来优化来自深层侧向路径的粗糙的预测图。</li><li>边缘检测是一个更加简单的任务，因为它不依赖于很多的高层语义表征（边缘显然是一个比较浅层的信息）。这是为什么HED 模型中具有深度监督的跳层结构不能在显著性检测任务上带来明显的提升的原因。</li><li>总体思想是将跳跃连接结构和深度监督思想都引入新模型。</li></ul><p><img src="/posts/14954/HED%E4%B8%8EDSS%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94.png" alt="HED与DSS效果对比"></p><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法</strong>（创新点）</h3><ul><li>在 HED 架构中引入短连接至跳层结构中</li><li>充分地利用了 FCNs 提取的多层次和多尺度特征，在每一层都提供了更高级的表征，而这一特性是进行分割检测所迫切需要的</li><li>我们提出了一个用于显著性物体检测的深度监督网络。我们没有将损失层直接连接到每一阶段的最后一层，而是在较浅和较深的侧面输出层之间引入了一系列的短连接。有了这些短连接，每个侧向输出层的激活都能获得突出整个显著性物体和准确定位其边界的能力。一个全连接的 CRF也被用于纠正错误的预测并进一步提高空间一致性。</li><li>高级特征可以被传送到较浅的侧向输出层中并因此可以帮助它们更好地定位最显著的区域</li><li>浅层的侧向输出层可以学习到丰富的低级特征，从而可以帮助调整深层侧向输出层产生的稀疏的、不规则的预测图</li><li>通过结合不同层次的特征，所形成的架构在每一层都提供了丰富的多尺度特征图，这一特性是进行有效的显著性物体检测所必需的。</li></ul><p><img src="/posts/14954/%E5%90%84%E7%A7%8D%E8%BF%9E%E6%8E%A5%E7%BB%93%E6%9E%84.png" alt="各种连接结构"></p><p><img src="/posts/14954/DSS%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="DSS结构示意图"></p><p><img src="/posts/14954/%E7%9F%AD%E8%BF%9E%E6%8E%A5%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="短连接示意图"></p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a>研究的成就</h3><ul><li>本文的工作：建立了端到端的深层次显著性网络，这是一种两阶段模型。第一阶段：显著性物体定位阶段；第二阶段：细节特征精炼阶段。在第二阶段中，将短连接从深层侧向输入引入到浅层侧向输出，以生成精细的显著性图。此外也使用了深度监督的思想，构造了side_loss和fusion_loss。它输入图片和groun-truth，输出显著性图。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR曲线和F-measure以及MAE</li></ul><p><img src="/posts/14954/DSS_PR.png" alt="DSS_PR"></p><p><img src="/posts/14954/DSS_F&MAE.png" alt="DSS_F"></p>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DHSNet论文笔记</title>
      <link href="/posts/4668.html"/>
      <url>/posts/4668.html</url>
      
        <content type="html"><![CDATA[<h1 id="DHSNet论文笔记"><a href="#DHSNet论文笔记" class="headerlink" title="DHSNet论文笔记"></a>DHSNet论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h3><p>［1］Liu N, Han J. Dhsnet: Deep hierarchical saliency network for salient object detection[C]&#x2F;&#x2F;Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 678-686.</p><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>传统SOD模型的缺点是要手动提取特征，来制定对比和各种先验知识，再人工把他们组合，效果好坏全靠人的经验。</li><li>传统方法靠显著性线索(文中列举了两类)。以对比为例子，目标是评估每个图片区域或图像像素相对于全局或局部上下文的独特性。其中局部对比法常关注物体边界而忽略了物体内部，全局对比法可以得到物体均匀地内部。但是全局对比法难以保全物体细节，且难以检测大目标和具有复杂纹理的目标，尤其是前景与背景很相似或背景很凌乱的时候。此外，全局对比方法最大的缺点是：通常靠手工提取的特征和人类设计的机制去构造对比，效果的好坏全部取决于人类有限的视觉注意力方面的知识。因此在不同场景表现不一，泛化能力差。</li><li>以三个先验为例（背景先验，紧凑先验，物体先验）。这两类的缺点都是靠经验靠人。此外，传统方法还会组合线索，但现有的组合方法（简单组合机制或浅层学习模型如CRF）难以发掘不同线索之间的深层联系，且为了保存细节使用的OP和过分割的缺点是费时间，效率低。</li><li>为了解决需要靠人类经验提取特征，运算速度慢，无法发掘线索间深层联系。发明了第一阶段。在第一阶段中，首先对全局视觉使用CNN，去粗略的检测和定位目标。好处是可以自动学习特征表示和各种全局的显著性线索以及它们的最优组合。</li><li>为了解决生成的显著性图太粗糙的问题（因为运算中损失了诸如物体边界的细节信息）。发明了第二阶段。在第二阶段中，接着使用HRCNN结合局部上下文，进一步改进显著性图。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a>研究的灵感</h3><ul><li><p>前人的工作同样使用了“渐进地改善显著性图的细节”的思想，但是使用的方法是deconvolution和unpooling。</p></li><li><p>前人工作的缺陷：没有优先考虑全局上下文，然后将局部区域分开进行处理，这样使得不同区域间的潜在联系没有被发掘。于是模型无法学到足够的全局信息。</p></li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法</strong>（创新点）</h3><p><img src="/posts/4668/DHSNet%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84.png" alt="DHSNet模型结构"></p><ul><li>使用GV-CNN</li></ul><p>使用VGG提取图像的深度特征。13个conv+4个pooling+1个FC+1个reshape。</p><ul><li>使用HRCNN</li></ul><p>只有GV-CNN是不够的：池化层丢弃了一些空间信息，而且全连接层参数的数量随着SMG尺寸的扩大而线性增长，使得训练很难，所以只能选择小尺寸的SMG，因此SMG的图像细节（比如物体边界和细微结构）无法满足要求。于是有了HRCNN。</p><p>VGG中某一组操作的结果进行1x1的卷积(64个kernel)，然后sigmoid激活，和上采样后（SMG不用上采样）的显著性图叠加（变成[65，W，H]）然后在进行RCL。用64个的1x1的激活函数为sigmoid的卷积层对VGG的特征图进行卷积的目的一方面是为了减少了feature map的数量，以至于可以减小计算量；另一方面是使用sigmoid可以将两张图都压缩到[0,1]，使两张图的影响力相当。对[65,W,H]使用RCL之后进行1x1卷积，sigmoid激活，得到最终的显著性图。</p><ul><li>采用了深度监督的思想：将ground-truth从224到28变化，去监督每一步的学习。</li></ul><p>卷积神经网络有一些问题：</p><p>1）中间隐藏层不透明;</p><p>2）早期阶段学习到的特征的辨别力和稳健性影响很大;</p><p>3）存在梯度消失，梯度爆炸，难以收敛等问题。</p><p>此外作者观察到提取的特征的区分能力越强，那分类器的性能就越好；因此作者试图使用深度监督思想，也就是在深度神经网络的某些中间隐藏层加了一个辅助的分类器（例如SVM或Softmax等）作为一种网络分支来对主干网络进行监督的技巧，例如本文中在每一个中间层添加了伴随目标函数。</p><p>1）这样的辅助loss可以起到一种类似正则化的效果；</p><p>2）可以用来解决深度神经网络训练梯度消失和收敛速度过慢等问题；</p><p>3）此外，这种辅助的分支分类器能够起到一种判断隐藏层特征图质量好坏的作用，方便网络提取出区分力更强的特征。</p><ul><li>使用RCL</li></ul><p><img src="/posts/4668/%E7%B2%BE%E7%BB%86%E5%8C%96%E9%98%B6%E6%AE%B5%E6%93%8D%E4%BD%9C.png" alt="精细化阶段操作"></p><p>当T&#x3D;0的时候会保存一个input为iT0，然后T&#x3D;1到T&#x3D;3进行3次卷积，每次卷积的输入会用到iT0和上一次的卷积的输入iTn-1的和（纯粹意义上的和），结果得到iTn，iT0的值是不变的。</p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a>研究的成就</h3><ul><li><p>本文的工作：建立了端到端的深层次显著性网络，这是一种两阶段模型。第一阶段：自动学习各种全局结构的显著性线索，生成粗糙的全局预测。第二阶段：使用层次递归卷积神经网络，通过一步步地整合局部上下文信息，更层次化地，更渐进地改进显著性图的细节。它输入图片和groun-truth，输出显著性图。</p></li><li><p>提出了端到端的显著性检测模型——DHSNet，它可以同时学习有效的特征表示、信息显著性线索、从全局视角学习它们最优的组合机制，然后可以学习如何改进显著图细节。DHSNet将全卷积分类网络应用到分割任务中，并且将不同分辨率的层相互融合（上采样之后融合），显著地提高了最先进的研究水平，同时化简并加速了模型的学习和推理。</p></li><li><p>提出了层次化改进模型——HRCNN，可以在不使用过分割的情况下，结合局部上下文层次化的，渐进的改进显著图，来恢复图片细节。它也可以被用于其他像素到像素的任务。HRCNN中使用的RCLs增强了模型整合上下文信息的能力，还限制了参数的数量。</p></li><li><p>提出了未来的四个方向：建立有意义的特征表示；同时开发所有显著性线索；找到最佳的线索整合策略；高效的保护细节信息。</p></li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>PR和F-measure</li></ul><p><img src="/posts/4668/DHSNet%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C.png" alt="DHSNet模型效果"></p><p><img src="/posts/4668/%E6%AF%8F%E4%B8%80%E6%AD%A5%E9%AA%A4%E6%98%BE%E8%91%97%E5%9B%BE%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96.png" alt="每一步骤显著图的可视化"></p><p><img src="/posts/4668/DHSNet%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.png" alt="DHSNet评价指标"></p>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FCN论文笔记</title>
      <link href="/posts/14036.html"/>
      <url>/posts/14036.html</url>
      
        <content type="html"><![CDATA[<h1 id="FCN论文笔记"><a href="#FCN论文笔记" class="headerlink" title="FCN论文笔记"></a>FCN论文笔记</h1><h3 id="引用格式"><a href="#引用格式" class="headerlink" title="引用格式"></a>引用格式</h3><p>［1］Evan Shelhamer,Jonathan Long,Trevor Darrell．Fully Convolutional Networks for Semantic Segmentation[J]．IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(4):640-651</p><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li>成就：证明了端到端，像素到像素的训练方式下的卷积神经网络超过了现有语义分割方向最先进的技术</li><li>思想：使用全卷积网络，输入任意尺寸图像，输出一样尺寸的图像</li><li>方法：将当前分类网络改成全卷积网络，然后进行微调，用跳跃连接结构将全局信息和局部信息结合，互补。</li><li>结果：FCN超过了state-of-the-arts</li></ul><h3 id="研究的背景"><a href="#研究的背景" class="headerlink" title="研究的背景"></a><strong>研究的背景</strong></h3><ul><li>全连接网络固定了输入的尺寸和维度，丢失了二维图片大量的空间信息。</li><li>全连接网络的无法输出图像。</li><li>全连接网络的参数太多，太耗时间和运算。</li><li>以往的方法效率低，而且需要前期或者后期处理。</li><li>全局信息解决了”是什么”，局部信息解决了“在哪里”，但是以往的方法语义和位置信息不可兼得。</li></ul><h3 id="研究的灵感"><a href="#研究的灵感" class="headerlink" title="研究的灵感"></a>研究的灵感</h3><p>全连接的网络可以被看做一个卷积核是和图片同样大的尺寸的卷积网络。（特殊到一般）</p><h3 id="研究的成就"><a href="#研究的成就" class="headerlink" title="研究的成就"></a>研究的成就</h3><ul><li>三个创新点</li><li>实现了dense-prediction，即对每个像素做分类预测</li><li>证明了端到端，像素到像素的训练方式下的卷积神经网络超过了现有语义分割方向最先进的技术</li><li>FCN成为了PASCAL VOC最好的分割方法，比2011和2012分割算法的MIoU提高了近20%</li><li>显著的降低了运算量和参数数量（卷积层替代全连接层实现了参数共享）</li><li>保留了空间信息（输入的图片不必被压缩成一维向量，这就保留了像素之间的二维空间信息）</li><li>可以输入任意尺寸图片并且可以输出相应尺寸的图片作为结果</li></ul><h3 id="使用的方法（创新点）"><a href="#使用的方法（创新点）" class="headerlink" title="使用的方法（创新点）"></a><strong>使用的方法</strong>（创新点）</h3><ul><li>将分类网络（VGG、AlexNet、GoogleNet等）改编成为全卷积网络，其中全连接层转化成了卷积层，上采样操作通过反卷积实现。</li><li>使用迁移学习的方法，在预训练网络的基础上进行了微调。</li><li>使用了跳跃连接结构使得网络深层的全局信息（是什么）和网络浅层的局部信息（在哪里）相结合，产生准确且精细的分割。其中，深层特征帮助浅层特征更好地定位，浅层特征帮助深层特征更好地完善细节（精细化）。</li></ul><h3 id="训练的trick"><a href="#训练的trick" class="headerlink" title="训练的trick"></a>训练的trick</h3><ul><li>加载预训练模型</li><li>初始化反卷积的参数</li><li>至少要175epoch</li><li>学习率在100轮之后再进行调整</li><li>不必进行2s和4s，因为出现了负反馈</li><li>minibatch为20，优化器是SGD+0.9动量，学习率是10^-3^,10^-4^,5^-5^，使用了Dropout。</li></ul><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h3><ul><li>pixel accuracy</li><li>mean accuracy</li><li>mean IU：计算真实值和预测值两个集合的交集和并集之比</li><li>frequency weighted IU</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>将全卷积分类网络应用到分割任务中，并且将不同分辨率的层相互融合（上采样之后融合），显著地提高了最先进的研究水平，同时化简并加速了模型的学习和推理。</p><p><img src="/posts/14036/FCN%E6%A8%A1%E5%9E%8B%E5%8D%B7%E7%A7%AF%E9%98%B6%E6%AE%B5.png" alt="FCN模型卷积阶段"></p><p><img src="/posts/14036/FCN%E6%A8%A1%E5%9E%8B%E8%B7%B3%E8%B7%83%E8%BF%9E%E6%8E%A5%E9%98%B6%E6%AE%B5.png" alt="FCN模型跳跃连接阶段"></p><p><img src="/posts/14036/FCN%E4%B8%8ECNN%E5%AF%B9%E6%AF%94.png" alt="FCN与CNN对比"></p>]]></content>
      
      
      <categories>
          
          <category> salient object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> salient object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书笔记</title>
      <link href="/posts/51847.html"/>
      <url>/posts/51847.html</url>
      
        <content type="html"><![CDATA[<h1 id="读书笔记"><a href="#读书笔记" class="headerlink" title="读书笔记"></a>读书笔记</h1><p>这一篇博客用于记录日常阅读中摘录的好的句子。从2022.2.2开始，希望从此之后阅读可以一直陪伴我的余生。</p><p>谨以此句勉励未来的自己：</p><p><strong>你太急切地想要一个答案了。想要风光的学位，瞬间的博学，想要意气风发，想闪着金光走向喜欢的人。</strong></p><p><strong>但现实告诉我，操之过急便会败北。它要我等，要我耐得住不断延长的时间线，要我交付出足够的努力堆砌在沉闷、晦涩的时光里，才肯将一切“我想要”一点一点递送至我手里。</strong></p><h2 id="爱的艺术"><a href="#爱的艺术" class="headerlink" title="爱的艺术"></a>爱的艺术</h2><h2 id="爱情笔记"><a href="#爱情笔记" class="headerlink" title="爱情笔记"></a>爱情笔记</h2><h2 id="百年孤独"><a href="#百年孤独" class="headerlink" title="百年孤独"></a>百年孤独</h2><h2 id="被讨厌的勇气"><a href="#被讨厌的勇气" class="headerlink" title="被讨厌的勇气"></a>被讨厌的勇气</h2><h2 id="表征：文化表象与意指实践"><a href="#表征：文化表象与意指实践" class="headerlink" title="表征：文化表象与意指实践"></a>表征：文化表象与意指实践</h2><h2 id="不能承受的生命之轻"><a href="#不能承受的生命之轻" class="headerlink" title="不能承受的生命之轻"></a>不能承受的生命之轻</h2><h2 id="非暴力沟通"><a href="#非暴力沟通" class="headerlink" title="非暴力沟通"></a>非暴力沟通</h2><h2 id="富爸爸穷爸爸"><a href="#富爸爸穷爸爸" class="headerlink" title="富爸爸穷爸爸"></a>富爸爸穷爸爸</h2><h2 id="蛤蟆先生去看心理医生"><a href="#蛤蟆先生去看心理医生" class="headerlink" title="蛤蟆先生去看心理医生"></a>蛤蟆先生去看心理医生</h2><h2 id="孩子你慢慢来"><a href="#孩子你慢慢来" class="headerlink" title="孩子你慢慢来"></a>孩子你慢慢来</h2><h2 id="荒原狼"><a href="#荒原狼" class="headerlink" title="荒原狼"></a>荒原狼</h2><h2 id="恋人絮语"><a href="#恋人絮语" class="headerlink" title="恋人絮语"></a>恋人絮语</h2><h2 id="目送"><a href="#目送" class="headerlink" title="目送"></a>目送</h2><h2 id="那些古怪又让人忧心的问题"><a href="#那些古怪又让人忧心的问题" class="headerlink" title="那些古怪又让人忧心的问题"></a>那些古怪又让人忧心的问题</h2><h2 id="能力陷阱"><a href="#能力陷阱" class="headerlink" title="能力陷阱"></a>能力陷阱</h2><h2 id="批判性思维"><a href="#批判性思维" class="headerlink" title="批判性思维"></a>批判性思维</h2><h2 id="强迫症的森田疗法"><a href="#强迫症的森田疗法" class="headerlink" title="强迫症的森田疗法"></a>强迫症的森田疗法</h2><h2 id="亲爱的安德烈"><a href="#亲爱的安德烈" class="headerlink" title="亲爱的安德烈"></a>亲爱的安德烈</h2><h2 id="亲密关系"><a href="#亲密关系" class="headerlink" title="亲密关系"></a>亲密关系</h2><h2 id="人类简史"><a href="#人类简史" class="headerlink" title="人类简史"></a>人类简史</h2><h2 id="人类群星闪耀时"><a href="#人类群星闪耀时" class="headerlink" title="人类群星闪耀时"></a>人类群星闪耀时</h2><h2 id="人生的智慧"><a href="#人生的智慧" class="headerlink" title="人生的智慧"></a>人生的智慧</h2><h2 id="杀死一只知更鸟"><a href="#杀死一只知更鸟" class="headerlink" title="杀死一只知更鸟"></a>杀死一只知更鸟</h2><h2 id="时间从来不语，却回答了所有问题"><a href="#时间从来不语，却回答了所有问题" class="headerlink" title="时间从来不语，却回答了所有问题"></a>时间从来不语，却回答了所有问题</h2><h2 id="斯坦福高效睡眠法"><a href="#斯坦福高效睡眠法" class="headerlink" title="斯坦福高效睡眠法"></a>斯坦福高效睡眠法</h2><h2 id="死水恶波"><a href="#死水恶波" class="headerlink" title="死水恶波"></a>死水恶波</h2><h2 id="天才在左疯子在右"><a href="#天才在左疯子在右" class="headerlink" title="天才在左疯子在右"></a>天才在左疯子在右</h2><h2 id="拖延心理学"><a href="#拖延心理学" class="headerlink" title="拖延心理学"></a>拖延心理学</h2><h2 id="未来简史"><a href="#未来简史" class="headerlink" title="未来简史"></a>未来简史</h2><h2 id="文化理论与大众文化导论"><a href="#文化理论与大众文化导论" class="headerlink" title="文化理论与大众文化导论"></a>文化理论与大众文化导论</h2><h2 id="乌合之众"><a href="#乌合之众" class="headerlink" title="乌合之众"></a>乌合之众</h2><h2 id="一个笔记本搞定你的拖延症"><a href="#一个笔记本搞定你的拖延症" class="headerlink" title="一个笔记本搞定你的拖延症"></a>一个笔记本搞定你的拖延症</h2><h2 id="优秀的绵羊"><a href="#优秀的绵羊" class="headerlink" title="优秀的绵羊"></a>优秀的绵羊</h2><h2 id="月亮和六便士"><a href="#月亮和六便士" class="headerlink" title="月亮和六便士"></a>月亮和六便士</h2><h2 id="自卑与超越：你要清楚自己应该怎样过好这一生"><a href="#自卑与超越：你要清楚自己应该怎样过好这一生" class="headerlink" title="自卑与超越：你要清楚自己应该怎样过好这一生"></a>自卑与超越：你要清楚自己应该怎样过好这一生</h2><p>我相信这世界上一定有这样的天才：他们的出现就是为了引领时代的潮流，将整个人类文明引导向某个方向；但是对于我们这种普通人来讲，时代的一粒微尘就是一座大山，顺应时代的发展才有成功的可能性，逆势而为只会把我们压得粉身碎骨，正是因此，对于我们来说，选择才大于努力。</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo-Theme-LiveMyLife</title>
      <link href="/posts/37674.html"/>
      <url>/posts/37674.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>移植 <a href="https://github.com/Huxpro/huxpro.github.io">Hux Blog</a> 的主题，感谢 <a href="https://github.com/Huxpro">Huxpro</a> 设计了如此完美的主题。</p><p>由 <a href="https://v-vincen.github.io/">Vincent</a> 创建的 LiveMyLife 的主题修改来源 <a href="https://github.com/YenYuHsuan/hexo-theme-beantech">YenYuHsuan</a>，参考主题 <a href="https://github.com/dusign/hexo-theme-snail">dusign</a>、<a href="https://github.com/shixiaohu2206/hexo-theme-huhu">Utone</a>，感谢 <a href="https://github.com/dusign/hexo-theme-snail">dusign</a>、<a href="https://github.com/shixiaohu2206/hexo-theme-huhu">Utone</a>。</p></blockquote><h2 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h2><p>Github 仓库地址：<a href="https://github.com/V-Vincen/hexo-theme-livemylife">https://github.com/V-Vincen/hexo-theme-livemylife</a><br>Gitee 仓库地址：<a href="https://gitee.com/V_Vincen/hexo-theme-livemylife">https://gitee.com/V_Vincen/hexo-theme-livemylife</a></p><h3 id="预览-LiveMyLife-博客-➾"><a href="#预览-LiveMyLife-博客-➾" class="headerlink" title="预览 LiveMyLife 博客 ➾"></a><a href="https://v-vincen.github.io/">预览 LiveMyLife 博客 ➾</a></h3><p><img src="/posts/37674/livemylife-desktop.png" alt="LiveMyLife Desktop"></p><h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><p>为了方便起见，我发布了整个项目，因此您可以按照下面的说明进行操作，然后就可以轻松自定义您自己的博客！</p><p>让我们开始!!!</p><h3 id="安装-Node-js-和-Git"><a href="#安装-Node-js-和-Git" class="headerlink" title="安装 Node.js 和 Git"></a>安装 Node.js 和 Git</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">For Mac</span></span><br><span class="line">brew install node</span><br><span class="line">brew install git</span><br></pre></td></tr></table></figure><blockquote><p>Windows：下载 &amp; 安装 Node.js。-&gt; <a href="https://nodejs.org/zh-cn/download/">Node.js</a></p><p>Windows：下载 &amp; 安装 Git。-&gt; <a href="https://git-scm.com/download/win">Git</a></p></blockquote><h3 id="安装-Hexo"><a href="#安装-Hexo" class="headerlink" title="安装 Hexo"></a>安装 Hexo</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install -g hexo-cli</span></span><br></pre></td></tr></table></figure><blockquote><p>什么是 <a href="https://hexo.io/docs/">Hexo</a>?</p><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p></blockquote><h3 id="设置你的博客"><a href="#设置你的博客" class="headerlink" title="设置你的博客"></a>设置你的博客</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo init blog</span></span><br></pre></td></tr></table></figure><blockquote><p>更多的命令 -&gt; <a href="https://hexo.io/docs/commands">Hexo Commands</a></p></blockquote><h2 id="主题使用"><a href="#主题使用" class="headerlink" title="主题使用"></a>主题使用</h2><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd blog</span><br><span class="line">rm -rf scaffolds source themes _config.landscape.yml _config.yml package.json yarn.lock #just keep node_modules</span><br><span class="line">git clone https://github.com/V-Vincen/hexo-theme-livemylife.git</span><br><span class="line">mv hexo-theme-livemylife/* ./</span><br><span class="line">rm -rf hexo-theme-livemylife</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><h3 id="设置主题"><a href="#设置主题" class="headerlink" title="设置主题"></a>设置主题</h3><p>修改 <code>theme</code> 属性值，在 <code>_config.yml</code> 配置文件中。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="attr">theme:</span> <span class="string">livemylife</span></span><br></pre></td></tr></table></figure><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo generate # or hexo g</span><br><span class="line">hexo server   # or hexo s</span><br></pre></td></tr></table></figure><p>启动本地服务器。 默认访问地址 <code>http://localhost:4000/</code>。</p><blockquote><p>更多命令 -&gt; <a href="https://hexo.io/docs/commands">Hexo Commands</a></p></blockquote><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>使用您自己的信息修改 <code>_config.yml</code> 配置文件，尤其是以下部分：</p><h3 id="网址信息配置"><a href="#网址信息配置" class="headerlink" title="网址信息配置"></a>网址信息配置</h3><p>将以下信息替换为您自己的信息。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Site</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">Live</span> <span class="string">My</span> <span class="string">Life</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">淡而无味也是一种味道</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Mr.Vincent</span></span><br><span class="line"><span class="attr">timezone:</span></span><br></pre></td></tr></table></figure><h3 id="语言国际化-i18n"><a href="#语言国际化-i18n" class="headerlink" title="语言国际化 (i18n)"></a>语言国际化 (i18n)</h3><p>若要让您的网站以不同语言呈现，您可使用国际化（internationalization）功能。-&gt; 文档：<a href="https://v-vincen.github.io/en/How-to-Use-Internationalization%EF%BC%88i18n%EF%BC%89/">How to Use Internationalization（i18n）</a></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Internationalization (i18n) Setting</span></span><br><span class="line"><span class="attr">language:</span> <span class="comment"># At present, only en、cn and tw are supported. You can customize the language，refer to `languages/en.yml`.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">en</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">cn</span></span><br><span class="line"></span><br><span class="line"><span class="attr">langselect:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># If open, it will automatically generation lang-select button.This button can jump in articles in different languages, but the articles must have the same name.</span></span><br><span class="line">  <span class="attr">options:</span> <span class="comment"># langselect button display options</span></span><br><span class="line">    <span class="attr">en:</span> <span class="string">English</span></span><br><span class="line">    <span class="attr">cn:</span> <span class="string">简体中文</span></span><br><span class="line">    <span class="comment"># tw: 正體中文</span></span><br><span class="line"></span><br><span class="line"><span class="attr">i18n_dir:</span> <span class="string">:lang</span>  </span><br><span class="line"><span class="attr">permalink:</span> <span class="string">:lang/:title/</span> </span><br><span class="line"><span class="attr">new_post_name:</span> <span class="string">:lang/:title.md</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hexo-generator-i18n config</span></span><br><span class="line"><span class="comment">## Docs: https://github.com/xcatliu/hexo-generator-index-i18n</span></span><br><span class="line"><span class="attr">index_generator:</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">pagination_dir:</span> <span class="string">page</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="attr">order_by:</span> <span class="string">-date</span></span><br><span class="line"></span><br><span class="line"><span class="attr">archive_generator:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">yearly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">monthly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">daily:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">order_by:</span> <span class="string">-date</span></span><br></pre></td></tr></table></figure><p><em>English 预览：</em></p><p><img src="/posts/37674/langen.png" alt="en"></p><p><em>Chinese 预览：</em></p><p><img src="/posts/37674/langcn.png" alt="cn"></p><h3 id="CDN-配置"><a href="#CDN-配置" class="headerlink" title="CDN 配置"></a>CDN 配置</h3><p>JsDelivr JsDelivr是一种免费，快速，可靠和自动化的CDN，可用于开源。如何使用 Jsdelivr？-&gt; 文档：<a href="https://v-vincen.github.io/en/Github-%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96/#%E5%85%8D%E8%B4%B9-CDN-%E6%8F%90%E9%80%9F-Github-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE">免费 CDN 提速 Github 静态资源访问</a></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CDN Setting</span></span><br><span class="line"><span class="comment"># Docs: https://www.jsdelivr.com/?docs=gh</span></span><br><span class="line"><span class="comment"># If Github Pages deploy，you can ues jsdelivr settings</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">jsdelivr:</span></span><br><span class="line">  <span class="attr">jsdelivr_url:</span> <span class="string">https://cdn.jsdelivr.net/gh/</span></span><br><span class="line">  <span class="attr">github_username:</span> <span class="string">V-Vincen</span></span><br></pre></td></tr></table></figure><p><strong>注意：</strong> Hexo-theme-livemylife 主题中有大量的 css、js 和 images，为了提高访问速度，主题中所有资源文件都使用了 JsDelivr CDN（内容分发）。但仅适用于 Github Pages 部署方式。-&gt; 文档：<a href="https://v-vincen.github.io/en/How-to-apply-JsDelivr-CDN-in-Hexo-theme-livemylife-Theme/">How to apply JsDelivr CDN in Hexo-theme-livemylife Theme</a></p><h3 id="站点设置"><a href="#站点设置" class="headerlink" title="站点设置"></a>站点设置</h3><p>将自定义图片放在 <code>img</code> 目录中。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Site settings</span></span><br><span class="line"><span class="attr">SEOTitle:</span> <span class="string">JavaDev</span> <span class="string">|</span> <span class="string">一如Java深似海</span></span><br><span class="line"><span class="attr">email:</span> <span class="string">hexo-theme-livemylife@mail.com</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&quot;It&#x27;s an IT blog...&quot;</span></span><br><span class="line"><span class="attr">keyword:</span> <span class="string">&quot;Java,v-vincen,v-vincen,livemylife,IT  blog,Blog&quot;</span></span><br><span class="line"><span class="attr">header-img:</span> <span class="string">img/header_img/newhome_bg.jpg</span></span><br><span class="line"><span class="attr">archives-img:</span> <span class="string">img/header_img/archive_bg2.jpg</span></span><br></pre></td></tr></table></figure><h3 id="网站图标设置"><a href="#网站图标设置" class="headerlink" title="网站图标设置"></a>网站图标设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">favicon:</span> <span class="string">img/avatar/favicon.jpg</span></span><br></pre></td></tr></table></figure><h3 id="签名设置"><a href="#签名设置" class="headerlink" title="签名设置"></a>签名设置</h3><p>将您的签名图片复制到 <code>&lt;root&gt;/img/signature</code> 并修改配置文件 <code>_config.yml</code>。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">signature:</span> <span class="literal">true</span>   <span class="comment"># show signature</span></span><br><span class="line"><span class="attr">signature-img:</span> <span class="string">img/signature/&lt;your-signature&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>如何制作签名 -&gt; <a href="https://fontmeme.com/signature-fonts/">Free Online Signature</a></p></blockquote><h3 id="波浪设置"><a href="#波浪设置" class="headerlink" title="波浪设置"></a>波浪设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Wave settings</span></span><br><span class="line"><span class="attr">wave:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><em>案例：</em></p><p><img src="/posts/37674/wave.png" alt="wave"></p><h3 id="社交网络服务设置"><a href="#社交网络服务设置" class="headerlink" title="社交网络服务设置"></a>社交网络服务设置</h3><p>如果您不想显示它，则可以直接将其删除。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SNS settings</span></span><br><span class="line"><span class="comment"># RSS: true</span></span><br><span class="line"><span class="attr">github_username:</span> <span class="string">V-Vincen</span></span><br><span class="line"><span class="attr">twitter_username:</span> <span class="string">V_Vincen_</span></span><br><span class="line"><span class="attr">instagram_username:</span> <span class="string">V_Vincen_</span></span><br><span class="line"><span class="comment"># facebook_username:  yourAccount</span></span><br><span class="line"><span class="comment"># linkedin_username:  yourAccount</span></span><br><span class="line"><span class="comment"># zhihu_username: yourAccount</span></span><br><span class="line"><span class="attr">weibo_username:</span> <span class="string">WVincen</span></span><br></pre></td></tr></table></figure><h3 id="侧边栏设置"><a href="#侧边栏设置" class="headerlink" title="侧边栏设置"></a>侧边栏设置</h3><p>将您的头像复制到 <code>&lt;root&gt;/img/avatar</code> 并修改配置文件 <code>_config.yml</code>。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">sidebar:</span> <span class="literal">true</span>   <span class="comment"># whether or not using Sidebar.</span></span><br><span class="line"><span class="attr">sidebar-about-description:</span> <span class="string">&quot;I don&#x27;t know where I am going ,but I am on my way...&quot;</span></span><br><span class="line"><span class="attr">sidebar-avatar:</span> <span class="string">img/avatar/vincnet.jpg</span>    <span class="comment"># use absolute URL, seeing it&#x27;s used in both `/` and `/about/`</span></span><br><span class="line"><span class="attr">widgets:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">visitor</span>   <span class="comment"># busuanzi: https://busuanzi.ibruce.info/</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">featured-tags</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">short-about</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">recent-posts</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">friends-blog</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">archive</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">category</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># widget behavior</span></span><br><span class="line"><span class="comment">## Archive</span></span><br><span class="line"><span class="attr">archive_type:</span> <span class="string">&#x27;monthly&#x27;</span></span><br><span class="line"><span class="attr">show_count:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Featured Tags</span></span><br><span class="line"><span class="attr">featured-tags:</span> <span class="literal">true</span>   <span class="comment"># whether or not using Feature-Tags</span></span><br><span class="line"><span class="attr">featured-condition-size:</span> <span class="number">0</span>    <span class="comment"># A tag will be featured if the size of it is more than this</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Friends</span></span><br><span class="line"><span class="attr">friends:</span> [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">title:</span> <span class="string">&quot;V_Vincen&quot;</span>,</span><br><span class="line">        <span class="attr">href:</span> <span class="string">&quot;https://v-vincen.life/&quot;</span></span><br><span class="line">    &#125;,&#123;</span><br><span class="line">        <span class="attr">title:</span> <span class="string">&quot;Teacher Ye&quot;</span>,</span><br><span class="line">        <span class="attr">href:</span> <span class="string">&quot;http://teacherye.com/&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h3 id="评论系统设置"><a href="#评论系统设置" class="headerlink" title="评论系统设置"></a>评论系统设置</h3><p>Hexo-Theme-LiveMyLife 主题暂时支持三种评论方式。我使用 gitalk 为默认评论系统。</p><h4 id="Gitalk"><a href="#Gitalk" class="headerlink" title="Gitalk"></a>Gitalk</h4><p>Gitalk 是基于 GitHub Issue 和 Preact 的现代化的评论组件。 有关详细的配置方法，请参考 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 官方文档。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gitalk Settings</span></span><br><span class="line"><span class="comment"># Doc: https://github.com/gitalk/gitalk/blob/master/readme-cn.md</span></span><br><span class="line"><span class="attr">gitalk:</span></span><br><span class="line">  <span class="attr">owner:</span>                          <span class="comment"># &#x27;GitHub repo owner&#x27;</span></span><br><span class="line">  <span class="attr">admin:</span>                          <span class="comment"># [&#x27;GitHub repo owner and collaborators, only these guys can initialize github issues&#x27;]</span></span><br><span class="line">  <span class="attr">repo:</span>                           <span class="comment"># &#x27;GitHub repo&#x27;</span></span><br><span class="line">  <span class="attr">clientID:</span>                       <span class="comment"># &#x27;GitHub Application Client ID&#x27;</span></span><br><span class="line">  <span class="attr">clientSecret:</span>                   <span class="comment"># &#x27;GitHub Application Client Secret&#x27;</span></span><br><span class="line">  <span class="attr">perPage:</span> <span class="number">10</span>                     <span class="comment"># Pagination size, with maximum 100.</span></span><br><span class="line">  <span class="attr">pagerDirection:</span> <span class="string">last</span>            <span class="comment"># Comment sorting direction, available values are last and first.</span></span><br><span class="line">  <span class="attr">createIssueManually:</span> <span class="literal">false</span>      <span class="comment"># By default, Gitalk will create a corresponding github issue for your every single page automatically when the logined user is belong to the admin users. You can create it manually by setting this option to true</span></span><br><span class="line">  <span class="attr">language:</span> <span class="string">en</span>                    <span class="comment"># Localization language key, en, zh-CN and zh-TW are currently available.</span></span><br><span class="line">  <span class="attr">maxCommentHeight:</span> <span class="number">250</span>           <span class="comment"># An optional number to limit comments&#x27; max height, over which comments will be folded.Default 250.</span></span><br><span class="line">  <span class="attr">proxy:</span> <span class="string">https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token</span>                         <span class="comment"># GitHub oauth request reverse proxy for CORS. For example, the demo url is &#x27;https://cors-anywhere.herokuapp.com/https://github.com/login/oauth/access_token&#x27;.You should deploy your own proxy url as in this issue https://github.com/gitalk/gitalk/issues/429.</span></span><br></pre></td></tr></table></figure><h4 id="Gitment"><a href="#Gitment" class="headerlink" title="Gitment"></a>Gitment</h4><p>Gitment 是一个基于 GitHub Issues 的评论系统，可以在前端使用它，而无需任何服务器端实现。有关详细的配置方法，请参见 <a href="https://github.com/imsun/gitment">Gitment</a> 官方文档。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Gitment Settings</span></span><br><span class="line"><span class="comment">## Doc: https://github.com/imsun/gitment</span></span><br><span class="line"><span class="attr">gitment:</span></span><br><span class="line">  <span class="attr">owner:</span>                          <span class="comment"># Your GitHub ID. Required.</span></span><br><span class="line">  <span class="attr">repo:</span>                           <span class="comment"># The repository to store your comments. Make sure you&#x27;re repo&#x27;s owner. Required.</span></span><br><span class="line">  <span class="attr">client_id:</span>                      <span class="comment"># GitHub client ID. Required.</span></span><br><span class="line">  <span class="attr">client_secret:</span>                  <span class="comment"># GitHub client secret. Required.</span></span><br><span class="line">  <span class="attr">desc:</span>                           <span class="comment"># An optional description for your page, used in issue&#x27;s body. Default &#x27;&#x27;.</span></span><br><span class="line">  <span class="attr">perPage:</span> <span class="number">10</span>                     <span class="comment"># An optional number to which comments will be paginated. Default 20.</span></span><br><span class="line">  <span class="attr">maxCommentHeight:</span> <span class="number">250</span>           <span class="comment"># An optional number to limit comments&#x27; max height, over which comments will be folded. Default 250.</span></span><br></pre></td></tr></table></figure><h4 id="Disqus"><a href="#Disqus" class="headerlink" title="Disqus"></a>Disqus</h4><p>如果你想要使用 <a href="https://disqus.com/">Disqus</a> 评论系统，则必须有代理。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Disqus settings</span></span><br><span class="line"><span class="attr">disqus_username:</span> <span class="string">your-disqus-ID</span></span><br></pre></td></tr></table></figure><h3 id="站点分析设置"><a href="#站点分析设置" class="headerlink" title="站点分析设置"></a>站点分析设置</h3><p>如何配置站点分析? -&gt; 文档：<a href="https://v-vincen.github.io/en/Analytics-and-Sitemap-Settings/">Analytics and Sitemap Settings</a></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Analytics settings</span></span><br><span class="line"><span class="comment"># Google Analytics</span></span><br><span class="line"><span class="attr">ga_track_id:</span> <span class="string">UA-xxxxxx-xx</span>   <span class="comment"># Format: UA-xxxxxx-xx</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Baidu Analytics</span></span><br><span class="line"><span class="attr">ba_track_id:</span> <span class="string">ba_track_id</span></span><br></pre></td></tr></table></figure><h3 id="站点地图设置"><a href="#站点地图设置" class="headerlink" title="站点地图设置"></a>站点地图设置</h3><p>如何配置站点地图? -&gt; 文档：<a href="https://v-vincen.github.io/en/Analytics-and-Sitemap-Settings/">Analytics and Sitemap Settings</a></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Google sitemap</span></span><br><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Baidu sitemap</span></span><br><span class="line"><span class="attr">baidusitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">baidusitemap.xml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">baidu_push:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="置顶图标设置"><a href="#置顶图标设置" class="headerlink" title="置顶图标设置"></a>置顶图标设置</h3><p>我使用的置顶图标是键头，你可以在 <code>sourcre/css/images</code> 目录下替换你自己想要的图标。</p><h3 id="文章标签"><a href="#文章标签" class="headerlink" title="文章标签"></a>文章标签</h3><p>您可以选择是否显示博文标签。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">home_posts_tag:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><em>案例：</em></p><p><img src="/posts/37674/home_posts_tag-true.png" alt="home_posts_tag-true"></p><h3 id="Markdown-渲染器"><a href="#Markdown-渲染器" class="headerlink" title="Markdown 渲染器"></a>Markdown 渲染器</h3><p>我使用的 markdown 渲染引擎插件是 <a href="https://github.com/celsomiranda/hexo-renderer-markdown-it">hexo-renderer-markdown-it</a>。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Markdown-it config</span></span><br><span class="line"><span class="comment">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class="line"><span class="attr">markdown:</span></span><br><span class="line">  <span class="attr">render:</span></span><br><span class="line">    <span class="attr">html:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">linkify:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">typographer:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">quotes:</span> <span class="string">&#x27;“”‘’&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="安装-Mathjax（数学公式渲染器）"><a href="#安装-Mathjax（数学公式渲染器）" class="headerlink" title="安装 Mathjax（数学公式渲染器）"></a>安装 Mathjax（数学公式渲染器）</h3><p>要安装 Mathjax，请单击 <a href="https://v-vincen.github.io/en/How-to-Use-Mathjax/">How to Use Mathjax</a>  以获取详细的教程。</p><h3 id="Anchorjs（锚点）设置"><a href="#Anchorjs（锚点）设置" class="headerlink" title="Anchorjs（锚点）设置"></a>Anchorjs（锚点）设置</h3><p>如果你想要更改文章目录标题前部的锚点 “❡”，则可以到 <code>layout/_partial/anchorjs.ejs</code> 目录下进行更改。如何使用 anchorjs，请参阅 <a href="https://www.bryanbraun.com/anchorjs/#examples">AnchorJS</a> 以获取详细示例。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Anchorjs Settings</span></span><br><span class="line"><span class="attr">anchorjs:</span> <span class="literal">true</span>    <span class="comment"># if you want to customize anchor. check out line:26 of `anchorjs.ejs`</span></span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">async</span>(<span class="string">&quot;//cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js&quot;</span>,<span class="keyword">function</span>(<span class="params"></span>)&#123;</span><br><span class="line">        anchors.<span class="property">options</span> = &#123;</span><br><span class="line">          <span class="attr">visible</span>: <span class="string">&#x27;hover&#x27;</span>,</span><br><span class="line">          <span class="attr">placement</span>: <span class="string">&#x27;left&#x27;</span>,</span><br><span class="line">          <span class="attr">icon</span>: <span class="string">&#x27;❡&#x27;</span></span><br><span class="line">          <span class="comment">// icon: &#x27;ℬ&#x27;</span></span><br><span class="line">        &#125;;</span><br><span class="line">        anchors.<span class="title function_">add</span>().<span class="title function_">remove</span>(<span class="string">&#x27;.intro-header h1&#x27;</span>).<span class="title function_">remove</span>(<span class="string">&#x27;.subheading&#x27;</span>).<span class="title function_">remove</span>(<span class="string">&#x27;.sidebar-container h5&#x27;</span>);</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><h3 id="博文置顶"><a href="#博文置顶" class="headerlink" title="博文置顶"></a>博文置顶</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># article top</span></span><br><span class="line"><span class="attr">top:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Hexo-theme-livemylife 主题添加了文章顶部功能，只要在您的 markdown 笔记中添加属性<code>sticky: number</code> 配置，文章按此数字排序。<br><em>案例：</em></p><p><img src="/posts/37674/top.png" alt="top"></p><h3 id="文章字数统计设置"><a href="#文章字数统计设置" class="headerlink" title="文章字数统计设置"></a>文章字数统计设置</h3><p>WordCount 是 Hexo 的文章字数统计插件. 有关详细的配置方法，请参见 <a href="https://github.com/willin/hexo-wordcount">WordCount</a> 文档。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dependencies: https://github.com/willin/hexo-wordcount</span></span><br><span class="line"><span class="comment"># Docs: https://www.npmjs.com/package/hexo-wordcount</span></span><br><span class="line"><span class="attr">wordcount:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="Busuanzi（不蒜子）设置"><a href="#Busuanzi（不蒜子）设置" class="headerlink" title="Busuanzi（不蒜子）设置"></a>Busuanzi（不蒜子）设置</h3><p>Busuanzi 是一个网站流量统计插件。如何使用 Busuanzi，有关详细示例，请参见 <a href="https://ibruce.info/2015/04/04/busuanzi/">Busuanzi</a> 文档。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Dependencies: https://busuanzi.ibruce.info/</span></span><br><span class="line"><span class="comment">## Docs: https://ibruce.info/</span></span><br><span class="line"><span class="attr">busuanzi:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="顶部滚动进度条设置"><a href="#顶部滚动进度条设置" class="headerlink" title="顶部滚动进度条设置"></a>顶部滚动进度条设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># top scroll progress</span></span><br><span class="line"><span class="attr">scroll:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="著作权声明设置"><a href="#著作权声明设置" class="headerlink" title="著作权声明设置"></a>著作权声明设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tip:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">copyright:</span> <span class="string">Say</span> <span class="string">what</span> <span class="string">you</span> <span class="string">think...</span> <span class="comment"># If the copyright is blank, the default value will be used.</span></span><br></pre></td></tr></table></figure><h3 id="社交分享博文设置"><a href="#社交分享博文设置" class="headerlink" title="社交分享博文设置"></a>社交分享博文设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Docs: https://github.com/overtrue/share.js</span></span><br><span class="line"><span class="attr">share:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="Viewer（图片预览）设置"><a href="#Viewer（图片预览）设置" class="headerlink" title="Viewer（图片预览）设置"></a>Viewer（图片预览）设置</h3><p>Viewer 是一个简单的 jQuery 图片预览插件. 让我们首先看一个 <a href="https://fengyuanchen.github.io/viewer/">demo</a>。有关详细配置，请参见 <a href="https://github.com/fengyuanchen/viewer">Viewer</a> 官方文档。 如果要修改 Viewer 的 <a href="https://github.com/fengyuanchen/viewerjs#options">options</a> 设置，则可以到 <code>sourcre/js/viewer/pic-viewer.js</code> 目录下修改。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Viewer config</span></span><br><span class="line"><span class="attr">viewer:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="主题模式设置"><a href="#主题模式设置" class="headerlink" title="主题模式设置"></a>主题模式设置</h3><p>Hexo-Theme-LiveMyLife 主题暂时支持两种主题模式。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ThemeColor config</span></span><br><span class="line"><span class="attr">themecolor:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">dark</span> <span class="comment"># themecolor mode light or dark, default light</span></span><br></pre></td></tr></table></figure><p><em>明亮主题模式预览：</em></p><p><img src="/posts/37674/light.png" alt="light theme"></p><p><em>黑暗主题模式预览：</em></p><p><img src="/posts/37674/dark.png" alt="dark theme"></p><h3 id="鼠标点击效果设置"><a href="#鼠标点击效果设置" class="headerlink" title="鼠标点击效果设置"></a>鼠标点击效果设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mouseclick config</span></span><br><span class="line"><span class="attr">mouseclick:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">content:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">The</span> <span class="string">first</span> <span class="string">step</span> <span class="string">is</span> <span class="string">as</span> <span class="string">good</span> <span class="string">as</span> <span class="string">half</span> <span class="string">over...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Laugh</span> <span class="string">and</span> <span class="string">grow</span> <span class="string">fat...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Man</span> <span class="string">proposes</span> <span class="string">God</span> <span class="string">disposes...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">When</span> <span class="string">all</span> <span class="string">else</span> <span class="string">is</span> <span class="string">lost</span> <span class="string">the</span> <span class="string">future</span> <span class="string">still</span> <span class="string">remains...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Wasting</span> <span class="string">time</span> <span class="string">is</span> <span class="string">robbing</span> <span class="string">oneself...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Sharp</span> <span class="string">tools</span> <span class="string">make</span> <span class="string">good</span> <span class="string">work...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Cease</span> <span class="string">to</span> <span class="string">struggle</span> <span class="string">and</span> <span class="string">you</span> <span class="string">cease</span> <span class="string">to</span> <span class="string">live...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">A</span> <span class="string">friend</span> <span class="string">in</span> <span class="string">need</span> <span class="string">is</span> <span class="string">a</span> <span class="string">friend</span> <span class="string">indeed...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Faith</span> <span class="string">can</span> <span class="string">move</span> <span class="string">mountains...</span></span><br><span class="line">  <span class="attr">color:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#9933CC&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#339933&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#66CCCC&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#FF99CC&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#CCCCFF&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#6666CC&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#663399&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#66CC99&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;#FF0033&#x27;</span></span><br></pre></td></tr></table></figure><p><em>鼠标点击效果预览：</em></p><p><img src="/posts/37674/mouseclick.png" alt="mouseclick"></p><h3 id="背景绸带效果设置"><a href="#背景绸带效果设置" class="headerlink" title="背景绸带效果设置"></a>背景绸带效果设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ribbonDynamic:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><em>背景绸带效果预览：</em></p><p><img src="/posts/37674/ribbon.png" alt="ribbon"></p><h3 id="背景线画布效果设置"><a href="#背景线画布效果设置" class="headerlink" title="背景线画布效果设置"></a>背景线画布效果设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">bglinecanvas:</span> <span class="literal">true</span>  <span class="comment"># The special effects will take up a lot of cpu resorces, please open it carefully.</span></span><br></pre></td></tr></table></figure><p><em>背景线画布效果预览：</em></p><p><img src="/posts/37674/bglinecanvas.png" alt="bglinecanvas"></p><h3 id="搜索设置"><a href="#搜索设置" class="headerlink" title="搜索设置"></a>搜索设置</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dependencies: https://github.com/V-Vincen/hexo-generator-zip-search</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.json</span></span><br><span class="line">  <span class="attr">zipPath:</span> <span class="string">search.flv</span></span><br><span class="line">  <span class="attr">versionPath:</span> <span class="string">searchVersion.json</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="comment"># if auto, trigger search by changing input</span></span><br><span class="line">  <span class="comment"># if manual, trigger search by pressing enter key or search button</span></span><br><span class="line">  <span class="attr">trigger:</span> <span class="string">auto</span></span><br><span class="line">  <span class="comment"># show top n results per article, show all results by setting to -1</span></span><br><span class="line">  <span class="attr">top_n_per_article:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="Gitter（聊天室）"><a href="#Gitter（聊天室）" class="headerlink" title="Gitter（聊天室）"></a>Gitter（聊天室）</h3><p>Gitter 是一个聊天和网络平台，通过消息、内容和发现，帮助管理、发展和连接社区。 详细配置方法请查看 <a href="https://gitter.im/">Gitter</a> 官方文档。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Docs:https://gitter.im/?utm_source=left-menu-logo</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="attr">gitter:</span></span><br><span class="line">  <span class="attr">room:</span> <span class="string">your-community/your-room</span></span><br></pre></td></tr></table></figure><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>替换为你自己的仓库地址。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/&lt;yourAccount&gt;/&lt;repo&gt;</span> <span class="comment"># or https://gitee.com/&lt;yourAccount&gt;/&lt;repo&gt;</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">&lt;your-branch&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Hexo-常用命令"><a href="#Hexo-常用命令" class="headerlink" title="Hexo 常用命令"></a>Hexo 常用命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hexo new post <span class="string">&quot;&lt;post name&gt;&quot;</span>   <span class="comment"># you can change post to another layout if you want</span></span><br><span class="line">hexo clean &amp;&amp; hexo generate   <span class="comment"># generate the static file</span></span><br><span class="line">hexo server   <span class="comment"># run hexo in local environment</span></span><br><span class="line">hexo deploy   <span class="comment"># hexo will push the static files automatically into the specific branch(gh-pages) of your repo!</span></span><br></pre></td></tr></table></figure><h2 id="有一个好的体验"><a href="#有一个好的体验" class="headerlink" title="有一个好的体验 ^_^"></a>有一个好的体验 ^_^</h2><p>如果你喜欢该主题，请 <a href="https://github.com/V-Vincen/hexo-theme-livemylife">Star</a>！不胜感激你的 <a href="https://github.com/V-Vincen">Follow</a>！比心！</p>]]></content>
      
      
      <categories>
          
          <category> Hexo-Theme-LiveMyLife </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo-Theme-LiveMyLife </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
