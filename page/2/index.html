<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DreamTomb - 好想30岁退休</title><meta name="author" content="魏涛"><meta name="copyright" content="魏涛"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. 星河璀璨，我虽仰望，却也借这星光，低头沉默却坚定地走下去。 2. 一切焦虑都来源于想得太多而做的太少。">
<meta property="og:type" content="website">
<meta property="og:title" content="DreamTomb">
<meta property="og:url" content="https://dreamtomb.github.io/page/2/index.html">
<meta property="og:site_name" content="DreamTomb">
<meta property="og:description" content="1. 星河璀璨，我虽仰望，却也借这星光，低头沉默却坚定地走下去。 2. 一切焦虑都来源于想得太多而做的太少。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:author" content="魏涛">
<meta property="article:tag" content="dreamtomb">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://dreamtomb.github.io/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DreamTomb',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-03-01 17:52:25'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">98</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/index_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="DreamTomb"><span class="site-name">DreamTomb</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">DreamTomb</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/dreamtomb" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/10769.html" title="RetNet">RetNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-08-22T05:37:56.000Z" title="发表于 2023-08-22 13:37:56">2023-08-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">一
二
三
</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/15520.html" title="Chinese_LLaMA2">Chinese_LLaMA2</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-08-22T05:37:34.000Z" title="发表于 2023-08-22 13:37:34">2023-08-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">Chinese_LLaMA2目前有一种很多人认同的观点：预训练学知识，指令微调学格式，强化学习对齐人类偏好，LIMA等论文算是这一观点的证据。（LIMA: Less Is More for Alignment这篇文章是Meta的一篇工作，作者提出了一个假设，即”大模型绝大部分知识已经在预训练阶段学习到了，因此我们只需要很少一部分精选的instructions去tuning模型，就能使得模型产生高质量的内容“，如标题所说less is more。在实验部分，作者在LLaMA-65B模型上仅仅使用1000个精心挑选的Instructions进行tuning，甚至也不用进行强化学习RLHF训练，就能达到GPT-4的效果。但是这一切的前提是预训练的大模型的参数量要足够大，预训练的数据量要足够多，像The False Promise of Imitating Proprietary LLMs这篇工作中指出的，13B的llama+100k的instruction tuning是不够的。）
为了更好地学习大语言模型，本人参考chinese-llama-alpaca-2项目，基于llama-2-7B模 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/27704.html" title="LLaMa2">LLaMa2</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-08-11T13:06:55.000Z" title="发表于 2023-08-11 21:06:55">2023-08-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">LLAMA2：预训练+SFT+RLHF详解（官方）及对话指令SFT+LORA全流程记录（自己）
LLAMA2 训练流程：

先经过自监督学习训练，得到llama2基座模型
再经过SFT再有标签的数据上进行有监督学习训练
再进行RLHF，其中使用拒绝采样和PPO算法
在RLHF流程中，使用到由用户偏好数据训练得到的两个RM，对RLHF的模型评判，反馈训练

Pretraining预训练阶段需要大量的数据，数据的量级往往是nT级别，通过预训练可以让模型学习到大量的知识。
训练数据LLAMA2以LLAMA1中描述的预训练方法为基础，采用了optimized auto-regressive transformer。但是做了以下优化：1、进行了更鲁棒的数据清洗。2、更新了数据，使得总token数增加了40%（两万亿）。3、将上下文长度翻倍，并使用了grouped-query attention（GQA）来提高大模型推理的可扩展性。对比如下图所示：

关于GQA：在Transformer的decoder中每一个timestep都要将之前一个timestep的k,v保存到cache中，这就是KV C ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/40640.html" title="LLM_inference_optimze">LLM_inference_optimze</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-08-08T07:47:24.000Z" title="发表于 2023-08-08 15:47:24">2023-08-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">大模型推理优化方法整理


优化技术
优化原理



硬件升级
硬件的性能和特性对于模型推理速度和效率有着重要影响，通过硬件升级，大语言模型可以实现更高的推理速度。


子图融合技术
子图融合通过将计算图中的一系列操作合并为更大的操作，减少计算和内存开销，以提高推理性能。它通过优化计算流程来加速模型推理。


模型压缩技术
模型压缩技术包括稀疏化、参数剪枝、量化、知识蒸馏等方法，通过减小模型的尺寸和计算量，提高模型在推理阶段的速度和资源效率。


并行化技术
并行化技术包括数据并行化、模型并行化、管道并行等方法，利用多核 CPU、多个 GPU 或其他硬件资源，同时处理多个数据样本或模型部分，以提高推理效率。


Transformer 结构优化
Transformer 结构优化通过对 Transformer 模型的各个组件（如注意力机制、前馈网络等）进行优化，减少计算量、参数数量和内存开销，以加速推理。


动态批处理
动态批处理技术根据输入数据的长度和特性自适应地调整批处理大小，以提高计算资源的利用率，适应不同输入情况，从而提高推理性能。


硬件升级NVIDIA H100 PCIe ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/37017.html" title="MedicalGPT_Text_Matching">MedicalGPT_Text_Matching</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-08-01T07:22:40.000Z" title="发表于 2023-08-01 15:22:40">2023-08-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">医疗GPT中基于向量数据库的文本匹配任务现在在构建基于大语言模型的医疗GPT，为了一定程度上缓解幻觉问题，决定将大量医学指南存入向量数据库，然后对用户query进行embedding后送入数据库进行查询。因此这部分内容本质上来讲是一个文本匹配任务，于是本周对该任务进行了一点探索，总结成这篇博文。
文本匹配模型范式在文本匹配任务中，一般有两种范式：Representation-based和Interaction-based。Representation-based method也称双塔式模型或孪生网络，就是用一个编码器分别给两个文本编码出句向量，然后把两个向量融合送入一个浅层的分类器；Interaction-based method也就是交互式模型，就是把两个文本一起输入进编码器，在编码的过程中让它们相互交换信息，再得到最终结果。如下图：

两种方法各有优缺点：

双塔式：优点是速度会快很多，一般来说候选的句子都是已经计算好embedding的，然后直接用query的embedding跟候选embedding去计算相似度就好，计算相似度要比送入模型里面进行推理要快很多。Represent ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/51617.html" title="ErnieHealth_CBLUE">ErnieHealth_CBLUE</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-07-25T08:51:29.000Z" title="发表于 2023-07-25 16:51:29">2023-07-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">Building Chinese Biomedical Language Models via Multi-Level Text Discrimination模型相关模型采用了ELECTRA模型的生成器-判别器架构，其中生成器被用于构造预训练信号，判别器被用作最终的目标编码器，不同点在于ELECTRA仅采用token级别的二分类来训练判别器，而该模型使用(i)更具信息量的token级别判别和(ii)序列级别判别来进行训练。模型的整体架构如下所示：

生成器生成器是一个通过MLM方法（完形填空）训练的transformer编码器。首先对于某个输入序列，生成器会先随机的生成一组位置，并将这些位置上的字符替换掉（80%替换为[MASK]，10%替换成其他token，10%不变），然后被送入transformer编码器，生成上下文表示，接着使用softmax预测这些位置上原本的字符。生成器的loss是所有被替换位置的原始字符预测概率的负对数之和，因为生成器的目标是生成最能以假乱真的篡改文本。
判别器判别器也是一个transformer，它进行了两个级别的文本判别——token-level和se ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/50073.html" title="LangChain-ChatGLM">LangChain-ChatGLM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-07-18T09:18:27.000Z" title="发表于 2023-07-18 17:18:27">2023-07-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">LangChain-ChatGLM以 LLM 为基础的知识问答系统构建方法，其整体的流程如下图所示：

在整个流程中，核心在于：

将用户问题和本地知识进行 Embedding，通过向量相似度(Vector Similarity)实现召回；
通过 LLM 对用户问题进行意图识别；并对原始答案加工整合。

ChatGLM2-6BChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，ChatGLM2-6B 引入了如下新特性：

更强大的性能：基于 ChatGLM 初代模型的开发经验，开发人员全面升级了 ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数，经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同大小开源模型中具有较强的竞争力。
更长的上下文：基于 Flash ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/28126.html" title="Milvus_LangChain">Milvus_LangChain</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-07-11T00:09:37.000Z" title="发表于 2023-07-11 08:09:37">2023-07-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">MilvusMilvus 是一个用于向量（Vector）存储和检索的特殊数据库，由国内的创业公司 Zilliz 开发。
所谓向量，可以看作一个长度为 N 的元组。很多 AI&#x2F;ML 系统（例如推荐系统、图片相似度检测等）都有类似的需求：这些系统首先将海量数据集经过特征提取得到很多向量，使用时给定一个向量，从数据集向量中快速检索出和它最“相似”的 K 个向量。相似度的定义有多种，最常见的有余弦距离、欧几里得距离等。

为了做到这一点，最容易想到的方法就是让给定向量和所有数据库中的向量依次做比较，但显然这个做法太慢了。RDBMS 中有索引的概念，那我们能不能为向量的相似度也建立索引呢？当然是可以的！
这个问题称为向量相似度检索（vector similarity search），Facebook 开源的 Faiss 就是这样一个 C++ library，它内置了多种索引，例如 IVF_FLAT、IVF_FQ8、IVF_PQ 等（这些算法不是本文的重点）。Milvus 基于 Faiss 开发，Milvus 添加了存储组件，使之成为一个完整的数据库产品（而不仅是个 libaray），同 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/21662.html" title="SelfCheckGPT_Neural Path Hunter">SelfCheckGPT_Neural Path Hunter</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-07-04T06:29:36.000Z" title="发表于 2023-07-04 14:29:36">2023-07-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models大语言模型会产生幻觉并输出虚假的内容，这对于我们的医疗GPT是需要尽量杜绝的。现有的检查方法要么需要访问输出概率分布，要么需要通过单独的、复杂的接口访问外部数据库。因此在这项工作中，作者提出了一种简单的，基于采样的方法，可以以零资源的方式对黑盒模型进行事实性检查，而不需要外部数据库。其基本思想是：如果LLMs了解给定的概念，那么采样的响应应当是相似的，并且包含一致的事实信息。然而，对于幻觉的内容，随机抽样到的响应可能会彼此矛盾。
以往方法以往的工作中，大家主要从不确定性角度分析了幻觉现象产生的原因：在预训练和微调阶段，假如某个知识被多次提及，那么模型就可以记住这个知识，并在推理阶段输出具有极高可能性以及极小熵的token；相反的，如果某个知识未曾提及，那么模型就要从一个更加平坦的概率分布中采样出结果，这样的结果具有很高的不确定性，极有可能包含幻觉内容。基于这样的分析，就有了以往工作中常用的灰盒 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/39612.html" title="HaluEval A Large-Scale Hallucination Evaluation Benchmark for Large Language Model">HaluEval A Large-Scale Hallucination Evaluation Benchmark for Large Language Model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-06-25T23:59:18.000Z" title="发表于 2023-06-26 07:59:18">2023-06-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span></div><div class="content">HaluEval benchmark大型语言模型容易生成幻觉，即与源内容相冲突或无法通过事实知识进行验证的内容。为了了解LLM倾向于产生何种类型、何种程度的幻觉，作者构建了一个用于评估LLM在识别幻觉方面性能的大规模语言模型幻觉评估（HaluEval）benchmark，这是一个包含大量生成的、经人工注释的幻觉样本的集合。HaluEval包含35000个样本，其中一些是幻觉样本另一些是正常样本；此外，其中5000个是用户query和ChatGPT的问答对，另外30000个是任务特定的样本，包括QA、KGD以及summarization三种任务，每种任务各10000个样本。
数据集的构建有两种方式：自动生成和人类标注。两种方法的示意图如下图所示：

自动生成生成流程包含两步：多样性幻觉采样以及高质量幻觉过滤。
在多样性幻觉采样过程中，作者使用了两种方法来生成幻觉样本，第一种方法是直接输入one-pass指令（如下图）到ChatGPT中来生成幻觉回答。第二种方法是使用对话形式的指令（类似于ChatGPT的prompt creator用法），让ChatGPT逐步学习指令的某一部分，并确保其正 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/#content-inner">10</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">魏涛</div><div class="author-info__description">1. 星河璀璨，我虽仰望，却也借这星光，低头沉默却坚定地走下去。 2. 一切焦虑都来源于想得太多而做的太少。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">98</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/dreamtomb" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">公告栏信息</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/63715.html" title="2023-12-19论文笔记">2023-12-19论文笔记</a><time datetime="2023-12-19T09:24:57.000Z" title="发表于 2023-12-19 17:24:57">2023-12-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/62963.html" title="2023-12-05论文笔记">2023-12-05论文笔记</a><time datetime="2023-12-04T12:58:41.000Z" title="发表于 2023-12-04 20:58:41">2023-12-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/17086.html" title="2023-11-21论文笔记">2023-11-21论文笔记</a><time datetime="2023-11-21T10:33:12.000Z" title="发表于 2023-11-21 18:33:12">2023-11-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/35052.html" title="2023-11-7论文笔记">2023-11-7论文笔记</a><time datetime="2023-11-07T10:09:42.000Z" title="发表于 2023-11-07 18:09:42">2023-11-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/20606.html" title="2023-10-10论文笔记">2023-10-10论文笔记</a><time datetime="2023-09-26T08:31:45.000Z" title="发表于 2023-09-26 16:31:45">2023-09-26</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hexo-Theme-LiveMyLife/"><span class="card-category-list-name">Hexo-Theme-LiveMyLife</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LLM/"><span class="card-category-list-name">LLM</span><span class="card-category-list-count">29</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Multi-Task-Learning/"><span class="card-category-list-name">Multi-Task Learning</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Path-Signature/"><span class="card-category-list-name">Path Signature</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Pooling-Semantic-Segmentation/"><span class="card-category-list-name">Pooling, Semantic Segmentation</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/RL/"><span class="card-category-list-name">RL</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Saliency-Object-Detection/"><span class="card-category-list-name">Saliency Object Detection</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Salient-Object-Detection/"><span class="card-category-list-name">Salient Object Detection</span><span class="card-category-list-count">10</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/image-segmentation/" style="font-size: 1.27em; color: #99a0a9">image segmentation</a> <a href="/tags/clash/" style="font-size: 1.1em; color: #999">clash</a> <a href="/tags/%E4%B8%80%E8%AF%AD%E6%83%8A%E9%86%92%E6%A2%A6%E4%B8%AD%E4%BA%BA/" style="font-size: 1.1em; color: #999">一语惊醒梦中人</a> <a href="/tags/Salient-Object-Detection-Camouflaged-Object-Detection/" style="font-size: 1.1em; color: #999">Salient Object Detection, Camouflaged Object Detection</a> <a href="/tags/hexo/" style="font-size: 1.1em; color: #999">hexo</a> <a href="/tags/Path-Signature/" style="font-size: 1.21em; color: #999ea4">Path Signature</a> <a href="/tags/salient-object-detection/" style="font-size: 1.5em; color: #99a9bf">salient object detection</a> <a href="/tags/medical-image-segmentation/" style="font-size: 1.1em; color: #999">medical image segmentation</a> <a href="/tags/Multi-Task-Learning/" style="font-size: 1.1em; color: #999">Multi-Task Learning</a> <a href="/tags/camouflaged-object-detection/" style="font-size: 1.1em; color: #999">camouflaged object detection</a> <a href="/tags/Salient-Object-Detection/" style="font-size: 1.39em; color: #99a4b4">Salient Object Detection</a> <a href="/tags/Saliency-Object-Detection/" style="font-size: 1.1em; color: #999">Saliency Object Detection</a> <a href="/tags/Hexo-Theme-LiveMyLife/" style="font-size: 1.1em; color: #999">Hexo-Theme-LiveMyLife</a> <a href="/tags/Pooling-Semantic-Segmentation/" style="font-size: 1.1em; color: #999">Pooling, Semantic Segmentation</a> <a href="/tags/LLM/" style="font-size: 1.44em; color: #99a7ba">LLM</a> <a href="/tags/object-detection/" style="font-size: 1.16em; color: #999b9e">object detection</a> <a href="/tags/weekly-paper/" style="font-size: 1.33em; color: #99a2af">weekly_paper</a> <a href="/tags/RL/" style="font-size: 1.21em; color: #999ea4">RL</a> <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" style="font-size: 1.1em; color: #999">读书笔记</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">十二月 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">十一月 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">七月 2023</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">五月 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">四月 2023</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">98</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">162.8k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-03-01T09:52:25.190Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 魏涛</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["你在抱怨什么呢","为明天到来的事，说人生像是没有意义","没有选择会是唯一的路","这不是你自己的问题，人终归要好好去生活"])
  } else {
    document.getElementById("subtitle").textContent = "你在抱怨什么呢"
  }
}
typedJSFn.run(subtitleType)</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>